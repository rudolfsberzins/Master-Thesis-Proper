{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from parse_and_prepare import ProteinProteinInteractionClassifier as ppi\n",
    "import file_readers as fr\n",
    "import prediction as pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mult_open(direct, pattern):\n",
    "    pickle_list = []\n",
    "    file_list = []\n",
    "    for f in os.listdir(direct):\n",
    "        if re.search(pattern, f):\n",
    "            f = f.split('_')\n",
    "            f[-1] = f[-1][:-4]\n",
    "            file_list.append(f)\n",
    "    file_list.sort(key = lambda x: int(x[-1]))\n",
    "    for file in file_list:\n",
    "        file = '_'.join(file)\n",
    "        file = file + '.pkl'\n",
    "        pkl = pickle.load(open(os.path.join(direct, file), 'rb'))\n",
    "        pickle_list.append(pkl)\n",
    "    return pickle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/drosophila/Seeded/Results/'\n",
    "errors_dros = mult_open(drct, '_errors_')\n",
    "fpr_dros = mult_open(drct, '_fpr_')\n",
    "tpr_dros = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error drosophila auc=0.563 error=0.369\n",
      "Strict error drosophila auc=0.553 error=0.369\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.632 error=0.376\n",
      "Gen error drosophila auc=0.645 error=0.358\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.616 error=0.363\n",
      "BE error drosophila auc=0.621 error=0.371\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.502 error=0.403\n",
      "Strict error drosophila auc=0.488 error=0.399\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.573 error=0.394\n",
      "Gen error drosophila auc=0.578 error=0.394\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.635 error=0.351\n",
      "BE error drosophila auc=0.643 error=0.363\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.538 error=0.358\n",
      "Strict error drosophila auc=0.528 error=0.351\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.564 error=0.375\n",
      "Gen error drosophila auc=0.544 error=0.356\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.586 error=0.363\n",
      "BE error drosophila auc=0.569 error=0.377\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.539 error=0.341\n",
      "Strict error drosophila auc=0.550 error=0.327\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.557 error=0.351\n",
      "Gen error drosophila auc=0.560 error=0.349\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.594 error=0.359\n",
      "BE error drosophila auc=0.571 error=0.344\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.500 error=0.402\n",
      "Strict error drosophila auc=0.505 error=0.403\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.572 error=0.374\n",
      "Gen error drosophila auc=0.576 error=0.374\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.576 error=0.384\n",
      "BE error drosophila auc=0.571 error=0.381\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.550 error=0.371\n",
      "Strict error drosophila auc=0.541 error=0.366\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.576 error=0.359\n",
      "Gen error drosophila auc=0.554 error=0.380\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.611 error=0.357\n",
      "BE error drosophila auc=0.582 error=0.378\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.502 error=0.360\n",
      "Strict error drosophila auc=0.495 error=0.360\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.534 error=0.360\n",
      "Gen error drosophila auc=0.529 error=0.352\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.569 error=0.352\n",
      "BE error drosophila auc=0.565 error=0.356\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.575 error=0.290\n",
      "Strict error drosophila auc=0.593 error=0.286\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.628 error=0.277\n",
      "Gen error drosophila auc=0.630 error=0.273\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.659 error=0.280\n",
      "BE error drosophila auc=0.648 error=0.278\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.527 error=0.356\n",
      "Strict error drosophila auc=0.542 error=0.343\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.582 error=0.353\n",
      "Gen error drosophila auc=0.561 error=0.358\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.590 error=0.348\n",
      "BE error drosophila auc=0.584 error=0.347\n",
      "\n",
      "\n",
      "Strict error drosophila auc=0.475 error=0.454\n",
      "Strict error drosophila auc=0.468 error=0.453\n",
      "\n",
      "\n",
      "Gen error drosophila auc=0.475 error=0.435\n",
      "Gen error drosophila auc=0.487 error=0.437\n",
      "\n",
      "\n",
      "BE error drosophila auc=0.476 error=0.447\n",
      "BE error drosophila auc=0.476 error=0.443\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_strict = []\n",
    "mean_auc_dros_strict = []\n",
    "mean_err_dros_gen = []\n",
    "mean_auc_dros_gen = []\n",
    "mean_err_dros_be = []\n",
    "mean_auc_dros_be = []\n",
    "for e, f, t in zip(errors_dros, fpr_dros, tpr_dros):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['drosophila']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_strict.append(error_item)\n",
    "                    mean_auc_dros_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_gen.append(error_item)\n",
    "                    mean_auc_dros_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_be.append(error_item)\n",
    "                    mean_auc_dros_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_dros_org_strict = mean_err_dros_strict[0::2]\n",
    "mean_err_dros_fs_strict = mean_err_dros_strict[1::2]\n",
    "mean_auc_dros_org_strict = mean_auc_dros_strict[0::2]\n",
    "mean_auc_dros_fs_strict = mean_auc_dros_strict[1::2]\n",
    "\n",
    "mean_err_dros_org_gen = mean_err_dros_gen[0::2]\n",
    "mean_err_dros_fs_gen = mean_err_dros_gen[1::2]\n",
    "mean_auc_dros_org_gen = mean_auc_dros_gen[0::2]\n",
    "mean_auc_dros_fs_gen = mean_auc_dros_gen[1::2]\n",
    "\n",
    "mean_err_dros_org_be = mean_err_dros_be[0::2]\n",
    "mean_err_dros_fs_be = mean_err_dros_be[1::2]\n",
    "mean_auc_dros_org_be = mean_auc_dros_be[0::2]\n",
    "mean_auc_dros_fs_be = mean_auc_dros_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drosophila mean strict error original -  0.370312184201\n",
      "Drosophila mean strict error feature selection -  0.365770114498\n",
      "Drosophila mean strict AUC original -  0.527126412103\n",
      "Drosophila mean strict AUC feature selection -  0.526148828001\n",
      "\n",
      "\n",
      "Drosophila mean gen error original -  0.365274706555\n",
      "Drosophila mean gen error feature selection -  0.36317450566\n",
      "Drosophila mean gen AUC original -  0.569131983405\n",
      "Drosophila mean gen AUC feature selection -  0.566429727322\n",
      "\n",
      "\n",
      "Drosophila mean BE error original -  0.360347119537\n",
      "Drosophila mean BE error feature selection -  0.363789873276\n",
      "Drosophila mean BE AUC original -  0.591175566443\n",
      "Drosophila mean BE AUC feature selection -  0.582930743125\n"
     ]
    }
   ],
   "source": [
    "print('Drosophila mean strict error original - ', np.mean(mean_err_dros_org_strict))\n",
    "print('Drosophila mean strict error feature selection - ', np.mean(mean_err_dros_fs_strict))\n",
    "print('Drosophila mean strict AUC original - ', np.mean(mean_auc_dros_org_strict))\n",
    "print('Drosophila mean strict AUC feature selection - ', np.mean(mean_auc_dros_fs_strict))\n",
    "print('\\n')\n",
    "print('Drosophila mean gen error original - ', np.mean(mean_err_dros_org_gen))\n",
    "print('Drosophila mean gen error feature selection - ', np.mean(mean_err_dros_fs_gen))\n",
    "print('Drosophila mean gen AUC original - ', np.mean(mean_auc_dros_org_gen))\n",
    "print('Drosophila mean gen AUC feature selection - ', np.mean(mean_auc_dros_fs_gen))\n",
    "print('\\n')\n",
    "print('Drosophila mean BE error original - ', np.mean(mean_err_dros_org_be))\n",
    "print('Drosophila mean BE error feature selection - ', np.mean(mean_err_dros_fs_be))\n",
    "print('Drosophila mean BE AUC original - ', np.mean(mean_auc_dros_org_be))\n",
    "print('Drosophila mean BE AUC feature selection - ', np.mean(mean_auc_dros_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast/Seeded/Results/'\n",
    "errors_yeast = mult_open(drct, '_errors_')\n",
    "fpr_yeast = mult_open(drct, '_fpr_')\n",
    "tpr_yeast = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast auc=0.654 error=0.394\n",
      "Strict error yeast auc=0.648 error=0.399\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.700 error=0.357\n",
      "Gen error yeast auc=0.700 error=0.347\n",
      "\n",
      "\n",
      "BE error yeast auc=0.700 error=0.359\n",
      "BE error yeast auc=0.695 error=0.352\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.660 error=0.397\n",
      "Strict error yeast auc=0.667 error=0.383\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.721 error=0.350\n",
      "Gen error yeast auc=0.725 error=0.353\n",
      "\n",
      "\n",
      "BE error yeast auc=0.737 error=0.337\n",
      "BE error yeast auc=0.748 error=0.328\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.601 error=0.419\n",
      "Strict error yeast auc=0.601 error=0.430\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.663 error=0.392\n",
      "Gen error yeast auc=0.667 error=0.369\n",
      "\n",
      "\n",
      "BE error yeast auc=0.686 error=0.363\n",
      "BE error yeast auc=0.668 error=0.383\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.651 error=0.370\n",
      "Strict error yeast auc=0.652 error=0.380\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.693 error=0.331\n",
      "Gen error yeast auc=0.695 error=0.343\n",
      "\n",
      "\n",
      "BE error yeast auc=0.689 error=0.338\n",
      "BE error yeast auc=0.674 error=0.365\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.657 error=0.398\n",
      "Strict error yeast auc=0.659 error=0.393\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.679 error=0.377\n",
      "Gen error yeast auc=0.666 error=0.383\n",
      "\n",
      "\n",
      "BE error yeast auc=0.693 error=0.365\n",
      "BE error yeast auc=0.687 error=0.383\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.643 error=0.397\n",
      "Strict error yeast auc=0.632 error=0.414\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.711 error=0.346\n",
      "Gen error yeast auc=0.710 error=0.343\n",
      "\n",
      "\n",
      "BE error yeast auc=0.733 error=0.331\n",
      "BE error yeast auc=0.728 error=0.348\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.665 error=0.378\n",
      "Strict error yeast auc=0.670 error=0.365\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.716 error=0.345\n",
      "Gen error yeast auc=0.726 error=0.327\n",
      "\n",
      "\n",
      "BE error yeast auc=0.721 error=0.366\n",
      "BE error yeast auc=0.720 error=0.348\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.688 error=0.345\n",
      "Strict error yeast auc=0.685 error=0.345\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.759 error=0.295\n",
      "Gen error yeast auc=0.743 error=0.317\n",
      "\n",
      "\n",
      "BE error yeast auc=0.756 error=0.306\n",
      "BE error yeast auc=0.752 error=0.275\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.612 error=0.378\n",
      "Strict error yeast auc=0.609 error=0.369\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.678 error=0.327\n",
      "Gen error yeast auc=0.667 error=0.322\n",
      "\n",
      "\n",
      "BE error yeast auc=0.686 error=0.321\n",
      "BE error yeast auc=0.671 error=0.345\n",
      "\n",
      "\n",
      "Strict error yeast auc=0.616 error=0.445\n",
      "Strict error yeast auc=0.613 error=0.451\n",
      "\n",
      "\n",
      "Gen error yeast auc=0.682 error=0.400\n",
      "Gen error yeast auc=0.681 error=0.391\n",
      "\n",
      "\n",
      "BE error yeast auc=0.668 error=0.408\n",
      "BE error yeast auc=0.685 error=0.395\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_strict = []\n",
    "mean_auc_yeast_strict = []\n",
    "mean_err_yeast_gen = []\n",
    "mean_auc_yeast_gen = []\n",
    "mean_err_yeast_be = []\n",
    "mean_auc_yeast_be = []\n",
    "for e, f, t in zip(errors_yeast, fpr_yeast, tpr_yeast):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_strict.append(error_item)\n",
    "                    mean_auc_yeast_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_gen.append(error_item)\n",
    "                    mean_auc_yeast_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_be.append(error_item)\n",
    "                    mean_auc_yeast_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_org_strict = mean_err_yeast_strict[0::2]\n",
    "mean_err_yeast_fs_strict = mean_err_yeast_strict[1::2]\n",
    "mean_auc_yeast_org_strict = mean_auc_yeast_strict[0::2]\n",
    "mean_auc_yeast_fs_strict = mean_auc_yeast_strict[1::2]\n",
    "\n",
    "mean_err_yeast_org_gen = mean_err_yeast_gen[0::2]\n",
    "mean_err_yeast_fs_gen = mean_err_yeast_gen[1::2]\n",
    "mean_auc_yeast_org_gen = mean_auc_yeast_gen[0::2]\n",
    "mean_auc_yeast_fs_gen = mean_auc_yeast_gen[1::2]\n",
    "\n",
    "mean_err_yeast_org_be = mean_err_yeast_be[0::2]\n",
    "mean_err_yeast_fs_be = mean_err_yeast_be[1::2]\n",
    "mean_auc_yeast_org_be = mean_auc_yeast_be[0::2]\n",
    "mean_auc_yeast_fs_be = mean_auc_yeast_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast mean strict error original -  0.392066509516\n",
      "yeast mean strict error feature selection -  0.393011149895\n",
      "yeast mean strict AUC original -  0.644757978778\n",
      "yeast mean strict AUC feature selection -  0.643656458215\n",
      "\n",
      "\n",
      "yeast mean gen error original -  0.352019788833\n",
      "yeast mean gen error feature selection -  0.349580929792\n",
      "yeast mean gen AUC original -  0.700189618101\n",
      "yeast mean gen AUC feature selection -  0.697984714893\n",
      "\n",
      "\n",
      "yeast mean BE error original -  0.349518040456\n",
      "yeast mean BE error feature selection -  0.352376666304\n",
      "yeast mean BE AUC original -  0.706990179697\n",
      "yeast mean BE AUC feature selection -  0.702797658294\n"
     ]
    }
   ],
   "source": [
    "print('yeast mean strict error original - ', np.mean(mean_err_yeast_org_strict))\n",
    "print('yeast mean strict error feature selection - ', np.mean(mean_err_yeast_fs_strict))\n",
    "print('yeast mean strict AUC original - ', np.mean(mean_auc_yeast_org_strict))\n",
    "print('yeast mean strict AUC feature selection - ', np.mean(mean_auc_yeast_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast mean gen error original - ', np.mean(mean_err_yeast_org_gen))\n",
    "print('yeast mean gen error feature selection - ', np.mean(mean_err_yeast_fs_gen))\n",
    "print('yeast mean gen AUC original - ', np.mean(mean_auc_yeast_org_gen))\n",
    "print('yeast mean gen AUC feature selection - ', np.mean(mean_auc_yeast_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast mean BE error original - ', np.mean(mean_err_yeast_org_be))\n",
    "print('yeast mean BE error feature selection - ', np.mean(mean_err_yeast_fs_be))\n",
    "print('yeast mean BE AUC original - ', np.mean(mean_auc_yeast_org_be))\n",
    "print('yeast mean BE AUC feature selection - ', np.mean(mean_auc_yeast_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat/Seeded/Results/'\n",
    "errors_rat = mult_open(drct, '_errors_')\n",
    "fpr_rat = mult_open(drct, '_fpr_')\n",
    "tpr_rat = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat auc=0.626 error=0.229\n",
      "Strict error rat auc=0.622 error=0.230\n",
      "\n",
      "\n",
      "Gen error rat auc=0.628 error=0.234\n",
      "Gen error rat auc=0.634 error=0.229\n",
      "\n",
      "\n",
      "BE error rat auc=0.644 error=0.233\n",
      "BE error rat auc=0.632 error=0.233\n",
      "\n",
      "\n",
      "Strict error rat auc=0.649 error=0.214\n",
      "Strict error rat auc=0.644 error=0.214\n",
      "\n",
      "\n",
      "Gen error rat auc=0.650 error=0.211\n",
      "Gen error rat auc=0.655 error=0.211\n",
      "\n",
      "\n",
      "BE error rat auc=0.661 error=0.208\n",
      "BE error rat auc=0.653 error=0.210\n",
      "\n",
      "\n",
      "Strict error rat auc=0.662 error=0.254\n",
      "Strict error rat auc=0.654 error=0.256\n",
      "\n",
      "\n",
      "Gen error rat auc=0.657 error=0.250\n",
      "Gen error rat auc=0.652 error=0.254\n",
      "\n",
      "\n",
      "BE error rat auc=0.655 error=0.251\n",
      "BE error rat auc=0.655 error=0.253\n",
      "\n",
      "\n",
      "Strict error rat auc=0.630 error=0.312\n",
      "Strict error rat auc=0.626 error=0.315\n",
      "\n",
      "\n",
      "Gen error rat auc=0.663 error=0.310\n",
      "Gen error rat auc=0.662 error=0.307\n",
      "\n",
      "\n",
      "BE error rat auc=0.653 error=0.315\n",
      "BE error rat auc=0.646 error=0.316\n",
      "\n",
      "\n",
      "Strict error rat auc=0.626 error=0.256\n",
      "Strict error rat auc=0.618 error=0.261\n",
      "\n",
      "\n",
      "Gen error rat auc=0.644 error=0.251\n",
      "Gen error rat auc=0.639 error=0.254\n",
      "\n",
      "\n",
      "BE error rat auc=0.631 error=0.248\n",
      "BE error rat auc=0.626 error=0.250\n",
      "\n",
      "\n",
      "Strict error rat auc=0.611 error=0.419\n",
      "Strict error rat auc=0.606 error=0.419\n",
      "\n",
      "\n",
      "Gen error rat auc=0.628 error=0.415\n",
      "Gen error rat auc=0.629 error=0.414\n",
      "\n",
      "\n",
      "BE error rat auc=0.633 error=0.411\n",
      "BE error rat auc=0.632 error=0.411\n",
      "\n",
      "\n",
      "Strict error rat auc=0.562 error=0.286\n",
      "Strict error rat auc=0.568 error=0.287\n",
      "\n",
      "\n",
      "Gen error rat auc=0.589 error=0.287\n",
      "Gen error rat auc=0.586 error=0.287\n",
      "\n",
      "\n",
      "BE error rat auc=0.601 error=0.287\n",
      "BE error rat auc=0.607 error=0.286\n",
      "\n",
      "\n",
      "Strict error rat auc=0.672 error=0.327\n",
      "Strict error rat auc=0.665 error=0.329\n",
      "\n",
      "\n",
      "Gen error rat auc=0.666 error=0.328\n",
      "Gen error rat auc=0.666 error=0.327\n",
      "\n",
      "\n",
      "BE error rat auc=0.670 error=0.325\n",
      "BE error rat auc=0.674 error=0.326\n",
      "\n",
      "\n",
      "Strict error rat auc=0.607 error=0.197\n",
      "Strict error rat auc=0.604 error=0.200\n",
      "\n",
      "\n",
      "Gen error rat auc=0.618 error=0.200\n",
      "Gen error rat auc=0.612 error=0.201\n",
      "\n",
      "\n",
      "BE error rat auc=0.634 error=0.205\n",
      "BE error rat auc=0.634 error=0.206\n",
      "\n",
      "\n",
      "Strict error rat auc=0.627 error=0.319\n",
      "Strict error rat auc=0.615 error=0.322\n",
      "\n",
      "\n",
      "Gen error rat auc=0.631 error=0.320\n",
      "Gen error rat auc=0.628 error=0.322\n",
      "\n",
      "\n",
      "BE error rat auc=0.628 error=0.321\n",
      "BE error rat auc=0.633 error=0.320\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_strict = []\n",
    "mean_auc_rat_strict = []\n",
    "mean_err_rat_gen = []\n",
    "mean_auc_rat_gen = []\n",
    "mean_err_rat_be = []\n",
    "mean_auc_rat_be = []\n",
    "for e, f, t in zip(errors_rat, fpr_rat, tpr_rat):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_strict.append(error_item)\n",
    "                    mean_auc_rat_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_gen.append(error_item)\n",
    "                    mean_auc_rat_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_be.append(error_item)\n",
    "                    mean_auc_rat_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_org_strict = mean_err_rat_strict[0::2]\n",
    "mean_err_rat_fs_strict = mean_err_rat_strict[1::2]\n",
    "mean_auc_rat_org_strict = mean_auc_rat_strict[0::2]\n",
    "mean_auc_rat_fs_strict = mean_auc_rat_strict[1::2]\n",
    "\n",
    "mean_err_rat_org_gen = mean_err_rat_gen[0::2]\n",
    "mean_err_rat_fs_gen = mean_err_rat_gen[1::2]\n",
    "mean_auc_rat_org_gen = mean_auc_rat_gen[0::2]\n",
    "mean_auc_rat_fs_gen = mean_auc_rat_gen[1::2]\n",
    "\n",
    "mean_err_rat_org_be = mean_err_rat_be[0::2]\n",
    "mean_err_rat_fs_be = mean_err_rat_be[1::2]\n",
    "mean_auc_rat_org_be = mean_auc_rat_be[0::2]\n",
    "mean_auc_rat_fs_be = mean_auc_rat_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat mean strict error original -  0.281396023777\n",
      "rat mean strict error feature selection -  0.283327226976\n",
      "rat mean strict AUC original -  0.627213546082\n",
      "rat mean strict AUC feature selection -  0.622096028331\n",
      "\n",
      "\n",
      "rat mean gen error original -  0.280504614113\n",
      "rat mean gen error feature selection -  0.280697035217\n",
      "rat mean gen AUC original -  0.637569574811\n",
      "rat mean gen AUC feature selection -  0.636323270249\n",
      "\n",
      "\n",
      "rat mean BE error original -  0.280379330424\n",
      "rat mean BE error feature selection -  0.28099092911\n",
      "rat mean BE AUC original -  0.641082459269\n",
      "rat mean BE AUC feature selection -  0.639162680819\n"
     ]
    }
   ],
   "source": [
    "print('rat mean strict error original - ', np.mean(mean_err_rat_org_strict))\n",
    "print('rat mean strict error feature selection - ', np.mean(mean_err_rat_fs_strict))\n",
    "print('rat mean strict AUC original - ', np.mean(mean_auc_rat_org_strict))\n",
    "print('rat mean strict AUC feature selection - ', np.mean(mean_auc_rat_fs_strict))\n",
    "print('\\n')\n",
    "print('rat mean gen error original - ', np.mean(mean_err_rat_org_gen))\n",
    "print('rat mean gen error feature selection - ', np.mean(mean_err_rat_fs_gen))\n",
    "print('rat mean gen AUC original - ', np.mean(mean_auc_rat_org_gen))\n",
    "print('rat mean gen AUC feature selection - ', np.mean(mean_auc_rat_fs_gen))\n",
    "print('\\n')\n",
    "print('rat mean BE error original - ', np.mean(mean_err_rat_org_be))\n",
    "print('rat mean BE error feature selection - ', np.mean(mean_err_rat_fs_be))\n",
    "print('rat mean BE AUC original - ', np.mean(mean_auc_rat_org_be))\n",
    "print('rat mean BE AUC feature selection - ', np.mean(mean_auc_rat_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse/Seeded/Results/'\n",
    "errors_mouse = mult_open(drct, '_errors_')\n",
    "fpr_mouse = mult_open(drct, '_fpr_')\n",
    "tpr_mouse = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse auc=0.673 error=0.322\n",
      "Strict error mouse auc=0.671 error=0.325\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.682 error=0.322\n",
      "Gen error mouse auc=0.678 error=0.324\n",
      "\n",
      "\n",
      "BE error mouse auc=0.681 error=0.322\n",
      "BE error mouse auc=0.675 error=0.322\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.666 error=0.272\n",
      "Strict error mouse auc=0.665 error=0.272\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.691 error=0.266\n",
      "Gen error mouse auc=0.687 error=0.270\n",
      "\n",
      "\n",
      "BE error mouse auc=0.689 error=0.264\n",
      "BE error mouse auc=0.685 error=0.268\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.717 error=0.252\n",
      "Strict error mouse auc=0.715 error=0.250\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.736 error=0.246\n",
      "Gen error mouse auc=0.734 error=0.247\n",
      "\n",
      "\n",
      "BE error mouse auc=0.734 error=0.247\n",
      "BE error mouse auc=0.728 error=0.250\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.657 error=0.293\n",
      "Strict error mouse auc=0.657 error=0.291\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.668 error=0.289\n",
      "Gen error mouse auc=0.664 error=0.288\n",
      "\n",
      "\n",
      "BE error mouse auc=0.669 error=0.287\n",
      "BE error mouse auc=0.665 error=0.288\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.637 error=0.297\n",
      "Strict error mouse auc=0.640 error=0.296\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.641 error=0.299\n",
      "Gen error mouse auc=0.643 error=0.298\n",
      "\n",
      "\n",
      "BE error mouse auc=0.648 error=0.300\n",
      "BE error mouse auc=0.646 error=0.301\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.680 error=0.214\n",
      "Strict error mouse auc=0.682 error=0.216\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.684 error=0.217\n",
      "Gen error mouse auc=0.688 error=0.220\n",
      "\n",
      "\n",
      "BE error mouse auc=0.691 error=0.212\n",
      "BE error mouse auc=0.693 error=0.215\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.577 error=0.313\n",
      "Strict error mouse auc=0.576 error=0.310\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.594 error=0.307\n",
      "Gen error mouse auc=0.594 error=0.303\n",
      "\n",
      "\n",
      "BE error mouse auc=0.585 error=0.307\n",
      "BE error mouse auc=0.583 error=0.307\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.686 error=0.231\n",
      "Strict error mouse auc=0.678 error=0.232\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.699 error=0.232\n",
      "Gen error mouse auc=0.701 error=0.230\n",
      "\n",
      "\n",
      "BE error mouse auc=0.707 error=0.231\n",
      "BE error mouse auc=0.703 error=0.229\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.664 error=0.316\n",
      "Strict error mouse auc=0.658 error=0.315\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.669 error=0.312\n",
      "Gen error mouse auc=0.669 error=0.311\n",
      "\n",
      "\n",
      "BE error mouse auc=0.672 error=0.310\n",
      "BE error mouse auc=0.669 error=0.311\n",
      "\n",
      "\n",
      "Strict error mouse auc=0.675 error=0.291\n",
      "Strict error mouse auc=0.679 error=0.288\n",
      "\n",
      "\n",
      "Gen error mouse auc=0.682 error=0.289\n",
      "Gen error mouse auc=0.677 error=0.291\n",
      "\n",
      "\n",
      "BE error mouse auc=0.688 error=0.288\n",
      "BE error mouse auc=0.685 error=0.289\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_strict = []\n",
    "mean_auc_mouse_strict = []\n",
    "mean_err_mouse_gen = []\n",
    "mean_auc_mouse_gen = []\n",
    "mean_err_mouse_be = []\n",
    "mean_auc_mouse_be = []\n",
    "for e, f, t in zip(errors_mouse, fpr_mouse, tpr_mouse):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_strict.append(error_item)\n",
    "                    mean_auc_mouse_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_gen.append(error_item)\n",
    "                    mean_auc_mouse_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_be.append(error_item)\n",
    "                    mean_auc_mouse_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_org_strict = mean_err_mouse_strict[0::2]\n",
    "mean_err_mouse_fs_strict = mean_err_mouse_strict[1::2]\n",
    "mean_auc_mouse_org_strict = mean_auc_mouse_strict[0::2]\n",
    "mean_auc_mouse_fs_strict = mean_auc_mouse_strict[1::2]\n",
    "\n",
    "mean_err_mouse_org_gen = mean_err_mouse_gen[0::2]\n",
    "mean_err_mouse_fs_gen = mean_err_mouse_gen[1::2]\n",
    "mean_auc_mouse_org_gen = mean_auc_mouse_gen[0::2]\n",
    "mean_auc_mouse_fs_gen = mean_auc_mouse_gen[1::2]\n",
    "\n",
    "mean_err_mouse_org_be = mean_err_mouse_be[0::2]\n",
    "mean_err_mouse_fs_be = mean_err_mouse_be[1::2]\n",
    "mean_auc_mouse_org_be = mean_auc_mouse_be[0::2]\n",
    "mean_auc_mouse_fs_be = mean_auc_mouse_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse mean strict error original -  0.279964969909\n",
      "mouse mean strict error feature selection -  0.279666433007\n",
      "mouse mean strict AUC original -  0.663282761548\n",
      "mouse mean strict AUC feature selection -  0.662140839143\n",
      "\n",
      "\n",
      "mouse mean gen error original -  0.277718673191\n",
      "mouse mean gen error feature selection -  0.278172216059\n",
      "mouse mean gen AUC original -  0.674614353843\n",
      "mouse mean gen AUC feature selection -  0.673521365044\n",
      "\n",
      "\n",
      "mouse mean BE error original -  0.276619365602\n",
      "mouse mean BE error feature selection -  0.278104817342\n",
      "mouse mean BE AUC original -  0.676328030196\n",
      "mouse mean BE AUC feature selection -  0.673276958444\n"
     ]
    }
   ],
   "source": [
    "print('mouse mean strict error original - ', np.mean(mean_err_mouse_org_strict))\n",
    "print('mouse mean strict error feature selection - ', np.mean(mean_err_mouse_fs_strict))\n",
    "print('mouse mean strict AUC original - ', np.mean(mean_auc_mouse_org_strict))\n",
    "print('mouse mean strict AUC feature selection - ', np.mean(mean_auc_mouse_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse mean gen error original - ', np.mean(mean_err_mouse_org_gen))\n",
    "print('mouse mean gen error feature selection - ', np.mean(mean_err_mouse_fs_gen))\n",
    "print('mouse mean gen AUC original - ', np.mean(mean_auc_mouse_org_gen))\n",
    "print('mouse mean gen AUC feature selection - ', np.mean(mean_auc_mouse_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse mean BE error original - ', np.mean(mean_err_mouse_org_be))\n",
    "print('mouse mean BE error feature selection - ', np.mean(mean_err_mouse_fs_be))\n",
    "print('mouse mean BE AUC original - ', np.mean(mean_auc_mouse_org_be))\n",
    "print('mouse mean BE AUC feature selection - ', np.mean(mean_auc_mouse_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Merging Models\n",
    "\n",
    "def add_sentences_to_model(model_path, sen_pkl_path, model_name):\n",
    "    \n",
    "    #Prepare datasets\n",
    "    pickle_dataset = pickle.load(open(sen_pkl_path, 'rb'))\n",
    "    sentences = [fr.sentence_to_wordlist(sen) for sen in pickle_dataset]\n",
    "    \n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "    \n",
    "    #Load previous model\n",
    "    model = word2vec.Word2Vec.load(model_path)\n",
    "    \n",
    "    #Train model using new sentences\n",
    "    model.train(sentences)\n",
    "    \n",
    "    #'Kill' the model\n",
    "    model.init_sims(replace=True)\n",
    "    \n",
    "    model_name = 'Results/' + model_name\n",
    "    model.save(model_name)\n",
    "    w2v_model = model\n",
    "    \n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:24:28,926 : INFO : loading Word2Vec object from Results/drosophila/Seeded/Results/drosophila_strict_real_model\n",
      "2017-04-24 08:24:28,981 : INFO : loading wv recursively from Results/drosophila/Seeded/Results/drosophila_strict_real_model.wv.* with mmap=None\n",
      "2017-04-24 08:24:28,982 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 08:24:28,983 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 08:24:28,983 : INFO : loaded Results/drosophila/Seeded/Results/drosophila_strict_real_model\n",
      "2017-04-24 08:24:28,993 : INFO : training model with 4 workers on 3537 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:24:28,993 : INFO : expecting 7271 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:24:29,811 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:24:29,813 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:24:29,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:24:29,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:24:29,825 : INFO : training on 942490 raw words (594178 effective words) took 0.8s, 718516 effective words/s\n",
      "2017-04-24 08:24:29,825 : WARNING : supplied example count (35725) did not equal expected count (36355)\n",
      "2017-04-24 08:24:29,826 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 08:24:29,846 : INFO : saving Word2Vec object under Results/dros_yeast_SR_model, separately None\n",
      "2017-04-24 08:24:29,846 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:24:29,847 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:24:29,847 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:24:29,917 : INFO : saved Results/dros_yeast_SR_model\n",
      "2017-04-24 08:24:30,634 : INFO : loading Word2Vec object from Results/drosophila/Seeded/Results/drosophila_gen_real_model\n",
      "2017-04-24 08:24:31,204 : INFO : loading wv recursively from Results/drosophila/Seeded/Results/drosophila_gen_real_model.wv.* with mmap=None\n",
      "2017-04-24 08:24:31,204 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 08:24:31,205 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 08:24:31,205 : INFO : loaded Results/drosophila/Seeded/Results/drosophila_gen_real_model\n",
      "2017-04-24 08:24:31,223 : INFO : training model with 4 workers on 8246 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:24:31,224 : INFO : expecting 37017 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:24:32,250 : INFO : PROGRESS: at 18.92% examples, 581614 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 08:24:33,252 : INFO : PROGRESS: at 40.25% examples, 624419 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:34,253 : INFO : PROGRESS: at 61.99% examples, 644036 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:35,265 : INFO : PROGRESS: at 81.95% examples, 638235 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:24:36,269 : INFO : PROGRESS: at 102.32% examples, 638526 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:37,271 : INFO : PROGRESS: at 123.18% examples, 641108 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 08:24:37,488 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:24:37,502 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:24:37,506 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:24:37,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:24:37,510 : INFO : training on 5840885 raw words (4038540 effective words) took 6.3s, 642999 effective words/s\n",
      "2017-04-24 08:24:37,510 : WARNING : supplied example count (237680) did not equal expected count (185085)\n",
      "2017-04-24 08:24:37,511 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 08:24:37,557 : INFO : saving Word2Vec object under Results/dros_yeast_GEN_model, separately None\n",
      "2017-04-24 08:24:37,557 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:24:37,558 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:24:37,558 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:24:37,728 : INFO : saved Results/dros_yeast_GEN_model\n",
      "2017-04-24 08:24:40,494 : INFO : loading Word2Vec object from Results/drosophila/Seeded/Results/drosophila_both_ents_model\n",
      "2017-04-24 08:24:41,779 : INFO : loading wv recursively from Results/drosophila/Seeded/Results/drosophila_both_ents_model.wv.* with mmap=None\n",
      "2017-04-24 08:24:41,780 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 08:24:41,781 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 08:24:41,782 : INFO : loaded Results/drosophila/Seeded/Results/drosophila_both_ents_model\n",
      "2017-04-24 08:24:41,826 : INFO : training model with 4 workers on 18427 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:24:41,827 : INFO : expecting 179573 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:24:42,859 : INFO : PROGRESS: at 4.22% examples, 634530 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:43,867 : INFO : PROGRESS: at 8.67% examples, 657844 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:44,876 : INFO : PROGRESS: at 12.17% examples, 617584 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:45,885 : INFO : PROGRESS: at 15.97% examples, 608439 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:46,889 : INFO : PROGRESS: at 19.97% examples, 610642 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:47,903 : INFO : PROGRESS: at 23.95% examples, 609955 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:48,908 : INFO : PROGRESS: at 27.83% examples, 607994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:49,911 : INFO : PROGRESS: at 32.00% examples, 612178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:50,923 : INFO : PROGRESS: at 36.22% examples, 615660 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:51,931 : INFO : PROGRESS: at 39.86% examples, 610009 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:52,939 : INFO : PROGRESS: at 43.77% examples, 609232 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:53,949 : INFO : PROGRESS: at 47.42% examples, 604965 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:54,950 : INFO : PROGRESS: at 50.98% examples, 600606 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:55,960 : INFO : PROGRESS: at 54.05% examples, 591299 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:24:56,981 : INFO : PROGRESS: at 57.89% examples, 590589 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:24:57,992 : INFO : PROGRESS: at 62.14% examples, 594397 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:24:59,002 : INFO : PROGRESS: at 65.97% examples, 593947 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:00,005 : INFO : PROGRESS: at 70.14% examples, 596588 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:01,025 : INFO : PROGRESS: at 74.13% examples, 596885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:02,039 : INFO : PROGRESS: at 77.92% examples, 595893 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:03,043 : INFO : PROGRESS: at 81.27% examples, 592166 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:04,052 : INFO : PROGRESS: at 84.48% examples, 587658 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:25:05,077 : INFO : PROGRESS: at 88.11% examples, 585967 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:06,080 : INFO : PROGRESS: at 92.33% examples, 588542 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:07,097 : INFO : PROGRESS: at 97.08% examples, 593811 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:08,097 : INFO : PROGRESS: at 101.39% examples, 596536 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:25:09,108 : INFO : PROGRESS: at 105.50% examples, 597806 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:25:09,684 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:25:09,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:25:09,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:25:09,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:25:09,700 : INFO : training on 22856325 raw words (16741966 effective words) took 27.9s, 600768 effective words/s\n",
      "2017-04-24 08:25:09,700 : WARNING : supplied example count (972535) did not equal expected count (897865)\n",
      "2017-04-24 08:25:09,701 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 08:25:09,811 : INFO : saving Word2Vec object under Results/dros_yeast_BE_model, separately None\n",
      "2017-04-24 08:25:09,812 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:25:09,813 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:25:09,813 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:25:10,174 : INFO : saved Results/dros_yeast_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "dros_old_SR_model = 'Results/drosophila/Seeded/Results/drosophila_strict_real_model'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "dros_yeast_SR_model = add_sentences_to_model(dros_old_SR_model, yeast_SR_sentences_pkl, 'dros_yeast_SR_model')\n",
    "\n",
    "#Gen model\n",
    "dros_old_GEN_model = 'Results/drosophila/Seeded/Results/drosophila_gen_real_model'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "dros_yeast_GEN_model = add_sentences_to_model(dros_old_GEN_model, yeast_GEN_sentences_pkl, 'dros_yeast_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "dros_old_BE_model = 'Results/drosophila/Seeded/Results/drosophila_both_ents_model'\n",
    "yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "dros_yeast_BE_model = add_sentences_to_model(dros_old_BE_model, yeast_BE_sentences_pkl, 'dros_yeast_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "dros_strict_real = pickle.load(open('Results/drosophila/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_SR_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_GEN_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_BE_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/dros_yeast_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/dros_yeast_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/dros_yeast_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/dros_yeast/Seeded/Results/'\n",
    "errors_dros_yeast = mult_open(drct, '_errors_')\n",
    "fpr_dros_yeast = mult_open(drct, '_fpr_')\n",
    "tpr_dros_yeast = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error dros_yeast auc=0.564 error=0.386\n",
      "Strict error dros_yeast auc=0.547 error=0.383\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.577 error=0.345\n",
      "Gen error dros_yeast auc=0.567 error=0.373\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.568 error=0.364\n",
      "BE error dros_yeast auc=0.574 error=0.356\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.551 error=0.342\n",
      "Strict error dros_yeast auc=0.562 error=0.332\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.604 error=0.344\n",
      "Gen error dros_yeast auc=0.602 error=0.359\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.589 error=0.338\n",
      "BE error dros_yeast auc=0.619 error=0.330\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.575 error=0.380\n",
      "Strict error dros_yeast auc=0.594 error=0.384\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.595 error=0.373\n",
      "Gen error dros_yeast auc=0.594 error=0.394\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.566 error=0.396\n",
      "BE error dros_yeast auc=0.588 error=0.387\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.505 error=0.368\n",
      "Strict error dros_yeast auc=0.490 error=0.373\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.543 error=0.335\n",
      "Gen error dros_yeast auc=0.537 error=0.350\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.566 error=0.338\n",
      "BE error dros_yeast auc=0.554 error=0.349\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.542 error=0.336\n",
      "Strict error dros_yeast auc=0.533 error=0.333\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.612 error=0.324\n",
      "Gen error dros_yeast auc=0.566 error=0.342\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.581 error=0.301\n",
      "BE error dros_yeast auc=0.621 error=0.312\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.571 error=0.311\n",
      "Strict error dros_yeast auc=0.546 error=0.323\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.598 error=0.316\n",
      "Gen error dros_yeast auc=0.605 error=0.301\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.569 error=0.322\n",
      "BE error dros_yeast auc=0.576 error=0.292\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.597 error=0.354\n",
      "Strict error dros_yeast auc=0.613 error=0.343\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.648 error=0.343\n",
      "Gen error dros_yeast auc=0.648 error=0.336\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.657 error=0.349\n",
      "BE error dros_yeast auc=0.657 error=0.332\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.531 error=0.411\n",
      "Strict error dros_yeast auc=0.530 error=0.416\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.598 error=0.385\n",
      "Gen error dros_yeast auc=0.598 error=0.385\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.577 error=0.406\n",
      "BE error dros_yeast auc=0.585 error=0.414\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.559 error=0.367\n",
      "Strict error dros_yeast auc=0.540 error=0.376\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.593 error=0.362\n",
      "Gen error dros_yeast auc=0.614 error=0.357\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.613 error=0.357\n",
      "BE error dros_yeast auc=0.588 error=0.346\n",
      "\n",
      "\n",
      "Strict error dros_yeast auc=0.544 error=0.374\n",
      "Strict error dros_yeast auc=0.544 error=0.388\n",
      "\n",
      "\n",
      "Gen error dros_yeast auc=0.545 error=0.378\n",
      "Gen error dros_yeast auc=0.538 error=0.389\n",
      "\n",
      "\n",
      "BE error dros_yeast auc=0.553 error=0.371\n",
      "BE error dros_yeast auc=0.546 error=0.389\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_strict = []\n",
    "mean_auc_dros_yeast_strict = []\n",
    "mean_err_dros_yeast_gen = []\n",
    "mean_auc_dros_yeast_gen = []\n",
    "mean_err_dros_yeast_be = []\n",
    "mean_auc_dros_yeast_be = []\n",
    "for e, f, t in zip(errors_dros_yeast, fpr_dros_yeast, tpr_dros_yeast):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['dros_yeast']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_yeast_strict.append(error_item)\n",
    "                    mean_auc_dros_yeast_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_yeast_gen.append(error_item)\n",
    "                    mean_auc_dros_yeast_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_yeast_be.append(error_item)\n",
    "                    mean_auc_dros_yeast_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_dros_yeast_org_strict = mean_err_dros_yeast_strict[0::2]\n",
    "mean_err_dros_yeast_fs_strict = mean_err_dros_yeast_strict[1::2]\n",
    "mean_auc_dros_yeast_org_strict = mean_auc_dros_yeast_strict[0::2]\n",
    "mean_auc_dros_yeast_fs_strict = mean_auc_dros_yeast_strict[1::2]\n",
    "\n",
    "mean_err_dros_yeast_org_gen = mean_err_dros_yeast_gen[0::2]\n",
    "mean_err_dros_yeast_fs_gen = mean_err_dros_yeast_gen[1::2]\n",
    "mean_auc_dros_yeast_org_gen = mean_auc_dros_yeast_gen[0::2]\n",
    "mean_auc_dros_yeast_fs_gen = mean_auc_dros_yeast_gen[1::2]\n",
    "\n",
    "mean_err_dros_yeast_org_be = mean_err_dros_yeast_be[0::2]\n",
    "mean_err_dros_yeast_fs_be = mean_err_dros_yeast_be[1::2]\n",
    "mean_auc_dros_yeast_org_be = mean_auc_dros_yeast_be[0::2]\n",
    "mean_auc_dros_yeast_fs_be = mean_auc_dros_yeast_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dros_yeast mean strict error original -  0.363068641168\n",
      "dros_yeast mean strict error feature selection -  0.365119891676\n",
      "dros_yeast mean strict AUC original -  0.55386435763\n",
      "dros_yeast mean strict AUC feature selection -  0.549975768023\n",
      "\n",
      "\n",
      "dros_yeast mean gen error original -  0.350451786964\n",
      "dros_yeast mean gen error feature selection -  0.358714790507\n",
      "dros_yeast mean gen AUC original -  0.591306362703\n",
      "dros_yeast mean gen AUC feature selection -  0.586915047211\n",
      "\n",
      "\n",
      "dros_yeast mean BE error original -  0.354168318043\n",
      "dros_yeast mean BE error feature selection -  0.350882479496\n",
      "dros_yeast mean BE AUC original -  0.583894749386\n",
      "dros_yeast mean BE AUC feature selection -  0.590684775844\n"
     ]
    }
   ],
   "source": [
    "print('dros_yeast mean strict error original - ', np.mean(mean_err_dros_yeast_org_strict))\n",
    "print('dros_yeast mean strict error feature selection - ', np.mean(mean_err_dros_yeast_fs_strict))\n",
    "print('dros_yeast mean strict AUC original - ', np.mean(mean_auc_dros_yeast_org_strict))\n",
    "print('dros_yeast mean strict AUC feature selection - ', np.mean(mean_auc_dros_yeast_fs_strict))\n",
    "print('\\n')\n",
    "print('dros_yeast mean gen error original - ', np.mean(mean_err_dros_yeast_org_gen))\n",
    "print('dros_yeast mean gen error feature selection - ', np.mean(mean_err_dros_yeast_fs_gen))\n",
    "print('dros_yeast mean gen AUC original - ', np.mean(mean_auc_dros_yeast_org_gen))\n",
    "print('dros_yeast mean gen AUC feature selection - ', np.mean(mean_auc_dros_yeast_fs_gen))\n",
    "print('\\n')\n",
    "print('dros_yeast mean BE error original - ', np.mean(mean_err_dros_yeast_org_be))\n",
    "print('dros_yeast mean BE error feature selection - ', np.mean(mean_err_dros_yeast_fs_be))\n",
    "print('dros_yeast mean BE AUC original - ', np.mean(mean_auc_dros_yeast_org_be))\n",
    "print('dros_yeast mean BE AUC feature selection - ', np.mean(mean_auc_dros_yeast_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-23 21:29:52,155 : INFO : loading Word2Vec object from Results/dros_yeast/Seeded/Results/dros_yeast_SR_model\n",
      "2017-04-23 21:29:52,209 : INFO : loading wv recursively from Results/dros_yeast/Seeded/Results/dros_yeast_SR_model.wv.* with mmap=None\n",
      "2017-04-23 21:29:52,209 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-23 21:29:52,210 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-23 21:29:52,210 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-23 21:29:52,211 : INFO : loaded Results/dros_yeast/Seeded/Results/dros_yeast_SR_model\n",
      "2017-04-23 21:29:52,217 : INFO : training model with 4 workers on 3537 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-23 21:29:52,218 : INFO : expecting 7271 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-23 21:29:53,234 : INFO : PROGRESS: at 156.11% examples, 929288 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:29:54,240 : INFO : PROGRESS: at 326.05% examples, 973183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:29:55,243 : INFO : PROGRESS: at 449.86% examples, 897001 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:29:56,247 : INFO : PROGRESS: at 601.05% examples, 899551 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:29:56,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-23 21:29:56,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-23 21:29:56,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-23 21:29:56,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-23 21:29:56,370 : INFO : training on 6296340 raw words (3731013 effective words) took 4.1s, 899476 effective words/s\n",
      "2017-04-23 21:29:56,371 : WARNING : supplied example count (225220) did not equal expected count (36355)\n",
      "2017-04-23 21:29:56,371 : INFO : saving Word2Vec object under Results/dros_yeast_rat_SR_model, separately None\n",
      "2017-04-23 21:29:56,372 : INFO : not storing attribute syn0norm\n",
      "2017-04-23 21:29:56,373 : INFO : not storing attribute syn0norm\n",
      "2017-04-23 21:29:56,374 : INFO : not storing attribute cum_table\n",
      "2017-04-23 21:29:56,438 : INFO : saved Results/dros_yeast_rat_SR_model\n",
      "2017-04-23 21:29:59,778 : INFO : loading Word2Vec object from Results/dros_yeast/Seeded/Results/dros_yeast_GEN_model\n",
      "2017-04-23 21:29:59,900 : INFO : loading wv recursively from Results/dros_yeast/Seeded/Results/dros_yeast_GEN_model.wv.* with mmap=None\n",
      "2017-04-23 21:29:59,901 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-23 21:29:59,902 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-23 21:29:59,902 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-23 21:29:59,903 : INFO : loaded Results/dros_yeast/Seeded/Results/dros_yeast_GEN_model\n",
      "2017-04-23 21:29:59,917 : INFO : training model with 4 workers on 8246 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-23 21:29:59,918 : INFO : expecting 37017 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-23 21:30:00,927 : INFO : PROGRESS: at 21.61% examples, 720275 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:01,928 : INFO : PROGRESS: at 45.57% examples, 760969 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:30:02,929 : INFO : PROGRESS: at 66.98% examples, 746122 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:03,940 : INFO : PROGRESS: at 93.71% examples, 781427 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:04,951 : INFO : PROGRESS: at 122.54% examples, 816031 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:30:05,963 : INFO : PROGRESS: at 149.08% examples, 826747 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:06,966 : INFO : PROGRESS: at 177.21% examples, 843105 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:30:07,975 : INFO : PROGRESS: at 207.24% examples, 862117 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-23 21:30:08,984 : INFO : PROGRESS: at 231.39% examples, 855536 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:09,985 : INFO : PROGRESS: at 256.78% examples, 854915 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-23 21:30:10,987 : INFO : PROGRESS: at 277.13% examples, 839217 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:11,990 : INFO : PROGRESS: at 304.36% examples, 844896 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:12,991 : INFO : PROGRESS: at 324.73% examples, 832475 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-23 21:30:13,994 : INFO : PROGRESS: at 349.90% examples, 833085 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:14,998 : INFO : PROGRESS: at 372.25% examples, 827277 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:16,017 : INFO : PROGRESS: at 393.44% examples, 818964 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:17,027 : INFO : PROGRESS: at 419.05% examples, 820730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:18,028 : INFO : PROGRESS: at 437.40% examples, 809367 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:30:19,032 : INFO : PROGRESS: at 460.38% examples, 807131 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:19,944 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-23 21:30:19,954 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-23 21:30:19,966 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-23 21:30:19,967 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-23 21:30:19,968 : INFO : training on 24192400 raw words (16220719 effective words) took 20.0s, 809209 effective words/s\n",
      "2017-04-23 21:30:19,968 : WARNING : supplied example count (896095) did not equal expected count (185085)\n",
      "2017-04-23 21:30:19,969 : INFO : saving Word2Vec object under Results/dros_yeast_rat_GEN_model, separately None\n",
      "2017-04-23 21:30:19,969 : INFO : not storing attribute syn0norm\n",
      "2017-04-23 21:30:19,970 : INFO : not storing attribute syn0norm\n",
      "2017-04-23 21:30:19,970 : INFO : not storing attribute cum_table\n",
      "2017-04-23 21:30:20,152 : INFO : saved Results/dros_yeast_rat_GEN_model\n",
      "2017-04-23 21:30:41,295 : INFO : loading Word2Vec object from Results/dros_yeast/Seeded/Results/dros_yeast_BE_model\n",
      "2017-04-23 21:30:41,557 : INFO : loading wv recursively from Results/dros_yeast/Seeded/Results/dros_yeast_BE_model.wv.* with mmap=None\n",
      "2017-04-23 21:30:41,558 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-23 21:30:41,559 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-23 21:30:41,560 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-23 21:30:41,561 : INFO : loaded Results/dros_yeast/Seeded/Results/dros_yeast_BE_model\n",
      "2017-04-23 21:30:41,609 : INFO : training model with 4 workers on 18427 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-23 21:30:41,610 : INFO : expecting 179573 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-23 21:30:42,620 : INFO : PROGRESS: at 4.95% examples, 794543 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:43,623 : INFO : PROGRESS: at 9.80% examples, 787615 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:30:44,630 : INFO : PROGRESS: at 14.60% examples, 781929 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:45,640 : INFO : PROGRESS: at 19.75% examples, 791011 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:30:46,654 : INFO : PROGRESS: at 24.64% examples, 788776 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:30:47,656 : INFO : PROGRESS: at 29.61% examples, 791172 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:30:48,664 : INFO : PROGRESS: at 34.85% examples, 797241 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:49,667 : INFO : PROGRESS: at 40.15% examples, 803951 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:50,671 : INFO : PROGRESS: at 45.51% examples, 810097 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:30:51,677 : INFO : PROGRESS: at 50.41% examples, 807691 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:52,696 : INFO : PROGRESS: at 54.87% examples, 798065 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:53,703 : INFO : PROGRESS: at 59.87% examples, 798183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:54,724 : INFO : PROGRESS: at 64.59% examples, 794097 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:30:55,728 : INFO : PROGRESS: at 69.85% examples, 797684 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:30:56,736 : INFO : PROGRESS: at 75.02% examples, 799642 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:30:57,737 : INFO : PROGRESS: at 80.18% examples, 801745 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:30:58,757 : INFO : PROGRESS: at 85.36% examples, 802667 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:30:59,772 : INFO : PROGRESS: at 90.26% examples, 801306 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:31:00,781 : INFO : PROGRESS: at 95.60% examples, 804115 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:31:01,787 : INFO : PROGRESS: at 100.00% examples, 799265 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:31:02,793 : INFO : PROGRESS: at 105.11% examples, 800023 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:03,793 : INFO : PROGRESS: at 109.84% examples, 798246 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:04,805 : INFO : PROGRESS: at 114.87% examples, 798392 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:05,810 : INFO : PROGRESS: at 119.73% examples, 797562 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:06,811 : INFO : PROGRESS: at 124.47% examples, 796369 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:07,818 : INFO : PROGRESS: at 128.59% examples, 791195 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:08,819 : INFO : PROGRESS: at 133.30% examples, 790052 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:09,822 : INFO : PROGRESS: at 138.18% examples, 789953 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:10,831 : INFO : PROGRESS: at 143.40% examples, 791462 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:11,837 : INFO : PROGRESS: at 148.12% examples, 790280 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-23 21:31:12,845 : INFO : PROGRESS: at 153.00% examples, 790063 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:13,848 : INFO : PROGRESS: at 157.57% examples, 788219 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:31:14,855 : INFO : PROGRESS: at 162.28% examples, 787278 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-23 21:31:15,860 : INFO : PROGRESS: at 167.17% examples, 787226 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:16,862 : INFO : PROGRESS: at 172.35% examples, 788477 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:17,872 : INFO : PROGRESS: at 177.97% examples, 791476 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:18,880 : INFO : PROGRESS: at 183.47% examples, 793806 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:31:19,886 : INFO : PROGRESS: at 188.67% examples, 794930 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:20,896 : INFO : PROGRESS: at 194.17% examples, 796973 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:21,908 : INFO : PROGRESS: at 199.04% examples, 796406 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:22,921 : INFO : PROGRESS: at 204.03% examples, 796381 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:23,929 : INFO : PROGRESS: at 209.11% examples, 796761 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:24,939 : INFO : PROGRESS: at 213.88% examples, 795915 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:25,953 : INFO : PROGRESS: at 218.00% examples, 792775 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:26,960 : INFO : PROGRESS: at 222.51% examples, 791157 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:27,963 : INFO : PROGRESS: at 227.32% examples, 790759 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:28,967 : INFO : PROGRESS: at 232.26% examples, 790820 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:29,969 : INFO : PROGRESS: at 237.41% examples, 791668 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:30,971 : INFO : PROGRESS: at 243.01% examples, 793827 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:31,979 : INFO : PROGRESS: at 248.07% examples, 794056 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:31:32,990 : INFO : PROGRESS: at 252.74% examples, 793088 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:31:33,997 : INFO : PROGRESS: at 257.51% examples, 792510 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:31:35,006 : INFO : PROGRESS: at 262.39% examples, 792324 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:36,027 : INFO : PROGRESS: at 267.00% examples, 791159 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:37,028 : INFO : PROGRESS: at 271.61% examples, 790355 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:38,035 : INFO : PROGRESS: at 276.46% examples, 790112 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:31:39,037 : INFO : PROGRESS: at 281.23% examples, 789703 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:40,044 : INFO : PROGRESS: at 285.99% examples, 789236 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:41,047 : INFO : PROGRESS: at 291.00% examples, 789571 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:31:42,058 : INFO : PROGRESS: at 296.33% examples, 790533 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:31:43,059 : INFO : PROGRESS: at 300.97% examples, 789810 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:44,065 : INFO : PROGRESS: at 305.27% examples, 788235 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:45,067 : INFO : PROGRESS: at 310.53% examples, 789147 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:31:46,072 : INFO : PROGRESS: at 315.84% examples, 790112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:47,074 : INFO : PROGRESS: at 320.93% examples, 790531 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:48,084 : INFO : PROGRESS: at 325.69% examples, 790078 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:49,095 : INFO : PROGRESS: at 330.68% examples, 790171 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:50,112 : INFO : PROGRESS: at 335.33% examples, 789325 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:51,117 : INFO : PROGRESS: at 340.28% examples, 789375 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:52,118 : INFO : PROGRESS: at 345.23% examples, 789482 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:53,120 : INFO : PROGRESS: at 349.99% examples, 789164 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:54,129 : INFO : PROGRESS: at 354.71% examples, 788687 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:55,133 : INFO : PROGRESS: at 359.92% examples, 789349 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:56,135 : INFO : PROGRESS: at 364.33% examples, 788278 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:31:57,145 : INFO : PROGRESS: at 369.10% examples, 787901 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:58,148 : INFO : PROGRESS: at 373.90% examples, 787698 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:31:59,156 : INFO : PROGRESS: at 378.35% examples, 786709 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:00,159 : INFO : PROGRESS: at 383.04% examples, 786272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:01,167 : INFO : PROGRESS: at 387.82% examples, 785966 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:02,177 : INFO : PROGRESS: at 392.41% examples, 785289 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:03,177 : INFO : PROGRESS: at 396.90% examples, 784541 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:04,177 : INFO : PROGRESS: at 402.19% examples, 785401 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:05,182 : INFO : PROGRESS: at 408.18% examples, 787583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:06,187 : INFO : PROGRESS: at 414.42% examples, 790131 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:07,190 : INFO : PROGRESS: at 419.99% examples, 791371 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:08,195 : INFO : PROGRESS: at 425.20% examples, 791889 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:09,201 : INFO : PROGRESS: at 430.04% examples, 791727 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:10,204 : INFO : PROGRESS: at 434.79% examples, 791361 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:11,218 : INFO : PROGRESS: at 439.64% examples, 791144 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:12,227 : INFO : PROGRESS: at 444.53% examples, 791069 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:13,232 : INFO : PROGRESS: at 448.57% examples, 789505 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:14,247 : INFO : PROGRESS: at 453.60% examples, 789610 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:15,261 : INFO : PROGRESS: at 458.34% examples, 789189 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:16,267 : INFO : PROGRESS: at 462.39% examples, 787688 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:17,275 : INFO : PROGRESS: at 466.65% examples, 786586 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:18,286 : INFO : PROGRESS: at 470.48% examples, 784725 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:19,287 : INFO : PROGRESS: at 475.40% examples, 784773 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:20,301 : INFO : PROGRESS: at 480.26% examples, 784639 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:21,314 : INFO : PROGRESS: at 485.20% examples, 784667 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:22,323 : INFO : PROGRESS: at 490.69% examples, 785596 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:32:23,337 : INFO : PROGRESS: at 495.85% examples, 785963 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:24,340 : INFO : PROGRESS: at 501.20% examples, 786691 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:25,344 : INFO : PROGRESS: at 506.51% examples, 787317 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:26,365 : INFO : PROGRESS: at 511.99% examples, 788088 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:27,383 : INFO : PROGRESS: at 516.34% examples, 787148 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:28,389 : INFO : PROGRESS: at 520.49% examples, 785986 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:29,404 : INFO : PROGRESS: at 524.70% examples, 784839 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:30,416 : INFO : PROGRESS: at 528.65% examples, 783399 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:31,421 : INFO : PROGRESS: at 534.14% examples, 784273 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:32,425 : INFO : PROGRESS: at 539.56% examples, 785081 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:33,433 : INFO : PROGRESS: at 544.76% examples, 785516 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:34,443 : INFO : PROGRESS: at 549.99% examples, 786005 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:35,446 : INFO : PROGRESS: at 554.88% examples, 786013 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:36,448 : INFO : PROGRESS: at 559.83% examples, 786108 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:37,449 : INFO : PROGRESS: at 564.50% examples, 785821 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:38,453 : INFO : PROGRESS: at 569.34% examples, 785764 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:32:39,458 : INFO : PROGRESS: at 574.53% examples, 786137 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:40,459 : INFO : PROGRESS: at 579.39% examples, 786115 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:41,463 : INFO : PROGRESS: at 584.59% examples, 786544 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-23 21:32:42,463 : INFO : PROGRESS: at 589.90% examples, 787112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:43,472 : INFO : PROGRESS: at 594.84% examples, 787132 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:44,480 : INFO : PROGRESS: at 599.94% examples, 787337 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:32:45,483 : INFO : PROGRESS: at 605.19% examples, 787812 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:46,490 : INFO : PROGRESS: at 609.92% examples, 787549 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:47,501 : INFO : PROGRESS: at 615.33% examples, 788137 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:48,517 : INFO : PROGRESS: at 620.73% examples, 788685 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-23 21:32:49,518 : INFO : PROGRESS: at 625.77% examples, 788858 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:50,530 : INFO : PROGRESS: at 631.07% examples, 789304 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:51,532 : INFO : PROGRESS: at 635.87% examples, 789194 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:52,535 : INFO : PROGRESS: at 639.88% examples, 788079 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:53,561 : INFO : PROGRESS: at 644.01% examples, 787007 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:54,561 : INFO : PROGRESS: at 647.80% examples, 785659 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:55,577 : INFO : PROGRESS: at 653.09% examples, 786084 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:56,585 : INFO : PROGRESS: at 658.45% examples, 786602 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:32:57,595 : INFO : PROGRESS: at 663.41% examples, 786628 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:32:58,602 : INFO : PROGRESS: at 668.22% examples, 786503 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-23 21:32:59,603 : INFO : PROGRESS: at 672.04% examples, 785260 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:33:00,640 : INFO : PROGRESS: at 675.91% examples, 783887 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:33:01,641 : INFO : PROGRESS: at 679.45% examples, 782372 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:33:02,647 : INFO : PROGRESS: at 683.70% examples, 781671 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:33:03,653 : INFO : PROGRESS: at 687.01% examples, 779910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:33:04,653 : INFO : PROGRESS: at 690.64% examples, 778559 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-23 21:33:05,670 : INFO : PROGRESS: at 694.37% examples, 777239 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-23 21:33:06,090 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-23 21:33:06,092 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-23 21:33:06,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-23 21:33:06,105 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-23 21:33:06,106 : INFO : training on 154634470 raw words (112244086 effective words) took 144.5s, 776832 effective words/s\n",
      "2017-04-23 21:33:06,106 : WARNING : supplied example count (6250045) did not equal expected count (897865)\n",
      "2017-04-23 21:33:06,107 : INFO : saving Word2Vec object under Results/dros_yeast_rat_BE_model, separately None\n",
      "2017-04-23 21:33:06,108 : INFO : not storing attribute syn0norm\n",
      "2017-04-23 21:33:06,108 : INFO : not storing attribute syn0norm\n",
      "2017-04-23 21:33:06,109 : INFO : not storing attribute cum_table\n",
      "2017-04-23 21:33:06,501 : INFO : saved Results/dros_yeast_rat_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "dros_yeast_old_SR_model = 'Results/dros_yeast/Seeded/Results/dros_yeast_SR_model'\n",
    "rat_SR_sentences_pkl = 'Results/rat/strict_real.pkl'\n",
    "dros_yeast_rat_SR_model = add_sentences_to_model(dros_yeast_old_SR_model, rat_SR_sentences_pkl, 'dros_yeast_rat_SR_model')\n",
    "\n",
    "#Gen model\n",
    "dros_yeast_old_GEN_model = 'Results/dros_yeast/Seeded/Results/dros_yeast_GEN_model'\n",
    "rat_GEN_sentences_pkl = 'Results/rat/gen_real.pkl'\n",
    "dros_yeast_rat_GEN_model = add_sentences_to_model(dros_yeast_old_GEN_model, rat_GEN_sentences_pkl, 'dros_yeast_rat_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "dros_yeast_old_BE_model = 'Results/dros_yeast/Seeded/Results/dros_yeast_BE_model'\n",
    "rat_BE_sentences_pkl = 'Results/rat/be_real.pkl'\n",
    "dros_yeast_rat_BE_model = add_sentences_to_model(dros_yeast_old_BE_model, rat_BE_sentences_pkl, 'dros_yeast_rat_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "dros_strict_real = pickle.load(open('Results/drosophila/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_SR_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_GEN_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_BE_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/dros_yeast_rat_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/dros_yeast_rat_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/dros_yeast_rat_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/dros_yeast_rat/Seeded/Results/'\n",
    "errors_dros_yeast_rat = mult_open(drct, '_errors_')\n",
    "fpr_dros_yeast_rat = mult_open(drct, '_fpr_')\n",
    "tpr_dros_yeast_rat = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error dros_yeast_rat auc=0.607 error=0.364\n",
      "Strict error dros_yeast_rat auc=0.560 error=0.371\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.594 error=0.360\n",
      "Gen error dros_yeast_rat auc=0.597 error=0.353\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.579 error=0.375\n",
      "BE error dros_yeast_rat auc=0.574 error=0.385\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.560 error=0.336\n",
      "Strict error dros_yeast_rat auc=0.557 error=0.338\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.612 error=0.336\n",
      "Gen error dros_yeast_rat auc=0.620 error=0.336\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.626 error=0.311\n",
      "BE error dros_yeast_rat auc=0.610 error=0.314\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.547 error=0.382\n",
      "Strict error dros_yeast_rat auc=0.565 error=0.382\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.596 error=0.368\n",
      "Gen error dros_yeast_rat auc=0.599 error=0.387\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.596 error=0.377\n",
      "BE error dros_yeast_rat auc=0.607 error=0.371\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.539 error=0.364\n",
      "Strict error dros_yeast_rat auc=0.540 error=0.350\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.527 error=0.370\n",
      "Gen error dros_yeast_rat auc=0.512 error=0.370\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.560 error=0.359\n",
      "BE error dros_yeast_rat auc=0.564 error=0.338\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.545 error=0.320\n",
      "Strict error dros_yeast_rat auc=0.556 error=0.312\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.581 error=0.325\n",
      "Gen error dros_yeast_rat auc=0.578 error=0.314\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.612 error=0.325\n",
      "BE error dros_yeast_rat auc=0.600 error=0.320\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.532 error=0.328\n",
      "Strict error dros_yeast_rat auc=0.519 error=0.333\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.559 error=0.320\n",
      "Gen error dros_yeast_rat auc=0.579 error=0.327\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.590 error=0.305\n",
      "BE error dros_yeast_rat auc=0.587 error=0.319\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.600 error=0.366\n",
      "Strict error dros_yeast_rat auc=0.589 error=0.360\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.617 error=0.354\n",
      "Gen error dros_yeast_rat auc=0.627 error=0.341\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.642 error=0.336\n",
      "BE error dros_yeast_rat auc=0.662 error=0.332\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.524 error=0.411\n",
      "Strict error dros_yeast_rat auc=0.514 error=0.406\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.559 error=0.388\n",
      "Gen error dros_yeast_rat auc=0.585 error=0.395\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.571 error=0.400\n",
      "BE error dros_yeast_rat auc=0.595 error=0.402\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.537 error=0.371\n",
      "Strict error dros_yeast_rat auc=0.511 error=0.369\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.556 error=0.362\n",
      "Gen error dros_yeast_rat auc=0.565 error=0.360\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.565 error=0.373\n",
      "BE error dros_yeast_rat auc=0.547 error=0.376\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat auc=0.522 error=0.372\n",
      "Strict error dros_yeast_rat auc=0.532 error=0.384\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat auc=0.539 error=0.378\n",
      "Gen error dros_yeast_rat auc=0.548 error=0.372\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat auc=0.540 error=0.367\n",
      "BE error dros_yeast_rat auc=0.556 error=0.360\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_rat_strict = []\n",
    "mean_auc_dros_yeast_rat_strict = []\n",
    "mean_err_dros_yeast_rat_gen = []\n",
    "mean_auc_dros_yeast_rat_gen = []\n",
    "mean_err_dros_yeast_rat_be = []\n",
    "mean_auc_dros_yeast_rat_be = []\n",
    "for e, f, t in zip(errors_dros_yeast_rat, fpr_dros_yeast_rat, tpr_dros_yeast_rat):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['dros_yeast_rat']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_yeast_rat_strict.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_yeast_rat_gen.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_yeast_rat_be.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_err_dros_yeast_rat_strict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2628c487170f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_err_dros_yeast_rat_org_strict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_err_dros_yeast_rat_strict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmean_err_dros_yeast_rat_fs_strict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_err_dros_yeast_rat_strict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmean_auc_dros_yeast_rat_org_strict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_auc_dros_yeast_rat_strict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean_auc_dros_yeast_rat_fs_strict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_auc_dros_yeast_rat_strict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_err_dros_yeast_rat_strict' is not defined"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_rat_org_strict = mean_err_dros_yeast_rat_strict[0::2]\n",
    "mean_err_dros_yeast_rat_fs_strict = mean_err_dros_yeast_rat_strict[1::2]\n",
    "mean_auc_dros_yeast_rat_org_strict = mean_auc_dros_yeast_rat_strict[0::2]\n",
    "mean_auc_dros_yeast_rat_fs_strict = mean_auc_dros_yeast_rat_strict[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_org_gen = mean_err_dros_yeast_rat_gen[0::2]\n",
    "mean_err_dros_yeast_rat_fs_gen = mean_err_dros_yeast_rat_gen[1::2]\n",
    "mean_auc_dros_yeast_rat_org_gen = mean_auc_dros_yeast_rat_gen[0::2]\n",
    "mean_auc_dros_yeast_rat_fs_gen = mean_auc_dros_yeast_rat_gen[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_org_be = mean_err_dros_yeast_rat_be[0::2]\n",
    "mean_err_dros_yeast_rat_fs_be = mean_err_dros_yeast_rat_be[1::2]\n",
    "mean_auc_dros_yeast_rat_org_be = mean_auc_dros_yeast_rat_be[0::2]\n",
    "mean_auc_dros_yeast_rat_fs_be = mean_auc_dros_yeast_rat_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dros_yeast_rat mean strict error original -  0.361365440077\n",
      "dros_yeast_rat mean strict error feature selection -  0.360558462959\n",
      "dros_yeast_rat mean strict AUC original -  0.551317252522\n",
      "dros_yeast_rat mean strict AUC feature selection -  0.544290881524\n",
      "\n",
      "\n",
      "dros_yeast_rat mean gen error original -  0.356225787131\n",
      "dros_yeast_rat mean gen error feature selection -  0.355586884301\n",
      "dros_yeast_rat mean gen AUC original -  0.573956420528\n",
      "dros_yeast_rat mean gen AUC feature selection -  0.581001290713\n",
      "\n",
      "\n",
      "dros_yeast_rat mean BE error original -  0.352750477727\n",
      "dros_yeast_rat mean BE error feature selection -  0.35176205428\n",
      "dros_yeast_rat mean BE AUC original -  0.588152440116\n",
      "dros_yeast_rat mean BE AUC feature selection -  0.590144517716\n"
     ]
    }
   ],
   "source": [
    "print('dros_yeast_rat mean strict error original - ', np.mean(mean_err_dros_yeast_rat_org_strict))\n",
    "print('dros_yeast_rat mean strict error feature selection - ', np.mean(mean_err_dros_yeast_rat_fs_strict))\n",
    "print('dros_yeast_rat mean strict AUC original - ', np.mean(mean_auc_dros_yeast_rat_org_strict))\n",
    "print('dros_yeast_rat mean strict AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_fs_strict))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat mean gen error original - ', np.mean(mean_err_dros_yeast_rat_org_gen))\n",
    "print('dros_yeast_rat mean gen error feature selection - ', np.mean(mean_err_dros_yeast_rat_fs_gen))\n",
    "print('dros_yeast_rat mean gen AUC original - ', np.mean(mean_auc_dros_yeast_rat_org_gen))\n",
    "print('dros_yeast_rat mean gen AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_fs_gen))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat mean BE error original - ', np.mean(mean_err_dros_yeast_rat_org_be))\n",
    "print('dros_yeast_rat mean BE error feature selection - ', np.mean(mean_err_dros_yeast_rat_fs_be))\n",
    "print('dros_yeast_rat mean BE AUC original - ', np.mean(mean_auc_dros_yeast_rat_org_be))\n",
    "print('dros_yeast_rat mean BE AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 07:59:08,605 : INFO : loading Word2Vec object from Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_SR_model\n",
      "2017-04-24 07:59:08,862 : INFO : loading wv recursively from Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_SR_model.wv.* with mmap=None\n",
      "2017-04-24 07:59:08,862 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 07:59:08,863 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 07:59:08,863 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 07:59:08,864 : INFO : loaded Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_SR_model\n",
      "2017-04-24 07:59:08,871 : INFO : training model with 4 workers on 3537 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 07:59:08,872 : INFO : expecting 7271 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 07:59:09,883 : INFO : PROGRESS: at 183.91% examples, 1099638 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 07:59:10,887 : INFO : PROGRESS: at 376.26% examples, 1124879 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 07:59:11,889 : INFO : PROGRESS: at 574.56% examples, 1146007 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:12,896 : INFO : PROGRESS: at 754.47% examples, 1127985 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 07:59:13,898 : INFO : PROGRESS: at 946.78% examples, 1132749 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:14,898 : INFO : PROGRESS: at 1158.25% examples, 1155594 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:15,153 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 07:59:15,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 07:59:15,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 07:59:15,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 07:59:15,160 : INFO : training on 11843775 raw words (7246440 effective words) took 6.3s, 1153380 effective words/s\n",
      "2017-04-24 07:59:15,161 : WARNING : supplied example count (438615) did not equal expected count (36355)\n",
      "2017-04-24 07:59:15,161 : INFO : saving Word2Vec object under Results/dros_yeast_rat_mouse_SR_model, separately None\n",
      "2017-04-24 07:59:15,162 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 07:59:15,162 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 07:59:15,163 : INFO : not storing attribute cum_table\n",
      "2017-04-24 07:59:15,255 : INFO : saved Results/dros_yeast_rat_mouse_SR_model\n",
      "2017-04-24 07:59:26,492 : INFO : loading Word2Vec object from Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_GEN_model\n",
      "2017-04-24 07:59:27,042 : INFO : loading wv recursively from Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_GEN_model.wv.* with mmap=None\n",
      "2017-04-24 07:59:27,043 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 07:59:27,043 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 07:59:27,044 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 07:59:27,045 : INFO : loaded Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_GEN_model\n",
      "2017-04-24 07:59:27,060 : INFO : training model with 4 workers on 8246 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 07:59:27,061 : INFO : expecting 37017 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 07:59:28,070 : INFO : PROGRESS: at 27.48% examples, 898111 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-24 07:59:29,089 : INFO : PROGRESS: at 56.89% examples, 921320 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 07:59:30,093 : INFO : PROGRESS: at 87.16% examples, 942933 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 07:59:31,099 : INFO : PROGRESS: at 117.32% examples, 951927 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:32,104 : INFO : PROGRESS: at 146.59% examples, 951861 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:33,109 : INFO : PROGRESS: at 173.07% examples, 937081 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 07:59:34,109 : INFO : PROGRESS: at 198.13% examples, 920388 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:35,116 : INFO : PROGRESS: at 217.81% examples, 885135 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:36,122 : INFO : PROGRESS: at 237.88% examples, 859173 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:37,128 : INFO : PROGRESS: at 256.79% examples, 835047 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:38,136 : INFO : PROGRESS: at 280.91% examples, 830661 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 07:59:39,141 : INFO : PROGRESS: at 313.40% examples, 849788 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:40,153 : INFO : PROGRESS: at 341.97% examples, 855559 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:41,159 : INFO : PROGRESS: at 367.57% examples, 853645 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 07:59:42,162 : INFO : PROGRESS: at 395.19% examples, 856663 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:43,174 : INFO : PROGRESS: at 419.58% examples, 852409 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 07:59:44,179 : INFO : PROGRESS: at 447.98% examples, 856558 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 07:59:45,185 : INFO : PROGRESS: at 476.63% examples, 860776 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:46,197 : INFO : PROGRESS: at 502.55% examples, 859492 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:47,202 : INFO : PROGRESS: at 521.03% examples, 846757 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 07:59:48,206 : INFO : PROGRESS: at 542.26% examples, 839527 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:49,214 : INFO : PROGRESS: at 563.87% examples, 833405 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:50,220 : INFO : PROGRESS: at 592.90% examples, 838160 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:51,230 : INFO : PROGRESS: at 623.84% examples, 845001 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:52,234 : INFO : PROGRESS: at 657.99% examples, 855545 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:53,238 : INFO : PROGRESS: at 688.68% examples, 861077 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 07:59:54,246 : INFO : PROGRESS: at 709.13% examples, 853731 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 07:59:55,264 : INFO : PROGRESS: at 730.44% examples, 847684 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 07:59:56,266 : INFO : PROGRESS: at 752.05% examples, 842687 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:57,282 : INFO : PROGRESS: at 770.96% examples, 834891 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:58,285 : INFO : PROGRESS: at 800.91% examples, 839591 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 07:59:59,287 : INFO : PROGRESS: at 830.68% examples, 843815 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:00,295 : INFO : PROGRESS: at 859.88% examples, 846949 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:01,298 : INFO : PROGRESS: at 884.34% examples, 845498 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:00:02,300 : INFO : PROGRESS: at 915.82% examples, 850557 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:03,313 : INFO : PROGRESS: at 942.30% examples, 850716 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:04,316 : INFO : PROGRESS: at 972.15% examples, 854003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:05,324 : INFO : PROGRESS: at 1001.84% examples, 856870 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:06,326 : INFO : PROGRESS: at 1026.51% examples, 855562 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:07,330 : INFO : PROGRESS: at 1048.91% examples, 852525 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:08,331 : INFO : PROGRESS: at 1075.36% examples, 852893 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:09,347 : INFO : PROGRESS: at 1103.72% examples, 854332 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:10,354 : INFO : PROGRESS: at 1124.75% examples, 850390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:11,362 : INFO : PROGRESS: at 1145.46% examples, 846323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:12,366 : INFO : PROGRESS: at 1166.25% examples, 842496 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:13,381 : INFO : PROGRESS: at 1184.23% examples, 836734 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:14,383 : INFO : PROGRESS: at 1208.43% examples, 835741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:15,406 : INFO : PROGRESS: at 1235.80% examples, 836539 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:00:16,414 : INFO : PROGRESS: at 1265.49% examples, 839137 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:17,420 : INFO : PROGRESS: at 1289.72% examples, 838113 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:00:18,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:00:18,174 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:00:18,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:00:18,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:00:18,189 : INFO : training on 62678565 raw words (42879350 effective words) took 51.1s, 838735 effective words/s\n",
      "2017-04-24 08:00:18,190 : WARNING : supplied example count (2425125) did not equal expected count (185085)\n",
      "2017-04-24 08:00:18,191 : INFO : saving Word2Vec object under Results/dros_yeast_rat_mouse_GEN_model, separately None\n",
      "2017-04-24 08:00:18,191 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:00:18,192 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:00:18,192 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:00:18,356 : INFO : saved Results/dros_yeast_rat_mouse_GEN_model\n",
      "2017-04-24 08:01:03,203 : INFO : loading Word2Vec object from Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_BE_model\n",
      "2017-04-24 08:01:04,681 : INFO : loading wv recursively from Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_BE_model.wv.* with mmap=None\n",
      "2017-04-24 08:01:04,683 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 08:01:04,683 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 08:01:04,684 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 08:01:04,684 : INFO : loaded Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_BE_model\n",
      "2017-04-24 08:01:04,724 : INFO : training model with 4 workers on 18427 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:01:04,724 : INFO : expecting 179573 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:01:05,734 : INFO : PROGRESS: at 5.19% examples, 820074 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:01:06,736 : INFO : PROGRESS: at 9.04% examples, 714473 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:07,740 : INFO : PROGRESS: at 12.81% examples, 674025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:08,745 : INFO : PROGRESS: at 16.43% examples, 648126 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:09,748 : INFO : PROGRESS: at 20.48% examples, 645918 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:01:10,749 : INFO : PROGRESS: at 25.64% examples, 674097 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:01:11,757 : INFO : PROGRESS: at 30.67% examples, 690285 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:01:12,763 : INFO : PROGRESS: at 35.38% examples, 696355 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:13,767 : INFO : PROGRESS: at 40.45% examples, 707605 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:14,784 : INFO : PROGRESS: at 45.67% examples, 717905 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:15,789 : INFO : PROGRESS: at 51.06% examples, 729709 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:16,795 : INFO : PROGRESS: at 57.14% examples, 748137 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:17,801 : INFO : PROGRESS: at 62.41% examples, 754683 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:18,808 : INFO : PROGRESS: at 67.35% examples, 756086 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:19,822 : INFO : PROGRESS: at 72.23% examples, 756399 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:20,825 : INFO : PROGRESS: at 77.23% examples, 758164 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:21,829 : INFO : PROGRESS: at 82.15% examples, 759200 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:22,834 : INFO : PROGRESS: at 85.41% examples, 745525 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:23,845 : INFO : PROGRESS: at 88.54% examples, 731861 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:24,846 : INFO : PROGRESS: at 91.98% examples, 722514 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:25,855 : INFO : PROGRESS: at 95.31% examples, 713081 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:26,858 : INFO : PROGRESS: at 99.11% examples, 707968 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:01:27,859 : INFO : PROGRESS: at 102.78% examples, 702502 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:01:28,861 : INFO : PROGRESS: at 106.59% examples, 698338 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:01:29,861 : INFO : PROGRESS: at 110.53% examples, 695392 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:30,877 : INFO : PROGRESS: at 114.21% examples, 690549 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:31,879 : INFO : PROGRESS: at 117.47% examples, 684043 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:32,886 : INFO : PROGRESS: at 120.93% examples, 678889 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:01:33,900 : INFO : PROGRESS: at 125.85% examples, 682013 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:34,911 : INFO : PROGRESS: at 131.49% examples, 688650 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:35,913 : INFO : PROGRESS: at 136.48% examples, 691784 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:36,924 : INFO : PROGRESS: at 141.42% examples, 694252 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:37,930 : INFO : PROGRESS: at 146.15% examples, 695788 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:38,934 : INFO : PROGRESS: at 151.47% examples, 700058 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:39,943 : INFO : PROGRESS: at 157.34% examples, 706310 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:40,946 : INFO : PROGRESS: at 163.26% examples, 712573 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:41,952 : INFO : PROGRESS: at 166.83% examples, 708544 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:42,975 : INFO : PROGRESS: at 170.28% examples, 703834 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:43,976 : INFO : PROGRESS: at 173.45% examples, 698615 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:44,994 : INFO : PROGRESS: at 176.76% examples, 693921 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:45,999 : INFO : PROGRESS: at 180.19% examples, 690225 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:47,012 : INFO : PROGRESS: at 184.29% examples, 688980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:48,032 : INFO : PROGRESS: at 188.30% examples, 687340 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:01:49,033 : INFO : PROGRESS: at 192.94% examples, 688413 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:50,037 : INFO : PROGRESS: at 196.67% examples, 686141 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:51,043 : INFO : PROGRESS: at 200.67% examples, 684905 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:52,044 : INFO : PROGRESS: at 205.72% examples, 687379 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:53,050 : INFO : PROGRESS: at 210.10% examples, 687366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:54,072 : INFO : PROGRESS: at 215.36% examples, 689973 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:55,079 : INFO : PROGRESS: at 220.59% examples, 692549 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:01:56,088 : INFO : PROGRESS: at 224.44% examples, 690819 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:01:57,109 : INFO : PROGRESS: at 228.38% examples, 689288 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:01:58,120 : INFO : PROGRESS: at 232.33% examples, 687963 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:01:59,134 : INFO : PROGRESS: at 236.46% examples, 687152 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:00,135 : INFO : PROGRESS: at 241.52% examples, 689203 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:02:01,141 : INFO : PROGRESS: at 246.60% examples, 691114 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:02,143 : INFO : PROGRESS: at 251.85% examples, 693541 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:03,151 : INFO : PROGRESS: at 256.45% examples, 694025 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:04,173 : INFO : PROGRESS: at 260.02% examples, 691622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:05,180 : INFO : PROGRESS: at 263.65% examples, 689592 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:06,191 : INFO : PROGRESS: at 267.31% examples, 687699 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:07,194 : INFO : PROGRESS: at 271.07% examples, 686181 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:08,207 : INFO : PROGRESS: at 276.60% examples, 689032 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:09,218 : INFO : PROGRESS: at 281.48% examples, 690185 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:10,221 : INFO : PROGRESS: at 287.29% examples, 693652 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:11,224 : INFO : PROGRESS: at 291.76% examples, 693799 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:12,245 : INFO : PROGRESS: at 295.53% examples, 692123 words/s, in_qsize 7, out_qsize 2\n",
      "2017-04-24 08:02:13,251 : INFO : PROGRESS: at 298.79% examples, 689473 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:14,257 : INFO : PROGRESS: at 301.93% examples, 686578 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:15,271 : INFO : PROGRESS: at 305.41% examples, 684530 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:02:16,272 : INFO : PROGRESS: at 309.56% examples, 684100 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:17,284 : INFO : PROGRESS: at 313.56% examples, 683282 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:02:18,295 : INFO : PROGRESS: at 317.62% examples, 682590 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:19,328 : INFO : PROGRESS: at 321.76% examples, 681914 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:20,356 : INFO : PROGRESS: at 325.51% examples, 680507 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:21,383 : INFO : PROGRESS: at 329.66% examples, 679938 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:22,386 : INFO : PROGRESS: at 333.88% examples, 679769 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:23,391 : INFO : PROGRESS: at 338.60% examples, 680523 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:24,395 : INFO : PROGRESS: at 343.26% examples, 681182 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:02:25,406 : INFO : PROGRESS: at 348.19% examples, 682304 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:26,413 : INFO : PROGRESS: at 353.08% examples, 683338 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:27,423 : INFO : PROGRESS: at 356.84% examples, 682192 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:28,442 : INFO : PROGRESS: at 359.74% examples, 679429 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:02:29,451 : INFO : PROGRESS: at 362.81% examples, 677056 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:30,466 : INFO : PROGRESS: at 365.92% examples, 674797 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:31,488 : INFO : PROGRESS: at 368.85% examples, 672187 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:32,502 : INFO : PROGRESS: at 372.19% examples, 670448 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:33,516 : INFO : PROGRESS: at 375.69% examples, 668994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:34,532 : INFO : PROGRESS: at 379.23% examples, 667646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:35,544 : INFO : PROGRESS: at 383.75% examples, 668069 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:36,548 : INFO : PROGRESS: at 388.48% examples, 668932 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 08:02:37,549 : INFO : PROGRESS: at 393.25% examples, 669806 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:38,554 : INFO : PROGRESS: at 397.99% examples, 670622 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:39,557 : INFO : PROGRESS: at 402.47% examples, 670973 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:40,563 : INFO : PROGRESS: at 406.54% examples, 670683 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:41,564 : INFO : PROGRESS: at 410.27% examples, 669818 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:42,571 : INFO : PROGRESS: at 413.51% examples, 668183 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:43,575 : INFO : PROGRESS: at 417.82% examples, 668313 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:44,595 : INFO : PROGRESS: at 422.86% examples, 669454 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:45,601 : INFO : PROGRESS: at 427.48% examples, 669991 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:46,605 : INFO : PROGRESS: at 432.39% examples, 671050 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:47,629 : INFO : PROGRESS: at 436.55% examples, 670738 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:48,635 : INFO : PROGRESS: at 440.55% examples, 670321 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:49,638 : INFO : PROGRESS: at 444.46% examples, 669807 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:50,639 : INFO : PROGRESS: at 447.95% examples, 668683 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:51,652 : INFO : PROGRESS: at 452.28% examples, 668739 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:02:52,670 : INFO : PROGRESS: at 457.16% examples, 669583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:53,685 : INFO : PROGRESS: at 461.77% examples, 670021 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:54,691 : INFO : PROGRESS: at 466.41% examples, 670588 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:55,700 : INFO : PROGRESS: at 470.27% examples, 669998 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:56,714 : INFO : PROGRESS: at 473.91% examples, 669046 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:02:57,718 : INFO : PROGRESS: at 477.58% examples, 668244 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:58,725 : INFO : PROGRESS: at 480.99% examples, 667051 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:02:59,747 : INFO : PROGRESS: at 485.04% examples, 666695 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:00,748 : INFO : PROGRESS: at 489.16% examples, 666583 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:01,758 : INFO : PROGRESS: at 492.98% examples, 665989 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:02,760 : INFO : PROGRESS: at 497.11% examples, 665879 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:03,775 : INFO : PROGRESS: at 500.72% examples, 665010 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:04,782 : INFO : PROGRESS: at 504.81% examples, 664817 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:05,783 : INFO : PROGRESS: at 508.45% examples, 664056 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:06,801 : INFO : PROGRESS: at 512.21% examples, 663403 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:07,808 : INFO : PROGRESS: at 516.16% examples, 663053 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:08,816 : INFO : PROGRESS: at 520.53% examples, 663234 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:03:09,821 : INFO : PROGRESS: at 524.10% examples, 662439 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:10,827 : INFO : PROGRESS: at 527.63% examples, 661580 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:03:11,835 : INFO : PROGRESS: at 530.73% examples, 660215 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:12,847 : INFO : PROGRESS: at 533.98% examples, 659010 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:13,859 : INFO : PROGRESS: at 537.89% examples, 658630 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:14,865 : INFO : PROGRESS: at 541.98% examples, 658511 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:15,869 : INFO : PROGRESS: at 546.26% examples, 658626 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:16,890 : INFO : PROGRESS: at 551.05% examples, 659267 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:03:17,903 : INFO : PROGRESS: at 555.89% examples, 659995 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:18,924 : INFO : PROGRESS: at 561.02% examples, 661001 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:03:19,926 : INFO : PROGRESS: at 565.21% examples, 660993 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:20,939 : INFO : PROGRESS: at 569.50% examples, 661042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:21,942 : INFO : PROGRESS: at 572.99% examples, 660233 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:22,945 : INFO : PROGRESS: at 576.71% examples, 659698 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:23,948 : INFO : PROGRESS: at 580.40% examples, 659121 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:24,952 : INFO : PROGRESS: at 584.35% examples, 658858 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:25,965 : INFO : PROGRESS: at 589.12% examples, 659495 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 08:03:26,968 : INFO : PROGRESS: at 594.29% examples, 660593 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:27,970 : INFO : PROGRESS: at 598.89% examples, 661048 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:28,979 : INFO : PROGRESS: at 602.63% examples, 660502 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:29,980 : INFO : PROGRESS: at 606.55% examples, 660201 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:31,002 : INFO : PROGRESS: at 609.90% examples, 659210 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:32,009 : INFO : PROGRESS: at 613.80% examples, 658900 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:33,012 : INFO : PROGRESS: at 618.13% examples, 659046 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:34,014 : INFO : PROGRESS: at 622.33% examples, 659102 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 08:03:35,028 : INFO : PROGRESS: at 626.66% examples, 659206 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:03:36,046 : INFO : PROGRESS: at 630.47% examples, 658760 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:03:37,049 : INFO : PROGRESS: at 634.27% examples, 658382 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:38,081 : INFO : PROGRESS: at 638.23% examples, 658020 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:03:39,082 : INFO : PROGRESS: at 642.14% examples, 657755 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:40,086 : INFO : PROGRESS: at 647.22% examples, 658662 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:41,094 : INFO : PROGRESS: at 652.14% examples, 659401 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:03:42,098 : INFO : PROGRESS: at 657.18% examples, 660241 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:43,104 : INFO : PROGRESS: at 662.40% examples, 661247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:44,105 : INFO : PROGRESS: at 666.31% examples, 660969 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:45,115 : INFO : PROGRESS: at 670.58% examples, 661018 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:03:46,115 : INFO : PROGRESS: at 674.44% examples, 660700 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:47,123 : INFO : PROGRESS: at 678.14% examples, 660223 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:48,130 : INFO : PROGRESS: at 683.16% examples, 661012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:49,137 : INFO : PROGRESS: at 688.39% examples, 661979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:50,151 : INFO : PROGRESS: at 693.45% examples, 662766 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:03:51,165 : INFO : PROGRESS: at 698.53% examples, 663551 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:52,172 : INFO : PROGRESS: at 702.77% examples, 663552 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:53,175 : INFO : PROGRESS: at 706.53% examples, 663144 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:54,185 : INFO : PROGRESS: at 710.31% examples, 662706 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:55,192 : INFO : PROGRESS: at 714.36% examples, 662543 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:56,193 : INFO : PROGRESS: at 719.38% examples, 663305 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:03:57,196 : INFO : PROGRESS: at 724.50% examples, 664134 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:58,203 : INFO : PROGRESS: at 729.88% examples, 665202 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:03:59,210 : INFO : PROGRESS: at 734.77% examples, 665789 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:00,219 : INFO : PROGRESS: at 739.14% examples, 665897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:01,226 : INFO : PROGRESS: at 743.25% examples, 665768 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:02,237 : INFO : PROGRESS: at 747.12% examples, 665418 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:04:03,258 : INFO : PROGRESS: at 751.06% examples, 665113 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:04:04,265 : INFO : PROGRESS: at 755.85% examples, 665603 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:05,270 : INFO : PROGRESS: at 761.18% examples, 666583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:06,282 : INFO : PROGRESS: at 766.05% examples, 667116 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:07,285 : INFO : PROGRESS: at 771.27% examples, 667962 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:08,300 : INFO : PROGRESS: at 775.12% examples, 667595 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:09,312 : INFO : PROGRESS: at 778.98% examples, 667242 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:10,326 : INFO : PROGRESS: at 783.02% examples, 667039 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:04:11,332 : INFO : PROGRESS: at 787.15% examples, 666953 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:12,352 : INFO : PROGRESS: at 791.98% examples, 667399 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:13,381 : INFO : PROGRESS: at 797.27% examples, 668198 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:14,391 : INFO : PROGRESS: at 802.11% examples, 668674 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:15,392 : INFO : PROGRESS: at 806.67% examples, 668941 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:16,397 : INFO : PROGRESS: at 810.34% examples, 668461 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:17,400 : INFO : PROGRESS: at 814.29% examples, 668228 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:18,408 : INFO : PROGRESS: at 818.19% examples, 667941 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:19,411 : INFO : PROGRESS: at 822.15% examples, 667709 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:20,417 : INFO : PROGRESS: at 826.95% examples, 668141 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:21,428 : INFO : PROGRESS: at 832.22% examples, 668933 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:04:22,444 : INFO : PROGRESS: at 837.35% examples, 669585 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:23,449 : INFO : PROGRESS: at 841.81% examples, 669750 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:24,457 : INFO : PROGRESS: at 845.88% examples, 669574 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:25,462 : INFO : PROGRESS: at 849.95% examples, 669448 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:26,476 : INFO : PROGRESS: at 853.76% examples, 669071 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:27,492 : INFO : PROGRESS: at 857.99% examples, 669021 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:04:28,492 : INFO : PROGRESS: at 862.79% examples, 669453 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:29,506 : INFO : PROGRESS: at 867.69% examples, 669905 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:04:30,524 : INFO : PROGRESS: at 872.53% examples, 670310 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:31,531 : INFO : PROGRESS: at 877.23% examples, 670636 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:32,533 : INFO : PROGRESS: at 881.37% examples, 670548 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:04:33,541 : INFO : PROGRESS: at 885.48% examples, 670447 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:34,551 : INFO : PROGRESS: at 889.43% examples, 670196 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:35,567 : INFO : PROGRESS: at 893.75% examples, 670216 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 08:04:36,572 : INFO : PROGRESS: at 898.53% examples, 670610 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:37,593 : INFO : PROGRESS: at 903.50% examples, 671086 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:38,594 : INFO : PROGRESS: at 908.50% examples, 671625 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-24 08:04:39,599 : INFO : PROGRESS: at 913.34% examples, 672045 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:40,611 : INFO : PROGRESS: at 917.72% examples, 672096 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:41,611 : INFO : PROGRESS: at 921.53% examples, 671777 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:42,614 : INFO : PROGRESS: at 925.68% examples, 671690 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:43,617 : INFO : PROGRESS: at 930.24% examples, 671900 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:44,624 : INFO : PROGRESS: at 935.44% examples, 672568 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:45,627 : INFO : PROGRESS: at 940.54% examples, 673174 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:46,629 : INFO : PROGRESS: at 945.93% examples, 673977 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:47,635 : INFO : PROGRESS: at 950.50% examples, 674172 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:48,643 : INFO : PROGRESS: at 954.88% examples, 674227 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:49,664 : INFO : PROGRESS: at 959.01% examples, 674075 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:50,679 : INFO : PROGRESS: at 962.88% examples, 673748 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:04:51,684 : INFO : PROGRESS: at 967.58% examples, 674033 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:52,694 : INFO : PROGRESS: at 972.65% examples, 674565 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:53,696 : INFO : PROGRESS: at 977.55% examples, 674985 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:54,698 : INFO : PROGRESS: at 981.87% examples, 675018 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:55,706 : INFO : PROGRESS: at 985.87% examples, 674809 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:04:56,727 : INFO : PROGRESS: at 989.50% examples, 674312 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:04:57,731 : INFO : PROGRESS: at 992.93% examples, 673745 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:04:58,766 : INFO : PROGRESS: at 996.51% examples, 673188 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:04:59,772 : INFO : PROGRESS: at 1000.66% examples, 673089 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:00,776 : INFO : PROGRESS: at 1005.46% examples, 673433 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:01,780 : INFO : PROGRESS: at 1010.21% examples, 673748 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:02,793 : INFO : PROGRESS: at 1014.89% examples, 674002 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:03,796 : INFO : PROGRESS: at 1018.90% examples, 673822 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:04,796 : INFO : PROGRESS: at 1022.70% examples, 673528 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:05,807 : INFO : PROGRESS: at 1027.01% examples, 673538 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:06,815 : INFO : PROGRESS: at 1030.96% examples, 673315 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:07,828 : INFO : PROGRESS: at 1035.95% examples, 673746 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:08,835 : INFO : PROGRESS: at 1040.74% examples, 674074 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:09,837 : INFO : PROGRESS: at 1046.03% examples, 674731 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:10,848 : INFO : PROGRESS: at 1051.04% examples, 675188 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:11,872 : INFO : PROGRESS: at 1054.85% examples, 674829 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:05:12,875 : INFO : PROGRESS: at 1057.95% examples, 674084 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:13,887 : INFO : PROGRESS: at 1061.21% examples, 673414 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:14,891 : INFO : PROGRESS: at 1064.41% examples, 672741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:15,905 : INFO : PROGRESS: at 1068.60% examples, 672659 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:16,931 : INFO : PROGRESS: at 1072.60% examples, 672429 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:17,931 : INFO : PROGRESS: at 1076.68% examples, 672328 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:18,938 : INFO : PROGRESS: at 1081.19% examples, 672470 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:19,947 : INFO : PROGRESS: at 1085.58% examples, 672518 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:20,953 : INFO : PROGRESS: at 1089.77% examples, 672456 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:05:21,961 : INFO : PROGRESS: at 1093.87% examples, 672337 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:22,973 : INFO : PROGRESS: at 1098.16% examples, 672323 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:23,974 : INFO : PROGRESS: at 1102.02% examples, 672076 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:24,981 : INFO : PROGRESS: at 1105.89% examples, 671825 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:25,986 : INFO : PROGRESS: at 1110.59% examples, 672084 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:26,990 : INFO : PROGRESS: at 1115.27% examples, 672343 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:27,995 : INFO : PROGRESS: at 1120.16% examples, 672711 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:29,013 : INFO : PROGRESS: at 1125.13% examples, 673094 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:30,020 : INFO : PROGRESS: at 1129.67% examples, 673226 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:31,025 : INFO : PROGRESS: at 1133.99% examples, 673252 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:32,028 : INFO : PROGRESS: at 1137.76% examples, 672957 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:33,032 : INFO : PROGRESS: at 1141.68% examples, 672739 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:34,048 : INFO : PROGRESS: at 1146.54% examples, 673065 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:35,053 : INFO : PROGRESS: at 1151.83% examples, 673664 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:36,054 : INFO : PROGRESS: at 1156.76% examples, 674053 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:37,059 : INFO : PROGRESS: at 1161.35% examples, 674239 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:38,062 : INFO : PROGRESS: at 1165.03% examples, 673887 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:39,066 : INFO : PROGRESS: at 1168.93% examples, 673671 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:40,072 : INFO : PROGRESS: at 1172.86% examples, 673454 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:41,098 : INFO : PROGRESS: at 1176.76% examples, 673189 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:42,103 : INFO : PROGRESS: at 1181.70% examples, 673558 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:43,111 : INFO : PROGRESS: at 1186.63% examples, 673920 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:44,111 : INFO : PROGRESS: at 1191.67% examples, 674350 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:45,116 : INFO : PROGRESS: at 1197.00% examples, 674947 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:46,118 : INFO : PROGRESS: at 1200.96% examples, 674764 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:47,124 : INFO : PROGRESS: at 1204.71% examples, 674468 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:48,146 : INFO : PROGRESS: at 1209.03% examples, 674450 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:05:49,162 : INFO : PROGRESS: at 1213.09% examples, 674294 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:50,167 : INFO : PROGRESS: at 1218.21% examples, 674755 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:51,173 : INFO : PROGRESS: at 1223.51% examples, 675311 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:52,177 : INFO : PROGRESS: at 1228.73% examples, 675817 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:05:53,193 : INFO : PROGRESS: at 1233.80% examples, 676217 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:54,202 : INFO : PROGRESS: at 1237.71% examples, 675994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:55,206 : INFO : PROGRESS: at 1241.90% examples, 675936 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:56,215 : INFO : PROGRESS: at 1246.22% examples, 675943 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:57,223 : INFO : PROGRESS: at 1250.37% examples, 675847 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:58,228 : INFO : PROGRESS: at 1255.57% examples, 676344 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:05:59,234 : INFO : PROGRESS: at 1260.45% examples, 676654 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:00,242 : INFO : PROGRESS: at 1265.10% examples, 676835 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:01,251 : INFO : PROGRESS: at 1269.77% examples, 677011 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:02,258 : INFO : PROGRESS: at 1273.49% examples, 676697 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:03,262 : INFO : PROGRESS: at 1277.20% examples, 676392 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:04,267 : INFO : PROGRESS: at 1280.83% examples, 676038 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:06:05,280 : INFO : PROGRESS: at 1284.96% examples, 675936 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:06:06,288 : INFO : PROGRESS: at 1289.60% examples, 676113 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:07,304 : INFO : PROGRESS: at 1294.24% examples, 676273 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:06:08,324 : INFO : PROGRESS: at 1299.23% examples, 676593 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:06:09,331 : INFO : PROGRESS: at 1304.16% examples, 676915 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:06:10,351 : INFO : PROGRESS: at 1308.38% examples, 676844 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:06:11,378 : INFO : PROGRESS: at 1312.28% examples, 676592 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:06:12,107 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:06:12,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:06:12,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:06:12,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:06:12,116 : INFO : training on 282383820 raw words (207925313 effective words) took 307.4s, 676429 effective words/s\n",
      "2017-04-24 08:06:12,117 : WARNING : supplied example count (11808085) did not equal expected count (897865)\n",
      "2017-04-24 08:06:12,118 : INFO : saving Word2Vec object under Results/dros_yeast_rat_mouse_BE_model, separately None\n",
      "2017-04-24 08:06:12,119 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:06:12,121 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:06:12,122 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:06:13,816 : INFO : saved Results/dros_yeast_rat_mouse_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "dros_yeast_rat_old_SR_model = 'Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_SR_model'\n",
    "mouse_SR_sentences_pkl = 'Results/mouse/strict_real.pkl'\n",
    "dros_yeast_rat_mouse_SR_model = add_sentences_to_model(dros_yeast_rat_old_SR_model, mouse_SR_sentences_pkl, 'dros_yeast_rat_mouse_SR_model')\n",
    "\n",
    "#Gen model\n",
    "dros_yeast_rat_old_GEN_model = 'Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_GEN_model'\n",
    "mouse_GEN_sentences_pkl = 'Results/mouse/gen_real.pkl'\n",
    "dros_yeast_rat_mouse_GEN_model = add_sentences_to_model(dros_yeast_rat_old_GEN_model, mouse_GEN_sentences_pkl, 'dros_yeast_rat_mouse_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "dros_yeast_rat_old_BE_model = 'Results/dros_yeast_rat/Seeded/Results/dros_yeast_rat_BE_model'\n",
    "mouse_BE_sentences_pkl = 'Results/mouse/be_real.pkl'\n",
    "dros_yeast_rat_mouse_BE_model = add_sentences_to_model(dros_yeast_rat_old_BE_model, mouse_BE_sentences_pkl, 'dros_yeast_rat_mouse_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "dros_strict_real = pickle.load(open('Results/drosophila/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_mouse_SR_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_mouse_GEN_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_mouse_BE_merger_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/dros_yeast_rat_mouse_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/dros_yeast_rat_mouse_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/dros_yeast_rat_mouse_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/dros_yeast_rat_mouse/Seeded/Results/'\n",
    "errors_dros_yeast_rat_mouse = mult_open(drct, '_errors_')\n",
    "fpr_dros_yeast_rat_mouse = mult_open(drct, '_fpr_')\n",
    "tpr_dros_yeast_rat_mouse = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error dros_yeast_rat_mouse auc=0.474 error=0.439\n",
      "Strict error dros_yeast_rat_mouse auc=0.468 error=0.424\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.480 error=0.424\n",
      "Gen error dros_yeast_rat_mouse auc=0.488 error=0.391\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.455 error=0.403\n",
      "BE error dros_yeast_rat_mouse auc=0.448 error=0.418\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.515 error=0.404\n",
      "Strict error dros_yeast_rat_mouse auc=0.527 error=0.406\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.577 error=0.381\n",
      "Gen error dros_yeast_rat_mouse auc=0.591 error=0.376\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.603 error=0.388\n",
      "BE error dros_yeast_rat_mouse auc=0.594 error=0.374\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.522 error=0.385\n",
      "Strict error dros_yeast_rat_mouse auc=0.538 error=0.390\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.546 error=0.381\n",
      "Gen error dros_yeast_rat_mouse auc=0.542 error=0.382\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.554 error=0.373\n",
      "BE error dros_yeast_rat_mouse auc=0.545 error=0.375\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.550 error=0.334\n",
      "Strict error dros_yeast_rat_mouse auc=0.539 error=0.330\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.590 error=0.305\n",
      "Gen error dros_yeast_rat_mouse auc=0.611 error=0.295\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.550 error=0.324\n",
      "BE error dros_yeast_rat_mouse auc=0.536 error=0.325\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.541 error=0.402\n",
      "Strict error dros_yeast_rat_mouse auc=0.565 error=0.405\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.585 error=0.397\n",
      "Gen error dros_yeast_rat_mouse auc=0.614 error=0.386\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.545 error=0.407\n",
      "BE error dros_yeast_rat_mouse auc=0.559 error=0.402\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.520 error=0.426\n",
      "Strict error dros_yeast_rat_mouse auc=0.545 error=0.426\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.553 error=0.434\n",
      "Gen error dros_yeast_rat_mouse auc=0.573 error=0.413\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.556 error=0.432\n",
      "BE error dros_yeast_rat_mouse auc=0.556 error=0.425\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.547 error=0.336\n",
      "Strict error dros_yeast_rat_mouse auc=0.537 error=0.353\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.592 error=0.331\n",
      "Gen error dros_yeast_rat_mouse auc=0.561 error=0.331\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.574 error=0.342\n",
      "BE error dros_yeast_rat_mouse auc=0.594 error=0.336\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.571 error=0.389\n",
      "Strict error dros_yeast_rat_mouse auc=0.563 error=0.390\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.565 error=0.369\n",
      "Gen error dros_yeast_rat_mouse auc=0.576 error=0.376\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.586 error=0.376\n",
      "BE error dros_yeast_rat_mouse auc=0.594 error=0.364\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.538 error=0.371\n",
      "Strict error dros_yeast_rat_mouse auc=0.546 error=0.386\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.570 error=0.362\n",
      "Gen error dros_yeast_rat_mouse auc=0.533 error=0.378\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.538 error=0.369\n",
      "BE error dros_yeast_rat_mouse auc=0.554 error=0.364\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse auc=0.589 error=0.375\n",
      "Strict error dros_yeast_rat_mouse auc=0.577 error=0.375\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse auc=0.626 error=0.341\n",
      "Gen error dros_yeast_rat_mouse auc=0.628 error=0.341\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse auc=0.629 error=0.351\n",
      "BE error dros_yeast_rat_mouse auc=0.627 error=0.357\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_rat_mouse_strict = []\n",
    "mean_auc_dros_yeast_rat_mouse_strict = []\n",
    "mean_err_dros_yeast_rat_mouse_gen = []\n",
    "mean_auc_dros_yeast_rat_mouse_gen = []\n",
    "mean_err_dros_yeast_rat_mouse_be = []\n",
    "mean_auc_dros_yeast_rat_mouse_be = []\n",
    "for e, f, t in zip(errors_dros_yeast_rat_mouse, fpr_dros_yeast_rat_mouse, tpr_dros_yeast_rat_mouse):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['dros_yeast_rat_mouse']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_yeast_rat_mouse_strict.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_mouse_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_yeast_rat_mouse_gen.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_mouse_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_yeast_rat_mouse_be.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_mouse_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_dros_yeast_rat_mouse_org_strict = mean_err_dros_yeast_rat_mouse_strict[0::2]\n",
    "mean_err_dros_yeast_rat_mouse_fs_strict = mean_err_dros_yeast_rat_mouse_strict[1::2]\n",
    "mean_auc_dros_yeast_rat_mouse_org_strict = mean_auc_dros_yeast_rat_mouse_strict[0::2]\n",
    "mean_auc_dros_yeast_rat_mouse_fs_strict = mean_auc_dros_yeast_rat_mouse_strict[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_mouse_org_gen = mean_err_dros_yeast_rat_mouse_gen[0::2]\n",
    "mean_err_dros_yeast_rat_mouse_fs_gen = mean_err_dros_yeast_rat_mouse_gen[1::2]\n",
    "mean_auc_dros_yeast_rat_mouse_org_gen = mean_auc_dros_yeast_rat_mouse_gen[0::2]\n",
    "mean_auc_dros_yeast_rat_mouse_fs_gen = mean_auc_dros_yeast_rat_mouse_gen[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_mouse_org_be = mean_err_dros_yeast_rat_mouse_be[0::2]\n",
    "mean_err_dros_yeast_rat_mouse_fs_be = mean_err_dros_yeast_rat_mouse_be[1::2]\n",
    "mean_auc_dros_yeast_rat_mouse_org_be = mean_auc_dros_yeast_rat_mouse_be[0::2]\n",
    "mean_auc_dros_yeast_rat_mouse_fs_be = mean_auc_dros_yeast_rat_mouse_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dros_yeast_rat_mouse mean strict error original -  0.386167122783\n",
      "dros_yeast_rat_mouse mean strict error feature selection -  0.388462137338\n",
      "dros_yeast_rat_mouse mean strict AUC original -  0.536623533932\n",
      "dros_yeast_rat_mouse mean strict AUC feature selection -  0.540623375155\n",
      "\n",
      "\n",
      "dros_yeast_rat_mouse mean gen error original -  0.372429014969\n",
      "dros_yeast_rat_mouse mean gen error feature selection -  0.367000816679\n",
      "dros_yeast_rat_mouse mean gen AUC original -  0.568530948901\n",
      "dros_yeast_rat_mouse mean gen AUC feature selection -  0.571640480298\n",
      "\n",
      "\n",
      "dros_yeast_rat_mouse mean BE error original -  0.376478169568\n",
      "dros_yeast_rat_mouse mean BE error feature selection -  0.374011445565\n",
      "dros_yeast_rat_mouse mean BE AUC original -  0.559054375678\n",
      "dros_yeast_rat_mouse mean BE AUC feature selection -  0.560923547191\n"
     ]
    }
   ],
   "source": [
    "print('dros_yeast_rat_mouse mean strict error original - ', np.mean(mean_err_dros_yeast_rat_mouse_org_strict))\n",
    "print('dros_yeast_rat_mouse mean strict error feature selection - ', np.mean(mean_err_dros_yeast_rat_mouse_fs_strict))\n",
    "print('dros_yeast_rat_mouse mean strict AUC original - ', np.mean(mean_auc_dros_yeast_rat_mouse_org_strict))\n",
    "print('dros_yeast_rat_mouse mean strict AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_mouse_fs_strict))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat_mouse mean gen error original - ', np.mean(mean_err_dros_yeast_rat_mouse_org_gen))\n",
    "print('dros_yeast_rat_mouse mean gen error feature selection - ', np.mean(mean_err_dros_yeast_rat_mouse_fs_gen))\n",
    "print('dros_yeast_rat_mouse mean gen AUC original - ', np.mean(mean_auc_dros_yeast_rat_mouse_org_gen))\n",
    "print('dros_yeast_rat_mouse mean gen AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_mouse_fs_gen))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat_mouse mean BE error original - ', np.mean(mean_err_dros_yeast_rat_mouse_org_be))\n",
    "print('dros_yeast_rat_mouse mean BE error feature selection - ', np.mean(mean_err_dros_yeast_rat_mouse_fs_be))\n",
    "print('dros_yeast_rat_mouse mean BE AUC original - ', np.mean(mean_auc_dros_yeast_rat_mouse_org_be))\n",
    "print('dros_yeast_rat_mouse mean BE AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_mouse_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_w2v_model(dataset_list, name_for_model, model_features=None):\n",
    "    \"\"\"Produce a Word2Vec Model\n",
    "\n",
    "    Model_features (list): Features of the word to vec models\n",
    "        1. Word vector dimensionality\n",
    "        2. Minimum word count\n",
    "        3. Number of threads to run in parallel\n",
    "        4. Context window size\n",
    "        5. Downsample setting for frequent words\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print ('Parsing datasets sentences')\n",
    "    \n",
    "    sentences = []\n",
    "    for dataset_path in dataset_list:\n",
    "        dataset = pickle.load(open(dataset_path, 'rb'))\n",
    "        sents = [fr.sentence_to_wordlist(sen) for sen in dataset]\n",
    "        sentences += sents\n",
    "        \n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "    # Set values for various parameters\n",
    "    if model_features:\n",
    "        num_features = model_features[0] #300  # Word vector dimensionality\n",
    "        min_word_count = model_features[1] #5  # Minimum word count\n",
    "        num_workers = model_features[2] #4  # Number of threads to run in parallel\n",
    "        context = model_features[3] #6  # Context window size\n",
    "        downsampling = model_features[4] #0.001  # Downsample setting for frequent words\n",
    "    else:\n",
    "        num_features = 300  # Word vector dimensionality\n",
    "        min_word_count = 5  # Minimum word count\n",
    "        num_workers = 4  # Number of threads to run in parallel\n",
    "        context = 6  # Context window size\n",
    "        downsampling = 0.001  # Downsample setting for frequent words\n",
    "\n",
    "    print('Training Word2Vec Model')\n",
    "\n",
    "    model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count=min_word_count, \\\n",
    "            window=context, sample=downsampling)\n",
    "\n",
    "    # If you don't plan to train the model any further, calling\n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    model_name = 'Results/' + name_for_model\n",
    "\n",
    "    model.save(model_name)\n",
    "\n",
    "    w2v_model = model\n",
    "\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:53:07,552 : INFO : collecting all words and their counts\n",
      "2017-04-24 08:53:07,552 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 08:53:07,608 : INFO : PROGRESS: at sentence #10000, processed 256400 words, keeping 15897 word types\n",
      "2017-04-24 08:53:07,628 : INFO : collected 18691 word types from a corpus of 374179 raw words and 14416 sentences\n",
      "2017-04-24 08:53:07,628 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 08:53:07,660 : INFO : min_count=5 retains 5485 unique words (29% of original 18691, drops 13206)\n",
      "2017-04-24 08:53:07,661 : INFO : min_count=5 leaves 352982 word corpus (94% of original 374179, drops 21197)\n",
      "2017-04-24 08:53:07,685 : INFO : deleting the raw counts dictionary of 18691 items\n",
      "2017-04-24 08:53:07,688 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2017-04-24 08:53:07,689 : INFO : downsampling leaves estimated 259757 word corpus (73.6% of prior 352982)\n",
      "2017-04-24 08:53:07,689 : INFO : estimated required memory for 5485 words and 300 dimensions: 15906500 bytes\n",
      "2017-04-24 08:53:07,717 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14416\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:53:07,804 : INFO : training model with 4 workers on 5485 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:53:07,805 : INFO : expecting 14416 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:53:08,813 : INFO : PROGRESS: at 46.49% examples, 599915 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:09,819 : INFO : PROGRESS: at 98.79% examples, 637792 words/s, in_qsize 2, out_qsize 3\n",
      "2017-04-24 08:53:09,820 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:53:09,821 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:53:09,824 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:53:09,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:53:09,826 : INFO : training on 1870895 raw words (1298171 effective words) took 2.0s, 643661 effective words/s\n",
      "2017-04-24 08:53:09,827 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 08:53:09,857 : INFO : saving Word2Vec object under Results/dros_yeast_SR_comb_model, separately None\n",
      "2017-04-24 08:53:09,858 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:53:09,858 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:53:09,964 : INFO : saved Results/dros_yeast_SR_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:53:11,483 : INFO : collecting all words and their counts\n",
      "2017-04-24 08:53:11,484 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 08:53:11,528 : INFO : PROGRESS: at sentence #10000, processed 243767 words, keeping 13425 word types\n",
      "2017-04-24 08:53:11,570 : INFO : PROGRESS: at sentence #20000, processed 487778 words, keeping 18119 word types\n",
      "2017-04-24 08:53:11,612 : INFO : PROGRESS: at sentence #30000, processed 731472 words, keeping 21474 word types\n",
      "2017-04-24 08:53:11,658 : INFO : PROGRESS: at sentence #40000, processed 974035 words, keeping 24814 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84553\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:53:11,704 : INFO : PROGRESS: at sentence #50000, processed 1217621 words, keeping 27640 word types\n",
      "2017-04-24 08:53:11,756 : INFO : PROGRESS: at sentence #60000, processed 1463219 words, keeping 29731 word types\n",
      "2017-04-24 08:53:11,803 : INFO : PROGRESS: at sentence #70000, processed 1709491 words, keeping 31548 word types\n",
      "2017-04-24 08:53:11,850 : INFO : PROGRESS: at sentence #80000, processed 1957174 words, keeping 33092 word types\n",
      "2017-04-24 08:53:11,871 : INFO : collected 33713 word types from a corpus of 2069701 raw words and 84553 sentences\n",
      "2017-04-24 08:53:11,872 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 08:53:11,911 : INFO : min_count=5 retains 12457 unique words (36% of original 33713, drops 21256)\n",
      "2017-04-24 08:53:11,911 : INFO : min_count=5 leaves 2034352 word corpus (98% of original 2069701, drops 35349)\n",
      "2017-04-24 08:53:11,943 : INFO : deleting the raw counts dictionary of 33713 items\n",
      "2017-04-24 08:53:11,945 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-04-24 08:53:11,946 : INFO : downsampling leaves estimated 1515565 word corpus (74.5% of prior 2034352)\n",
      "2017-04-24 08:53:11,946 : INFO : estimated required memory for 12457 words and 300 dimensions: 36125300 bytes\n",
      "2017-04-24 08:53:11,992 : INFO : resetting layer weights\n",
      "2017-04-24 08:53:12,136 : INFO : training model with 4 workers on 12457 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:53:12,137 : INFO : expecting 84553 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:53:13,148 : INFO : PROGRESS: at 10.18% examples, 760915 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:14,166 : INFO : PROGRESS: at 17.87% examples, 668625 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:53:15,185 : INFO : PROGRESS: at 26.17% examples, 650537 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:16,207 : INFO : PROGRESS: at 35.37% examples, 658184 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:17,215 : INFO : PROGRESS: at 44.21% examples, 659926 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:18,233 : INFO : PROGRESS: at 52.74% examples, 655158 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:53:19,244 : INFO : PROGRESS: at 62.35% examples, 665031 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:53:20,266 : INFO : PROGRESS: at 72.05% examples, 671156 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:53:21,279 : INFO : PROGRESS: at 80.67% examples, 669025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:22,296 : INFO : PROGRESS: at 90.67% examples, 675985 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:23,306 : INFO : PROGRESS: at 98.35% examples, 667399 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:23,515 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:53:23,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:53:23,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:53:23,524 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:53:23,524 : INFO : training on 10348505 raw words (7576992 effective words) took 11.4s, 665720 effective words/s\n",
      "2017-04-24 08:53:23,525 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 08:53:23,593 : INFO : saving Word2Vec object under Results/dros_yeast_GEN_comb_model, separately None\n",
      "2017-04-24 08:53:23,594 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:53:23,595 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:53:24,467 : INFO : saved Results/dros_yeast_GEN_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:53:30,759 : INFO : collecting all words and their counts\n",
      "2017-04-24 08:53:30,760 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 08:53:30,805 : INFO : PROGRESS: at sentence #10000, processed 229788 words, keeping 14470 word types\n",
      "2017-04-24 08:53:30,852 : INFO : PROGRESS: at sentence #20000, processed 460388 words, keeping 19917 word types\n",
      "2017-04-24 08:53:30,898 : INFO : PROGRESS: at sentence #30000, processed 690788 words, keeping 23764 word types\n",
      "2017-04-24 08:53:30,940 : INFO : PROGRESS: at sentence #40000, processed 922942 words, keeping 27008 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374080\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 08:53:30,987 : INFO : PROGRESS: at sentence #50000, processed 1153814 words, keeping 29788 word types\n",
      "2017-04-24 08:53:31,038 : INFO : PROGRESS: at sentence #60000, processed 1384782 words, keeping 32176 word types\n",
      "2017-04-24 08:53:31,086 : INFO : PROGRESS: at sentence #70000, processed 1615191 words, keeping 34406 word types\n",
      "2017-04-24 08:53:31,137 : INFO : PROGRESS: at sentence #80000, processed 1846457 words, keeping 36392 word types\n",
      "2017-04-24 08:53:31,185 : INFO : PROGRESS: at sentence #90000, processed 2075150 words, keeping 38166 word types\n",
      "2017-04-24 08:53:31,232 : INFO : PROGRESS: at sentence #100000, processed 2305071 words, keeping 39733 word types\n",
      "2017-04-24 08:53:31,279 : INFO : PROGRESS: at sentence #110000, processed 2536428 words, keeping 41192 word types\n",
      "2017-04-24 08:53:31,321 : INFO : PROGRESS: at sentence #120000, processed 2767447 words, keeping 42645 word types\n",
      "2017-04-24 08:53:31,365 : INFO : PROGRESS: at sentence #130000, processed 2998492 words, keeping 44044 word types\n",
      "2017-04-24 08:53:31,411 : INFO : PROGRESS: at sentence #140000, processed 3230188 words, keeping 45345 word types\n",
      "2017-04-24 08:53:31,460 : INFO : PROGRESS: at sentence #150000, processed 3460267 words, keeping 46545 word types\n",
      "2017-04-24 08:53:31,513 : INFO : PROGRESS: at sentence #160000, processed 3689650 words, keeping 47678 word types\n",
      "2017-04-24 08:53:31,562 : INFO : PROGRESS: at sentence #170000, processed 3920110 words, keeping 48786 word types\n",
      "2017-04-24 08:53:31,611 : INFO : PROGRESS: at sentence #180000, processed 4151938 words, keeping 50038 word types\n",
      "2017-04-24 08:53:31,663 : INFO : PROGRESS: at sentence #190000, processed 4387466 words, keeping 52511 word types\n",
      "2017-04-24 08:53:31,714 : INFO : PROGRESS: at sentence #200000, processed 4621579 words, keeping 54515 word types\n",
      "2017-04-24 08:53:31,760 : INFO : PROGRESS: at sentence #210000, processed 4856235 words, keeping 56178 word types\n",
      "2017-04-24 08:53:31,805 : INFO : PROGRESS: at sentence #220000, processed 5090984 words, keeping 57585 word types\n",
      "2017-04-24 08:53:31,849 : INFO : PROGRESS: at sentence #230000, processed 5326844 words, keeping 58973 word types\n",
      "2017-04-24 08:53:31,892 : INFO : PROGRESS: at sentence #240000, processed 5559987 words, keeping 60198 word types\n",
      "2017-04-24 08:53:31,936 : INFO : PROGRESS: at sentence #250000, processed 5795841 words, keeping 61320 word types\n",
      "2017-04-24 08:53:31,985 : INFO : PROGRESS: at sentence #260000, processed 6029354 words, keeping 62324 word types\n",
      "2017-04-24 08:53:32,032 : INFO : PROGRESS: at sentence #270000, processed 6264512 words, keeping 63360 word types\n",
      "2017-04-24 08:53:32,082 : INFO : PROGRESS: at sentence #280000, processed 6500455 words, keeping 64377 word types\n",
      "2017-04-24 08:53:32,135 : INFO : PROGRESS: at sentence #290000, processed 6734783 words, keeping 65349 word types\n",
      "2017-04-24 08:53:32,186 : INFO : PROGRESS: at sentence #300000, processed 6968095 words, keeping 66255 word types\n",
      "2017-04-24 08:53:32,236 : INFO : PROGRESS: at sentence #310000, processed 7204108 words, keeping 67143 word types\n",
      "2017-04-24 08:53:32,287 : INFO : PROGRESS: at sentence #320000, processed 7438064 words, keeping 67940 word types\n",
      "2017-04-24 08:53:32,337 : INFO : PROGRESS: at sentence #330000, processed 7674525 words, keeping 68733 word types\n",
      "2017-04-24 08:53:32,389 : INFO : PROGRESS: at sentence #340000, processed 7910373 words, keeping 69482 word types\n",
      "2017-04-24 08:53:32,441 : INFO : PROGRESS: at sentence #350000, processed 8145924 words, keeping 70174 word types\n",
      "2017-04-24 08:53:32,492 : INFO : PROGRESS: at sentence #360000, processed 8382233 words, keeping 70899 word types\n",
      "2017-04-24 08:53:32,544 : INFO : PROGRESS: at sentence #370000, processed 8615973 words, keeping 71621 word types\n",
      "2017-04-24 08:53:32,568 : INFO : collected 71866 word types from a corpus of 8713053 raw words and 374080 sentences\n",
      "2017-04-24 08:53:32,569 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 08:53:32,650 : INFO : min_count=5 retains 26312 unique words (36% of original 71866, drops 45554)\n",
      "2017-04-24 08:53:32,652 : INFO : min_count=5 leaves 8637273 word corpus (99% of original 8713053, drops 75780)\n",
      "2017-04-24 08:53:32,717 : INFO : deleting the raw counts dictionary of 71866 items\n",
      "2017-04-24 08:53:32,722 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2017-04-24 08:53:32,722 : INFO : downsampling leaves estimated 6536414 word corpus (75.7% of prior 8637273)\n",
      "2017-04-24 08:53:32,723 : INFO : estimated required memory for 26312 words and 300 dimensions: 76304800 bytes\n",
      "2017-04-24 08:53:32,832 : INFO : resetting layer weights\n",
      "2017-04-24 08:53:33,152 : INFO : training model with 4 workers on 26312 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 08:53:33,153 : INFO : expecting 374080 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 08:53:34,176 : INFO : PROGRESS: at 1.85% examples, 587529 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:53:35,182 : INFO : PROGRESS: at 3.63% examples, 579914 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:53:36,188 : INFO : PROGRESS: at 5.70% examples, 606829 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:37,190 : INFO : PROGRESS: at 7.66% examples, 613689 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:38,200 : INFO : PROGRESS: at 9.24% examples, 591672 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:39,215 : INFO : PROGRESS: at 10.99% examples, 587729 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:40,228 : INFO : PROGRESS: at 13.38% examples, 615017 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:41,245 : INFO : PROGRESS: at 15.29% examples, 615603 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:42,249 : INFO : PROGRESS: at 17.16% examples, 615353 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 08:53:43,255 : INFO : PROGRESS: at 19.58% examples, 633618 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:53:44,260 : INFO : PROGRESS: at 21.33% examples, 627482 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:45,266 : INFO : PROGRESS: at 23.37% examples, 629660 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:53:46,270 : INFO : PROGRESS: at 25.25% examples, 627660 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:47,276 : INFO : PROGRESS: at 27.16% examples, 626897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:48,289 : INFO : PROGRESS: at 29.11% examples, 626433 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:49,291 : INFO : PROGRESS: at 31.01% examples, 626116 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:50,296 : INFO : PROGRESS: at 32.69% examples, 621839 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:51,335 : INFO : PROGRESS: at 34.03% examples, 610692 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:52,346 : INFO : PROGRESS: at 35.67% examples, 606662 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 08:53:53,350 : INFO : PROGRESS: at 37.31% examples, 603277 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:53:54,351 : INFO : PROGRESS: at 39.09% examples, 602780 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:55,361 : INFO : PROGRESS: at 40.93% examples, 602339 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:56,370 : INFO : PROGRESS: at 42.78% examples, 601952 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:57,390 : INFO : PROGRESS: at 44.68% examples, 601877 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:53:58,395 : INFO : PROGRESS: at 46.55% examples, 601919 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:53:59,402 : INFO : PROGRESS: at 48.36% examples, 601024 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:00,406 : INFO : PROGRESS: at 50.13% examples, 600034 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:01,417 : INFO : PROGRESS: at 51.84% examples, 598476 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:02,418 : INFO : PROGRESS: at 53.52% examples, 596987 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:03,446 : INFO : PROGRESS: at 55.22% examples, 595309 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:54:04,471 : INFO : PROGRESS: at 56.96% examples, 594043 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:05,473 : INFO : PROGRESS: at 58.68% examples, 593280 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:06,483 : INFO : PROGRESS: at 60.43% examples, 592624 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:07,483 : INFO : PROGRESS: at 62.14% examples, 591473 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:54:08,490 : INFO : PROGRESS: at 63.97% examples, 591341 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:09,516 : INFO : PROGRESS: at 65.78% examples, 590689 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:54:10,548 : INFO : PROGRESS: at 67.58% examples, 589971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:11,570 : INFO : PROGRESS: at 69.32% examples, 588871 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:12,587 : INFO : PROGRESS: at 71.10% examples, 588526 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:13,607 : INFO : PROGRESS: at 72.62% examples, 586127 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:14,608 : INFO : PROGRESS: at 74.63% examples, 587929 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 08:54:15,620 : INFO : PROGRESS: at 76.22% examples, 586295 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:16,629 : INFO : PROGRESS: at 77.94% examples, 585818 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:17,665 : INFO : PROGRESS: at 79.60% examples, 584497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:18,665 : INFO : PROGRESS: at 81.19% examples, 582992 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:19,669 : INFO : PROGRESS: at 82.78% examples, 581483 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:20,695 : INFO : PROGRESS: at 84.52% examples, 580744 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:21,704 : INFO : PROGRESS: at 86.26% examples, 580218 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:22,709 : INFO : PROGRESS: at 88.08% examples, 580361 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 08:54:23,711 : INFO : PROGRESS: at 89.77% examples, 579662 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 08:54:24,717 : INFO : PROGRESS: at 91.38% examples, 578688 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:25,719 : INFO : PROGRESS: at 93.09% examples, 578371 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:26,721 : INFO : PROGRESS: at 94.66% examples, 577224 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:27,734 : INFO : PROGRESS: at 96.46% examples, 577379 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:28,735 : INFO : PROGRESS: at 98.02% examples, 576303 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:29,747 : INFO : PROGRESS: at 99.63% examples, 575418 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 08:54:29,897 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 08:54:29,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 08:54:29,910 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 08:54:29,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 08:54:29,916 : INFO : training on 43565265 raw words (32684066 effective words) took 56.8s, 575844 effective words/s\n",
      "2017-04-24 08:54:29,917 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 08:54:30,071 : INFO : saving Word2Vec object under Results/dros_yeast_BE_comb_model, separately None\n",
      "2017-04-24 08:54:30,072 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 08:54:30,073 : INFO : not storing attribute cum_table\n",
      "2017-04-24 08:54:31,484 : INFO : saved Results/dros_yeast_BE_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "dros_old_SR_sentence_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "data_list = [dros_old_SR_sentence_pkl, yeast_SR_sentences_pkl]\n",
    "dros_yeast_SR_comb_model = make_w2v_model(data_list, 'dros_yeast_SR_comb_model')\n",
    "\n",
    "#Gen model\n",
    "dros_old_GEN_sentence_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "data_list = [dros_old_GEN_sentence_pkl, yeast_GEN_sentences_pkl]\n",
    "dros_yeast_GEN_comb_model = make_w2v_model(data_list, 'dros_yeast_GEN_comb_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "dros_old_BE_sentence_pkl = 'Results/drosophila/be_real.pkl'\n",
    "yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "data_list = [dros_old_BE_sentence_pkl, yeast_BE_sentences_pkl]\n",
    "dros_yeast_BE_comb_model = make_w2v_model(data_list, 'dros_yeast_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "dros_strict_real = pickle.load(open('Results/drosophila/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_SR_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_GEN_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_BE_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/dros_yeast_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/dros_yeast_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/dros_yeast_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/dros_yeast_comb/Seeded/Results/'\n",
    "errors_dros_yeast_comb = mult_open(drct, '_errors_')\n",
    "fpr_dros_yeast_comb = mult_open(drct, '_fpr_')\n",
    "tpr_dros_yeast_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error dros_yeast_comb auc=0.453 error=0.435\n",
      "Strict error dros_yeast_comb auc=0.466 error=0.435\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.515 error=0.408\n",
      "Gen error dros_yeast_comb auc=0.515 error=0.405\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.508 error=0.415\n",
      "BE error dros_yeast_comb auc=0.510 error=0.398\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.523 error=0.406\n",
      "Strict error dros_yeast_comb auc=0.535 error=0.406\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.625 error=0.376\n",
      "Gen error dros_yeast_comb auc=0.627 error=0.372\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.618 error=0.359\n",
      "BE error dros_yeast_comb auc=0.616 error=0.359\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.529 error=0.373\n",
      "Strict error dros_yeast_comb auc=0.532 error=0.379\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.564 error=0.366\n",
      "Gen error dros_yeast_comb auc=0.548 error=0.373\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.503 error=0.405\n",
      "BE error dros_yeast_comb auc=0.503 error=0.396\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.543 error=0.348\n",
      "Strict error dros_yeast_comb auc=0.519 error=0.354\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.597 error=0.338\n",
      "Gen error dros_yeast_comb auc=0.582 error=0.334\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.592 error=0.343\n",
      "BE error dros_yeast_comb auc=0.607 error=0.319\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.566 error=0.436\n",
      "Strict error dros_yeast_comb auc=0.564 error=0.410\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.593 error=0.408\n",
      "Gen error dros_yeast_comb auc=0.595 error=0.408\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.590 error=0.397\n",
      "BE error dros_yeast_comb auc=0.562 error=0.410\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.555 error=0.436\n",
      "Strict error dros_yeast_comb auc=0.561 error=0.422\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.578 error=0.408\n",
      "Gen error dros_yeast_comb auc=0.567 error=0.416\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.566 error=0.416\n",
      "BE error dros_yeast_comb auc=0.576 error=0.406\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.536 error=0.365\n",
      "Strict error dros_yeast_comb auc=0.543 error=0.360\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.604 error=0.358\n",
      "Gen error dros_yeast_comb auc=0.597 error=0.365\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.643 error=0.331\n",
      "BE error dros_yeast_comb auc=0.618 error=0.333\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.555 error=0.405\n",
      "Strict error dros_yeast_comb auc=0.549 error=0.380\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.635 error=0.338\n",
      "Gen error dros_yeast_comb auc=0.639 error=0.369\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.637 error=0.371\n",
      "BE error dros_yeast_comb auc=0.622 error=0.376\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.543 error=0.378\n",
      "Strict error dros_yeast_comb auc=0.527 error=0.381\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.578 error=0.351\n",
      "Gen error dros_yeast_comb auc=0.583 error=0.357\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.572 error=0.354\n",
      "BE error dros_yeast_comb auc=0.569 error=0.357\n",
      "\n",
      "\n",
      "Strict error dros_yeast_comb auc=0.617 error=0.371\n",
      "Strict error dros_yeast_comb auc=0.625 error=0.373\n",
      "\n",
      "\n",
      "Gen error dros_yeast_comb auc=0.644 error=0.351\n",
      "Gen error dros_yeast_comb auc=0.643 error=0.353\n",
      "\n",
      "\n",
      "BE error dros_yeast_comb auc=0.655 error=0.351\n",
      "BE error dros_yeast_comb auc=0.646 error=0.351\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_comb_strict = []\n",
    "mean_auc_dros_yeast_comb_strict = []\n",
    "mean_err_dros_yeast_comb_gen = []\n",
    "mean_auc_dros_yeast_comb_gen = []\n",
    "mean_err_dros_yeast_comb_be = []\n",
    "mean_auc_dros_yeast_comb_be = []\n",
    "for e, f, t in zip(errors_dros_yeast_comb, fpr_dros_yeast_comb, tpr_dros_yeast_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['dros_yeast_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_yeast_comb_strict.append(error_item)\n",
    "                    mean_auc_dros_yeast_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_yeast_comb_gen.append(error_item)\n",
    "                    mean_auc_dros_yeast_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_yeast_comb_be.append(error_item)\n",
    "                    mean_auc_dros_yeast_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_dros_yeast_comb_org_strict = mean_err_dros_yeast_comb_strict[0::2]\n",
    "mean_err_dros_yeast_comb_fs_strict = mean_err_dros_yeast_comb_strict[1::2]\n",
    "mean_auc_dros_yeast_comb_org_strict = mean_auc_dros_yeast_comb_strict[0::2]\n",
    "mean_auc_dros_yeast_comb_fs_strict = mean_auc_dros_yeast_comb_strict[1::2]\n",
    "\n",
    "mean_err_dros_yeast_comb_org_gen = mean_err_dros_yeast_comb_gen[0::2]\n",
    "mean_err_dros_yeast_comb_fs_gen = mean_err_dros_yeast_comb_gen[1::2]\n",
    "mean_auc_dros_yeast_comb_org_gen = mean_auc_dros_yeast_comb_gen[0::2]\n",
    "mean_auc_dros_yeast_comb_fs_gen = mean_auc_dros_yeast_comb_gen[1::2]\n",
    "\n",
    "mean_err_dros_yeast_comb_org_be = mean_err_dros_yeast_comb_be[0::2]\n",
    "mean_err_dros_yeast_comb_fs_be = mean_err_dros_yeast_comb_be[1::2]\n",
    "mean_auc_dros_yeast_comb_org_be = mean_auc_dros_yeast_comb_be[0::2]\n",
    "mean_auc_dros_yeast_comb_fs_be = mean_auc_dros_yeast_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dros_yeast_comb mean strict error original -  0.395312347178\n",
      "dros_yeast_comb mean strict error feature selection -  0.389992853789\n",
      "dros_yeast_comb mean strict AUC original -  0.5419998637\n",
      "dros_yeast_comb mean strict AUC feature selection -  0.54216191341\n",
      "\n",
      "\n",
      "dros_yeast_comb mean gen error original -  0.370317634807\n",
      "dros_yeast_comb mean gen error feature selection -  0.375421518014\n",
      "dros_yeast_comb mean gen AUC original -  0.593397457286\n",
      "dros_yeast_comb mean gen AUC feature selection -  0.589678146531\n",
      "\n",
      "\n",
      "dros_yeast_comb mean BE error original -  0.374242121677\n",
      "dros_yeast_comb mean BE error feature selection -  0.370477404356\n",
      "dros_yeast_comb mean BE AUC original -  0.588504190963\n",
      "dros_yeast_comb mean BE AUC feature selection -  0.58290578757\n"
     ]
    }
   ],
   "source": [
    "print('dros_yeast_comb mean strict error original - ', np.mean(mean_err_dros_yeast_comb_org_strict))\n",
    "print('dros_yeast_comb mean strict error feature selection - ', np.mean(mean_err_dros_yeast_comb_fs_strict))\n",
    "print('dros_yeast_comb mean strict AUC original - ', np.mean(mean_auc_dros_yeast_comb_org_strict))\n",
    "print('dros_yeast_comb mean strict AUC feature selection - ', np.mean(mean_auc_dros_yeast_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('dros_yeast_comb mean gen error original - ', np.mean(mean_err_dros_yeast_comb_org_gen))\n",
    "print('dros_yeast_comb mean gen error feature selection - ', np.mean(mean_err_dros_yeast_comb_fs_gen))\n",
    "print('dros_yeast_comb mean gen AUC original - ', np.mean(mean_auc_dros_yeast_comb_org_gen))\n",
    "print('dros_yeast_comb mean gen AUC feature selection - ', np.mean(mean_auc_dros_yeast_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('dros_yeast_comb mean BE error original - ', np.mean(mean_err_dros_yeast_comb_org_be))\n",
    "print('dros_yeast_comb mean BE error feature selection - ', np.mean(mean_err_dros_yeast_comb_fs_be))\n",
    "print('dros_yeast_comb mean BE AUC original - ', np.mean(mean_auc_dros_yeast_comb_org_be))\n",
    "print('dros_yeast_comb mean BE AUC feature selection - ', np.mean(mean_auc_dros_yeast_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 09:17:50,218 : INFO : collecting all words and their counts\n",
      "2017-04-24 09:17:50,219 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 09:17:50,272 : INFO : PROGRESS: at sentence #10000, processed 256400 words, keeping 15897 word types\n",
      "2017-04-24 09:17:50,326 : INFO : PROGRESS: at sentence #20000, processed 530355 words, keeping 24450 word types\n",
      "2017-04-24 09:17:50,385 : INFO : PROGRESS: at sentence #30000, processed 810299 words, keeping 30044 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 09:17:50,439 : INFO : PROGRESS: at sentence #40000, processed 1088558 words, keeping 34226 word types\n",
      "2017-04-24 09:17:50,501 : INFO : PROGRESS: at sentence #50000, processed 1368579 words, keeping 37761 word types\n",
      "2017-04-24 09:17:50,555 : INFO : collected 40603 word types from a corpus of 1633447 raw words and 59460 sentences\n",
      "2017-04-24 09:17:50,556 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 09:17:50,602 : INFO : min_count=5 retains 12851 unique words (31% of original 40603, drops 27752)\n",
      "2017-04-24 09:17:50,603 : INFO : min_count=5 leaves 1588822 word corpus (97% of original 1633447, drops 44625)\n",
      "2017-04-24 09:17:50,635 : INFO : deleting the raw counts dictionary of 40603 items\n",
      "2017-04-24 09:17:50,638 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2017-04-24 09:17:50,638 : INFO : downsampling leaves estimated 1220297 word corpus (76.8% of prior 1588822)\n",
      "2017-04-24 09:17:50,639 : INFO : estimated required memory for 12851 words and 300 dimensions: 37267900 bytes\n",
      "2017-04-24 09:17:50,698 : INFO : resetting layer weights\n",
      "2017-04-24 09:17:50,858 : INFO : training model with 4 workers on 12851 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 09:17:50,859 : INFO : expecting 59460 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 09:17:51,873 : INFO : PROGRESS: at 13.21% examples, 789070 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:52,874 : INFO : PROGRESS: at 24.34% examples, 729152 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:53,890 : INFO : PROGRESS: at 35.30% examples, 709543 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:54,899 : INFO : PROGRESS: at 48.12% examples, 723893 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:17:55,909 : INFO : PROGRESS: at 60.81% examples, 734718 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:56,915 : INFO : PROGRESS: at 72.99% examples, 734427 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:57,925 : INFO : PROGRESS: at 85.83% examples, 738913 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:58,931 : INFO : PROGRESS: at 97.23% examples, 735004 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:17:59,141 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 09:17:59,143 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 09:17:59,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 09:17:59,153 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 09:17:59,154 : INFO : training on 8167235 raw words (6101981 effective words) took 8.3s, 736003 effective words/s\n",
      "2017-04-24 09:17:59,155 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 09:17:59,234 : INFO : saving Word2Vec object under Results/dros_yeast_rat_SR_comb_model, separately None\n",
      "2017-04-24 09:17:59,235 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 09:17:59,236 : INFO : not storing attribute cum_table\n",
      "2017-04-24 09:17:59,529 : INFO : saved Results/dros_yeast_rat_SR_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 09:18:05,083 : INFO : collecting all words and their counts\n",
      "2017-04-24 09:18:05,085 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 09:18:05,133 : INFO : PROGRESS: at sentence #10000, processed 243767 words, keeping 13425 word types\n",
      "2017-04-24 09:18:05,186 : INFO : PROGRESS: at sentence #20000, processed 487778 words, keeping 18119 word types\n",
      "2017-04-24 09:18:05,236 : INFO : PROGRESS: at sentence #30000, processed 731472 words, keeping 21474 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 09:18:05,286 : INFO : PROGRESS: at sentence #40000, processed 974035 words, keeping 24814 word types\n",
      "2017-04-24 09:18:05,341 : INFO : PROGRESS: at sentence #50000, processed 1217621 words, keeping 27640 word types\n",
      "2017-04-24 09:18:05,389 : INFO : PROGRESS: at sentence #60000, processed 1463219 words, keeping 29731 word types\n",
      "2017-04-24 09:18:05,440 : INFO : PROGRESS: at sentence #70000, processed 1709491 words, keeping 31548 word types\n",
      "2017-04-24 09:18:05,489 : INFO : PROGRESS: at sentence #80000, processed 1957174 words, keeping 33092 word types\n",
      "2017-04-24 09:18:05,545 : INFO : PROGRESS: at sentence #90000, processed 2216968 words, keeping 37418 word types\n",
      "2017-04-24 09:18:05,601 : INFO : PROGRESS: at sentence #100000, processed 2486112 words, keeping 41533 word types\n",
      "2017-04-24 09:18:05,658 : INFO : PROGRESS: at sentence #110000, processed 2755651 words, keeping 44637 word types\n",
      "2017-04-24 09:18:05,713 : INFO : PROGRESS: at sentence #120000, processed 3026544 words, keeping 47212 word types\n",
      "2017-04-24 09:18:05,770 : INFO : PROGRESS: at sentence #130000, processed 3298755 words, keeping 49569 word types\n",
      "2017-04-24 09:18:05,825 : INFO : PROGRESS: at sentence #140000, processed 3568859 words, keeping 51672 word types\n",
      "2017-04-24 09:18:05,881 : INFO : PROGRESS: at sentence #150000, processed 3838811 words, keeping 53544 word types\n",
      "2017-04-24 09:18:05,939 : INFO : PROGRESS: at sentence #160000, processed 4108857 words, keeping 55196 word types\n",
      "2017-04-24 09:18:05,991 : INFO : PROGRESS: at sentence #170000, processed 4378948 words, keeping 56819 word types\n",
      "2017-04-24 09:18:06,044 : INFO : PROGRESS: at sentence #180000, processed 4647762 words, keeping 58467 word types\n",
      "2017-04-24 09:18:06,097 : INFO : PROGRESS: at sentence #190000, processed 4917214 words, keeping 59924 word types\n",
      "2017-04-24 09:18:06,150 : INFO : PROGRESS: at sentence #200000, processed 5186810 words, keeping 61307 word types\n",
      "2017-04-24 09:18:06,203 : INFO : PROGRESS: at sentence #210000, processed 5456613 words, keeping 62634 word types\n",
      "2017-04-24 09:18:06,255 : INFO : PROGRESS: at sentence #220000, processed 5726463 words, keeping 63929 word types\n",
      "2017-04-24 09:18:06,309 : INFO : PROGRESS: at sentence #230000, processed 5997008 words, keeping 65146 word types\n",
      "2017-04-24 09:18:06,376 : INFO : PROGRESS: at sentence #240000, processed 6266288 words, keeping 66287 word types\n",
      "2017-04-24 09:18:06,448 : INFO : PROGRESS: at sentence #250000, processed 6536042 words, keeping 67485 word types\n",
      "2017-04-24 09:18:06,506 : INFO : PROGRESS: at sentence #260000, processed 6805884 words, keeping 68514 word types\n",
      "2017-04-24 09:18:06,528 : INFO : collected 68948 word types from a corpus of 6908181 raw words and 263772 sentences\n",
      "2017-04-24 09:18:06,530 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 09:18:06,606 : INFO : min_count=5 retains 24735 unique words (35% of original 68948, drops 44213)\n",
      "2017-04-24 09:18:06,607 : INFO : min_count=5 leaves 6835627 word corpus (98% of original 6908181, drops 72554)\n",
      "2017-04-24 09:18:06,668 : INFO : deleting the raw counts dictionary of 68948 items\n",
      "2017-04-24 09:18:06,672 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2017-04-24 09:18:06,673 : INFO : downsampling leaves estimated 5229343 word corpus (76.5% of prior 6835627)\n",
      "2017-04-24 09:18:06,674 : INFO : estimated required memory for 24735 words and 300 dimensions: 71731500 bytes\n",
      "2017-04-24 09:18:06,773 : INFO : resetting layer weights\n",
      "2017-04-24 09:18:07,069 : INFO : training model with 4 workers on 24735 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 09:18:07,069 : INFO : expecting 263772 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 09:18:08,076 : INFO : PROGRESS: at 2.67% examples, 643793 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:09,078 : INFO : PROGRESS: at 5.79% examples, 700926 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:18:10,086 : INFO : PROGRESS: at 8.73% examples, 725042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:11,091 : INFO : PROGRESS: at 11.47% examples, 728501 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:12,108 : INFO : PROGRESS: at 14.34% examples, 735060 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:18:13,109 : INFO : PROGRESS: at 17.28% examples, 744934 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:14,112 : INFO : PROGRESS: at 19.92% examples, 739992 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:15,115 : INFO : PROGRESS: at 22.86% examples, 736408 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:16,120 : INFO : PROGRESS: at 25.64% examples, 729408 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:17,121 : INFO : PROGRESS: at 27.75% examples, 711671 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:18:18,124 : INFO : PROGRESS: at 29.79% examples, 697085 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:18:19,131 : INFO : PROGRESS: at 32.15% examples, 691719 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:20,134 : INFO : PROGRESS: at 34.37% examples, 684424 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:21,143 : INFO : PROGRESS: at 36.61% examples, 678389 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:22,165 : INFO : PROGRESS: at 39.08% examples, 676656 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:23,173 : INFO : PROGRESS: at 41.71% examples, 675431 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:24,188 : INFO : PROGRESS: at 44.29% examples, 671783 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:18:25,193 : INFO : PROGRESS: at 46.77% examples, 668571 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:18:26,195 : INFO : PROGRESS: at 49.07% examples, 666077 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:27,214 : INFO : PROGRESS: at 51.59% examples, 666186 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:28,252 : INFO : PROGRESS: at 53.72% examples, 660746 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:18:29,268 : INFO : PROGRESS: at 55.89% examples, 656775 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:30,274 : INFO : PROGRESS: at 58.44% examples, 658031 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:31,291 : INFO : PROGRESS: at 61.10% examples, 658756 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:18:32,292 : INFO : PROGRESS: at 63.99% examples, 660323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:33,298 : INFO : PROGRESS: at 66.97% examples, 663442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:34,303 : INFO : PROGRESS: at 69.60% examples, 665111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:35,329 : INFO : PROGRESS: at 72.32% examples, 666969 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:36,329 : INFO : PROGRESS: at 75.16% examples, 670332 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:18:37,344 : INFO : PROGRESS: at 77.80% examples, 671401 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:38,346 : INFO : PROGRESS: at 80.48% examples, 672645 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:39,347 : INFO : PROGRESS: at 83.59% examples, 675043 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:40,351 : INFO : PROGRESS: at 86.56% examples, 676568 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:18:41,356 : INFO : PROGRESS: at 89.22% examples, 677748 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:42,357 : INFO : PROGRESS: at 91.46% examples, 675698 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:18:43,371 : INFO : PROGRESS: at 93.98% examples, 675598 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:18:44,375 : INFO : PROGRESS: at 96.65% examples, 676702 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:18:45,381 : INFO : PROGRESS: at 98.87% examples, 674578 words/s, in_qsize 8, out_qsize 3\n",
      "2017-04-24 09:18:45,886 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 09:18:45,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 09:18:45,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 09:18:45,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 09:18:45,912 : INFO : training on 34540905 raw words (26147762 effective words) took 38.8s, 673261 effective words/s\n",
      "2017-04-24 09:18:45,913 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 09:18:46,087 : INFO : saving Word2Vec object under Results/dros_yeast_rat_GEN_comb_model, separately None\n",
      "2017-04-24 09:18:46,088 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 09:18:46,088 : INFO : not storing attribute cum_table\n",
      "2017-04-24 09:18:46,881 : INFO : saved Results/dros_yeast_rat_GEN_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 09:19:19,050 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 09:19:19,509 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 09:19:19,551 : INFO : PROGRESS: at sentence #10000, processed 229788 words, keeping 14470 word types\n",
      "2017-04-24 09:19:19,594 : INFO : PROGRESS: at sentence #20000, processed 460388 words, keeping 19917 word types\n",
      "2017-04-24 09:19:19,643 : INFO : PROGRESS: at sentence #30000, processed 690788 words, keeping 23764 word types\n",
      "2017-04-24 09:19:19,687 : INFO : PROGRESS: at sentence #40000, processed 922942 words, keeping 27008 word types\n",
      "2017-04-24 09:19:19,734 : INFO : PROGRESS: at sentence #50000, processed 1153814 words, keeping 29788 word types\n",
      "2017-04-24 09:19:19,780 : INFO : PROGRESS: at sentence #60000, processed 1384782 words, keeping 32176 word types\n",
      "2017-04-24 09:19:19,825 : INFO : PROGRESS: at sentence #70000, processed 1615191 words, keeping 34406 word types\n",
      "2017-04-24 09:19:19,875 : INFO : PROGRESS: at sentence #80000, processed 1846457 words, keeping 36392 word types\n",
      "2017-04-24 09:19:19,923 : INFO : PROGRESS: at sentence #90000, processed 2075150 words, keeping 38166 word types\n",
      "2017-04-24 09:19:19,971 : INFO : PROGRESS: at sentence #100000, processed 2305071 words, keeping 39733 word types\n",
      "2017-04-24 09:19:20,016 : INFO : PROGRESS: at sentence #110000, processed 2536428 words, keeping 41192 word types\n",
      "2017-04-24 09:19:20,063 : INFO : PROGRESS: at sentence #120000, processed 2767447 words, keeping 42645 word types\n",
      "2017-04-24 09:19:20,111 : INFO : PROGRESS: at sentence #130000, processed 2998492 words, keeping 44044 word types\n",
      "2017-04-24 09:19:20,156 : INFO : PROGRESS: at sentence #140000, processed 3230188 words, keeping 45345 word types\n",
      "2017-04-24 09:19:20,205 : INFO : PROGRESS: at sentence #150000, processed 3460267 words, keeping 46545 word types\n",
      "2017-04-24 09:19:20,250 : INFO : PROGRESS: at sentence #160000, processed 3689650 words, keeping 47678 word types\n",
      "2017-04-24 09:19:20,294 : INFO : PROGRESS: at sentence #170000, processed 3920110 words, keeping 48786 word types\n",
      "2017-04-24 09:19:20,343 : INFO : PROGRESS: at sentence #180000, processed 4151938 words, keeping 50038 word types\n",
      "2017-04-24 09:19:20,392 : INFO : PROGRESS: at sentence #190000, processed 4387466 words, keeping 52511 word types\n",
      "2017-04-24 09:19:20,441 : INFO : PROGRESS: at sentence #200000, processed 4621579 words, keeping 54515 word types\n",
      "2017-04-24 09:19:20,490 : INFO : PROGRESS: at sentence #210000, processed 4856235 words, keeping 56178 word types\n",
      "2017-04-24 09:19:20,540 : INFO : PROGRESS: at sentence #220000, processed 5090984 words, keeping 57585 word types\n",
      "2017-04-24 09:19:20,588 : INFO : PROGRESS: at sentence #230000, processed 5326844 words, keeping 58973 word types\n",
      "2017-04-24 09:19:20,637 : INFO : PROGRESS: at sentence #240000, processed 5559987 words, keeping 60198 word types\n",
      "2017-04-24 09:19:20,684 : INFO : PROGRESS: at sentence #250000, processed 5795841 words, keeping 61320 word types\n",
      "2017-04-24 09:19:20,729 : INFO : PROGRESS: at sentence #260000, processed 6029354 words, keeping 62324 word types\n",
      "2017-04-24 09:19:20,776 : INFO : PROGRESS: at sentence #270000, processed 6264512 words, keeping 63360 word types\n",
      "2017-04-24 09:19:20,821 : INFO : PROGRESS: at sentence #280000, processed 6500455 words, keeping 64377 word types\n",
      "2017-04-24 09:19:20,869 : INFO : PROGRESS: at sentence #290000, processed 6734783 words, keeping 65349 word types\n",
      "2017-04-24 09:19:20,914 : INFO : PROGRESS: at sentence #300000, processed 6968095 words, keeping 66255 word types\n",
      "2017-04-24 09:19:20,959 : INFO : PROGRESS: at sentence #310000, processed 7204108 words, keeping 67143 word types\n",
      "2017-04-24 09:19:21,008 : INFO : PROGRESS: at sentence #320000, processed 7438064 words, keeping 67940 word types\n",
      "2017-04-24 09:19:21,053 : INFO : PROGRESS: at sentence #330000, processed 7674525 words, keeping 68733 word types\n",
      "2017-04-24 09:19:21,102 : INFO : PROGRESS: at sentence #340000, processed 7910373 words, keeping 69482 word types\n",
      "2017-04-24 09:19:21,150 : INFO : PROGRESS: at sentence #350000, processed 8145924 words, keeping 70174 word types\n",
      "2017-04-24 09:19:21,196 : INFO : PROGRESS: at sentence #360000, processed 8382233 words, keeping 70899 word types\n",
      "2017-04-24 09:19:21,249 : INFO : PROGRESS: at sentence #370000, processed 8615973 words, keeping 71621 word types\n",
      "2017-04-24 09:19:21,304 : INFO : PROGRESS: at sentence #380000, processed 8859975 words, keeping 74317 word types\n",
      "2017-04-24 09:19:21,361 : INFO : PROGRESS: at sentence #390000, processed 9107314 words, keeping 77181 word types\n",
      "2017-04-24 09:19:21,412 : INFO : PROGRESS: at sentence #400000, processed 9354552 words, keeping 79569 word types\n",
      "2017-04-24 09:19:21,472 : INFO : PROGRESS: at sentence #410000, processed 9599850 words, keeping 81622 word types\n",
      "2017-04-24 09:19:21,521 : INFO : PROGRESS: at sentence #420000, processed 9848380 words, keeping 83589 word types\n",
      "2017-04-24 09:19:21,574 : INFO : PROGRESS: at sentence #430000, processed 10095385 words, keeping 85312 word types\n",
      "2017-04-24 09:19:21,626 : INFO : PROGRESS: at sentence #440000, processed 10343286 words, keeping 87019 word types\n",
      "2017-04-24 09:19:21,685 : INFO : PROGRESS: at sentence #450000, processed 10590892 words, keeping 88545 word types\n",
      "2017-04-24 09:19:21,736 : INFO : PROGRESS: at sentence #460000, processed 10837229 words, keeping 90004 word types\n",
      "2017-04-24 09:19:21,787 : INFO : PROGRESS: at sentence #470000, processed 11085887 words, keeping 91349 word types\n",
      "2017-04-24 09:19:21,840 : INFO : PROGRESS: at sentence #480000, processed 11333829 words, keeping 92703 word types\n",
      "2017-04-24 09:19:21,891 : INFO : PROGRESS: at sentence #490000, processed 11581573 words, keeping 94039 word types\n",
      "2017-04-24 09:19:21,944 : INFO : PROGRESS: at sentence #500000, processed 11830799 words, keeping 95307 word types\n",
      "2017-04-24 09:19:21,995 : INFO : PROGRESS: at sentence #510000, processed 12076669 words, keeping 96541 word types\n",
      "2017-04-24 09:19:22,048 : INFO : PROGRESS: at sentence #520000, processed 12323309 words, keeping 97715 word types\n",
      "2017-04-24 09:19:22,099 : INFO : PROGRESS: at sentence #530000, processed 12570810 words, keeping 98754 word types\n",
      "2017-04-24 09:19:22,154 : INFO : PROGRESS: at sentence #540000, processed 12818358 words, keeping 99923 word types\n",
      "2017-04-24 09:19:22,207 : INFO : PROGRESS: at sentence #550000, processed 13066192 words, keeping 101054 word types\n",
      "2017-04-24 09:19:22,259 : INFO : PROGRESS: at sentence #560000, processed 13314478 words, keeping 102075 word types\n",
      "2017-04-24 09:19:22,311 : INFO : PROGRESS: at sentence #570000, processed 13562500 words, keeping 103114 word types\n",
      "2017-04-24 09:19:22,362 : INFO : PROGRESS: at sentence #580000, processed 13810344 words, keeping 104129 word types\n",
      "2017-04-24 09:19:22,418 : INFO : PROGRESS: at sentence #590000, processed 14056635 words, keeping 105019 word types\n",
      "2017-04-24 09:19:22,473 : INFO : PROGRESS: at sentence #600000, processed 14304343 words, keeping 105969 word types\n",
      "2017-04-24 09:19:22,525 : INFO : PROGRESS: at sentence #610000, processed 14549707 words, keeping 106919 word types\n",
      "2017-04-24 09:19:22,577 : INFO : PROGRESS: at sentence #620000, processed 14797594 words, keeping 107852 word types\n",
      "2017-04-24 09:19:22,628 : INFO : PROGRESS: at sentence #630000, processed 15043102 words, keeping 108755 word types\n",
      "2017-04-24 09:19:22,685 : INFO : PROGRESS: at sentence #640000, processed 15292732 words, keeping 109631 word types\n",
      "2017-04-24 09:19:22,742 : INFO : PROGRESS: at sentence #650000, processed 15539878 words, keeping 110491 word types\n",
      "2017-04-24 09:19:22,802 : INFO : PROGRESS: at sentence #660000, processed 15787376 words, keeping 111382 word types\n",
      "2017-04-24 09:19:22,852 : INFO : PROGRESS: at sentence #670000, processed 16033400 words, keeping 112182 word types\n",
      "2017-04-24 09:19:22,903 : INFO : PROGRESS: at sentence #680000, processed 16280957 words, keeping 112997 word types\n",
      "2017-04-24 09:19:22,984 : INFO : PROGRESS: at sentence #690000, processed 16527856 words, keeping 113733 word types\n",
      "2017-04-24 09:19:23,046 : INFO : PROGRESS: at sentence #700000, processed 16773865 words, keeping 114535 word types\n",
      "2017-04-24 09:19:23,127 : INFO : PROGRESS: at sentence #710000, processed 17021168 words, keeping 115335 word types\n",
      "2017-04-24 09:19:23,194 : INFO : PROGRESS: at sentence #720000, processed 17268230 words, keeping 116138 word types\n",
      "2017-04-24 09:19:23,257 : INFO : PROGRESS: at sentence #730000, processed 17515757 words, keeping 116919 word types\n",
      "2017-04-24 09:19:23,314 : INFO : PROGRESS: at sentence #740000, processed 17764941 words, keeping 117592 word types\n",
      "2017-04-24 09:19:23,370 : INFO : PROGRESS: at sentence #750000, processed 18012664 words, keeping 118340 word types\n",
      "2017-04-24 09:19:23,432 : INFO : PROGRESS: at sentence #760000, processed 18263440 words, keeping 119119 word types\n",
      "2017-04-24 09:19:23,489 : INFO : PROGRESS: at sentence #770000, processed 18511091 words, keeping 119832 word types\n",
      "2017-04-24 09:19:23,552 : INFO : PROGRESS: at sentence #780000, processed 18760929 words, keeping 120553 word types\n",
      "2017-04-24 09:19:23,612 : INFO : PROGRESS: at sentence #790000, processed 19008090 words, keeping 121249 word types\n",
      "2017-04-24 09:19:23,672 : INFO : PROGRESS: at sentence #800000, processed 19255191 words, keeping 121960 word types\n",
      "2017-04-24 09:19:23,731 : INFO : PROGRESS: at sentence #810000, processed 19503489 words, keeping 122615 word types\n",
      "2017-04-24 09:19:23,789 : INFO : PROGRESS: at sentence #820000, processed 19752585 words, keeping 123349 word types\n",
      "2017-04-24 09:19:23,847 : INFO : PROGRESS: at sentence #830000, processed 19998367 words, keeping 124025 word types\n",
      "2017-04-24 09:19:23,903 : INFO : PROGRESS: at sentence #840000, processed 20245101 words, keeping 124664 word types\n",
      "2017-04-24 09:19:23,968 : INFO : PROGRESS: at sentence #850000, processed 20493114 words, keeping 125262 word types\n",
      "2017-04-24 09:19:24,026 : INFO : PROGRESS: at sentence #860000, processed 20740579 words, keeping 125868 word types\n",
      "2017-04-24 09:19:24,080 : INFO : PROGRESS: at sentence #870000, processed 20986975 words, keeping 126462 word types\n",
      "2017-04-24 09:19:24,151 : INFO : PROGRESS: at sentence #880000, processed 21234125 words, keeping 127124 word types\n",
      "2017-04-24 09:19:24,214 : INFO : PROGRESS: at sentence #890000, processed 21481222 words, keeping 127744 word types\n",
      "2017-04-24 09:19:24,274 : INFO : PROGRESS: at sentence #900000, processed 21728804 words, keeping 128311 word types\n",
      "2017-04-24 09:19:24,329 : INFO : PROGRESS: at sentence #910000, processed 21975148 words, keeping 128970 word types\n",
      "2017-04-24 09:19:24,386 : INFO : PROGRESS: at sentence #920000, processed 22222043 words, keeping 129622 word types\n",
      "2017-04-24 09:19:24,444 : INFO : PROGRESS: at sentence #930000, processed 22469438 words, keeping 130193 word types\n",
      "2017-04-24 09:19:24,502 : INFO : PROGRESS: at sentence #940000, processed 22716843 words, keeping 130839 word types\n",
      "2017-04-24 09:19:24,561 : INFO : PROGRESS: at sentence #950000, processed 22963699 words, keeping 131405 word types\n",
      "2017-04-24 09:19:24,621 : INFO : PROGRESS: at sentence #960000, processed 23209704 words, keeping 132015 word types\n",
      "2017-04-24 09:19:24,679 : INFO : PROGRESS: at sentence #970000, processed 23459002 words, keeping 132605 word types\n",
      "2017-04-24 09:19:24,737 : INFO : PROGRESS: at sentence #980000, processed 23708697 words, keeping 133221 word types\n",
      "2017-04-24 09:19:24,793 : INFO : PROGRESS: at sentence #990000, processed 23957189 words, keeping 133787 word types\n",
      "2017-04-24 09:19:24,849 : INFO : PROGRESS: at sentence #1000000, processed 24206108 words, keeping 134351 word types\n",
      "2017-04-24 09:19:24,906 : INFO : PROGRESS: at sentence #1010000, processed 24451694 words, keeping 134927 word types\n",
      "2017-04-24 09:19:24,963 : INFO : PROGRESS: at sentence #1020000, processed 24700280 words, keeping 135456 word types\n",
      "2017-04-24 09:19:25,021 : INFO : PROGRESS: at sentence #1030000, processed 24947172 words, keeping 136016 word types\n",
      "2017-04-24 09:19:25,079 : INFO : PROGRESS: at sentence #1040000, processed 25196211 words, keeping 136548 word types\n",
      "2017-04-24 09:19:25,138 : INFO : PROGRESS: at sentence #1050000, processed 25443593 words, keeping 137156 word types\n",
      "2017-04-24 09:19:25,199 : INFO : PROGRESS: at sentence #1060000, processed 25689867 words, keeping 137758 word types\n",
      "2017-04-24 09:19:25,259 : INFO : PROGRESS: at sentence #1070000, processed 25936832 words, keeping 138263 word types\n",
      "2017-04-24 09:19:25,316 : INFO : PROGRESS: at sentence #1080000, processed 26184536 words, keeping 138849 word types\n",
      "2017-04-24 09:19:25,374 : INFO : PROGRESS: at sentence #1090000, processed 26431323 words, keeping 139316 word types\n",
      "2017-04-24 09:19:25,432 : INFO : PROGRESS: at sentence #1100000, processed 26677404 words, keeping 139923 word types\n",
      "2017-04-24 09:19:25,488 : INFO : PROGRESS: at sentence #1110000, processed 26924214 words, keeping 140381 word types\n",
      "2017-04-24 09:19:25,545 : INFO : PROGRESS: at sentence #1120000, processed 27171845 words, keeping 140862 word types\n",
      "2017-04-24 09:19:25,603 : INFO : PROGRESS: at sentence #1130000, processed 27417409 words, keeping 141329 word types\n",
      "2017-04-24 09:19:25,659 : INFO : PROGRESS: at sentence #1140000, processed 27663165 words, keeping 141829 word types\n",
      "2017-04-24 09:19:25,716 : INFO : PROGRESS: at sentence #1150000, processed 27911206 words, keeping 142353 word types\n",
      "2017-04-24 09:19:25,774 : INFO : PROGRESS: at sentence #1160000, processed 28158765 words, keeping 142884 word types\n",
      "2017-04-24 09:19:25,830 : INFO : PROGRESS: at sentence #1170000, processed 28405337 words, keeping 143355 word types\n",
      "2017-04-24 09:19:25,886 : INFO : PROGRESS: at sentence #1180000, processed 28652014 words, keeping 143823 word types\n",
      "2017-04-24 09:19:25,943 : INFO : PROGRESS: at sentence #1190000, processed 28899164 words, keeping 144353 word types\n",
      "2017-04-24 09:19:25,996 : INFO : PROGRESS: at sentence #1200000, processed 29148450 words, keeping 144895 word types\n",
      "2017-04-24 09:19:26,055 : INFO : PROGRESS: at sentence #1210000, processed 29397106 words, keeping 145413 word types\n",
      "2017-04-24 09:19:26,110 : INFO : PROGRESS: at sentence #1220000, processed 29645475 words, keeping 145920 word types\n",
      "2017-04-24 09:19:26,168 : INFO : PROGRESS: at sentence #1230000, processed 29890778 words, keeping 146395 word types\n",
      "2017-04-24 09:19:26,225 : INFO : PROGRESS: at sentence #1240000, processed 30139783 words, keeping 146860 word types\n",
      "2017-04-24 09:19:26,281 : INFO : PROGRESS: at sentence #1250000, processed 30387380 words, keeping 147320 word types\n",
      "2017-04-24 09:19:26,337 : INFO : PROGRESS: at sentence #1260000, processed 30637005 words, keeping 147778 word types\n",
      "2017-04-24 09:19:26,393 : INFO : PROGRESS: at sentence #1270000, processed 30884468 words, keeping 148250 word types\n",
      "2017-04-24 09:19:26,450 : INFO : PROGRESS: at sentence #1280000, processed 31132586 words, keeping 148756 word types\n",
      "2017-04-24 09:19:26,508 : INFO : PROGRESS: at sentence #1290000, processed 31379371 words, keeping 149243 word types\n",
      "2017-04-24 09:19:26,564 : INFO : PROGRESS: at sentence #1300000, processed 31627379 words, keeping 149675 word types\n",
      "2017-04-24 09:19:26,623 : INFO : PROGRESS: at sentence #1310000, processed 31873779 words, keeping 150103 word types\n",
      "2017-04-24 09:19:26,680 : INFO : PROGRESS: at sentence #1320000, processed 32120961 words, keeping 150547 word types\n",
      "2017-04-24 09:19:26,739 : INFO : PROGRESS: at sentence #1330000, processed 32369130 words, keeping 150991 word types\n",
      "2017-04-24 09:19:26,793 : INFO : PROGRESS: at sentence #1340000, processed 32616735 words, keeping 151511 word types\n",
      "2017-04-24 09:19:26,849 : INFO : PROGRESS: at sentence #1350000, processed 32864180 words, keeping 151954 word types\n",
      "2017-04-24 09:19:26,906 : INFO : PROGRESS: at sentence #1360000, processed 33109929 words, keeping 152421 word types\n",
      "2017-04-24 09:19:26,963 : INFO : PROGRESS: at sentence #1370000, processed 33356697 words, keeping 152873 word types\n",
      "2017-04-24 09:19:27,021 : INFO : PROGRESS: at sentence #1380000, processed 33604270 words, keeping 153318 word types\n",
      "2017-04-24 09:19:27,078 : INFO : PROGRESS: at sentence #1390000, processed 33849564 words, keeping 153714 word types\n",
      "2017-04-24 09:19:27,139 : INFO : PROGRESS: at sentence #1400000, processed 34095929 words, keeping 154125 word types\n",
      "2017-04-24 09:19:27,195 : INFO : PROGRESS: at sentence #1410000, processed 34343746 words, keeping 154564 word types\n",
      "2017-04-24 09:19:27,254 : INFO : PROGRESS: at sentence #1420000, processed 34590979 words, keeping 154969 word types\n",
      "2017-04-24 09:19:27,311 : INFO : PROGRESS: at sentence #1430000, processed 34837287 words, keeping 155368 word types\n",
      "2017-04-24 09:19:27,369 : INFO : PROGRESS: at sentence #1440000, processed 35086337 words, keeping 155741 word types\n",
      "2017-04-24 09:19:27,426 : INFO : PROGRESS: at sentence #1450000, processed 35333810 words, keeping 156182 word types\n",
      "2017-04-24 09:19:27,497 : INFO : PROGRESS: at sentence #1460000, processed 35581789 words, keeping 156597 word types\n",
      "2017-04-24 09:19:27,554 : INFO : PROGRESS: at sentence #1470000, processed 35829668 words, keeping 157004 word types\n",
      "2017-04-24 09:19:27,610 : INFO : PROGRESS: at sentence #1480000, processed 36076237 words, keeping 157375 word types\n",
      "2017-04-24 09:19:27,664 : INFO : PROGRESS: at sentence #1490000, processed 36323842 words, keeping 157772 word types\n",
      "2017-04-24 09:19:27,723 : INFO : PROGRESS: at sentence #1500000, processed 36570534 words, keeping 158129 word types\n",
      "2017-04-24 09:19:27,781 : INFO : PROGRESS: at sentence #1510000, processed 36818361 words, keeping 158579 word types\n",
      "2017-04-24 09:19:27,840 : INFO : PROGRESS: at sentence #1520000, processed 37066359 words, keeping 158968 word types\n",
      "2017-04-24 09:19:27,897 : INFO : PROGRESS: at sentence #1530000, processed 37314601 words, keeping 159327 word types\n",
      "2017-04-24 09:19:27,953 : INFO : PROGRESS: at sentence #1540000, processed 37560303 words, keeping 159744 word types\n",
      "2017-04-24 09:19:28,013 : INFO : PROGRESS: at sentence #1550000, processed 37809405 words, keeping 160145 word types\n",
      "2017-04-24 09:19:28,070 : INFO : PROGRESS: at sentence #1560000, processed 38055679 words, keeping 160523 word types\n",
      "2017-04-24 09:19:28,122 : INFO : PROGRESS: at sentence #1570000, processed 38302008 words, keeping 160920 word types\n",
      "2017-04-24 09:19:28,178 : INFO : PROGRESS: at sentence #1580000, processed 38550745 words, keeping 161287 word types\n",
      "2017-04-24 09:19:28,233 : INFO : PROGRESS: at sentence #1590000, processed 38796570 words, keeping 161662 word types\n",
      "2017-04-24 09:19:28,289 : INFO : PROGRESS: at sentence #1600000, processed 39043771 words, keeping 162025 word types\n",
      "2017-04-24 09:19:28,343 : INFO : PROGRESS: at sentence #1610000, processed 39289427 words, keeping 162391 word types\n",
      "2017-04-24 09:19:28,397 : INFO : PROGRESS: at sentence #1620000, processed 39537841 words, keeping 162739 word types\n",
      "2017-04-24 09:19:28,423 : INFO : collected 162897 word types from a corpus of 39639947 raw words and 1624089 sentences\n",
      "2017-04-24 09:19:28,424 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 09:19:28,591 : INFO : min_count=5 retains 57399 unique words (35% of original 162897, drops 105498)\n",
      "2017-04-24 09:19:28,592 : INFO : min_count=5 leaves 39466786 word corpus (99% of original 39639947, drops 173161)\n",
      "2017-04-24 09:19:28,729 : INFO : deleting the raw counts dictionary of 162897 items\n",
      "2017-04-24 09:19:28,741 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2017-04-24 09:19:28,742 : INFO : downsampling leaves estimated 30541664 word corpus (77.4% of prior 39466786)\n",
      "2017-04-24 09:19:28,742 : INFO : estimated required memory for 57399 words and 300 dimensions: 166457100 bytes\n",
      "2017-04-24 09:19:28,970 : INFO : resetting layer weights\n",
      "2017-04-24 09:19:29,716 : INFO : training model with 4 workers on 57399 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 09:19:29,716 : INFO : expecting 1624089 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 09:19:30,726 : INFO : PROGRESS: at 0.44% examples, 632619 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:31,732 : INFO : PROGRESS: at 0.93% examples, 662805 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:32,746 : INFO : PROGRESS: at 1.40% examples, 663307 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 09:19:33,756 : INFO : PROGRESS: at 1.87% examples, 664437 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:34,757 : INFO : PROGRESS: at 2.34% examples, 667702 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:35,760 : INFO : PROGRESS: at 2.79% examples, 666892 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:36,772 : INFO : PROGRESS: at 3.26% examples, 667827 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:37,781 : INFO : PROGRESS: at 3.72% examples, 667759 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:38,786 : INFO : PROGRESS: at 4.21% examples, 672211 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:39,790 : INFO : PROGRESS: at 4.59% examples, 661476 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 09:19:40,816 : INFO : PROGRESS: at 4.95% examples, 649537 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:19:41,817 : INFO : PROGRESS: at 5.26% examples, 635932 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:42,826 : INFO : PROGRESS: at 5.64% examples, 631616 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:19:43,830 : INFO : PROGRESS: at 6.00% examples, 626013 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:44,852 : INFO : PROGRESS: at 6.42% examples, 627513 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:45,860 : INFO : PROGRESS: at 6.88% examples, 632248 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:46,884 : INFO : PROGRESS: at 7.31% examples, 633128 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:47,895 : INFO : PROGRESS: at 7.72% examples, 632662 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:19:48,922 : INFO : PROGRESS: at 8.07% examples, 627323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:49,936 : INFO : PROGRESS: at 8.41% examples, 621777 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:50,941 : INFO : PROGRESS: at 8.75% examples, 617011 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:19:51,959 : INFO : PROGRESS: at 9.10% examples, 613338 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-24 09:19:52,965 : INFO : PROGRESS: at 9.48% examples, 612330 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:53,973 : INFO : PROGRESS: at 9.91% examples, 614785 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:54,985 : INFO : PROGRESS: at 10.31% examples, 614259 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:19:55,993 : INFO : PROGRESS: at 10.69% examples, 613298 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:56,993 : INFO : PROGRESS: at 11.14% examples, 616495 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:19:58,010 : INFO : PROGRESS: at 11.58% examples, 618033 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-24 09:19:59,013 : INFO : PROGRESS: at 12.02% examples, 620544 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:00,014 : INFO : PROGRESS: at 12.44% examples, 621668 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:01,020 : INFO : PROGRESS: at 12.90% examples, 624333 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:02,031 : INFO : PROGRESS: at 13.34% examples, 626021 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:03,034 : INFO : PROGRESS: at 13.73% examples, 624969 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:04,045 : INFO : PROGRESS: at 14.15% examples, 625432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:05,056 : INFO : PROGRESS: at 14.60% examples, 627605 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:06,062 : INFO : PROGRESS: at 14.97% examples, 625706 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:07,070 : INFO : PROGRESS: at 15.31% examples, 623049 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:08,072 : INFO : PROGRESS: at 15.60% examples, 618434 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 09:20:09,091 : INFO : PROGRESS: at 15.90% examples, 614552 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:10,091 : INFO : PROGRESS: at 16.27% examples, 613255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:11,121 : INFO : PROGRESS: at 16.63% examples, 611591 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:12,125 : INFO : PROGRESS: at 16.96% examples, 609082 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:13,132 : INFO : PROGRESS: at 17.31% examples, 607375 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:14,139 : INFO : PROGRESS: at 17.69% examples, 606961 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:20:15,145 : INFO : PROGRESS: at 18.04% examples, 605588 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:16,146 : INFO : PROGRESS: at 18.43% examples, 605291 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:17,152 : INFO : PROGRESS: at 18.84% examples, 605928 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:18,166 : INFO : PROGRESS: at 19.19% examples, 604379 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:19,183 : INFO : PROGRESS: at 19.53% examples, 602703 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:20,194 : INFO : PROGRESS: at 19.88% examples, 601319 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:21,201 : INFO : PROGRESS: at 20.27% examples, 600737 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:22,214 : INFO : PROGRESS: at 20.68% examples, 600518 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:23,217 : INFO : PROGRESS: at 21.04% examples, 598703 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:24,232 : INFO : PROGRESS: at 21.47% examples, 599075 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:25,240 : INFO : PROGRESS: at 21.93% examples, 600068 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:26,248 : INFO : PROGRESS: at 22.31% examples, 599111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:27,261 : INFO : PROGRESS: at 22.69% examples, 598003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:28,270 : INFO : PROGRESS: at 23.05% examples, 596727 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:20:29,278 : INFO : PROGRESS: at 23.41% examples, 595614 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:30,293 : INFO : PROGRESS: at 23.84% examples, 595864 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:31,297 : INFO : PROGRESS: at 24.33% examples, 597960 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:32,310 : INFO : PROGRESS: at 24.80% examples, 599563 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:33,314 : INFO : PROGRESS: at 25.23% examples, 600505 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:34,319 : INFO : PROGRESS: at 25.68% examples, 602015 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:35,327 : INFO : PROGRESS: at 26.12% examples, 602982 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 09:20:36,335 : INFO : PROGRESS: at 26.52% examples, 603216 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:37,345 : INFO : PROGRESS: at 26.89% examples, 602759 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:38,345 : INFO : PROGRESS: at 27.26% examples, 602281 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:39,360 : INFO : PROGRESS: at 27.62% examples, 601585 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:40,374 : INFO : PROGRESS: at 28.02% examples, 601685 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:41,378 : INFO : PROGRESS: at 28.48% examples, 603266 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:20:42,393 : INFO : PROGRESS: at 28.95% examples, 604809 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:43,409 : INFO : PROGRESS: at 29.40% examples, 605983 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:20:44,415 : INFO : PROGRESS: at 29.83% examples, 606677 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:45,418 : INFO : PROGRESS: at 30.19% examples, 606178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:46,433 : INFO : PROGRESS: at 30.56% examples, 605496 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:47,444 : INFO : PROGRESS: at 30.93% examples, 605046 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:48,465 : INFO : PROGRESS: at 31.33% examples, 605136 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:49,476 : INFO : PROGRESS: at 31.80% examples, 606444 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:50,477 : INFO : PROGRESS: at 32.22% examples, 607127 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:51,486 : INFO : PROGRESS: at 32.68% examples, 608393 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:52,488 : INFO : PROGRESS: at 33.13% examples, 609314 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:53,506 : INFO : PROGRESS: at 33.57% examples, 610188 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:20:54,512 : INFO : PROGRESS: at 34.03% examples, 611213 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:55,523 : INFO : PROGRESS: at 34.46% examples, 611740 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:56,533 : INFO : PROGRESS: at 34.82% examples, 611106 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:57,537 : INFO : PROGRESS: at 35.17% examples, 610343 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:58,549 : INFO : PROGRESS: at 35.54% examples, 609817 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:20:59,577 : INFO : PROGRESS: at 35.93% examples, 609524 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:00,591 : INFO : PROGRESS: at 36.27% examples, 608663 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:01,600 : INFO : PROGRESS: at 36.70% examples, 609195 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:02,609 : INFO : PROGRESS: at 37.16% examples, 610119 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:03,616 : INFO : PROGRESS: at 37.58% examples, 610637 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:04,639 : INFO : PROGRESS: at 38.02% examples, 611205 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:05,655 : INFO : PROGRESS: at 38.41% examples, 610990 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:06,669 : INFO : PROGRESS: at 38.79% examples, 610712 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:07,677 : INFO : PROGRESS: at 39.16% examples, 610330 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:08,682 : INFO : PROGRESS: at 39.57% examples, 610435 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:09,688 : INFO : PROGRESS: at 39.99% examples, 610848 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:10,690 : INFO : PROGRESS: at 40.44% examples, 611151 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:11,704 : INFO : PROGRESS: at 40.90% examples, 611610 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:12,706 : INFO : PROGRESS: at 41.37% examples, 612203 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:13,715 : INFO : PROGRESS: at 41.77% examples, 611789 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:14,735 : INFO : PROGRESS: at 42.14% examples, 610878 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:21:15,741 : INFO : PROGRESS: at 42.53% examples, 610424 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:16,755 : INFO : PROGRESS: at 42.92% examples, 610000 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:17,776 : INFO : PROGRESS: at 43.34% examples, 609907 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:18,793 : INFO : PROGRESS: at 43.80% examples, 610395 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:19,802 : INFO : PROGRESS: at 44.31% examples, 611617 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:20,806 : INFO : PROGRESS: at 44.78% examples, 612370 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:21,816 : INFO : PROGRESS: at 45.22% examples, 613031 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:21:22,841 : INFO : PROGRESS: at 45.61% examples, 612783 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:23,856 : INFO : PROGRESS: at 45.96% examples, 612128 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:24,862 : INFO : PROGRESS: at 46.31% examples, 611399 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:25,878 : INFO : PROGRESS: at 46.68% examples, 610964 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:26,878 : INFO : PROGRESS: at 47.02% examples, 610280 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:27,889 : INFO : PROGRESS: at 47.37% examples, 609627 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:28,895 : INFO : PROGRESS: at 47.80% examples, 610169 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:29,899 : INFO : PROGRESS: at 48.21% examples, 610339 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:30,904 : INFO : PROGRESS: at 48.65% examples, 610938 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:31,927 : INFO : PROGRESS: at 49.09% examples, 611375 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:32,932 : INFO : PROGRESS: at 49.51% examples, 611635 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 09:21:33,934 : INFO : PROGRESS: at 49.94% examples, 612153 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:34,945 : INFO : PROGRESS: at 50.39% examples, 612692 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:35,949 : INFO : PROGRESS: at 50.76% examples, 612400 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:36,970 : INFO : PROGRESS: at 51.13% examples, 612025 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:37,971 : INFO : PROGRESS: at 51.49% examples, 611515 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:38,979 : INFO : PROGRESS: at 51.83% examples, 610920 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:39,997 : INFO : PROGRESS: at 52.16% examples, 610114 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:40,999 : INFO : PROGRESS: at 52.48% examples, 609156 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:42,008 : INFO : PROGRESS: at 52.83% examples, 608702 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:43,012 : INFO : PROGRESS: at 53.21% examples, 608510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:44,013 : INFO : PROGRESS: at 53.59% examples, 608276 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:45,015 : INFO : PROGRESS: at 53.96% examples, 608043 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:46,025 : INFO : PROGRESS: at 54.33% examples, 607772 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:47,033 : INFO : PROGRESS: at 54.72% examples, 607636 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:48,044 : INFO : PROGRESS: at 55.08% examples, 607263 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:49,045 : INFO : PROGRESS: at 55.40% examples, 606442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:50,046 : INFO : PROGRESS: at 55.69% examples, 605409 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:51,049 : INFO : PROGRESS: at 55.99% examples, 604382 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:52,055 : INFO : PROGRESS: at 56.30% examples, 603469 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:21:53,083 : INFO : PROGRESS: at 56.66% examples, 603017 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:54,107 : INFO : PROGRESS: at 57.03% examples, 602743 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:55,114 : INFO : PROGRESS: at 57.44% examples, 602859 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:21:56,126 : INFO : PROGRESS: at 57.86% examples, 603222 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:57,126 : INFO : PROGRESS: at 58.26% examples, 603308 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:21:58,161 : INFO : PROGRESS: at 58.61% examples, 602786 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:21:59,164 : INFO : PROGRESS: at 58.98% examples, 602505 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:00,174 : INFO : PROGRESS: at 59.31% examples, 601941 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:22:01,179 : INFO : PROGRESS: at 59.71% examples, 602019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:02,179 : INFO : PROGRESS: at 60.18% examples, 602656 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:03,213 : INFO : PROGRESS: at 60.68% examples, 603288 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:22:04,222 : INFO : PROGRESS: at 61.13% examples, 603563 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:22:05,226 : INFO : PROGRESS: at 61.63% examples, 604247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:06,258 : INFO : PROGRESS: at 62.05% examples, 604175 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:07,277 : INFO : PROGRESS: at 62.45% examples, 603914 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:08,282 : INFO : PROGRESS: at 62.81% examples, 603461 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:09,287 : INFO : PROGRESS: at 63.19% examples, 603112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:10,303 : INFO : PROGRESS: at 63.60% examples, 602966 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:11,309 : INFO : PROGRESS: at 64.06% examples, 603381 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:22:12,314 : INFO : PROGRESS: at 64.52% examples, 603792 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:13,325 : INFO : PROGRESS: at 64.94% examples, 604003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:14,331 : INFO : PROGRESS: at 65.36% examples, 604239 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:15,333 : INFO : PROGRESS: at 65.80% examples, 604777 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:16,361 : INFO : PROGRESS: at 66.25% examples, 605252 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:17,361 : INFO : PROGRESS: at 66.60% examples, 604815 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:18,387 : INFO : PROGRESS: at 66.94% examples, 604284 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:19,404 : INFO : PROGRESS: at 67.28% examples, 603755 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:20,410 : INFO : PROGRESS: at 67.64% examples, 603445 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:21,428 : INFO : PROGRESS: at 68.08% examples, 603864 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-24 09:22:22,437 : INFO : PROGRESS: at 68.50% examples, 604087 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:23,446 : INFO : PROGRESS: at 68.95% examples, 604614 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:24,450 : INFO : PROGRESS: at 69.37% examples, 604840 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:25,452 : INFO : PROGRESS: at 69.82% examples, 605422 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:26,473 : INFO : PROGRESS: at 70.26% examples, 605763 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:27,476 : INFO : PROGRESS: at 70.70% examples, 606206 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:28,481 : INFO : PROGRESS: at 71.08% examples, 606075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:29,486 : INFO : PROGRESS: at 71.42% examples, 605602 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:30,509 : INFO : PROGRESS: at 71.80% examples, 605455 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:31,528 : INFO : PROGRESS: at 72.16% examples, 605157 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:32,538 : INFO : PROGRESS: at 72.50% examples, 604726 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:33,539 : INFO : PROGRESS: at 72.84% examples, 604282 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:34,546 : INFO : PROGRESS: at 73.30% examples, 604824 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:35,551 : INFO : PROGRESS: at 73.73% examples, 605120 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:36,559 : INFO : PROGRESS: at 74.15% examples, 605320 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:37,573 : INFO : PROGRESS: at 74.57% examples, 605539 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:38,591 : INFO : PROGRESS: at 74.91% examples, 605049 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:39,593 : INFO : PROGRESS: at 75.23% examples, 604497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:40,593 : INFO : PROGRESS: at 75.55% examples, 603911 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:41,618 : INFO : PROGRESS: at 75.88% examples, 603414 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:22:42,626 : INFO : PROGRESS: at 76.25% examples, 603179 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:43,629 : INFO : PROGRESS: at 76.66% examples, 603359 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:44,661 : INFO : PROGRESS: at 77.08% examples, 603524 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:45,688 : INFO : PROGRESS: at 77.55% examples, 604061 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:46,708 : INFO : PROGRESS: at 78.00% examples, 604455 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:47,712 : INFO : PROGRESS: at 78.40% examples, 604502 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:48,713 : INFO : PROGRESS: at 78.77% examples, 604404 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:49,714 : INFO : PROGRESS: at 79.12% examples, 604071 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:22:50,714 : INFO : PROGRESS: at 79.47% examples, 603787 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:51,718 : INFO : PROGRESS: at 79.82% examples, 603421 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:52,721 : INFO : PROGRESS: at 80.23% examples, 603428 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:53,733 : INFO : PROGRESS: at 80.65% examples, 603436 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 09:22:54,742 : INFO : PROGRESS: at 81.12% examples, 603714 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:55,750 : INFO : PROGRESS: at 81.61% examples, 604181 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:56,756 : INFO : PROGRESS: at 82.06% examples, 604351 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:22:57,767 : INFO : PROGRESS: at 82.51% examples, 604578 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:22:58,797 : INFO : PROGRESS: at 82.87% examples, 604088 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:22:59,797 : INFO : PROGRESS: at 83.22% examples, 603690 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:00,814 : INFO : PROGRESS: at 83.63% examples, 603609 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:01,815 : INFO : PROGRESS: at 84.01% examples, 603394 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:02,817 : INFO : PROGRESS: at 84.46% examples, 603646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:03,824 : INFO : PROGRESS: at 84.89% examples, 603855 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:04,826 : INFO : PROGRESS: at 85.34% examples, 604265 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:23:05,834 : INFO : PROGRESS: at 85.79% examples, 604689 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:06,848 : INFO : PROGRESS: at 86.21% examples, 604847 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:07,850 : INFO : PROGRESS: at 86.64% examples, 605175 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:08,860 : INFO : PROGRESS: at 87.07% examples, 605376 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:09,903 : INFO : PROGRESS: at 87.45% examples, 605202 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:10,923 : INFO : PROGRESS: at 87.79% examples, 604818 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:11,953 : INFO : PROGRESS: at 88.15% examples, 604512 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:12,963 : INFO : PROGRESS: at 88.53% examples, 604403 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:13,971 : INFO : PROGRESS: at 88.99% examples, 604879 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:14,986 : INFO : PROGRESS: at 89.41% examples, 605060 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:15,988 : INFO : PROGRESS: at 89.88% examples, 605575 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:16,990 : INFO : PROGRESS: at 90.32% examples, 605923 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:18,002 : INFO : PROGRESS: at 90.73% examples, 606006 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:19,012 : INFO : PROGRESS: at 91.05% examples, 605519 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:20,019 : INFO : PROGRESS: at 91.38% examples, 605045 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:21,039 : INFO : PROGRESS: at 91.68% examples, 604411 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:23:22,054 : INFO : PROGRESS: at 92.05% examples, 604260 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:23,060 : INFO : PROGRESS: at 92.39% examples, 603934 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 09:23:24,079 : INFO : PROGRESS: at 92.79% examples, 603971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:25,090 : INFO : PROGRESS: at 93.21% examples, 604093 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:23:26,103 : INFO : PROGRESS: at 93.64% examples, 604306 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:27,125 : INFO : PROGRESS: at 94.05% examples, 604400 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:28,141 : INFO : PROGRESS: at 94.49% examples, 604668 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:29,142 : INFO : PROGRESS: at 94.83% examples, 604359 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:30,153 : INFO : PROGRESS: at 95.17% examples, 603997 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:23:31,163 : INFO : PROGRESS: at 95.52% examples, 603736 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 09:23:32,186 : INFO : PROGRESS: at 95.86% examples, 603348 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:33,203 : INFO : PROGRESS: at 96.27% examples, 603488 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:34,212 : INFO : PROGRESS: at 96.70% examples, 603710 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:35,239 : INFO : PROGRESS: at 97.16% examples, 604039 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:36,247 : INFO : PROGRESS: at 97.58% examples, 604256 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:37,255 : INFO : PROGRESS: at 98.05% examples, 604693 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:38,277 : INFO : PROGRESS: at 98.42% examples, 604562 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 09:23:39,290 : INFO : PROGRESS: at 98.73% examples, 604022 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 09:23:40,304 : INFO : PROGRESS: at 99.08% examples, 603761 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:41,316 : INFO : PROGRESS: at 99.39% examples, 603200 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:42,349 : INFO : PROGRESS: at 99.78% examples, 603112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 09:23:42,926 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 09:23:42,931 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 09:23:42,933 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 09:23:42,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 09:23:42,939 : INFO : training on 198199735 raw words (152709424 effective words) took 253.2s, 603076 effective words/s\n",
      "2017-04-24 09:23:42,940 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 09:23:43,311 : INFO : saving Word2Vec object under Results/dros_yeast_rat_BE_comb_model, separately None\n",
      "2017-04-24 09:23:43,312 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 09:23:43,312 : INFO : storing np array 'syn0' to Results/dros_yeast_rat_BE_comb_model.wv.syn0.npy\n",
      "2017-04-24 09:23:43,352 : INFO : storing np array 'syn1neg' to Results/dros_yeast_rat_BE_comb_model.syn1neg.npy\n",
      "2017-04-24 09:23:43,394 : INFO : not storing attribute cum_table\n",
      "2017-04-24 09:23:43,545 : INFO : saved Results/dros_yeast_rat_BE_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "dros_old_SR_sentence_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "rat_SR_sentences_pkl = 'Results/rat/strict_real.pkl'\n",
    "data_list = [dros_old_SR_sentence_pkl, yeast_SR_sentences_pkl, rat_SR_sentences_pkl]\n",
    "dros_yeast_rat_SR_comb_model = make_w2v_model(data_list, 'dros_yeast_rat_SR_comb_model')\n",
    "\n",
    "#Gen model\n",
    "dros_old_GEN_sentence_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "rat_GEN_sentences_pkl = 'Results/rat/gen_real.pkl'\n",
    "data_list = [dros_old_GEN_sentence_pkl, yeast_GEN_sentences_pkl, rat_GEN_sentences_pkl]\n",
    "dros_yeast_rat_GEN_comb_model = make_w2v_model(data_list, 'dros_yeast_rat_GEN_comb_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "dros_old_BE_sentence_pkl = 'Results/drosophila/be_real.pkl'\n",
    "yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "rat_BE_sentences_pkl = 'Results/rat/be_real.pkl'\n",
    "data_list = [dros_old_BE_sentence_pkl, yeast_BE_sentences_pkl, rat_BE_sentences_pkl]\n",
    "dros_yeast_rat_BE_comb_model = make_w2v_model(data_list, 'dros_yeast_rat_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "dros_strict_real = pickle.load(open('Results/drosophila/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_SR_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_GEN_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_BE_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/dros_yeast_rat_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/dros_yeast_rat_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/dros_yeast_rat_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/dros_yeast_rat_comb/Seeded/Results/'\n",
    "errors_dros_yeast_rat_comb = mult_open(drct, '_errors_')\n",
    "fpr_dros_yeast_rat_comb = mult_open(drct, '_fpr_')\n",
    "tpr_dros_yeast_rat_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error dros_yeast_rat_comb auc=0.524 error=0.405\n",
      "Strict error dros_yeast_rat_comb auc=0.517 error=0.404\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.490 error=0.404\n",
      "Gen error dros_yeast_rat_comb auc=0.486 error=0.414\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.499 error=0.398\n",
      "BE error dros_yeast_rat_comb auc=0.495 error=0.411\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.565 error=0.391\n",
      "Strict error dros_yeast_rat_comb auc=0.573 error=0.382\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.615 error=0.376\n",
      "Gen error dros_yeast_rat_comb auc=0.640 error=0.365\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.623 error=0.388\n",
      "BE error dros_yeast_rat_comb auc=0.621 error=0.379\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.492 error=0.387\n",
      "Strict error dros_yeast_rat_comb auc=0.504 error=0.390\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.513 error=0.385\n",
      "Gen error dros_yeast_rat_comb auc=0.521 error=0.370\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.560 error=0.399\n",
      "BE error dros_yeast_rat_comb auc=0.544 error=0.387\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.613 error=0.310\n",
      "Strict error dros_yeast_rat_comb auc=0.611 error=0.314\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.627 error=0.316\n",
      "Gen error dros_yeast_rat_comb auc=0.628 error=0.307\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.583 error=0.332\n",
      "BE error dros_yeast_rat_comb auc=0.609 error=0.337\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.561 error=0.402\n",
      "Strict error dros_yeast_rat_comb auc=0.582 error=0.402\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.564 error=0.413\n",
      "Gen error dros_yeast_rat_comb auc=0.588 error=0.404\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.583 error=0.387\n",
      "BE error dros_yeast_rat_comb auc=0.585 error=0.421\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.577 error=0.418\n",
      "Strict error dros_yeast_rat_comb auc=0.537 error=0.435\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.588 error=0.418\n",
      "Gen error dros_yeast_rat_comb auc=0.584 error=0.411\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.558 error=0.426\n",
      "BE error dros_yeast_rat_comb auc=0.558 error=0.430\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.644 error=0.327\n",
      "Strict error dros_yeast_rat_comb auc=0.610 error=0.347\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.649 error=0.320\n",
      "Gen error dros_yeast_rat_comb auc=0.646 error=0.324\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.638 error=0.335\n",
      "BE error dros_yeast_rat_comb auc=0.638 error=0.340\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.611 error=0.363\n",
      "Strict error dros_yeast_rat_comb auc=0.618 error=0.350\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.675 error=0.345\n",
      "Gen error dros_yeast_rat_comb auc=0.626 error=0.361\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.617 error=0.377\n",
      "BE error dros_yeast_rat_comb auc=0.618 error=0.377\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.549 error=0.369\n",
      "Strict error dros_yeast_rat_comb auc=0.547 error=0.389\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.560 error=0.383\n",
      "Gen error dros_yeast_rat_comb auc=0.543 error=0.381\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.559 error=0.354\n",
      "BE error dros_yeast_rat_comb auc=0.556 error=0.371\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_comb auc=0.623 error=0.361\n",
      "Strict error dros_yeast_rat_comb auc=0.612 error=0.379\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_comb auc=0.631 error=0.353\n",
      "Gen error dros_yeast_rat_comb auc=0.623 error=0.361\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_comb auc=0.646 error=0.369\n",
      "BE error dros_yeast_rat_comb auc=0.647 error=0.347\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_rat_comb_strict = []\n",
    "mean_auc_dros_yeast_rat_comb_strict = []\n",
    "mean_err_dros_yeast_rat_comb_gen = []\n",
    "mean_auc_dros_yeast_rat_comb_gen = []\n",
    "mean_err_dros_yeast_rat_comb_be = []\n",
    "mean_auc_dros_yeast_rat_comb_be = []\n",
    "for e, f, t in zip(errors_dros_yeast_rat_comb, fpr_dros_yeast_rat_comb, tpr_dros_yeast_rat_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['dros_yeast_rat_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_yeast_rat_comb_strict.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_yeast_rat_comb_gen.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_yeast_rat_comb_be.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_dros_yeast_rat_comb_org_strict = mean_err_dros_yeast_rat_comb_strict[0::2]\n",
    "mean_err_dros_yeast_rat_comb_fs_strict = mean_err_dros_yeast_rat_comb_strict[1::2]\n",
    "mean_auc_dros_yeast_rat_comb_org_strict = mean_auc_dros_yeast_rat_comb_strict[0::2]\n",
    "mean_auc_dros_yeast_rat_comb_fs_strict = mean_auc_dros_yeast_rat_comb_strict[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_comb_org_gen = mean_err_dros_yeast_rat_comb_gen[0::2]\n",
    "mean_err_dros_yeast_rat_comb_fs_gen = mean_err_dros_yeast_rat_comb_gen[1::2]\n",
    "mean_auc_dros_yeast_rat_comb_org_gen = mean_auc_dros_yeast_rat_comb_gen[0::2]\n",
    "mean_auc_dros_yeast_rat_comb_fs_gen = mean_auc_dros_yeast_rat_comb_gen[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_comb_org_be = mean_err_dros_yeast_rat_comb_be[0::2]\n",
    "mean_err_dros_yeast_rat_comb_fs_be = mean_err_dros_yeast_rat_comb_be[1::2]\n",
    "mean_auc_dros_yeast_rat_comb_org_be = mean_auc_dros_yeast_rat_comb_be[0::2]\n",
    "mean_auc_dros_yeast_rat_comb_fs_be = mean_auc_dros_yeast_rat_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dros_yeast_rat_comb mean strict error original -  0.373356974412\n",
      "dros_yeast_rat_comb mean strict error feature selection -  0.379191546198\n",
      "dros_yeast_rat_comb mean strict AUC original -  0.576093046847\n",
      "dros_yeast_rat_comb mean strict AUC feature selection -  0.571067877239\n",
      "\n",
      "\n",
      "dros_yeast_rat_comb mean gen error original -  0.371423105182\n",
      "dros_yeast_rat_comb mean gen error feature selection -  0.369701949599\n",
      "dros_yeast_rat_comb mean gen AUC original -  0.591084187421\n",
      "dros_yeast_rat_comb mean gen AUC feature selection -  0.588507873466\n",
      "\n",
      "\n",
      "dros_yeast_rat_comb mean BE error original -  0.376554236552\n",
      "dros_yeast_rat_comb mean BE error feature selection -  0.380057541852\n",
      "dros_yeast_rat_comb mean BE AUC original -  0.586503981378\n",
      "dros_yeast_rat_comb mean BE AUC feature selection -  0.587105970421\n"
     ]
    }
   ],
   "source": [
    "print('dros_yeast_rat_comb mean strict error original - ', np.mean(mean_err_dros_yeast_rat_comb_org_strict))\n",
    "print('dros_yeast_rat_comb mean strict error feature selection - ', np.mean(mean_err_dros_yeast_rat_comb_fs_strict))\n",
    "print('dros_yeast_rat_comb mean strict AUC original - ', np.mean(mean_auc_dros_yeast_rat_comb_org_strict))\n",
    "print('dros_yeast_rat_comb mean strict AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat_comb mean gen error original - ', np.mean(mean_err_dros_yeast_rat_comb_org_gen))\n",
    "print('dros_yeast_rat_comb mean gen error feature selection - ', np.mean(mean_err_dros_yeast_rat_comb_fs_gen))\n",
    "print('dros_yeast_rat_comb mean gen AUC original - ', np.mean(mean_auc_dros_yeast_rat_comb_org_gen))\n",
    "print('dros_yeast_rat_comb mean gen AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat_comb mean BE error original - ', np.mean(mean_err_dros_yeast_rat_comb_org_be))\n",
    "print('dros_yeast_rat_comb mean BE error feature selection - ', np.mean(mean_err_dros_yeast_rat_comb_fs_be))\n",
    "print('dros_yeast_rat_comb mean BE AUC original - ', np.mean(mean_auc_dros_yeast_rat_comb_org_be))\n",
    "print('dros_yeast_rat_comb mean BE AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 10:30:54,374 : INFO : collecting all words and their counts\n",
      "2017-04-24 10:30:54,375 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 10:30:54,424 : INFO : PROGRESS: at sentence #10000, processed 257628 words, keeping 15914 word types\n",
      "2017-04-24 10:30:54,480 : INFO : PROGRESS: at sentence #20000, processed 530973 words, keeping 24392 word types\n",
      "2017-04-24 10:30:54,538 : INFO : PROGRESS: at sentence #30000, processed 809741 words, keeping 30001 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 10:30:54,597 : INFO : PROGRESS: at sentence #40000, processed 1088700 words, keeping 34182 word types\n",
      "2017-04-24 10:30:54,657 : INFO : PROGRESS: at sentence #50000, processed 1369481 words, keeping 37729 word types\n",
      "2017-04-24 10:30:54,712 : INFO : PROGRESS: at sentence #60000, processed 1648379 words, keeping 40839 word types\n",
      "2017-04-24 10:30:54,771 : INFO : PROGRESS: at sentence #70000, processed 1918006 words, keeping 44303 word types\n",
      "2017-04-24 10:30:54,829 : INFO : PROGRESS: at sentence #80000, processed 2188984 words, keeping 47268 word types\n",
      "2017-04-24 10:30:54,883 : INFO : PROGRESS: at sentence #90000, processed 2459814 words, keeping 49899 word types\n",
      "2017-04-24 10:30:54,939 : INFO : PROGRESS: at sentence #100000, processed 2730971 words, keeping 52378 word types\n",
      "2017-04-24 10:30:54,997 : INFO : PROGRESS: at sentence #110000, processed 3000125 words, keeping 54606 word types\n",
      "2017-04-24 10:30:55,052 : INFO : PROGRESS: at sentence #120000, processed 3268035 words, keeping 56775 word types\n",
      "2017-04-24 10:30:55,111 : INFO : PROGRESS: at sentence #130000, processed 3537329 words, keeping 58805 word types\n",
      "2017-04-24 10:30:55,169 : INFO : PROGRESS: at sentence #140000, processed 3808393 words, keeping 60614 word types\n",
      "2017-04-24 10:30:55,213 : INFO : collected 61975 word types from a corpus of 4002202 raw words and 147183 sentences\n",
      "2017-04-24 10:30:55,214 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 10:30:55,499 : INFO : min_count=5 retains 19903 unique words (32% of original 61975, drops 42072)\n",
      "2017-04-24 10:30:55,500 : INFO : min_count=5 leaves 3935217 word corpus (98% of original 4002202, drops 66985)\n",
      "2017-04-24 10:30:55,570 : INFO : deleting the raw counts dictionary of 61975 items\n",
      "2017-04-24 10:30:55,574 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2017-04-24 10:30:55,574 : INFO : downsampling leaves estimated 3041386 word corpus (77.3% of prior 3935217)\n",
      "2017-04-24 10:30:55,575 : INFO : estimated required memory for 19903 words and 300 dimensions: 57718700 bytes\n",
      "2017-04-24 10:30:55,659 : INFO : resetting layer weights\n",
      "2017-04-24 10:30:55,916 : INFO : training model with 4 workers on 19903 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 10:30:55,917 : INFO : expecting 147183 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 10:30:56,933 : INFO : PROGRESS: at 4.27% examples, 634299 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:30:57,940 : INFO : PROGRESS: at 8.15% examples, 619778 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:30:58,945 : INFO : PROGRESS: at 12.76% examples, 644661 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:30:59,967 : INFO : PROGRESS: at 17.65% examples, 663857 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:31:00,970 : INFO : PROGRESS: at 22.52% examples, 675405 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:01,986 : INFO : PROGRESS: at 27.42% examples, 689200 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:02,988 : INFO : PROGRESS: at 32.32% examples, 696700 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:04,001 : INFO : PROGRESS: at 36.54% examples, 688319 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:31:05,004 : INFO : PROGRESS: at 40.17% examples, 672435 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:31:06,007 : INFO : PROGRESS: at 43.89% examples, 660881 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 10:31:07,015 : INFO : PROGRESS: at 47.43% examples, 650930 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:08,017 : INFO : PROGRESS: at 51.52% examples, 648497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:09,025 : INFO : PROGRESS: at 56.75% examples, 658833 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:10,046 : INFO : PROGRESS: at 61.34% examples, 659353 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:11,050 : INFO : PROGRESS: at 66.51% examples, 668885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:12,064 : INFO : PROGRESS: at 71.18% examples, 671121 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:31:13,067 : INFO : PROGRESS: at 75.95% examples, 673897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:14,085 : INFO : PROGRESS: at 80.66% examples, 674897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:15,096 : INFO : PROGRESS: at 85.55% examples, 678429 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:16,101 : INFO : PROGRESS: at 89.63% examples, 675947 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:17,104 : INFO : PROGRESS: at 93.14% examples, 669013 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:18,143 : INFO : PROGRESS: at 96.66% examples, 661646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:18,988 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 10:31:18,989 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 10:31:19,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 10:31:19,007 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 10:31:19,008 : INFO : training on 20011010 raw words (15206080 effective words) took 23.1s, 658655 effective words/s\n",
      "2017-04-24 10:31:19,010 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 10:31:19,225 : INFO : saving Word2Vec object under Results/dros_yeast_rat_mouse_SR_comb_model, separately None\n",
      "2017-04-24 10:31:19,226 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 10:31:19,227 : INFO : not storing attribute cum_table\n",
      "2017-04-24 10:31:20,638 : INFO : saved Results/dros_yeast_rat_mouse_SR_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "dros_old_SR_sentence_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "rat_SR_sentences_pkl = 'Results/rat/strict_real.pkl'\n",
    "mouse_SR_sentences_pkl = 'Results/mouse/strict_real.pkl'\n",
    "data_list = [dros_old_SR_sentence_pkl, yeast_SR_sentences_pkl, rat_SR_sentences_pkl, mouse_SR_sentences_pkl]\n",
    "dros_yeast_rat_mouse_SR_comb_model = make_w2v_model(data_list, 'dros_yeast_rat_mouse_SR_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 10:31:41,586 : INFO : collecting all words and their counts\n",
      "2017-04-24 10:31:41,586 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-24 10:31:41,632 : INFO : PROGRESS: at sentence #10000, processed 244783 words, keeping 13510 word types\n",
      "2017-04-24 10:31:41,677 : INFO : PROGRESS: at sentence #20000, processed 489468 words, keeping 18202 word types\n",
      "2017-04-24 10:31:41,725 : INFO : PROGRESS: at sentence #30000, processed 731716 words, keeping 21534 word types\n",
      "2017-04-24 10:31:41,776 : INFO : PROGRESS: at sentence #40000, processed 974762 words, keeping 24812 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 10:31:41,831 : INFO : PROGRESS: at sentence #50000, processed 1219607 words, keeping 27699 word types\n",
      "2017-04-24 10:31:41,884 : INFO : PROGRESS: at sentence #60000, processed 1465718 words, keeping 29841 word types\n",
      "2017-04-24 10:31:41,940 : INFO : PROGRESS: at sentence #70000, processed 1711745 words, keeping 31513 word types\n",
      "2017-04-24 10:31:41,994 : INFO : PROGRESS: at sentence #80000, processed 1957977 words, keeping 33076 word types\n",
      "2017-04-24 10:31:42,049 : INFO : PROGRESS: at sentence #90000, processed 2218472 words, keeping 37460 word types\n",
      "2017-04-24 10:31:42,106 : INFO : PROGRESS: at sentence #100000, processed 2489271 words, keeping 41654 word types\n",
      "2017-04-24 10:31:42,165 : INFO : PROGRESS: at sentence #110000, processed 2758812 words, keeping 44721 word types\n",
      "2017-04-24 10:31:42,220 : INFO : PROGRESS: at sentence #120000, processed 3029421 words, keeping 47377 word types\n",
      "2017-04-24 10:31:42,280 : INFO : PROGRESS: at sentence #130000, processed 3297987 words, keeping 49609 word types\n",
      "2017-04-24 10:31:42,336 : INFO : PROGRESS: at sentence #140000, processed 3569978 words, keeping 51716 word types\n",
      "2017-04-24 10:31:42,398 : INFO : PROGRESS: at sentence #150000, processed 3839454 words, keeping 53596 word types\n",
      "2017-04-24 10:31:42,453 : INFO : PROGRESS: at sentence #160000, processed 4107457 words, keeping 55323 word types\n",
      "2017-04-24 10:31:42,511 : INFO : PROGRESS: at sentence #170000, processed 4377204 words, keeping 56925 word types\n",
      "2017-04-24 10:31:42,570 : INFO : PROGRESS: at sentence #180000, processed 4647923 words, keeping 58440 word types\n",
      "2017-04-24 10:31:42,626 : INFO : PROGRESS: at sentence #190000, processed 4916446 words, keeping 59893 word types\n",
      "2017-04-24 10:31:42,682 : INFO : PROGRESS: at sentence #200000, processed 5184727 words, keeping 61317 word types\n",
      "2017-04-24 10:31:42,739 : INFO : PROGRESS: at sentence #210000, processed 5452646 words, keeping 62590 word types\n",
      "2017-04-24 10:31:42,798 : INFO : PROGRESS: at sentence #220000, processed 5722233 words, keeping 63883 word types\n",
      "2017-04-24 10:31:42,854 : INFO : PROGRESS: at sentence #230000, processed 5994695 words, keeping 65115 word types\n",
      "2017-04-24 10:31:42,911 : INFO : PROGRESS: at sentence #240000, processed 6264224 words, keeping 66248 word types\n",
      "2017-04-24 10:31:42,971 : INFO : PROGRESS: at sentence #250000, processed 6535810 words, keeping 67392 word types\n",
      "2017-04-24 10:31:43,030 : INFO : PROGRESS: at sentence #260000, processed 6805394 words, keeping 68532 word types\n",
      "2017-04-24 10:31:43,090 : INFO : PROGRESS: at sentence #270000, processed 7070590 words, keeping 70082 word types\n",
      "2017-04-24 10:31:43,144 : INFO : PROGRESS: at sentence #280000, processed 7330458 words, keeping 71683 word types\n",
      "2017-04-24 10:31:43,201 : INFO : PROGRESS: at sentence #290000, processed 7591500 words, keeping 73179 word types\n",
      "2017-04-24 10:31:43,254 : INFO : PROGRESS: at sentence #300000, processed 7850094 words, keeping 74678 word types\n",
      "2017-04-24 10:31:43,308 : INFO : PROGRESS: at sentence #310000, processed 8106411 words, keeping 75992 word types\n",
      "2017-04-24 10:31:43,364 : INFO : PROGRESS: at sentence #320000, processed 8364293 words, keeping 77188 word types\n",
      "2017-04-24 10:31:43,418 : INFO : PROGRESS: at sentence #330000, processed 8622227 words, keeping 78362 word types\n",
      "2017-04-24 10:31:43,474 : INFO : PROGRESS: at sentence #340000, processed 8881599 words, keeping 79539 word types\n",
      "2017-04-24 10:31:43,530 : INFO : PROGRESS: at sentence #350000, processed 9139893 words, keeping 80682 word types\n",
      "2017-04-24 10:31:43,588 : INFO : PROGRESS: at sentence #360000, processed 9400116 words, keeping 81820 word types\n",
      "2017-04-24 10:31:43,645 : INFO : PROGRESS: at sentence #370000, processed 9658487 words, keeping 82860 word types\n",
      "2017-04-24 10:31:43,703 : INFO : PROGRESS: at sentence #380000, processed 9915456 words, keeping 83917 word types\n",
      "2017-04-24 10:31:43,760 : INFO : PROGRESS: at sentence #390000, processed 10173630 words, keeping 84936 word types\n",
      "2017-04-24 10:31:43,817 : INFO : PROGRESS: at sentence #400000, processed 10432776 words, keeping 85889 word types\n",
      "2017-04-24 10:31:43,876 : INFO : PROGRESS: at sentence #410000, processed 10693425 words, keeping 86799 word types\n",
      "2017-04-24 10:31:43,938 : INFO : PROGRESS: at sentence #420000, processed 10951060 words, keeping 87671 word types\n",
      "2017-04-24 10:31:43,996 : INFO : PROGRESS: at sentence #430000, processed 11210820 words, keeping 88578 word types\n",
      "2017-04-24 10:31:44,052 : INFO : PROGRESS: at sentence #440000, processed 11468621 words, keeping 89405 word types\n",
      "2017-04-24 10:31:44,112 : INFO : PROGRESS: at sentence #450000, processed 11728214 words, keeping 90292 word types\n",
      "2017-04-24 10:31:44,168 : INFO : PROGRESS: at sentence #460000, processed 11982709 words, keeping 91072 word types\n",
      "2017-04-24 10:31:44,224 : INFO : PROGRESS: at sentence #470000, processed 12240236 words, keeping 91901 word types\n",
      "2017-04-24 10:31:44,283 : INFO : PROGRESS: at sentence #480000, processed 12498137 words, keeping 92697 word types\n",
      "2017-04-24 10:31:44,344 : INFO : PROGRESS: at sentence #490000, processed 12756236 words, keeping 93540 word types\n",
      "2017-04-24 10:31:44,404 : INFO : PROGRESS: at sentence #500000, processed 13014218 words, keeping 94356 word types\n",
      "2017-04-24 10:31:44,464 : INFO : PROGRESS: at sentence #510000, processed 13272553 words, keeping 95130 word types\n",
      "2017-04-24 10:31:44,525 : INFO : PROGRESS: at sentence #520000, processed 13531023 words, keeping 95931 word types\n",
      "2017-04-24 10:31:44,584 : INFO : PROGRESS: at sentence #530000, processed 13789359 words, keeping 96659 word types\n",
      "2017-04-24 10:31:44,640 : INFO : PROGRESS: at sentence #540000, processed 14045908 words, keeping 97363 word types\n",
      "2017-04-24 10:31:44,697 : INFO : PROGRESS: at sentence #550000, processed 14303408 words, keeping 98084 word types\n",
      "2017-04-24 10:31:44,755 : INFO : PROGRESS: at sentence #560000, processed 14560839 words, keeping 98767 word types\n",
      "2017-04-24 10:31:44,813 : INFO : PROGRESS: at sentence #570000, processed 14819997 words, keeping 99473 word types\n",
      "2017-04-24 10:31:44,873 : INFO : PROGRESS: at sentence #580000, processed 15078629 words, keeping 100164 word types\n",
      "2017-04-24 10:31:44,952 : INFO : PROGRESS: at sentence #590000, processed 15337361 words, keeping 100890 word types\n",
      "2017-04-24 10:31:45,031 : INFO : PROGRESS: at sentence #600000, processed 15597200 words, keeping 101611 word types\n",
      "2017-04-24 10:31:45,106 : INFO : PROGRESS: at sentence #610000, processed 15854773 words, keeping 102303 word types\n",
      "2017-04-24 10:31:45,181 : INFO : PROGRESS: at sentence #620000, processed 16112763 words, keeping 102912 word types\n",
      "2017-04-24 10:31:45,240 : INFO : PROGRESS: at sentence #630000, processed 16369733 words, keeping 103507 word types\n",
      "2017-04-24 10:31:45,302 : INFO : PROGRESS: at sentence #640000, processed 16628592 words, keeping 104143 word types\n",
      "2017-04-24 10:31:45,371 : INFO : PROGRESS: at sentence #650000, processed 16887568 words, keeping 104743 word types\n",
      "2017-04-24 10:31:45,450 : INFO : PROGRESS: at sentence #660000, processed 17147447 words, keeping 105408 word types\n",
      "2017-04-24 10:31:45,521 : INFO : PROGRESS: at sentence #670000, processed 17408622 words, keeping 106010 word types\n",
      "2017-04-24 10:31:45,585 : INFO : PROGRESS: at sentence #680000, processed 17667368 words, keeping 106592 word types\n",
      "2017-04-24 10:31:45,643 : INFO : PROGRESS: at sentence #690000, processed 17924190 words, keeping 107180 word types\n",
      "2017-04-24 10:31:45,698 : INFO : PROGRESS: at sentence #700000, processed 18181782 words, keeping 107728 word types\n",
      "2017-04-24 10:31:45,754 : INFO : PROGRESS: at sentence #710000, processed 18440278 words, keeping 108293 word types\n",
      "2017-04-24 10:31:45,812 : INFO : PROGRESS: at sentence #720000, processed 18698968 words, keeping 108861 word types\n",
      "2017-04-24 10:31:45,868 : INFO : PROGRESS: at sentence #730000, processed 18956778 words, keeping 109386 word types\n",
      "2017-04-24 10:31:45,924 : INFO : PROGRESS: at sentence #740000, processed 19215928 words, keeping 109951 word types\n",
      "2017-04-24 10:31:45,974 : INFO : collected 110438 word types from a corpus of 19443894 raw words and 748797 sentences\n",
      "2017-04-24 10:31:45,975 : INFO : Loading a fresh vocabulary\n",
      "2017-04-24 10:31:46,090 : INFO : min_count=5 retains 39153 unique words (35% of original 110438, drops 71285)\n",
      "2017-04-24 10:31:46,091 : INFO : min_count=5 leaves 19326839 word corpus (99% of original 19443894, drops 117055)\n",
      "2017-04-24 10:31:46,196 : INFO : deleting the raw counts dictionary of 110438 items\n",
      "2017-04-24 10:31:46,202 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-04-24 10:31:46,203 : INFO : downsampling leaves estimated 14850649 word corpus (76.8% of prior 19326839)\n",
      "2017-04-24 10:31:46,204 : INFO : estimated required memory for 39153 words and 300 dimensions: 113543700 bytes\n",
      "2017-04-24 10:31:46,356 : INFO : resetting layer weights\n",
      "2017-04-24 10:31:46,875 : INFO : training model with 4 workers on 39153 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 10:31:46,876 : INFO : expecting 748797 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 10:31:47,917 : INFO : PROGRESS: at 0.79% examples, 524857 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 10:31:48,947 : INFO : PROGRESS: at 1.47% examples, 490022 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:49,957 : INFO : PROGRESS: at 2.25% examples, 506204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:50,963 : INFO : PROGRESS: at 2.89% examples, 503277 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:51,974 : INFO : PROGRESS: at 3.56% examples, 505401 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:52,980 : INFO : PROGRESS: at 4.32% examples, 518392 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:53,985 : INFO : PROGRESS: at 5.21% examples, 541881 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:54,991 : INFO : PROGRESS: at 6.11% examples, 560483 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-24 10:31:56,015 : INFO : PROGRESS: at 7.06% examples, 577972 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:57,016 : INFO : PROGRESS: at 7.99% examples, 589432 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:31:58,018 : INFO : PROGRESS: at 8.97% examples, 601514 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:31:59,033 : INFO : PROGRESS: at 9.99% examples, 613410 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:00,037 : INFO : PROGRESS: at 10.84% examples, 614148 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:01,039 : INFO : PROGRESS: at 11.74% examples, 617588 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:02,077 : INFO : PROGRESS: at 12.62% examples, 618111 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:03,078 : INFO : PROGRESS: at 13.41% examples, 616175 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:04,094 : INFO : PROGRESS: at 14.10% examples, 609495 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:05,105 : INFO : PROGRESS: at 14.70% examples, 599595 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:06,117 : INFO : PROGRESS: at 15.44% examples, 596622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:07,130 : INFO : PROGRESS: at 16.11% examples, 591265 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:08,134 : INFO : PROGRESS: at 16.94% examples, 592057 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:09,135 : INFO : PROGRESS: at 17.88% examples, 596945 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-24 10:32:10,150 : INFO : PROGRESS: at 18.88% examples, 602728 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 10:32:11,151 : INFO : PROGRESS: at 19.92% examples, 609336 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:12,160 : INFO : PROGRESS: at 20.90% examples, 612221 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:13,177 : INFO : PROGRESS: at 22.00% examples, 617589 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:14,187 : INFO : PROGRESS: at 22.96% examples, 621270 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:15,187 : INFO : PROGRESS: at 23.91% examples, 625221 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:16,191 : INFO : PROGRESS: at 24.72% examples, 625174 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:17,197 : INFO : PROGRESS: at 25.43% examples, 622329 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:18,207 : INFO : PROGRESS: at 26.22% examples, 621804 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:19,235 : INFO : PROGRESS: at 26.88% examples, 617882 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:32:20,238 : INFO : PROGRESS: at 27.73% examples, 618538 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:21,255 : INFO : PROGRESS: at 28.59% examples, 618660 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:22,265 : INFO : PROGRESS: at 29.42% examples, 618482 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:23,272 : INFO : PROGRESS: at 30.22% examples, 617510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:24,298 : INFO : PROGRESS: at 31.01% examples, 616281 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:25,326 : INFO : PROGRESS: at 31.71% examples, 613297 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:26,335 : INFO : PROGRESS: at 32.44% examples, 611156 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:27,340 : INFO : PROGRESS: at 33.19% examples, 609745 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:28,349 : INFO : PROGRESS: at 34.07% examples, 610548 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:29,354 : INFO : PROGRESS: at 35.14% examples, 614611 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:30,365 : INFO : PROGRESS: at 36.12% examples, 616990 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:31,365 : INFO : PROGRESS: at 37.15% examples, 620267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:32,370 : INFO : PROGRESS: at 37.93% examples, 619312 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:33,384 : INFO : PROGRESS: at 38.63% examples, 616978 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:34,387 : INFO : PROGRESS: at 39.31% examples, 614557 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:32:35,421 : INFO : PROGRESS: at 40.09% examples, 613244 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:36,422 : INFO : PROGRESS: at 41.17% examples, 615783 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:37,448 : INFO : PROGRESS: at 42.30% examples, 619010 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:38,451 : INFO : PROGRESS: at 43.28% examples, 621635 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:39,454 : INFO : PROGRESS: at 44.20% examples, 623281 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:32:40,481 : INFO : PROGRESS: at 45.15% examples, 625029 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:41,489 : INFO : PROGRESS: at 46.13% examples, 627339 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:42,495 : INFO : PROGRESS: at 47.13% examples, 630014 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:43,503 : INFO : PROGRESS: at 48.09% examples, 631341 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:44,517 : INFO : PROGRESS: at 48.98% examples, 631622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:45,546 : INFO : PROGRESS: at 49.82% examples, 631210 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:46,571 : INFO : PROGRESS: at 50.54% examples, 629196 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:47,574 : INFO : PROGRESS: at 51.31% examples, 628231 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:48,587 : INFO : PROGRESS: at 52.01% examples, 626332 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:49,599 : INFO : PROGRESS: at 52.74% examples, 624754 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:50,604 : INFO : PROGRESS: at 53.56% examples, 624466 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 10:32:51,609 : INFO : PROGRESS: at 54.18% examples, 621846 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:52,624 : INFO : PROGRESS: at 54.83% examples, 619447 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:32:53,646 : INFO : PROGRESS: at 55.45% examples, 616938 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 10:32:54,670 : INFO : PROGRESS: at 56.16% examples, 615281 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:32:55,678 : INFO : PROGRESS: at 56.82% examples, 613357 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 10:32:56,679 : INFO : PROGRESS: at 57.49% examples, 611673 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:57,699 : INFO : PROGRESS: at 58.13% examples, 609646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:58,722 : INFO : PROGRESS: at 58.93% examples, 609161 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:32:59,732 : INFO : PROGRESS: at 59.74% examples, 608889 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:00,740 : INFO : PROGRESS: at 60.51% examples, 608074 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-24 10:33:01,743 : INFO : PROGRESS: at 61.55% examples, 609507 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:02,744 : INFO : PROGRESS: at 62.43% examples, 609760 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:03,759 : INFO : PROGRESS: at 63.27% examples, 610162 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:33:04,764 : INFO : PROGRESS: at 64.28% examples, 612303 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:05,767 : INFO : PROGRESS: at 65.13% examples, 612844 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:06,772 : INFO : PROGRESS: at 66.17% examples, 615178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:07,773 : INFO : PROGRESS: at 67.01% examples, 615603 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:08,786 : INFO : PROGRESS: at 67.77% examples, 614888 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:09,817 : INFO : PROGRESS: at 68.67% examples, 615247 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:10,830 : INFO : PROGRESS: at 69.35% examples, 613821 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:11,845 : INFO : PROGRESS: at 69.94% examples, 611697 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:33:12,861 : INFO : PROGRESS: at 70.65% examples, 610500 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:13,867 : INFO : PROGRESS: at 71.37% examples, 609586 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:14,871 : INFO : PROGRESS: at 72.04% examples, 608269 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:15,891 : INFO : PROGRESS: at 72.84% examples, 607910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:16,891 : INFO : PROGRESS: at 73.61% examples, 607511 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:17,901 : INFO : PROGRESS: at 74.32% examples, 606556 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:18,902 : INFO : PROGRESS: at 75.14% examples, 606512 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:19,904 : INFO : PROGRESS: at 76.00% examples, 606782 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:20,906 : INFO : PROGRESS: at 76.83% examples, 606812 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:21,907 : INFO : PROGRESS: at 77.78% examples, 607890 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:22,911 : INFO : PROGRESS: at 78.77% examples, 609169 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:23,916 : INFO : PROGRESS: at 79.68% examples, 609791 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:24,929 : INFO : PROGRESS: at 80.64% examples, 610452 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:25,938 : INFO : PROGRESS: at 81.54% examples, 610488 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:26,938 : INFO : PROGRESS: at 82.36% examples, 610208 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:33:27,959 : INFO : PROGRESS: at 83.06% examples, 609421 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 10:33:28,963 : INFO : PROGRESS: at 83.80% examples, 609034 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:29,974 : INFO : PROGRESS: at 84.76% examples, 610253 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:30,978 : INFO : PROGRESS: at 85.64% examples, 610825 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:31,989 : INFO : PROGRESS: at 86.52% examples, 611426 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:32,991 : INFO : PROGRESS: at 87.51% examples, 612778 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:33,992 : INFO : PROGRESS: at 88.49% examples, 613817 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:35,008 : INFO : PROGRESS: at 89.43% examples, 614469 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:36,020 : INFO : PROGRESS: at 90.39% examples, 615269 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:33:37,024 : INFO : PROGRESS: at 91.32% examples, 615963 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 10:33:38,032 : INFO : PROGRESS: at 92.22% examples, 616352 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:39,043 : INFO : PROGRESS: at 93.16% examples, 616988 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:40,050 : INFO : PROGRESS: at 94.16% examples, 617966 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:41,056 : INFO : PROGRESS: at 95.19% examples, 619209 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:42,062 : INFO : PROGRESS: at 96.25% examples, 620630 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:43,066 : INFO : PROGRESS: at 97.20% examples, 621305 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:44,075 : INFO : PROGRESS: at 98.19% examples, 622204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 10:33:45,086 : INFO : PROGRESS: at 99.17% examples, 623021 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 10:33:45,932 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 10:33:45,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 10:33:45,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 10:33:45,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 10:33:45,952 : INFO : training on 97219470 raw words (74257185 effective words) took 119.1s, 623634 effective words/s\n",
      "2017-04-24 10:33:45,953 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 10:33:46,211 : INFO : saving Word2Vec object under Results/dros_yeast_rat_mouse_GEN_comb_model, separately None\n",
      "2017-04-24 10:33:46,212 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 10:33:46,212 : INFO : storing np array 'syn0' to Results/dros_yeast_rat_mouse_GEN_comb_model.wv.syn0.npy\n",
      "2017-04-24 10:33:46,243 : INFO : not storing attribute cum_table\n",
      "2017-04-24 10:33:46,244 : INFO : storing np array 'syn1neg' to Results/dros_yeast_rat_mouse_GEN_comb_model.syn1neg.npy\n",
      "2017-04-24 10:33:46,377 : INFO : saved Results/dros_yeast_rat_mouse_GEN_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Gen model\n",
    "dros_old_GEN_sentence_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "rat_GEN_sentences_pkl = 'Results/rat/gen_real.pkl'\n",
    "mouse_GEN_sentences_pkl = 'Results/mouse/gen_real.pkl'\n",
    "data_list = [dros_old_GEN_sentence_pkl, yeast_GEN_sentences_pkl, rat_GEN_sentences_pkl, mouse_GEN_sentences_pkl]\n",
    "dros_yeast_rat_mouse_GEN_comb_model = make_w2v_model(data_list, 'dros_yeast_rat_mouse_GEN_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Both Ents model                                              \n",
    "# dros_old_BE_sentence_pkl = 'Results/drosophila/be_real.pkl'\n",
    "# yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "# rat_BE_sentences_pkl = 'Results/rat/be_real.pkl'\n",
    "# mouse_BE_sentences_pkl = 'Results/mouse/be_real.pkl'\n",
    "# data_list = [dros_old_BE_sentence_pkl, yeast_BE_sentences_pkl, rat_BE_sentences_pkl, mouse_BE_sentences_pkl]\n",
    "# dros_yeast_rat_mouse_BE_comb_model = make_w2v_model(data_list, 'dros_yeast_rat_mouse_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dros_yeast_rat_mouse_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model')\n",
    "dros_yeast_rat_mouse_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model')\n",
    "dros_yeast_rat_mouse_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "dros_strict_real = pickle.load(open('Results/drosophila/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_mouse_SR_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_mouse_GEN_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(dros_strict_real, \n",
    "                                             'dros_yeast_rat_mouse_BE_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/dros_yeast_rat_mouse_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/dros_yeast_rat_mouse_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/dros_yeast_rat_mouse_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/dros_yeast_rat_mouse_comb/Seeded/Results/'\n",
    "errors_dros_yeast_rat_mouse_comb = mult_open(drct, '_errors_')\n",
    "fpr_dros_yeast_rat_mouse_comb = mult_open(drct, '_fpr_')\n",
    "tpr_dros_yeast_rat_mouse_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error dros_yeast_rat_mouse_comb auc=0.557 error=0.330\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.557 error=0.321\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.564 error=0.326\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.558 error=0.325\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.558 error=0.353\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.561 error=0.349\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.489 error=0.479\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.492 error=0.479\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.483 error=0.479\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.496 error=0.468\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.493 error=0.491\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.493 error=0.489\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.579 error=0.324\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.578 error=0.310\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.584 error=0.320\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.583 error=0.321\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.579 error=0.313\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.584 error=0.321\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.582 error=0.428\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.579 error=0.428\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.578 error=0.419\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.563 error=0.443\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.586 error=0.419\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.591 error=0.428\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.499 error=0.326\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.514 error=0.324\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.595 error=0.316\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.590 error=0.316\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.523 error=0.308\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.543 error=0.318\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.650 error=0.287\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.644 error=0.287\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.648 error=0.283\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.667 error=0.270\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.657 error=0.292\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.657 error=0.298\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.590 error=0.314\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.569 error=0.303\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.583 error=0.314\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.590 error=0.309\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.586 error=0.281\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.604 error=0.303\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.564 error=0.348\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.582 error=0.331\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.570 error=0.356\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.585 error=0.370\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.577 error=0.323\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.587 error=0.323\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.596 error=0.403\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.585 error=0.407\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.599 error=0.415\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.607 error=0.410\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.596 error=0.417\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.597 error=0.407\n",
      "\n",
      "\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.578 error=0.382\n",
      "Strict error dros_yeast_rat_mouse_comb auc=0.571 error=0.400\n",
      "\n",
      "\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.595 error=0.390\n",
      "Gen error dros_yeast_rat_mouse_comb auc=0.591 error=0.373\n",
      "\n",
      "\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.572 error=0.379\n",
      "BE error dros_yeast_rat_mouse_comb auc=0.560 error=0.379\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_dros_yeast_rat_mouse_comb_strict = []\n",
    "mean_auc_dros_yeast_rat_mouse_comb_strict = []\n",
    "mean_err_dros_yeast_rat_mouse_comb_gen = []\n",
    "mean_auc_dros_yeast_rat_mouse_comb_gen = []\n",
    "mean_err_dros_yeast_rat_mouse_comb_be = []\n",
    "mean_auc_dros_yeast_rat_mouse_comb_be = []\n",
    "for e, f, t in zip(errors_dros_yeast_rat_mouse_comb, fpr_dros_yeast_rat_mouse_comb, tpr_dros_yeast_rat_mouse_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['dros_yeast_rat_mouse_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_dros_yeast_rat_mouse_comb_strict.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_mouse_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_dros_yeast_rat_mouse_comb_gen.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_mouse_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_dros_yeast_rat_mouse_comb_be.append(error_item)\n",
    "                    mean_auc_dros_yeast_rat_mouse_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_dros_yeast_rat_mouse_comb_org_strict = mean_err_dros_yeast_rat_mouse_comb_strict[0::2]\n",
    "mean_err_dros_yeast_rat_mouse_comb_fs_strict = mean_err_dros_yeast_rat_mouse_comb_strict[1::2]\n",
    "mean_auc_dros_yeast_rat_mouse_comb_org_strict = mean_auc_dros_yeast_rat_mouse_comb_strict[0::2]\n",
    "mean_auc_dros_yeast_rat_mouse_comb_fs_strict = mean_auc_dros_yeast_rat_mouse_comb_strict[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_mouse_comb_org_gen = mean_err_dros_yeast_rat_mouse_comb_gen[0::2]\n",
    "mean_err_dros_yeast_rat_mouse_comb_fs_gen = mean_err_dros_yeast_rat_mouse_comb_gen[1::2]\n",
    "mean_auc_dros_yeast_rat_mouse_comb_org_gen = mean_auc_dros_yeast_rat_mouse_comb_gen[0::2]\n",
    "mean_auc_dros_yeast_rat_mouse_comb_fs_gen = mean_auc_dros_yeast_rat_mouse_comb_gen[1::2]\n",
    "\n",
    "mean_err_dros_yeast_rat_mouse_comb_org_be = mean_err_dros_yeast_rat_mouse_comb_be[0::2]\n",
    "mean_err_dros_yeast_rat_mouse_comb_fs_be = mean_err_dros_yeast_rat_mouse_comb_be[1::2]\n",
    "mean_auc_dros_yeast_rat_mouse_comb_org_be = mean_auc_dros_yeast_rat_mouse_comb_be[0::2]\n",
    "mean_auc_dros_yeast_rat_mouse_comb_fs_be = mean_auc_dros_yeast_rat_mouse_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dros_yeast_rat_mouse_comb mean strict error original -  0.362068238365\n",
      "dros_yeast_rat_mouse_comb mean strict error feature selection -  0.359065007175\n",
      "dros_yeast_rat_mouse_comb mean strict AUC original -  0.568274831853\n",
      "dros_yeast_rat_mouse_comb mean strict AUC feature selection -  0.567170952716\n",
      "\n",
      "\n",
      "dros_yeast_rat_mouse_comb mean gen error original -  0.361726172819\n",
      "dros_yeast_rat_mouse_comb mean gen error feature selection -  0.360493736614\n",
      "dros_yeast_rat_mouse_comb mean gen AUC original -  0.579955070097\n",
      "dros_yeast_rat_mouse_comb mean gen AUC feature selection -  0.583121501557\n",
      "\n",
      "\n",
      "dros_yeast_rat_mouse_comb mean BE error original -  0.357601618994\n",
      "dros_yeast_rat_mouse_comb mean BE error feature selection -  0.361580269987\n",
      "dros_yeast_rat_mouse_comb mean BE AUC original -  0.572531326575\n",
      "dros_yeast_rat_mouse_comb mean BE AUC feature selection -  0.577407022855\n"
     ]
    }
   ],
   "source": [
    "print('dros_yeast_rat_mouse_comb mean strict error original - ', np.mean(mean_err_dros_yeast_rat_mouse_comb_org_strict))\n",
    "print('dros_yeast_rat_mouse_comb mean strict error feature selection - ', np.mean(mean_err_dros_yeast_rat_mouse_comb_fs_strict))\n",
    "print('dros_yeast_rat_mouse_comb mean strict AUC original - ', np.mean(mean_auc_dros_yeast_rat_mouse_comb_org_strict))\n",
    "print('dros_yeast_rat_mouse_comb mean strict AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_mouse_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat_mouse_comb mean gen error original - ', np.mean(mean_err_dros_yeast_rat_mouse_comb_org_gen))\n",
    "print('dros_yeast_rat_mouse_comb mean gen error feature selection - ', np.mean(mean_err_dros_yeast_rat_mouse_comb_fs_gen))\n",
    "print('dros_yeast_rat_mouse_comb mean gen AUC original - ', np.mean(mean_auc_dros_yeast_rat_mouse_comb_org_gen))\n",
    "print('dros_yeast_rat_mouse_comb mean gen AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_mouse_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('dros_yeast_rat_mouse_comb mean BE error original - ', np.mean(mean_err_dros_yeast_rat_mouse_comb_org_be))\n",
    "print('dros_yeast_rat_mouse_comb mean BE error feature selection - ', np.mean(mean_err_dros_yeast_rat_mouse_comb_fs_be))\n",
    "print('dros_yeast_rat_mouse_comb mean BE AUC original - ', np.mean(mean_auc_dros_yeast_rat_mouse_comb_org_be))\n",
    "print('dros_yeast_rat_mouse_comb mean BE AUC feature selection - ', np.mean(mean_auc_dros_yeast_rat_mouse_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 17:56:14,759 : INFO : loading Word2Vec object from Results/yeast/Seeded/Results/yeast_strict_real_model\n",
      "2017-04-24 17:56:14,815 : INFO : loading wv recursively from Results/yeast/Seeded/Results/yeast_strict_real_model.wv.* with mmap=None\n",
      "2017-04-24 17:56:14,816 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 17:56:14,816 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 17:56:14,817 : INFO : loaded Results/yeast/Seeded/Results/yeast_strict_real_model\n",
      "2017-04-24 17:56:14,822 : INFO : training model with 4 workers on 3400 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 17:56:14,823 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 17:56:15,402 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 17:56:15,403 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 17:56:15,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 17:56:15,408 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 17:56:15,409 : INFO : training on 928405 raw words (543800 effective words) took 0.6s, 934701 effective words/s\n",
      "2017-04-24 17:56:15,411 : WARNING : supplied example count (36355) did not equal expected count (35725)\n",
      "2017-04-24 17:56:15,413 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 17:56:15,435 : INFO : saving Word2Vec object under Results/yeast_dros_SR_model, separately None\n",
      "2017-04-24 17:56:15,436 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 17:56:15,437 : INFO : not storing attribute cum_table\n",
      "2017-04-24 17:56:15,438 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 17:56:15,519 : INFO : saved Results/yeast_dros_SR_model\n",
      "2017-04-24 17:56:16,789 : INFO : loading Word2Vec object from Results/yeast/Seeded/Results/yeast_gen_real_model\n",
      "2017-04-24 17:56:16,924 : INFO : loading wv recursively from Results/yeast/Seeded/Results/yeast_gen_real_model.wv.* with mmap=None\n",
      "2017-04-24 17:56:16,925 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 17:56:16,926 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 17:56:16,926 : INFO : loaded Results/yeast/Seeded/Results/yeast_gen_real_model\n",
      "2017-04-24 17:56:16,945 : INFO : training model with 4 workers on 8289 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 17:56:16,945 : INFO : expecting 47536 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 17:56:17,956 : INFO : PROGRESS: at 20.71% examples, 776927 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:18,961 : INFO : PROGRESS: at 43.33% examples, 812228 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:19,987 : INFO : PROGRESS: at 64.51% examples, 801247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:20,619 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 17:56:20,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 17:56:20,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 17:56:20,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 17:56:20,634 : INFO : training on 4507620 raw words (2936329 effective words) took 3.7s, 797063 effective words/s\n",
      "2017-04-24 17:56:20,635 : WARNING : supplied example count (185085) did not equal expected count (237680)\n",
      "2017-04-24 17:56:20,636 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 17:56:20,686 : INFO : saving Word2Vec object under Results/yeast_dros_GEN_model, separately None\n",
      "2017-04-24 17:56:20,687 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 17:56:20,688 : INFO : not storing attribute cum_table\n",
      "2017-04-24 17:56:20,689 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 17:56:20,884 : INFO : saved Results/yeast_dros_GEN_model\n",
      "2017-04-24 17:56:24,287 : INFO : loading Word2Vec object from Results/yeast/Seeded/Results/yeast_both_ents_model\n",
      "2017-04-24 17:56:25,408 : INFO : loading wv recursively from Results/yeast/Seeded/Results/yeast_both_ents_model.wv.* with mmap=None\n",
      "2017-04-24 17:56:25,410 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 17:56:25,410 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 17:56:25,411 : INFO : loaded Results/yeast/Seeded/Results/yeast_both_ents_model\n",
      "2017-04-24 17:56:25,448 : INFO : training model with 4 workers on 16896 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 17:56:25,448 : INFO : expecting 194507 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 17:56:26,454 : INFO : PROGRESS: at 5.04% examples, 799450 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:27,470 : INFO : PROGRESS: at 10.16% examples, 800641 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:28,478 : INFO : PROGRESS: at 15.10% examples, 793299 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 17:56:29,484 : INFO : PROGRESS: at 19.99% examples, 788637 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:30,502 : INFO : PROGRESS: at 24.85% examples, 782510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:31,504 : INFO : PROGRESS: at 28.55% examples, 750199 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:32,508 : INFO : PROGRESS: at 32.11% examples, 723612 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:33,511 : INFO : PROGRESS: at 35.44% examples, 699376 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 17:56:34,538 : INFO : PROGRESS: at 38.92% examples, 681039 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:35,548 : INFO : PROGRESS: at 43.60% examples, 686627 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:36,563 : INFO : PROGRESS: at 48.14% examples, 688942 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:37,583 : INFO : PROGRESS: at 52.76% examples, 691627 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:38,585 : INFO : PROGRESS: at 57.44% examples, 695462 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:39,599 : INFO : PROGRESS: at 62.26% examples, 699702 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 17:56:40,600 : INFO : PROGRESS: at 67.33% examples, 706766 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:41,618 : INFO : PROGRESS: at 72.17% examples, 709936 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:42,633 : INFO : PROGRESS: at 77.03% examples, 712965 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:43,634 : INFO : PROGRESS: at 81.71% examples, 714569 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 17:56:44,660 : INFO : PROGRESS: at 86.61% examples, 716960 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 17:56:45,681 : INFO : PROGRESS: at 91.05% examples, 715791 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 17:56:45,916 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 17:56:45,923 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 17:56:45,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 17:56:45,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 17:56:45,932 : INFO : training on 20708940 raw words (14680931 effective words) took 20.5s, 716880 effective words/s\n",
      "2017-04-24 17:56:45,933 : WARNING : supplied example count (897865) did not equal expected count (972535)\n",
      "2017-04-24 17:56:45,934 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 17:56:46,052 : INFO : saving Word2Vec object under Results/yeast_dros_BE_model, separately None\n",
      "2017-04-24 17:56:46,053 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 17:56:46,054 : INFO : not storing attribute cum_table\n",
      "2017-04-24 17:56:46,055 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 17:56:46,426 : INFO : saved Results/yeast_dros_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "yeast_old_SR_model = 'Results/yeast/Seeded/Results/yeast_strict_real_model'\n",
    "dros_SR_sentences_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "yeast_dros_SR_model = add_sentences_to_model(yeast_old_SR_model, dros_SR_sentences_pkl, 'yeast_dros_SR_model')\n",
    "\n",
    "#Gen model\n",
    "yeast_old_GEN_model = 'Results/yeast/Seeded/Results/yeast_gen_real_model'\n",
    "dros_GEN_sentences_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "yeast_dros_GEN_model = add_sentences_to_model(yeast_old_GEN_model, dros_GEN_sentences_pkl, 'yeast_dros_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "yeast_old_BE_model = 'Results/yeast/Seeded/Results/yeast_both_ents_model'\n",
    "dros_BE_sentences_pkl = 'Results/drosophila/be_real.pkl'\n",
    "yeast_dros_BE_model = add_sentences_to_model(yeast_old_BE_model, dros_BE_sentences_pkl, 'yeast_dros_BE_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "yeast_strict_real = pickle.load(open('Results/yeast/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_SR_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_GEN_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_BE_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/yeast_dros_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/yeast_dros_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/yeast_dros_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast_dros/Seeded/Results/'\n",
    "errors_yeast_dros = mult_open(drct, '_errors_')\n",
    "fpr_yeast_dros = mult_open(drct, '_fpr_')\n",
    "tpr_yeast_dros = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast_dros auc=0.639 error=0.437\n",
      "Strict error yeast_dros auc=0.650 error=0.420\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.705 error=0.340\n",
      "Gen error yeast_dros auc=0.713 error=0.316\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.714 error=0.342\n",
      "BE error yeast_dros auc=0.711 error=0.348\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.654 error=0.393\n",
      "Strict error yeast_dros auc=0.649 error=0.387\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.684 error=0.361\n",
      "Gen error yeast_dros auc=0.683 error=0.357\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.674 error=0.371\n",
      "BE error yeast_dros auc=0.682 error=0.353\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.620 error=0.372\n",
      "Strict error yeast_dros auc=0.632 error=0.386\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.700 error=0.336\n",
      "Gen error yeast_dros auc=0.703 error=0.333\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.691 error=0.346\n",
      "BE error yeast_dros auc=0.682 error=0.350\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.667 error=0.356\n",
      "Strict error yeast_dros auc=0.664 error=0.356\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.742 error=0.335\n",
      "Gen error yeast_dros auc=0.740 error=0.332\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.725 error=0.328\n",
      "BE error yeast_dros auc=0.717 error=0.328\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.628 error=0.425\n",
      "Strict error yeast_dros auc=0.634 error=0.405\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.680 error=0.349\n",
      "Gen error yeast_dros auc=0.688 error=0.349\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.703 error=0.345\n",
      "BE error yeast_dros auc=0.687 error=0.354\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.659 error=0.361\n",
      "Strict error yeast_dros auc=0.656 error=0.374\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.695 error=0.343\n",
      "Gen error yeast_dros auc=0.698 error=0.352\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.710 error=0.352\n",
      "BE error yeast_dros auc=0.714 error=0.347\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.660 error=0.379\n",
      "Strict error yeast_dros auc=0.645 error=0.402\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.688 error=0.368\n",
      "Gen error yeast_dros auc=0.680 error=0.381\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.677 error=0.373\n",
      "BE error yeast_dros auc=0.695 error=0.342\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.642 error=0.399\n",
      "Strict error yeast_dros auc=0.645 error=0.396\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.670 error=0.362\n",
      "Gen error yeast_dros auc=0.677 error=0.346\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.685 error=0.375\n",
      "BE error yeast_dros auc=0.687 error=0.378\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.637 error=0.416\n",
      "Strict error yeast_dros auc=0.636 error=0.420\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.663 error=0.406\n",
      "Gen error yeast_dros auc=0.665 error=0.413\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.665 error=0.404\n",
      "BE error yeast_dros auc=0.667 error=0.404\n",
      "\n",
      "\n",
      "Strict error yeast_dros auc=0.654 error=0.348\n",
      "Strict error yeast_dros auc=0.648 error=0.360\n",
      "\n",
      "\n",
      "Gen error yeast_dros auc=0.741 error=0.308\n",
      "Gen error yeast_dros auc=0.746 error=0.311\n",
      "\n",
      "\n",
      "BE error yeast_dros auc=0.741 error=0.295\n",
      "BE error yeast_dros auc=0.739 error=0.293\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_dros_strict = []\n",
    "mean_auc_yeast_dros_strict = []\n",
    "mean_err_yeast_dros_gen = []\n",
    "mean_auc_yeast_dros_gen = []\n",
    "mean_err_yeast_dros_be = []\n",
    "mean_auc_yeast_dros_be = []\n",
    "for e, f, t in zip(errors_yeast_dros, fpr_yeast_dros, tpr_yeast_dros):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast_dros']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_dros_strict.append(error_item)\n",
    "                    mean_auc_yeast_dros_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_dros_gen.append(error_item)\n",
    "                    mean_auc_yeast_dros_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_dros_be.append(error_item)\n",
    "                    mean_auc_yeast_dros_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_dros_org_strict = mean_err_yeast_dros_strict[0::2]\n",
    "mean_err_yeast_dros_fs_strict = mean_err_yeast_dros_strict[1::2]\n",
    "mean_auc_yeast_dros_org_strict = mean_auc_yeast_dros_strict[0::2]\n",
    "mean_auc_yeast_dros_fs_strict = mean_auc_yeast_dros_strict[1::2]\n",
    "\n",
    "mean_err_yeast_dros_org_gen = mean_err_yeast_dros_gen[0::2]\n",
    "mean_err_yeast_dros_fs_gen = mean_err_yeast_dros_gen[1::2]\n",
    "mean_auc_yeast_dros_org_gen = mean_auc_yeast_dros_gen[0::2]\n",
    "mean_auc_yeast_dros_fs_gen = mean_auc_yeast_dros_gen[1::2]\n",
    "\n",
    "mean_err_yeast_dros_org_be = mean_err_yeast_dros_be[0::2]\n",
    "mean_err_yeast_dros_fs_be = mean_err_yeast_dros_be[1::2]\n",
    "mean_auc_yeast_dros_org_be = mean_auc_yeast_dros_be[0::2]\n",
    "mean_auc_yeast_dros_fs_be = mean_auc_yeast_dros_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast_dros mean strict error original -  0.388679979671\n",
      "yeast_dros mean strict error feature selection -  0.390777364387\n",
      "yeast_dros mean strict AUC original -  0.64586467146\n",
      "yeast_dros mean strict AUC feature selection -  0.645932144082\n",
      "\n",
      "\n",
      "yeast_dros mean gen error original -  0.350794380731\n",
      "yeast_dros mean gen error feature selection -  0.349071375837\n",
      "yeast_dros mean gen AUC original -  0.696766387711\n",
      "yeast_dros mean gen AUC feature selection -  0.699218135582\n",
      "\n",
      "\n",
      "yeast_dros mean BE error original -  0.353186480273\n",
      "yeast_dros mean BE error feature selection -  0.349641005257\n",
      "yeast_dros mean BE AUC original -  0.698560598409\n",
      "yeast_dros mean BE AUC feature selection -  0.69806288019\n"
     ]
    }
   ],
   "source": [
    "print('yeast_dros mean strict error original - ', np.mean(mean_err_yeast_dros_org_strict))\n",
    "print('yeast_dros mean strict error feature selection - ', np.mean(mean_err_yeast_dros_fs_strict))\n",
    "print('yeast_dros mean strict AUC original - ', np.mean(mean_auc_yeast_dros_org_strict))\n",
    "print('yeast_dros mean strict AUC feature selection - ', np.mean(mean_auc_yeast_dros_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast_dros mean gen error original - ', np.mean(mean_err_yeast_dros_org_gen))\n",
    "print('yeast_dros mean gen error feature selection - ', np.mean(mean_err_yeast_dros_fs_gen))\n",
    "print('yeast_dros mean gen AUC original - ', np.mean(mean_auc_yeast_dros_org_gen))\n",
    "print('yeast_dros mean gen AUC feature selection - ', np.mean(mean_auc_yeast_dros_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast_dros mean BE error original - ', np.mean(mean_err_yeast_dros_org_be))\n",
    "print('yeast_dros mean BE error feature selection - ', np.mean(mean_err_yeast_dros_fs_be))\n",
    "print('yeast_dros mean BE AUC original - ', np.mean(mean_auc_yeast_dros_org_be))\n",
    "print('yeast_dros mean BE AUC feature selection - ', np.mean(mean_auc_yeast_dros_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 18:16:04,235 : INFO : loading Word2Vec object from Results/yeast_dros/Seeded/Results/yeast_dros_SR_model\n",
      "2017-04-24 18:16:04,286 : INFO : loading wv recursively from Results/yeast_dros/Seeded/Results/yeast_dros_SR_model.wv.* with mmap=None\n",
      "2017-04-24 18:16:04,287 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 18:16:04,287 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 18:16:04,288 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 18:16:04,288 : INFO : loaded Results/yeast_dros/Seeded/Results/yeast_dros_SR_model\n",
      "2017-04-24 18:16:04,294 : INFO : training model with 4 workers on 3400 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 18:16:04,295 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 18:16:05,300 : INFO : PROGRESS: at 206.81% examples, 1122555 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:06,301 : INFO : PROGRESS: at 402.71% examples, 1092484 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:07,312 : INFO : PROGRESS: at 591.60% examples, 1066343 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:07,502 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 18:16:07,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 18:16:07,510 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 18:16:07,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 18:16:07,513 : INFO : training on 6296340 raw words (3422486 effective words) took 3.2s, 1064925 effective words/s\n",
      "2017-04-24 18:16:07,513 : WARNING : supplied example count (225220) did not equal expected count (35725)\n",
      "2017-04-24 18:16:07,514 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 18:16:07,535 : INFO : saving Word2Vec object under Results/yeast_dros_rat_SR_model, separately None\n",
      "2017-04-24 18:16:07,536 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 18:16:07,537 : INFO : not storing attribute cum_table\n",
      "2017-04-24 18:16:07,537 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 18:16:07,601 : INFO : saved Results/yeast_dros_rat_SR_model\n",
      "2017-04-24 18:16:11,157 : INFO : loading Word2Vec object from Results/yeast_dros/Seeded/Results/yeast_dros_GEN_model\n",
      "2017-04-24 18:16:11,603 : INFO : loading wv recursively from Results/yeast_dros/Seeded/Results/yeast_dros_GEN_model.wv.* with mmap=None\n",
      "2017-04-24 18:16:11,604 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 18:16:11,605 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 18:16:11,605 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 18:16:11,606 : INFO : loaded Results/yeast_dros/Seeded/Results/yeast_dros_GEN_model\n",
      "2017-04-24 18:16:11,621 : INFO : training model with 4 workers on 8289 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 18:16:11,622 : INFO : expecting 47536 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 18:16:12,634 : INFO : PROGRESS: at 25.78% examples, 1018803 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:13,643 : INFO : PROGRESS: at 51.50% examples, 1013918 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:16:14,652 : INFO : PROGRESS: at 77.17% examples, 1012051 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:15,658 : INFO : PROGRESS: at 103.42% examples, 1018439 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:16:16,667 : INFO : PROGRESS: at 131.18% examples, 1032351 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:17,670 : INFO : PROGRESS: at 157.91% examples, 1036449 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:18,675 : INFO : PROGRESS: at 175.61% examples, 988491 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:19,689 : INFO : PROGRESS: at 193.40% examples, 951420 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:20,700 : INFO : PROGRESS: at 210.84% examples, 921534 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:21,703 : INFO : PROGRESS: at 231.65% examples, 911697 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:22,706 : INFO : PROGRESS: at 263.39% examples, 942915 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:16:23,707 : INFO : PROGRESS: at 294.84% examples, 967859 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:24,709 : INFO : PROGRESS: at 326.07% examples, 988579 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:25,710 : INFO : PROGRESS: at 353.82% examples, 996368 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:26,508 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 18:16:26,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 18:16:26,517 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 18:16:26,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 18:16:26,521 : INFO : training on 24192400 raw words (14950034 effective words) took 14.9s, 1003802 effective words/s\n",
      "2017-04-24 18:16:26,522 : WARNING : supplied example count (896095) did not equal expected count (237680)\n",
      "2017-04-24 18:16:26,522 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 18:16:26,571 : INFO : saving Word2Vec object under Results/yeast_dros_rat_GEN_model, separately None\n",
      "2017-04-24 18:16:26,572 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 18:16:26,573 : INFO : not storing attribute cum_table\n",
      "2017-04-24 18:16:26,573 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 18:16:26,726 : INFO : saved Results/yeast_dros_rat_GEN_model\n",
      "2017-04-24 18:16:49,115 : INFO : loading Word2Vec object from Results/yeast_dros/Seeded/Results/yeast_dros_BE_model\n",
      "2017-04-24 18:16:49,410 : INFO : loading wv recursively from Results/yeast_dros/Seeded/Results/yeast_dros_BE_model.wv.* with mmap=None\n",
      "2017-04-24 18:16:49,411 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 18:16:49,412 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 18:16:49,412 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 18:16:49,413 : INFO : loaded Results/yeast_dros/Seeded/Results/yeast_dros_BE_model\n",
      "2017-04-24 18:16:49,448 : INFO : training model with 4 workers on 16896 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 18:16:49,449 : INFO : expecting 194507 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 18:16:50,456 : INFO : PROGRESS: at 3.93% examples, 663360 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:16:51,467 : INFO : PROGRESS: at 8.45% examples, 708755 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:52,487 : INFO : PROGRESS: at 12.38% examples, 689420 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:16:53,487 : INFO : PROGRESS: at 16.91% examples, 707470 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:54,492 : INFO : PROGRESS: at 22.81% examples, 763432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:55,494 : INFO : PROGRESS: at 28.91% examples, 806689 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:56,507 : INFO : PROGRESS: at 34.36% examples, 820501 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:16:57,509 : INFO : PROGRESS: at 39.74% examples, 831080 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:16:58,513 : INFO : PROGRESS: at 44.90% examples, 834579 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:16:59,523 : INFO : PROGRESS: at 50.16% examples, 839022 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:00,526 : INFO : PROGRESS: at 55.18% examples, 839469 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:01,532 : INFO : PROGRESS: at 60.63% examples, 845268 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:02,538 : INFO : PROGRESS: at 65.37% examples, 841099 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:03,539 : INFO : PROGRESS: at 69.90% examples, 835451 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:04,542 : INFO : PROGRESS: at 74.19% examples, 827614 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:05,564 : INFO : PROGRESS: at 78.09% examples, 815884 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:17:06,574 : INFO : PROGRESS: at 82.94% examples, 815439 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:17:07,577 : INFO : PROGRESS: at 87.42% examples, 811908 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:08,581 : INFO : PROGRESS: at 92.57% examples, 814620 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:09,584 : INFO : PROGRESS: at 98.38% examples, 822589 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:10,591 : INFO : PROGRESS: at 104.06% examples, 828693 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:11,595 : INFO : PROGRESS: at 110.14% examples, 837469 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:12,598 : INFO : PROGRESS: at 116.30% examples, 845825 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:13,604 : INFO : PROGRESS: at 122.44% examples, 853405 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:14,604 : INFO : PROGRESS: at 128.31% examples, 858894 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:15,606 : INFO : PROGRESS: at 133.90% examples, 862114 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:16,612 : INFO : PROGRESS: at 139.59% examples, 865449 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:17,619 : INFO : PROGRESS: at 144.89% examples, 866275 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:18,623 : INFO : PROGRESS: at 148.51% examples, 857310 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:17:19,635 : INFO : PROGRESS: at 151.87% examples, 847347 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:17:20,638 : INFO : PROGRESS: at 155.77% examples, 841127 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:21,640 : INFO : PROGRESS: at 159.68% examples, 835347 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:22,642 : INFO : PROGRESS: at 164.13% examples, 832633 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:23,659 : INFO : PROGRESS: at 168.06% examples, 827281 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:24,665 : INFO : PROGRESS: at 172.51% examples, 824882 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:25,670 : INFO : PROGRESS: at 177.10% examples, 823415 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:26,673 : INFO : PROGRESS: at 182.12% examples, 823923 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:27,676 : INFO : PROGRESS: at 187.16% examples, 824419 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:28,686 : INFO : PROGRESS: at 192.44% examples, 825813 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 18:17:29,704 : INFO : PROGRESS: at 197.68% examples, 826792 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:30,710 : INFO : PROGRESS: at 202.29% examples, 825447 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:31,728 : INFO : PROGRESS: at 206.90% examples, 823929 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:32,729 : INFO : PROGRESS: at 211.50% examples, 822768 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:33,739 : INFO : PROGRESS: at 216.15% examples, 821667 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:34,744 : INFO : PROGRESS: at 222.21% examples, 825979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:35,750 : INFO : PROGRESS: at 227.40% examples, 826884 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:36,755 : INFO : PROGRESS: at 232.67% examples, 828085 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:17:37,758 : INFO : PROGRESS: at 237.88% examples, 829082 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:38,768 : INFO : PROGRESS: at 241.96% examples, 825983 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:39,777 : INFO : PROGRESS: at 245.82% examples, 822338 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:17:40,793 : INFO : PROGRESS: at 249.63% examples, 818583 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:17:41,796 : INFO : PROGRESS: at 253.62% examples, 815706 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:42,801 : INFO : PROGRESS: at 258.33% examples, 815269 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:43,809 : INFO : PROGRESS: at 263.09% examples, 814942 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:44,823 : INFO : PROGRESS: at 267.90% examples, 814658 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:45,826 : INFO : PROGRESS: at 272.71% examples, 814557 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:46,827 : INFO : PROGRESS: at 278.19% examples, 816436 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 18:17:47,829 : INFO : PROGRESS: at 284.21% examples, 819779 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:48,832 : INFO : PROGRESS: at 290.53% examples, 823797 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:49,838 : INFO : PROGRESS: at 296.83% examples, 827648 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:50,838 : INFO : PROGRESS: at 302.07% examples, 828502 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:51,844 : INFO : PROGRESS: at 307.33% examples, 829367 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 18:17:52,846 : INFO : PROGRESS: at 312.27% examples, 829384 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:53,849 : INFO : PROGRESS: at 317.01% examples, 828820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:54,859 : INFO : PROGRESS: at 320.47% examples, 824903 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:55,891 : INFO : PROGRESS: at 323.91% examples, 820822 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:17:56,892 : INFO : PROGRESS: at 327.45% examples, 817447 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:17:57,899 : INFO : PROGRESS: at 331.44% examples, 815223 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:58,904 : INFO : PROGRESS: at 336.00% examples, 814501 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:17:59,905 : INFO : PROGRESS: at 340.52% examples, 813718 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:00,907 : INFO : PROGRESS: at 345.05% examples, 812970 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:01,907 : INFO : PROGRESS: at 349.91% examples, 813035 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:02,908 : INFO : PROGRESS: at 355.26% examples, 814231 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:03,923 : INFO : PROGRESS: at 360.48% examples, 814959 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:04,933 : INFO : PROGRESS: at 365.62% examples, 815533 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:05,938 : INFO : PROGRESS: at 370.81% examples, 816244 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:06,939 : INFO : PROGRESS: at 374.71% examples, 814170 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:07,940 : INFO : PROGRESS: at 378.44% examples, 811799 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:08,947 : INFO : PROGRESS: at 381.81% examples, 808624 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:09,952 : INFO : PROGRESS: at 385.40% examples, 806072 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:10,958 : INFO : PROGRESS: at 390.57% examples, 806848 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:11,964 : INFO : PROGRESS: at 395.71% examples, 807509 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:12,971 : INFO : PROGRESS: at 400.85% examples, 808164 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:13,971 : INFO : PROGRESS: at 405.88% examples, 808609 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:14,984 : INFO : PROGRESS: at 409.87% examples, 806869 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:16,000 : INFO : PROGRESS: at 413.77% examples, 804989 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:17,015 : INFO : PROGRESS: at 417.72% examples, 803234 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:18,021 : INFO : PROGRESS: at 421.96% examples, 802148 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:19,027 : INFO : PROGRESS: at 426.93% examples, 802490 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:20,029 : INFO : PROGRESS: at 432.08% examples, 803183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:21,039 : INFO : PROGRESS: at 437.18% examples, 803722 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-24 18:18:22,049 : INFO : PROGRESS: at 442.34% examples, 804307 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:23,060 : INFO : PROGRESS: at 446.24% examples, 802627 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:24,072 : INFO : PROGRESS: at 450.15% examples, 800994 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:25,074 : INFO : PROGRESS: at 454.68% examples, 800563 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:26,078 : INFO : PROGRESS: at 459.71% examples, 800996 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:27,080 : INFO : PROGRESS: at 464.90% examples, 801733 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:28,085 : INFO : PROGRESS: at 470.20% examples, 802624 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:29,091 : INFO : PROGRESS: at 475.40% examples, 803287 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:30,110 : INFO : PROGRESS: at 480.75% examples, 804124 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:31,115 : INFO : PROGRESS: at 486.35% examples, 805444 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:32,116 : INFO : PROGRESS: at 491.82% examples, 806565 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:33,122 : INFO : PROGRESS: at 497.26% examples, 807567 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:34,126 : INFO : PROGRESS: at 502.44% examples, 808166 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:35,146 : INFO : PROGRESS: at 507.64% examples, 808626 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:36,168 : INFO : PROGRESS: at 512.73% examples, 808928 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:37,169 : INFO : PROGRESS: at 517.98% examples, 809658 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:38,175 : INFO : PROGRESS: at 522.34% examples, 808911 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:39,183 : INFO : PROGRESS: at 525.77% examples, 806772 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:40,199 : INFO : PROGRESS: at 529.18% examples, 804550 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:41,202 : INFO : PROGRESS: at 532.95% examples, 803026 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:42,206 : INFO : PROGRESS: at 537.20% examples, 802198 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:43,211 : INFO : PROGRESS: at 541.67% examples, 801741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:44,213 : INFO : PROGRESS: at 545.09% examples, 799726 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:45,221 : INFO : PROGRESS: at 549.08% examples, 798560 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:46,232 : INFO : PROGRESS: at 553.47% examples, 797984 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:47,236 : INFO : PROGRESS: at 558.79% examples, 798771 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:48,240 : INFO : PROGRESS: at 563.92% examples, 799318 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:49,242 : INFO : PROGRESS: at 569.74% examples, 800798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:50,246 : INFO : PROGRESS: at 575.47% examples, 802118 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:51,253 : INFO : PROGRESS: at 579.51% examples, 801054 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:52,254 : INFO : PROGRESS: at 583.54% examples, 800049 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:53,262 : INFO : PROGRESS: at 587.49% examples, 798899 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:18:54,263 : INFO : PROGRESS: at 591.97% examples, 798540 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:55,281 : INFO : PROGRESS: at 597.16% examples, 799021 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 18:18:56,292 : INFO : PROGRESS: at 602.35% examples, 799529 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:57,293 : INFO : PROGRESS: at 607.62% examples, 800223 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:18:58,307 : INFO : PROGRESS: at 612.77% examples, 800650 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 18:18:59,319 : INFO : PROGRESS: at 616.79% examples, 799622 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:19:00,331 : INFO : PROGRESS: at 620.76% examples, 798560 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 18:19:01,334 : INFO : PROGRESS: at 624.74% examples, 797576 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:19:02,341 : INFO : PROGRESS: at 629.28% examples, 797262 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:19:03,352 : INFO : PROGRESS: at 634.59% examples, 797918 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:19:04,357 : INFO : PROGRESS: at 639.90% examples, 798596 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 18:19:04,856 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 18:19:04,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 18:19:04,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 18:19:04,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 18:19:04,877 : INFO : training on 154634470 raw words (108199636 effective words) took 135.4s, 798980 effective words/s\n",
      "2017-04-24 18:19:04,878 : WARNING : supplied example count (6250045) did not equal expected count (972535)\n",
      "2017-04-24 18:19:04,878 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 18:19:05,035 : INFO : saving Word2Vec object under Results/yeast_dros_rat_BE_model, separately None\n",
      "2017-04-24 18:19:05,036 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 18:19:05,037 : INFO : not storing attribute cum_table\n",
      "2017-04-24 18:19:05,038 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 18:19:05,541 : INFO : saved Results/yeast_dros_rat_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "yeast_dros_old_SR_model = 'Results/yeast_dros/Seeded/Results/yeast_dros_SR_model'\n",
    "rat_SR_sentences_pkl = 'Results/rat/strict_real.pkl'\n",
    "yeast_dros_rat_SR_model = add_sentences_to_model(yeast_dros_old_SR_model, rat_SR_sentences_pkl, 'yeast_dros_rat_SR_model')\n",
    "\n",
    "#Gen model\n",
    "yeast_dros_old_GEN_model = 'Results/yeast_dros/Seeded/Results/yeast_dros_GEN_model'\n",
    "rat_GEN_sentences_pkl = 'Results/rat/gen_real.pkl'\n",
    "yeast_dros_rat_GEN_model = add_sentences_to_model(yeast_dros_old_GEN_model, rat_GEN_sentences_pkl, 'yeast_dros_rat_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "yeast_dros_old_BE_model = 'Results/yeast_dros/Seeded/Results/yeast_dros_BE_model'\n",
    "rat_BE_sentences_pkl = 'Results/rat/be_real.pkl'\n",
    "yeast_dros_rat_BE_model = add_sentences_to_model(yeast_dros_old_BE_model, rat_BE_sentences_pkl, 'yeast_dros_rat_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "yeast_strict_real = pickle.load(open('Results/yeast/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_SR_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_rat_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_GEN_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_rat_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_BE_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_rat_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/yeast_dros_rat_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/yeast_dros_rat_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/yeast_dros_rat_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast_dros_rat/Seeded/Results/'\n",
    "errors_yeast_dros_rat = mult_open(drct, '_errors_')\n",
    "fpr_yeast_dros_rat = mult_open(drct, '_fpr_')\n",
    "tpr_yeast_dros_rat = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast_dros_rat auc=0.641 error=0.395\n",
      "Strict error yeast_dros_rat auc=0.631 error=0.417\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.717 error=0.330\n",
      "Gen error yeast_dros_rat auc=0.707 error=0.337\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.712 error=0.331\n",
      "BE error yeast_dros_rat auc=0.710 error=0.337\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.667 error=0.373\n",
      "Strict error yeast_dros_rat auc=0.649 error=0.381\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.677 error=0.345\n",
      "Gen error yeast_dros_rat auc=0.685 error=0.343\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.685 error=0.370\n",
      "BE error yeast_dros_rat auc=0.695 error=0.359\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.635 error=0.368\n",
      "Strict error yeast_dros_rat auc=0.649 error=0.349\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.707 error=0.332\n",
      "Gen error yeast_dros_rat auc=0.709 error=0.328\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.698 error=0.349\n",
      "BE error yeast_dros_rat auc=0.693 error=0.340\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.660 error=0.376\n",
      "Strict error yeast_dros_rat auc=0.662 error=0.366\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.739 error=0.330\n",
      "Gen error yeast_dros_rat auc=0.733 error=0.327\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.734 error=0.304\n",
      "BE error yeast_dros_rat auc=0.724 error=0.322\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.630 error=0.405\n",
      "Strict error yeast_dros_rat auc=0.625 error=0.405\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.675 error=0.363\n",
      "Gen error yeast_dros_rat auc=0.667 error=0.376\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.671 error=0.372\n",
      "BE error yeast_dros_rat auc=0.671 error=0.377\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.621 error=0.394\n",
      "Strict error yeast_dros_rat auc=0.613 error=0.393\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.716 error=0.345\n",
      "Gen error yeast_dros_rat auc=0.690 error=0.358\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.700 error=0.350\n",
      "BE error yeast_dros_rat auc=0.702 error=0.338\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.634 error=0.404\n",
      "Strict error yeast_dros_rat auc=0.646 error=0.396\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.700 error=0.366\n",
      "Gen error yeast_dros_rat auc=0.698 error=0.359\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.723 error=0.336\n",
      "BE error yeast_dros_rat auc=0.713 error=0.349\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.603 error=0.416\n",
      "Strict error yeast_dros_rat auc=0.613 error=0.411\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.704 error=0.359\n",
      "Gen error yeast_dros_rat auc=0.698 error=0.361\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.693 error=0.361\n",
      "BE error yeast_dros_rat auc=0.706 error=0.339\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.635 error=0.419\n",
      "Strict error yeast_dros_rat auc=0.647 error=0.409\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.658 error=0.410\n",
      "Gen error yeast_dros_rat auc=0.657 error=0.397\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.667 error=0.401\n",
      "BE error yeast_dros_rat auc=0.670 error=0.397\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat auc=0.648 error=0.373\n",
      "Strict error yeast_dros_rat auc=0.646 error=0.363\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat auc=0.757 error=0.293\n",
      "Gen error yeast_dros_rat auc=0.746 error=0.305\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat auc=0.750 error=0.298\n",
      "BE error yeast_dros_rat auc=0.753 error=0.292\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_dros_rat_strict = []\n",
    "mean_auc_yeast_dros_rat_strict = []\n",
    "mean_err_yeast_dros_rat_gen = []\n",
    "mean_auc_yeast_dros_rat_gen = []\n",
    "mean_err_yeast_dros_rat_be = []\n",
    "mean_auc_yeast_dros_rat_be = []\n",
    "for e, f, t in zip(errors_yeast_dros_rat, fpr_yeast_dros_rat, tpr_yeast_dros_rat):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast_dros_rat']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_dros_rat_strict.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_dros_rat_gen.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_dros_rat_be.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_dros_rat_org_strict = mean_err_yeast_dros_rat_strict[0::2]\n",
    "mean_err_yeast_dros_rat_fs_strict = mean_err_yeast_dros_rat_strict[1::2]\n",
    "mean_auc_yeast_dros_rat_org_strict = mean_auc_yeast_dros_rat_strict[0::2]\n",
    "mean_auc_yeast_dros_rat_fs_strict = mean_auc_yeast_dros_rat_strict[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_org_gen = mean_err_yeast_dros_rat_gen[0::2]\n",
    "mean_err_yeast_dros_rat_fs_gen = mean_err_yeast_dros_rat_gen[1::2]\n",
    "mean_auc_yeast_dros_rat_org_gen = mean_auc_yeast_dros_rat_gen[0::2]\n",
    "mean_auc_yeast_dros_rat_fs_gen = mean_auc_yeast_dros_rat_gen[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_org_be = mean_err_yeast_dros_rat_be[0::2]\n",
    "mean_err_yeast_dros_rat_fs_be = mean_err_yeast_dros_rat_be[1::2]\n",
    "mean_auc_yeast_dros_rat_org_be = mean_auc_yeast_dros_rat_be[0::2]\n",
    "mean_auc_yeast_dros_rat_fs_be = mean_auc_yeast_dros_rat_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast_dros_rat mean strict error original -  0.392239488443\n",
      "yeast_dros_rat mean strict error feature selection -  0.388957500092\n",
      "yeast_dros_rat mean strict AUC original -  0.637498909749\n",
      "yeast_dros_rat mean strict AUC feature selection -  0.638094560211\n",
      "\n",
      "\n",
      "yeast_dros_rat mean gen error original -  0.347328731628\n",
      "yeast_dros_rat mean gen error feature selection -  0.349134713188\n",
      "yeast_dros_rat mean gen AUC original -  0.704770151045\n",
      "yeast_dros_rat mean gen AUC feature selection -  0.699010988593\n",
      "\n",
      "\n",
      "yeast_dros_rat mean BE error original -  0.347230361178\n",
      "yeast_dros_rat mean BE error feature selection -  0.34499552812\n",
      "yeast_dros_rat mean BE AUC original -  0.703286729065\n",
      "yeast_dros_rat mean BE AUC feature selection -  0.703823160432\n"
     ]
    }
   ],
   "source": [
    "print('yeast_dros_rat mean strict error original - ', np.mean(mean_err_yeast_dros_rat_org_strict))\n",
    "print('yeast_dros_rat mean strict error feature selection - ', np.mean(mean_err_yeast_dros_rat_fs_strict))\n",
    "print('yeast_dros_rat mean strict AUC original - ', np.mean(mean_auc_yeast_dros_rat_org_strict))\n",
    "print('yeast_dros_rat mean strict AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat mean gen error original - ', np.mean(mean_err_yeast_dros_rat_org_gen))\n",
    "print('yeast_dros_rat mean gen error feature selection - ', np.mean(mean_err_yeast_dros_rat_fs_gen))\n",
    "print('yeast_dros_rat mean gen AUC original - ', np.mean(mean_auc_yeast_dros_rat_org_gen))\n",
    "print('yeast_dros_rat mean gen AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat mean BE error original - ', np.mean(mean_err_yeast_dros_rat_org_be))\n",
    "print('yeast_dros_rat mean BE error feature selection - ', np.mean(mean_err_yeast_dros_rat_fs_be))\n",
    "print('yeast_dros_rat mean BE AUC original - ', np.mean(mean_auc_yeast_dros_rat_org_be))\n",
    "print('yeast_dros_rat mean BE AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-24 19:22:14,185 : INFO : loading Word2Vec object from Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_SR_model\n",
      "2017-04-24 19:22:14,239 : INFO : loading wv recursively from Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_SR_model.wv.* with mmap=None\n",
      "2017-04-24 19:22:14,240 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 19:22:14,240 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 19:22:14,241 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 19:22:14,242 : INFO : loaded Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_SR_model\n",
      "2017-04-24 19:22:14,249 : INFO : training model with 4 workers on 3400 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 19:22:14,250 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 19:22:15,258 : INFO : PROGRESS: at 205.79% examples, 1113280 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:22:16,259 : INFO : PROGRESS: at 410.70% examples, 1112654 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:17,261 : INFO : PROGRESS: at 609.69% examples, 1101163 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:17,355 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 19:22:17,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 19:22:17,362 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 19:22:17,363 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 19:22:17,364 : INFO : training on 6296340 raw words (3423012 effective words) took 3.1s, 1100676 effective words/s\n",
      "2017-04-24 19:22:17,365 : WARNING : supplied example count (225220) did not equal expected count (35725)\n",
      "2017-04-24 19:22:17,365 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 19:22:17,387 : INFO : saving Word2Vec object under Results/yeast_dros_rat_mouse_SR_model, separately None\n",
      "2017-04-24 19:22:17,387 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 19:22:17,388 : INFO : not storing attribute cum_table\n",
      "2017-04-24 19:22:17,389 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 19:22:17,455 : INFO : saved Results/yeast_dros_rat_mouse_SR_model\n",
      "2017-04-24 19:22:20,744 : INFO : loading Word2Vec object from Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_GEN_model\n",
      "2017-04-24 19:22:20,871 : INFO : loading wv recursively from Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_GEN_model.wv.* with mmap=None\n",
      "2017-04-24 19:22:20,872 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 19:22:20,873 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 19:22:20,873 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 19:22:20,874 : INFO : loaded Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_GEN_model\n",
      "2017-04-24 19:22:20,892 : INFO : training model with 4 workers on 8289 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 19:22:20,892 : INFO : expecting 47536 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 19:22:21,900 : INFO : PROGRESS: at 23.16% examples, 915806 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:22,906 : INFO : PROGRESS: at 45.74% examples, 902980 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:22:23,910 : INFO : PROGRESS: at 71.41% examples, 939442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:24,910 : INFO : PROGRESS: at 96.75% examples, 955828 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:25,917 : INFO : PROGRESS: at 123.67% examples, 976885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:26,922 : INFO : PROGRESS: at 147.50% examples, 970432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:27,926 : INFO : PROGRESS: at 172.36% examples, 972262 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:28,928 : INFO : PROGRESS: at 197.59% examples, 975539 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:29,929 : INFO : PROGRESS: at 215.20% examples, 944540 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:30,950 : INFO : PROGRESS: at 231.04% examples, 911111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:31,955 : INFO : PROGRESS: at 247.21% examples, 886374 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:22:32,961 : INFO : PROGRESS: at 266.52% examples, 875989 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:33,961 : INFO : PROGRESS: at 291.12% examples, 883491 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:34,973 : INFO : PROGRESS: at 314.57% examples, 886111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:35,976 : INFO : PROGRESS: at 339.95% examples, 893979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:22:36,984 : INFO : PROGRESS: at 363.63% examples, 896255 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:22:37,659 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 19:22:37,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 19:22:37,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 19:22:37,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 19:22:37,675 : INFO : training on 24192400 raw words (14948710 effective words) took 16.8s, 890966 effective words/s\n",
      "2017-04-24 19:22:37,676 : WARNING : supplied example count (896095) did not equal expected count (237680)\n",
      "2017-04-24 19:22:37,677 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 19:22:37,726 : INFO : saving Word2Vec object under Results/yeast_dros_rat_mouse_GEN_model, separately None\n",
      "2017-04-24 19:22:37,727 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 19:22:37,728 : INFO : not storing attribute cum_table\n",
      "2017-04-24 19:22:37,728 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 19:22:37,903 : INFO : saved Results/yeast_dros_rat_mouse_GEN_model\n",
      "2017-04-24 19:23:00,397 : INFO : loading Word2Vec object from Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_BE_model\n",
      "2017-04-24 19:23:00,714 : INFO : loading wv recursively from Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_BE_model.wv.* with mmap=None\n",
      "2017-04-24 19:23:00,716 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 19:23:00,716 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-24 19:23:00,717 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-24 19:23:00,718 : INFO : loaded Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_BE_model\n",
      "2017-04-24 19:23:00,756 : INFO : training model with 4 workers on 16896 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-24 19:23:00,757 : INFO : expecting 194507 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-24 19:23:01,780 : INFO : PROGRESS: at 4.10% examples, 681089 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:02,783 : INFO : PROGRESS: at 9.44% examples, 789133 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:03,784 : INFO : PROGRESS: at 14.54% examples, 812585 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:04,790 : INFO : PROGRESS: at 19.69% examples, 824998 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:05,793 : INFO : PROGRESS: at 24.68% examples, 827120 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:06,796 : INFO : PROGRESS: at 29.79% examples, 831921 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:07,802 : INFO : PROGRESS: at 34.82% examples, 833166 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:08,804 : INFO : PROGRESS: at 39.66% examples, 830842 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:09,811 : INFO : PROGRESS: at 43.15% examples, 803289 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:23:10,818 : INFO : PROGRESS: at 46.59% examples, 780474 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:11,844 : INFO : PROGRESS: at 50.37% examples, 765587 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:12,845 : INFO : PROGRESS: at 53.81% examples, 750179 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:13,853 : INFO : PROGRESS: at 58.02% examples, 746324 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:14,857 : INFO : PROGRESS: at 63.38% examples, 757173 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:15,868 : INFO : PROGRESS: at 67.91% examples, 756895 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:16,877 : INFO : PROGRESS: at 72.32% examples, 755501 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:17,877 : INFO : PROGRESS: at 76.81% examples, 755479 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:18,880 : INFO : PROGRESS: at 81.53% examples, 757605 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:19,886 : INFO : PROGRESS: at 86.67% examples, 762979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:20,909 : INFO : PROGRESS: at 91.48% examples, 764525 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:21,915 : INFO : PROGRESS: at 95.60% examples, 760889 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:22,921 : INFO : PROGRESS: at 99.13% examples, 753109 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:23,925 : INFO : PROGRESS: at 102.82% examples, 747296 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:24,931 : INFO : PROGRESS: at 107.03% examples, 745666 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:25,948 : INFO : PROGRESS: at 112.19% examples, 749915 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:26,959 : INFO : PROGRESS: at 116.59% examples, 749255 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:27,969 : INFO : PROGRESS: at 120.94% examples, 748391 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:28,988 : INFO : PROGRESS: at 125.51% examples, 748590 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:30,004 : INFO : PROGRESS: at 128.89% examples, 742172 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:31,010 : INFO : PROGRESS: at 132.49% examples, 737586 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:32,018 : INFO : PROGRESS: at 136.03% examples, 732807 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:33,023 : INFO : PROGRESS: at 139.83% examples, 729923 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:34,024 : INFO : PROGRESS: at 144.89% examples, 733591 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:35,025 : INFO : PROGRESS: at 150.05% examples, 737439 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:36,028 : INFO : PROGRESS: at 154.90% examples, 739638 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:37,035 : INFO : PROGRESS: at 160.06% examples, 742954 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:38,042 : INFO : PROGRESS: at 165.05% examples, 745358 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:39,046 : INFO : PROGRESS: at 170.35% examples, 749153 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:40,053 : INFO : PROGRESS: at 175.53% examples, 752182 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:41,069 : INFO : PROGRESS: at 180.71% examples, 754894 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:42,086 : INFO : PROGRESS: at 184.67% examples, 752372 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:23:43,091 : INFO : PROGRESS: at 189.24% examples, 752650 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:44,092 : INFO : PROGRESS: at 193.60% examples, 752202 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:45,092 : INFO : PROGRESS: at 197.93% examples, 751627 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:46,106 : INFO : PROGRESS: at 200.88% examples, 745768 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:47,112 : INFO : PROGRESS: at 203.87% examples, 740444 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:48,121 : INFO : PROGRESS: at 206.57% examples, 734250 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:49,127 : INFO : PROGRESS: at 209.38% examples, 728806 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:50,136 : INFO : PROGRESS: at 213.20% examples, 726922 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:51,137 : INFO : PROGRESS: at 216.90% examples, 724820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:52,150 : INFO : PROGRESS: at 220.93% examples, 723723 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:53,163 : INFO : PROGRESS: at 224.79% examples, 722145 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:54,170 : INFO : PROGRESS: at 229.56% examples, 723565 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:55,172 : INFO : PROGRESS: at 234.44% examples, 725388 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:23:56,173 : INFO : PROGRESS: at 239.13% examples, 726526 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:57,176 : INFO : PROGRESS: at 244.03% examples, 728222 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:23:58,187 : INFO : PROGRESS: at 247.64% examples, 725985 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:23:59,198 : INFO : PROGRESS: at 251.55% examples, 724660 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:00,198 : INFO : PROGRESS: at 255.26% examples, 723036 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:01,200 : INFO : PROGRESS: at 259.61% examples, 723194 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:02,205 : INFO : PROGRESS: at 264.46% examples, 724678 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:03,210 : INFO : PROGRESS: at 269.01% examples, 725322 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:04,219 : INFO : PROGRESS: at 273.99% examples, 727009 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:05,219 : INFO : PROGRESS: at 278.44% examples, 727333 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:06,234 : INFO : PROGRESS: at 282.35% examples, 726091 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:07,236 : INFO : PROGRESS: at 286.29% examples, 725125 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:08,242 : INFO : PROGRESS: at 290.20% examples, 724040 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:09,251 : INFO : PROGRESS: at 294.92% examples, 724987 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:10,251 : INFO : PROGRESS: at 299.87% examples, 726527 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:11,253 : INFO : PROGRESS: at 304.76% examples, 727887 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:12,271 : INFO : PROGRESS: at 310.06% examples, 730028 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:13,275 : INFO : PROGRESS: at 315.10% examples, 731580 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:14,295 : INFO : PROGRESS: at 320.34% examples, 733410 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:15,300 : INFO : PROGRESS: at 325.49% examples, 735138 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:16,305 : INFO : PROGRESS: at 330.73% examples, 737008 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:17,314 : INFO : PROGRESS: at 335.88% examples, 738621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:18,325 : INFO : PROGRESS: at 340.65% examples, 739349 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:19,329 : INFO : PROGRESS: at 346.00% examples, 741372 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:20,333 : INFO : PROGRESS: at 350.89% examples, 742392 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-24 19:24:21,365 : INFO : PROGRESS: at 355.26% examples, 741984 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 19:24:22,372 : INFO : PROGRESS: at 358.83% examples, 740182 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:23,383 : INFO : PROGRESS: at 362.05% examples, 737720 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:24,392 : INFO : PROGRESS: at 365.33% examples, 735412 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:25,403 : INFO : PROGRESS: at 369.52% examples, 734970 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:26,408 : INFO : PROGRESS: at 375.17% examples, 737434 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:27,411 : INFO : PROGRESS: at 380.73% examples, 739692 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:28,416 : INFO : PROGRESS: at 386.31% examples, 741971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:29,424 : INFO : PROGRESS: at 391.37% examples, 743151 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:30,436 : INFO : PROGRESS: at 396.55% examples, 744510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:31,441 : INFO : PROGRESS: at 401.68% examples, 745820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:32,446 : INFO : PROGRESS: at 406.63% examples, 746723 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-24 19:24:33,450 : INFO : PROGRESS: at 411.32% examples, 747150 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:24:34,453 : INFO : PROGRESS: at 415.28% examples, 746232 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:35,470 : INFO : PROGRESS: at 419.10% examples, 745000 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:36,479 : INFO : PROGRESS: at 422.96% examples, 743939 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:37,487 : INFO : PROGRESS: at 427.27% examples, 743693 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:38,488 : INFO : PROGRESS: at 432.29% examples, 744730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:39,489 : INFO : PROGRESS: at 437.34% examples, 745817 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:40,489 : INFO : PROGRESS: at 442.75% examples, 747445 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:41,492 : INFO : PROGRESS: at 447.07% examples, 747214 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:42,494 : INFO : PROGRESS: at 450.61% examples, 745691 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:43,503 : INFO : PROGRESS: at 454.31% examples, 744427 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:44,504 : INFO : PROGRESS: at 457.85% examples, 742967 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:45,505 : INFO : PROGRESS: at 462.46% examples, 743272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:46,519 : INFO : PROGRESS: at 467.55% examples, 744269 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:47,522 : INFO : PROGRESS: at 472.62% examples, 745257 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:48,526 : INFO : PROGRESS: at 477.64% examples, 746168 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:49,527 : INFO : PROGRESS: at 482.75% examples, 747202 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:50,528 : INFO : PROGRESS: at 488.09% examples, 748599 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:51,529 : INFO : PROGRESS: at 492.98% examples, 749277 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:52,540 : INFO : PROGRESS: at 497.39% examples, 749124 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:53,543 : INFO : PROGRESS: at 501.87% examples, 749152 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:54,552 : INFO : PROGRESS: at 506.30% examples, 749075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:55,555 : INFO : PROGRESS: at 510.29% examples, 748370 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:24:56,565 : INFO : PROGRESS: at 514.17% examples, 747515 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:57,574 : INFO : PROGRESS: at 517.98% examples, 746565 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:58,588 : INFO : PROGRESS: at 521.05% examples, 744527 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:24:59,616 : INFO : PROGRESS: at 524.20% examples, 742552 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:25:00,650 : INFO : PROGRESS: at 526.85% examples, 739886 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:01,653 : INFO : PROGRESS: at 529.92% examples, 738025 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:25:02,673 : INFO : PROGRESS: at 533.58% examples, 736902 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:03,679 : INFO : PROGRESS: at 536.91% examples, 735415 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:25:04,686 : INFO : PROGRESS: at 540.18% examples, 733893 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:05,691 : INFO : PROGRESS: at 545.01% examples, 734468 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:25:06,704 : INFO : PROGRESS: at 550.07% examples, 735322 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 19:25:07,718 : INFO : PROGRESS: at 555.17% examples, 736218 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-24 19:25:08,728 : INFO : PROGRESS: at 560.44% examples, 737341 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:09,728 : INFO : PROGRESS: at 566.49% examples, 739530 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:10,765 : INFO : PROGRESS: at 571.20% examples, 739708 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:11,771 : INFO : PROGRESS: at 575.43% examples, 739471 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:12,784 : INFO : PROGRESS: at 579.76% examples, 739304 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:13,785 : INFO : PROGRESS: at 584.54% examples, 739781 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:14,791 : INFO : PROGRESS: at 588.62% examples, 739334 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:15,805 : INFO : PROGRESS: at 592.81% examples, 739012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:16,818 : INFO : PROGRESS: at 597.62% examples, 739461 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:17,838 : INFO : PROGRESS: at 601.02% examples, 738137 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:18,852 : INFO : PROGRESS: at 604.05% examples, 736411 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:19,859 : INFO : PROGRESS: at 607.54% examples, 735305 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:20,868 : INFO : PROGRESS: at 610.66% examples, 733752 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:25:21,871 : INFO : PROGRESS: at 615.71% examples, 734578 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-24 19:25:22,878 : INFO : PROGRESS: at 621.26% examples, 735955 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:23,887 : INFO : PROGRESS: at 626.28% examples, 736668 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:24,901 : INFO : PROGRESS: at 631.56% examples, 737647 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-24 19:25:25,906 : INFO : PROGRESS: at 636.66% examples, 738460 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-24 19:25:26,912 : INFO : PROGRESS: at 641.79% examples, 739302 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-24 19:25:27,055 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-24 19:25:27,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-24 19:25:27,066 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-24 19:25:27,068 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-24 19:25:27,069 : INFO : training on 154634470 raw words (108193113 effective words) took 146.3s, 739503 effective words/s\n",
      "2017-04-24 19:25:27,069 : WARNING : supplied example count (6250045) did not equal expected count (972535)\n",
      "2017-04-24 19:25:27,070 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-24 19:25:27,172 : INFO : saving Word2Vec object under Results/yeast_dros_rat_mouse_BE_model, separately None\n",
      "2017-04-24 19:25:27,173 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 19:25:27,174 : INFO : not storing attribute cum_table\n",
      "2017-04-24 19:25:27,175 : INFO : not storing attribute syn0norm\n",
      "2017-04-24 19:25:27,641 : INFO : saved Results/yeast_dros_rat_mouse_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "yeast_dros_rat_old_SR_model = 'Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_SR_model'\n",
    "mouse_SR_sentences_pkl = 'Results/mouse/strict_real.pkl'\n",
    "yeast_dros_rat_mouse_SR_model = add_sentences_to_model(yeast_dros_rat_old_SR_model, rat_SR_sentences_pkl, 'yeast_dros_rat_mouse_SR_model')\n",
    "\n",
    "#Gen model\n",
    "yeast_dros_rat_old_GEN_model = 'Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_GEN_model'\n",
    "mouse_GEN_sentences_pkl = 'Results/mouse/gen_real.pkl'\n",
    "yeast_dros_rat_mouse_GEN_model = add_sentences_to_model(yeast_dros_rat_old_GEN_model, rat_GEN_sentences_pkl, 'yeast_dros_rat_mouse_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "yeast_dros_rat_old_BE_model = 'Results/yeast_dros_rat/Seeded/Results/yeast_dros_rat_BE_model'\n",
    "mouse_BE_sentences_pkl = 'Results/mouse/be_real.pkl'\n",
    "yeast_dros_rat_mouse_BE_model = add_sentences_to_model(yeast_dros_rat_old_BE_model, rat_BE_sentences_pkl, 'yeast_dros_rat_mouse_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "yeast_strict_real = pickle.load(open('Results/yeast/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_mouse_SR_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_rat_mouse_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_mouse_GEN_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_rat_mouse_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_mouse_BE_merger_'+str(seed),\n",
    "                                             prev_model=yeast_dros_rat_mouse_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/yeast_dros_rat_mouse_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/yeast_dros_rat_mouse_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/yeast_dros_rat_mouse_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast_dros_rat_mouse/Seeded/Results/'\n",
    "errors_yeast_dros_rat_mouse = mult_open(drct, '_errors_')\n",
    "fpr_yeast_dros_rat_mouse = mult_open(drct, '_fpr_')\n",
    "tpr_yeast_dros_rat_mouse = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast_dros_rat_mouse auc=0.657 error=0.396\n",
      "Strict error yeast_dros_rat_mouse auc=0.656 error=0.386\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.701 error=0.331\n",
      "Gen error yeast_dros_rat_mouse auc=0.703 error=0.339\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.710 error=0.346\n",
      "BE error yeast_dros_rat_mouse auc=0.707 error=0.337\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.632 error=0.386\n",
      "Strict error yeast_dros_rat_mouse auc=0.641 error=0.386\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.687 error=0.356\n",
      "Gen error yeast_dros_rat_mouse auc=0.687 error=0.375\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.690 error=0.361\n",
      "BE error yeast_dros_rat_mouse auc=0.687 error=0.356\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.654 error=0.364\n",
      "Strict error yeast_dros_rat_mouse auc=0.654 error=0.356\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.714 error=0.331\n",
      "Gen error yeast_dros_rat_mouse auc=0.719 error=0.317\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.706 error=0.328\n",
      "BE error yeast_dros_rat_mouse auc=0.697 error=0.307\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.647 error=0.388\n",
      "Strict error yeast_dros_rat_mouse auc=0.661 error=0.389\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.734 error=0.327\n",
      "Gen error yeast_dros_rat_mouse auc=0.726 error=0.338\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.716 error=0.323\n",
      "BE error yeast_dros_rat_mouse auc=0.712 error=0.335\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.639 error=0.406\n",
      "Strict error yeast_dros_rat_mouse auc=0.622 error=0.414\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.677 error=0.362\n",
      "Gen error yeast_dros_rat_mouse auc=0.674 error=0.367\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.683 error=0.372\n",
      "BE error yeast_dros_rat_mouse auc=0.663 error=0.389\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.647 error=0.387\n",
      "Strict error yeast_dros_rat_mouse auc=0.645 error=0.374\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.698 error=0.356\n",
      "Gen error yeast_dros_rat_mouse auc=0.704 error=0.363\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.716 error=0.347\n",
      "BE error yeast_dros_rat_mouse auc=0.715 error=0.354\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.632 error=0.400\n",
      "Strict error yeast_dros_rat_mouse auc=0.631 error=0.400\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.703 error=0.343\n",
      "Gen error yeast_dros_rat_mouse auc=0.706 error=0.347\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.700 error=0.356\n",
      "BE error yeast_dros_rat_mouse auc=0.707 error=0.338\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.610 error=0.412\n",
      "Strict error yeast_dros_rat_mouse auc=0.604 error=0.418\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.686 error=0.368\n",
      "Gen error yeast_dros_rat_mouse auc=0.695 error=0.359\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.681 error=0.371\n",
      "BE error yeast_dros_rat_mouse auc=0.697 error=0.361\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.651 error=0.406\n",
      "Strict error yeast_dros_rat_mouse auc=0.637 error=0.414\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.677 error=0.396\n",
      "Gen error yeast_dros_rat_mouse auc=0.682 error=0.400\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.665 error=0.391\n",
      "BE error yeast_dros_rat_mouse auc=0.689 error=0.384\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse auc=0.636 error=0.360\n",
      "Strict error yeast_dros_rat_mouse auc=0.636 error=0.377\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse auc=0.756 error=0.296\n",
      "Gen error yeast_dros_rat_mouse auc=0.743 error=0.321\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse auc=0.739 error=0.311\n",
      "BE error yeast_dros_rat_mouse auc=0.734 error=0.305\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_dros_rat_mouse_strict = []\n",
    "mean_auc_yeast_dros_rat_mouse_strict = []\n",
    "mean_err_yeast_dros_rat_mouse_gen = []\n",
    "mean_auc_yeast_dros_rat_mouse_gen = []\n",
    "mean_err_yeast_dros_rat_mouse_be = []\n",
    "mean_auc_yeast_dros_rat_mouse_be = []\n",
    "for e, f, t in zip(errors_yeast_dros_rat_mouse, fpr_yeast_dros_rat_mouse, tpr_yeast_dros_rat_mouse):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast_dros_rat_mouse']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_dros_rat_mouse_strict.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_mouse_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_dros_rat_mouse_gen.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_mouse_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_dros_rat_mouse_be.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_mouse_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_dros_rat_mouse_org_strict = mean_err_yeast_dros_rat_mouse_strict[0::2]\n",
    "mean_err_yeast_dros_rat_mouse_fs_strict = mean_err_yeast_dros_rat_mouse_strict[1::2]\n",
    "mean_auc_yeast_dros_rat_mouse_org_strict = mean_auc_yeast_dros_rat_mouse_strict[0::2]\n",
    "mean_auc_yeast_dros_rat_mouse_fs_strict = mean_auc_yeast_dros_rat_mouse_strict[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_mouse_org_gen = mean_err_yeast_dros_rat_mouse_gen[0::2]\n",
    "mean_err_yeast_dros_rat_mouse_fs_gen = mean_err_yeast_dros_rat_mouse_gen[1::2]\n",
    "mean_auc_yeast_dros_rat_mouse_org_gen = mean_auc_yeast_dros_rat_mouse_gen[0::2]\n",
    "mean_auc_yeast_dros_rat_mouse_fs_gen = mean_auc_yeast_dros_rat_mouse_gen[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_mouse_org_be = mean_err_yeast_dros_rat_mouse_be[0::2]\n",
    "mean_err_yeast_dros_rat_mouse_fs_be = mean_err_yeast_dros_rat_mouse_be[1::2]\n",
    "mean_auc_yeast_dros_rat_mouse_org_be = mean_auc_yeast_dros_rat_mouse_be[0::2]\n",
    "mean_auc_yeast_dros_rat_mouse_fs_be = mean_auc_yeast_dros_rat_mouse_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast_dros_rat_mouse mean strict error original -  0.390472636314\n",
      "yeast_dros_rat_mouse mean strict error feature selection -  0.39136271363\n",
      "yeast_dros_rat_mouse mean strict AUC original -  0.640474251643\n",
      "yeast_dros_rat_mouse mean strict AUC feature selection -  0.638652737808\n",
      "\n",
      "\n",
      "yeast_dros_rat_mouse mean gen error original -  0.346502470048\n",
      "yeast_dros_rat_mouse mean gen error feature selection -  0.352519292307\n",
      "yeast_dros_rat_mouse mean gen AUC original -  0.703189209597\n",
      "yeast_dros_rat_mouse mean gen AUC feature selection -  0.703878316297\n",
      "\n",
      "\n",
      "yeast_dros_rat_mouse mean BE error original -  0.350622551893\n",
      "yeast_dros_rat_mouse mean BE error feature selection -  0.346642385215\n",
      "yeast_dros_rat_mouse mean BE AUC original -  0.700618402903\n",
      "yeast_dros_rat_mouse mean BE AUC feature selection -  0.700883886736\n"
     ]
    }
   ],
   "source": [
    "print('yeast_dros_rat_mouse mean strict error original - ', np.mean(mean_err_yeast_dros_rat_mouse_org_strict))\n",
    "print('yeast_dros_rat_mouse mean strict error feature selection - ', np.mean(mean_err_yeast_dros_rat_mouse_fs_strict))\n",
    "print('yeast_dros_rat_mouse mean strict AUC original - ', np.mean(mean_auc_yeast_dros_rat_mouse_org_strict))\n",
    "print('yeast_dros_rat_mouse mean strict AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_mouse_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat_mouse mean gen error original - ', np.mean(mean_err_yeast_dros_rat_mouse_org_gen))\n",
    "print('yeast_dros_rat_mouse mean gen error feature selection - ', np.mean(mean_err_yeast_dros_rat_mouse_fs_gen))\n",
    "print('yeast_dros_rat_mouse mean gen AUC original - ', np.mean(mean_auc_yeast_dros_rat_mouse_org_gen))\n",
    "print('yeast_dros_rat_mouse mean gen AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_mouse_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat_mouse mean BE error original - ', np.mean(mean_err_yeast_dros_rat_mouse_org_be))\n",
    "print('yeast_dros_rat_mouse mean BE error feature selection - ', np.mean(mean_err_yeast_dros_rat_mouse_fs_be))\n",
    "print('yeast_dros_rat_mouse mean BE AUC original - ', np.mean(mean_auc_yeast_dros_rat_mouse_org_be))\n",
    "print('yeast_dros_rat_mouse mean BE AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_mouse_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dros_yeast_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_comb/Seeded/Results/dros_yeast_SR_comb_model')\n",
    "dros_yeast_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_comb/Seeded/Results/dros_yeast_GEN_comb_model')\n",
    "dros_yeast_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_comb/Seeded/Results/dros_yeast_BE_comb_model')\n",
    "\n",
    "dros_yeast_rat_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_SR_comb_model')\n",
    "dros_yeast_rat_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_GEN_comb_model')\n",
    "dros_yeast_rat_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model')\n",
    "\n",
    "dros_yeast_rat_mouse_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model')\n",
    "dros_yeast_rat_mouse_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model')\n",
    "dros_yeast_rat_mouse_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "yeast_strict_real = pickle.load(open('Results/yeast/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_SR_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_GEN_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_BE_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb,\n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/yeast_dros_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/yeast_dros_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/yeast_dros_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast_dros_comb/Seeded/Results/'\n",
    "errors_yeast_dros_comb = mult_open(drct, '_errors_')\n",
    "fpr_yeast_dros_comb = mult_open(drct, '_fpr_')\n",
    "tpr_yeast_dros_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast_dros_comb auc=0.669 error=0.385\n",
      "Strict error yeast_dros_comb auc=0.657 error=0.392\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.721 error=0.329\n",
      "Gen error yeast_dros_comb auc=0.724 error=0.328\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.727 error=0.339\n",
      "BE error yeast_dros_comb auc=0.726 error=0.334\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.662 error=0.374\n",
      "Strict error yeast_dros_comb auc=0.649 error=0.382\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.714 error=0.324\n",
      "Gen error yeast_dros_comb auc=0.725 error=0.331\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.722 error=0.332\n",
      "BE error yeast_dros_comb auc=0.724 error=0.324\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.691 error=0.368\n",
      "Strict error yeast_dros_comb auc=0.693 error=0.357\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.724 error=0.353\n",
      "Gen error yeast_dros_comb auc=0.742 error=0.341\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.760 error=0.333\n",
      "BE error yeast_dros_comb auc=0.755 error=0.318\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.629 error=0.391\n",
      "Strict error yeast_dros_comb auc=0.646 error=0.360\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.661 error=0.363\n",
      "Gen error yeast_dros_comb auc=0.670 error=0.373\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.700 error=0.340\n",
      "BE error yeast_dros_comb auc=0.695 error=0.325\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.672 error=0.384\n",
      "Strict error yeast_dros_comb auc=0.664 error=0.369\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.693 error=0.357\n",
      "Gen error yeast_dros_comb auc=0.694 error=0.356\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.718 error=0.312\n",
      "BE error yeast_dros_comb auc=0.704 error=0.328\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.679 error=0.345\n",
      "Strict error yeast_dros_comb auc=0.681 error=0.336\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.710 error=0.327\n",
      "Gen error yeast_dros_comb auc=0.721 error=0.320\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.737 error=0.311\n",
      "BE error yeast_dros_comb auc=0.728 error=0.302\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.661 error=0.372\n",
      "Strict error yeast_dros_comb auc=0.650 error=0.376\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.705 error=0.338\n",
      "Gen error yeast_dros_comb auc=0.697 error=0.333\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.703 error=0.341\n",
      "BE error yeast_dros_comb auc=0.711 error=0.332\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.671 error=0.338\n",
      "Strict error yeast_dros_comb auc=0.667 error=0.360\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.681 error=0.346\n",
      "Gen error yeast_dros_comb auc=0.678 error=0.330\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.703 error=0.318\n",
      "BE error yeast_dros_comb auc=0.701 error=0.326\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.684 error=0.364\n",
      "Strict error yeast_dros_comb auc=0.678 error=0.368\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.709 error=0.357\n",
      "Gen error yeast_dros_comb auc=0.729 error=0.322\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.719 error=0.332\n",
      "BE error yeast_dros_comb auc=0.721 error=0.340\n",
      "\n",
      "\n",
      "Strict error yeast_dros_comb auc=0.673 error=0.366\n",
      "Strict error yeast_dros_comb auc=0.680 error=0.372\n",
      "\n",
      "\n",
      "Gen error yeast_dros_comb auc=0.679 error=0.372\n",
      "Gen error yeast_dros_comb auc=0.683 error=0.344\n",
      "\n",
      "\n",
      "BE error yeast_dros_comb auc=0.675 error=0.370\n",
      "BE error yeast_dros_comb auc=0.690 error=0.362\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_dros_comb_strict = []\n",
    "mean_auc_yeast_dros_comb_strict = []\n",
    "mean_err_yeast_dros_comb_gen = []\n",
    "mean_auc_yeast_dros_comb_gen = []\n",
    "mean_err_yeast_dros_comb_be = []\n",
    "mean_auc_yeast_dros_comb_be = []\n",
    "for e, f, t in zip(errors_yeast_dros_comb, fpr_yeast_dros_comb, tpr_yeast_dros_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast_dros_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_dros_comb_strict.append(error_item)\n",
    "                    mean_auc_yeast_dros_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_dros_comb_gen.append(error_item)\n",
    "                    mean_auc_yeast_dros_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_dros_comb_be.append(error_item)\n",
    "                    mean_auc_yeast_dros_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_dros_comb_org_strict = mean_err_yeast_dros_comb_strict[0::2]\n",
    "mean_err_yeast_dros_comb_fs_strict = mean_err_yeast_dros_comb_strict[1::2]\n",
    "mean_auc_yeast_dros_comb_org_strict = mean_auc_yeast_dros_comb_strict[0::2]\n",
    "mean_auc_yeast_dros_comb_fs_strict = mean_auc_yeast_dros_comb_strict[1::2]\n",
    "\n",
    "mean_err_yeast_dros_comb_org_gen = mean_err_yeast_dros_comb_gen[0::2]\n",
    "mean_err_yeast_dros_comb_fs_gen = mean_err_yeast_dros_comb_gen[1::2]\n",
    "mean_auc_yeast_dros_comb_org_gen = mean_auc_yeast_dros_comb_gen[0::2]\n",
    "mean_auc_yeast_dros_comb_fs_gen = mean_auc_yeast_dros_comb_gen[1::2]\n",
    "\n",
    "mean_err_yeast_dros_comb_org_be = mean_err_yeast_dros_comb_be[0::2]\n",
    "mean_err_yeast_dros_comb_fs_be = mean_err_yeast_dros_comb_be[1::2]\n",
    "mean_auc_yeast_dros_comb_org_be = mean_auc_yeast_dros_comb_be[0::2]\n",
    "mean_auc_yeast_dros_comb_fs_be = mean_auc_yeast_dros_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast_dros_comb mean strict error original -  0.3685932094\n",
      "yeast_dros_comb mean strict error feature selection -  0.367089024003\n",
      "yeast_dros_comb mean strict AUC original -  0.66901623624\n",
      "yeast_dros_comb mean strict AUC feature selection -  0.666422164743\n",
      "\n",
      "\n",
      "yeast_dros_comb mean gen error original -  0.346666961772\n",
      "yeast_dros_comb mean gen error feature selection -  0.337682193371\n",
      "yeast_dros_comb mean gen AUC original -  0.699617307641\n",
      "yeast_dros_comb mean gen AUC feature selection -  0.706287938841\n",
      "\n",
      "\n",
      "yeast_dros_comb mean BE error original -  0.332876769315\n",
      "yeast_dros_comb mean BE error feature selection -  0.3292115127\n",
      "yeast_dros_comb mean BE AUC original -  0.716490751726\n",
      "yeast_dros_comb mean BE AUC feature selection -  0.715575796959\n"
     ]
    }
   ],
   "source": [
    "print('yeast_dros_comb mean strict error original - ', np.mean(mean_err_yeast_dros_comb_org_strict))\n",
    "print('yeast_dros_comb mean strict error feature selection - ', np.mean(mean_err_yeast_dros_comb_fs_strict))\n",
    "print('yeast_dros_comb mean strict AUC original - ', np.mean(mean_auc_yeast_dros_comb_org_strict))\n",
    "print('yeast_dros_comb mean strict AUC feature selection - ', np.mean(mean_auc_yeast_dros_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast_dros_comb mean gen error original - ', np.mean(mean_err_yeast_dros_comb_org_gen))\n",
    "print('yeast_dros_comb mean gen error feature selection - ', np.mean(mean_err_yeast_dros_comb_fs_gen))\n",
    "print('yeast_dros_comb mean gen AUC original - ', np.mean(mean_auc_yeast_dros_comb_org_gen))\n",
    "print('yeast_dros_comb mean gen AUC feature selection - ', np.mean(mean_auc_yeast_dros_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast_dros_comb mean BE error original - ', np.mean(mean_err_yeast_dros_comb_org_be))\n",
    "print('yeast_dros_comb mean BE error feature selection - ', np.mean(mean_err_yeast_dros_comb_fs_be))\n",
    "print('yeast_dros_comb mean BE AUC original - ', np.mean(mean_auc_yeast_dros_comb_org_be))\n",
    "print('yeast_dros_comb mean BE AUC feature selection - ', np.mean(mean_auc_yeast_dros_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "yeast_strict_real = pickle.load(open('Results/yeast/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_SR_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_GEN_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_BE_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb,\n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/yeast_dros_rat_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/yeast_dros_rat_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/yeast_dros_rat_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast_dros_rat_comb/Seeded/Results/'\n",
    "errors_yeast_dros_rat_comb = mult_open(drct, '_errors_')\n",
    "fpr_yeast_dros_rat_comb = mult_open(drct, '_fpr_')\n",
    "tpr_yeast_dros_rat_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast_dros_rat_comb auc=0.674 error=0.366\n",
      "Strict error yeast_dros_rat_comb auc=0.662 error=0.400\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.714 error=0.345\n",
      "Gen error yeast_dros_rat_comb auc=0.716 error=0.355\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.714 error=0.348\n",
      "BE error yeast_dros_rat_comb auc=0.709 error=0.339\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.700 error=0.356\n",
      "Strict error yeast_dros_rat_comb auc=0.699 error=0.337\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.732 error=0.328\n",
      "Gen error yeast_dros_rat_comb auc=0.717 error=0.337\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.712 error=0.340\n",
      "BE error yeast_dros_rat_comb auc=0.712 error=0.337\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.698 error=0.350\n",
      "Strict error yeast_dros_rat_comb auc=0.698 error=0.368\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.723 error=0.345\n",
      "Gen error yeast_dros_rat_comb auc=0.713 error=0.356\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.728 error=0.342\n",
      "BE error yeast_dros_rat_comb auc=0.733 error=0.327\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.664 error=0.360\n",
      "Strict error yeast_dros_rat_comb auc=0.657 error=0.367\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.680 error=0.347\n",
      "Gen error yeast_dros_rat_comb auc=0.682 error=0.349\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.691 error=0.325\n",
      "BE error yeast_dros_rat_comb auc=0.691 error=0.335\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.670 error=0.369\n",
      "Strict error yeast_dros_rat_comb auc=0.682 error=0.377\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.694 error=0.336\n",
      "Gen error yeast_dros_rat_comb auc=0.699 error=0.345\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.704 error=0.327\n",
      "BE error yeast_dros_rat_comb auc=0.687 error=0.353\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.713 error=0.341\n",
      "Strict error yeast_dros_rat_comb auc=0.715 error=0.329\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.725 error=0.300\n",
      "Gen error yeast_dros_rat_comb auc=0.705 error=0.316\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.718 error=0.327\n",
      "BE error yeast_dros_rat_comb auc=0.715 error=0.320\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.664 error=0.353\n",
      "Strict error yeast_dros_rat_comb auc=0.655 error=0.364\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.694 error=0.330\n",
      "Gen error yeast_dros_rat_comb auc=0.689 error=0.338\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.719 error=0.328\n",
      "BE error yeast_dros_rat_comb auc=0.718 error=0.332\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.682 error=0.336\n",
      "Strict error yeast_dros_rat_comb auc=0.692 error=0.333\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.679 error=0.365\n",
      "Gen error yeast_dros_rat_comb auc=0.679 error=0.329\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.701 error=0.326\n",
      "BE error yeast_dros_rat_comb auc=0.692 error=0.323\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.675 error=0.352\n",
      "Strict error yeast_dros_rat_comb auc=0.676 error=0.360\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.708 error=0.340\n",
      "Gen error yeast_dros_rat_comb auc=0.694 error=0.342\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.704 error=0.352\n",
      "BE error yeast_dros_rat_comb auc=0.709 error=0.328\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_comb auc=0.683 error=0.352\n",
      "Strict error yeast_dros_rat_comb auc=0.693 error=0.350\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_comb auc=0.677 error=0.358\n",
      "Gen error yeast_dros_rat_comb auc=0.703 error=0.324\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_comb auc=0.696 error=0.342\n",
      "BE error yeast_dros_rat_comb auc=0.686 error=0.350\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_dros_rat_comb_strict = []\n",
    "mean_auc_yeast_dros_rat_comb_strict = []\n",
    "mean_err_yeast_dros_rat_comb_gen = []\n",
    "mean_auc_yeast_dros_rat_comb_gen = []\n",
    "mean_err_yeast_dros_rat_comb_be = []\n",
    "mean_auc_yeast_dros_rat_comb_be = []\n",
    "for e, f, t in zip(errors_yeast_dros_rat_comb, fpr_yeast_dros_rat_comb, tpr_yeast_dros_rat_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast_dros_rat_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_dros_rat_comb_strict.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_dros_rat_comb_gen.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_dros_rat_comb_be.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_dros_rat_comb_org_strict = mean_err_yeast_dros_rat_comb_strict[0::2]\n",
    "mean_err_yeast_dros_rat_comb_fs_strict = mean_err_yeast_dros_rat_comb_strict[1::2]\n",
    "mean_auc_yeast_dros_rat_comb_org_strict = mean_auc_yeast_dros_rat_comb_strict[0::2]\n",
    "mean_auc_yeast_dros_rat_comb_fs_strict = mean_auc_yeast_dros_rat_comb_strict[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_comb_org_gen = mean_err_yeast_dros_rat_comb_gen[0::2]\n",
    "mean_err_yeast_dros_rat_comb_fs_gen = mean_err_yeast_dros_rat_comb_gen[1::2]\n",
    "mean_auc_yeast_dros_rat_comb_org_gen = mean_auc_yeast_dros_rat_comb_gen[0::2]\n",
    "mean_auc_yeast_dros_rat_comb_fs_gen = mean_auc_yeast_dros_rat_comb_gen[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_comb_org_be = mean_err_yeast_dros_rat_comb_be[0::2]\n",
    "mean_err_yeast_dros_rat_comb_fs_be = mean_err_yeast_dros_rat_comb_be[1::2]\n",
    "mean_auc_yeast_dros_rat_comb_org_be = mean_auc_yeast_dros_rat_comb_be[0::2]\n",
    "mean_auc_yeast_dros_rat_comb_fs_be = mean_auc_yeast_dros_rat_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast_dros_rat_comb mean strict error original -  0.353509867328\n",
      "yeast_dros_rat_comb mean strict error feature selection -  0.358528359171\n",
      "yeast_dros_rat_comb mean strict AUC original -  0.682247769716\n",
      "yeast_dros_rat_comb mean strict AUC feature selection -  0.682977205365\n",
      "\n",
      "\n",
      "yeast_dros_rat_comb mean gen error original -  0.339387354713\n",
      "yeast_dros_rat_comb mean gen error feature selection -  0.33911384333\n",
      "yeast_dros_rat_comb mean gen AUC original -  0.702630252132\n",
      "yeast_dros_rat_comb mean gen AUC feature selection -  0.699816563237\n",
      "\n",
      "\n",
      "yeast_dros_rat_comb mean BE error original -  0.335792499398\n",
      "yeast_dros_rat_comb mean BE error feature selection -  0.334438589451\n",
      "yeast_dros_rat_comb mean BE AUC original -  0.708698742639\n",
      "yeast_dros_rat_comb mean BE AUC feature selection -  0.705152156817\n"
     ]
    }
   ],
   "source": [
    "print('yeast_dros_rat_comb mean strict error original - ', np.mean(mean_err_yeast_dros_rat_comb_org_strict))\n",
    "print('yeast_dros_rat_comb mean strict error feature selection - ', np.mean(mean_err_yeast_dros_rat_comb_fs_strict))\n",
    "print('yeast_dros_rat_comb mean strict AUC original - ', np.mean(mean_auc_yeast_dros_rat_comb_org_strict))\n",
    "print('yeast_dros_rat_comb mean strict AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat_comb mean gen error original - ', np.mean(mean_err_yeast_dros_rat_comb_org_gen))\n",
    "print('yeast_dros_rat_comb mean gen error feature selection - ', np.mean(mean_err_yeast_dros_rat_comb_fs_gen))\n",
    "print('yeast_dros_rat_comb mean gen AUC original - ', np.mean(mean_auc_yeast_dros_rat_comb_org_gen))\n",
    "print('yeast_dros_rat_comb mean gen AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat_comb mean BE error original - ', np.mean(mean_err_yeast_dros_rat_comb_org_be))\n",
    "print('yeast_dros_rat_comb mean BE error feature selection - ', np.mean(mean_err_yeast_dros_rat_comb_fs_be))\n",
    "print('yeast_dros_rat_comb mean BE AUC original - ', np.mean(mean_auc_yeast_dros_rat_comb_org_be))\n",
    "print('yeast_dros_rat_comb mean BE AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "yeast_strict_real = pickle.load(open('Results/yeast/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_mouse_SR_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_mouse_GEN_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(yeast_strict_real, \n",
    "                                             'yeast_dros_rat_mouse_BE_comb_'+str(seed),\n",
    "                                             prev_model=dros_yeast_rat_mouse_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb,\n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/yeast_dros_rat_mouse_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/yeast_dros_rat_mouse_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/yeast_dros_rat_mouse_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/yeast_dros_rat_mouse_comb/Seeded/Results/'\n",
    "errors_yeast_dros_rat_mouse_comb = mult_open(drct, '_errors_')\n",
    "fpr_yeast_dros_rat_mouse_comb = mult_open(drct, '_fpr_')\n",
    "tpr_yeast_dros_rat_mouse_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error yeast_dros_rat_mouse_comb auc=0.708 error=0.326\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.707 error=0.333\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.715 error=0.331\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.709 error=0.328\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.715 error=0.348\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.715 error=0.341\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.709 error=0.341\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.713 error=0.319\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.719 error=0.333\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.720 error=0.332\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.710 error=0.350\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.710 error=0.343\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.714 error=0.342\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.715 error=0.354\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.717 error=0.359\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.721 error=0.353\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.747 error=0.342\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.730 error=0.339\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.658 error=0.347\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.667 error=0.338\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.674 error=0.347\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.674 error=0.363\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.690 error=0.333\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.695 error=0.329\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.716 error=0.336\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.713 error=0.327\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.686 error=0.335\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.672 error=0.345\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.713 error=0.321\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.721 error=0.324\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.725 error=0.306\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.710 error=0.320\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.720 error=0.329\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.731 error=0.314\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.731 error=0.311\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.725 error=0.311\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.695 error=0.345\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.701 error=0.343\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.701 error=0.328\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.679 error=0.348\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.706 error=0.333\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.705 error=0.333\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.673 error=0.352\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.682 error=0.345\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.678 error=0.343\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.677 error=0.339\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.678 error=0.336\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.676 error=0.363\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.691 error=0.363\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.675 error=0.371\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.707 error=0.342\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.708 error=0.349\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.710 error=0.345\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.715 error=0.360\n",
      "\n",
      "\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.707 error=0.338\n",
      "Strict error yeast_dros_rat_mouse_comb auc=0.714 error=0.326\n",
      "\n",
      "\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.672 error=0.360\n",
      "Gen error yeast_dros_rat_mouse_comb auc=0.684 error=0.344\n",
      "\n",
      "\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.694 error=0.356\n",
      "BE error yeast_dros_rat_mouse_comb auc=0.677 error=0.356\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_yeast_dros_rat_mouse_comb_strict = []\n",
    "mean_auc_yeast_dros_rat_mouse_comb_strict = []\n",
    "mean_err_yeast_dros_rat_mouse_comb_gen = []\n",
    "mean_auc_yeast_dros_rat_mouse_comb_gen = []\n",
    "mean_err_yeast_dros_rat_mouse_comb_be = []\n",
    "mean_auc_yeast_dros_rat_mouse_comb_be = []\n",
    "for e, f, t in zip(errors_yeast_dros_rat_mouse_comb, fpr_yeast_dros_rat_mouse_comb, tpr_yeast_dros_rat_mouse_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['yeast_dros_rat_mouse_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_yeast_dros_rat_mouse_comb_strict.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_mouse_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_yeast_dros_rat_mouse_comb_gen.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_mouse_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_yeast_dros_rat_mouse_comb_be.append(error_item)\n",
    "                    mean_auc_yeast_dros_rat_mouse_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_yeast_dros_rat_mouse_comb_org_strict = mean_err_yeast_dros_rat_mouse_comb_strict[0::2]\n",
    "mean_err_yeast_dros_rat_mouse_comb_fs_strict = mean_err_yeast_dros_rat_mouse_comb_strict[1::2]\n",
    "mean_auc_yeast_dros_rat_mouse_comb_org_strict = mean_auc_yeast_dros_rat_mouse_comb_strict[0::2]\n",
    "mean_auc_yeast_dros_rat_mouse_comb_fs_strict = mean_auc_yeast_dros_rat_mouse_comb_strict[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_mouse_comb_org_gen = mean_err_yeast_dros_rat_mouse_comb_gen[0::2]\n",
    "mean_err_yeast_dros_rat_mouse_comb_fs_gen = mean_err_yeast_dros_rat_mouse_comb_gen[1::2]\n",
    "mean_auc_yeast_dros_rat_mouse_comb_org_gen = mean_auc_yeast_dros_rat_mouse_comb_gen[0::2]\n",
    "mean_auc_yeast_dros_rat_mouse_comb_fs_gen = mean_auc_yeast_dros_rat_mouse_comb_gen[1::2]\n",
    "\n",
    "mean_err_yeast_dros_rat_mouse_comb_org_be = mean_err_yeast_dros_rat_mouse_comb_be[0::2]\n",
    "mean_err_yeast_dros_rat_mouse_comb_fs_be = mean_err_yeast_dros_rat_mouse_comb_be[1::2]\n",
    "mean_auc_yeast_dros_rat_mouse_comb_org_be = mean_auc_yeast_dros_rat_mouse_comb_be[0::2]\n",
    "mean_auc_yeast_dros_rat_mouse_comb_fs_be = mean_auc_yeast_dros_rat_mouse_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast_dros_rat_mouse_comb mean strict error original -  0.339589389067\n",
      "yeast_dros_rat_mouse_comb mean strict error feature selection -  0.337498692218\n",
      "yeast_dros_rat_mouse_comb mean strict AUC original -  0.699661602343\n",
      "yeast_dros_rat_mouse_comb mean strict AUC feature selection -  0.699709025274\n",
      "\n",
      "\n",
      "yeast_dros_rat_mouse_comb mean gen error original -  0.340660053443\n",
      "yeast_dros_rat_mouse_comb mean gen error feature selection -  0.341583523103\n",
      "yeast_dros_rat_mouse_comb mean gen AUC original -  0.698937452595\n",
      "yeast_dros_rat_mouse_comb mean gen AUC feature selection -  0.697546586286\n",
      "\n",
      "\n",
      "yeast_dros_rat_mouse_comb mean BE error original -  0.337549064109\n",
      "yeast_dros_rat_mouse_comb mean BE error feature selection -  0.339930276994\n",
      "yeast_dros_rat_mouse_comb mean BE AUC original -  0.709395402814\n",
      "yeast_dros_rat_mouse_comb mean BE AUC feature selection -  0.706944975382\n"
     ]
    }
   ],
   "source": [
    "print('yeast_dros_rat_mouse_comb mean strict error original - ', np.mean(mean_err_yeast_dros_rat_mouse_comb_org_strict))\n",
    "print('yeast_dros_rat_mouse_comb mean strict error feature selection - ', np.mean(mean_err_yeast_dros_rat_mouse_comb_fs_strict))\n",
    "print('yeast_dros_rat_mouse_comb mean strict AUC original - ', np.mean(mean_auc_yeast_dros_rat_mouse_comb_org_strict))\n",
    "print('yeast_dros_rat_mouse_comb mean strict AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_mouse_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat_mouse_comb mean gen error original - ', np.mean(mean_err_yeast_dros_rat_mouse_comb_org_gen))\n",
    "print('yeast_dros_rat_mouse_comb mean gen error feature selection - ', np.mean(mean_err_yeast_dros_rat_mouse_comb_fs_gen))\n",
    "print('yeast_dros_rat_mouse_comb mean gen AUC original - ', np.mean(mean_auc_yeast_dros_rat_mouse_comb_org_gen))\n",
    "print('yeast_dros_rat_mouse_comb mean gen AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_mouse_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('yeast_dros_rat_mouse_comb mean BE error original - ', np.mean(mean_err_yeast_dros_rat_mouse_comb_org_be))\n",
    "print('yeast_dros_rat_mouse_comb mean BE error feature selection - ', np.mean(mean_err_yeast_dros_rat_mouse_comb_fs_be))\n",
    "print('yeast_dros_rat_mouse_comb mean BE AUC original - ', np.mean(mean_auc_yeast_dros_rat_mouse_comb_org_be))\n",
    "print('yeast_dros_rat_mouse_comb mean BE AUC feature selection - ', np.mean(mean_auc_yeast_dros_rat_mouse_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 09:42:30,046 : INFO : loading Word2Vec object from Results/rat/Seeded/Results/rat_strict_real_model\n",
      "2017-04-25 09:42:30,201 : INFO : loading wv recursively from Results/rat/Seeded/Results/rat_strict_real_model.wv.* with mmap=None\n",
      "2017-04-25 09:42:30,202 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 09:42:30,202 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 09:42:30,203 : INFO : loaded Results/rat/Seeded/Results/rat_strict_real_model\n",
      "2017-04-25 09:42:30,222 : INFO : training model with 4 workers on 10523 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 09:42:30,223 : INFO : expecting 45044 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 09:42:30,920 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 09:42:30,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 09:42:30,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 09:42:30,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 09:42:30,937 : INFO : training on 928405 raw words (636726 effective words) took 0.7s, 898683 effective words/s\n",
      "2017-04-25 09:42:30,938 : WARNING : supplied example count (36355) did not equal expected count (225220)\n",
      "2017-04-25 09:42:30,938 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 09:42:30,998 : INFO : saving Word2Vec object under Results/rat_dros_SR_model, separately None\n",
      "2017-04-25 09:42:30,999 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 09:42:31,000 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 09:42:31,000 : INFO : not storing attribute cum_table\n",
      "2017-04-25 09:42:31,201 : INFO : saved Results/rat_dros_SR_model\n",
      "2017-04-25 09:42:31,870 : INFO : loading Word2Vec object from Results/rat/Seeded/Results/rat_gen_real_model\n",
      "2017-04-25 09:42:32,148 : INFO : loading wv recursively from Results/rat/Seeded/Results/rat_gen_real_model.wv.* with mmap=None\n",
      "2017-04-25 09:42:32,150 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 09:42:32,151 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 09:42:32,151 : INFO : loaded Results/rat/Seeded/Results/rat_gen_real_model\n",
      "2017-04-25 09:42:32,191 : INFO : training model with 4 workers on 19441 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 09:42:32,191 : INFO : expecting 179219 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 09:42:33,202 : INFO : PROGRESS: at 6.27% examples, 981489 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:34,202 : INFO : PROGRESS: at 12.67% examples, 994749 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:35,208 : INFO : PROGRESS: at 18.67% examples, 975968 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:35,519 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 09:42:35,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 09:42:35,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 09:42:35,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 09:42:35,531 : INFO : training on 4507620 raw words (3251276 effective words) took 3.3s, 974918 effective words/s\n",
      "2017-04-25 09:42:35,532 : WARNING : supplied example count (185085) did not equal expected count (896095)\n",
      "2017-04-25 09:42:35,532 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 09:42:35,637 : INFO : saving Word2Vec object under Results/rat_dros_GEN_model, separately None\n",
      "2017-04-25 09:42:35,638 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 09:42:35,638 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 09:42:35,639 : INFO : not storing attribute cum_table\n",
      "2017-04-25 09:42:36,485 : INFO : saved Results/rat_dros_GEN_model\n",
      "2017-04-25 09:42:39,872 : INFO : loading Word2Vec object from Results/rat/Seeded/Results/rat_both_ents_model\n",
      "2017-04-25 09:42:39,949 : INFO : loading wv recursively from Results/rat/Seeded/Results/rat_both_ents_model.wv.* with mmap=None\n",
      "2017-04-25 09:42:39,952 : INFO : loading syn0 from Results/rat/Seeded/Results/rat_both_ents_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 09:42:39,971 : INFO : loading syn1neg from Results/rat/Seeded/Results/rat_both_ents_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 09:42:39,987 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 09:42:39,988 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 09:42:39,988 : INFO : loaded Results/rat/Seeded/Results/rat_both_ents_model\n",
      "2017-04-25 09:42:40,088 : INFO : training model with 4 workers on 47220 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 09:42:40,088 : INFO : expecting 1250009 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 09:42:41,104 : INFO : PROGRESS: at 0.67% examples, 720086 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:42,107 : INFO : PROGRESS: at 1.36% examples, 730251 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:43,108 : INFO : PROGRESS: at 2.02% examples, 724150 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 09:42:44,111 : INFO : PROGRESS: at 2.68% examples, 722691 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 09:42:45,113 : INFO : PROGRESS: at 3.26% examples, 704044 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:46,123 : INFO : PROGRESS: at 3.81% examples, 684332 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:47,158 : INFO : PROGRESS: at 4.34% examples, 664860 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:48,158 : INFO : PROGRESS: at 4.90% examples, 657798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:49,171 : INFO : PROGRESS: at 5.45% examples, 649714 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:50,195 : INFO : PROGRESS: at 5.99% examples, 641773 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 09:42:51,212 : INFO : PROGRESS: at 6.54% examples, 636351 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 09:42:52,218 : INFO : PROGRESS: at 7.22% examples, 644807 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 09:42:53,241 : INFO : PROGRESS: at 7.85% examples, 646616 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 09:42:54,245 : INFO : PROGRESS: at 8.54% examples, 653251 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 09:42:55,258 : INFO : PROGRESS: at 9.21% examples, 657595 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:56,269 : INFO : PROGRESS: at 9.74% examples, 651719 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:57,283 : INFO : PROGRESS: at 10.27% examples, 647338 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 09:42:58,296 : INFO : PROGRESS: at 10.81% examples, 643465 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:42:59,299 : INFO : PROGRESS: at 11.36% examples, 640738 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:43:00,310 : INFO : PROGRESS: at 11.88% examples, 636508 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:43:01,331 : INFO : PROGRESS: at 12.42% examples, 633116 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 09:43:02,333 : INFO : PROGRESS: at 13.00% examples, 633258 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 09:43:03,339 : INFO : PROGRESS: at 13.67% examples, 636869 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 09:43:04,340 : INFO : PROGRESS: at 14.33% examples, 639948 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-25 09:43:04,368 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 09:43:04,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 09:43:04,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 09:43:04,390 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 09:43:04,391 : INFO : training on 20708940 raw words (15558170 effective words) took 24.3s, 640330 effective words/s\n",
      "2017-04-25 09:43:04,392 : WARNING : supplied example count (897865) did not equal expected count (6250045)\n",
      "2017-04-25 09:43:04,392 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 09:43:04,707 : INFO : saving Word2Vec object under Results/rat_dros_BE_model, separately None\n",
      "2017-04-25 09:43:04,708 : INFO : storing np array 'syn0' to Results/rat_dros_BE_model.wv.syn0.npy\n",
      "2017-04-25 09:43:05,384 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 09:43:05,384 : INFO : storing np array 'syn1neg' to Results/rat_dros_BE_model.syn1neg.npy\n",
      "2017-04-25 09:43:05,665 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 09:43:05,666 : INFO : not storing attribute cum_table\n",
      "2017-04-25 09:43:05,779 : INFO : saved Results/rat_dros_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "rat_old_SR_model = 'Results/rat/Seeded/Results/rat_strict_real_model'\n",
    "dros_SR_sentences_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "rat_dros_SR_model = add_sentences_to_model(rat_old_SR_model, dros_SR_sentences_pkl, 'rat_dros_SR_model')\n",
    "\n",
    "#Gen model\n",
    "rat_old_GEN_model = 'Results/rat/Seeded/Results/rat_gen_real_model'\n",
    "dros_GEN_sentences_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "rat_dros_GEN_model = add_sentences_to_model(rat_old_GEN_model, dros_GEN_sentences_pkl, 'rat_dros_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "rat_old_BE_model = 'Results/rat/Seeded/Results/rat_both_ents_model'\n",
    "dros_BE_sentences_pkl = 'Results/drosophila/be_real.pkl'\n",
    "rat_dros_BE_model = add_sentences_to_model(rat_old_BE_model, dros_BE_sentences_pkl, 'rat_dros_BE_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "rat_strict_real = pickle.load(open('Results/rat/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_SR_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_GEN_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_BE_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/rat_dros_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/rat_dros_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/rat_dros_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat_dros/Seeded/Results/'\n",
    "errors_rat_dros = mult_open(drct, '_errors_')\n",
    "fpr_rat_dros = mult_open(drct, '_fpr_')\n",
    "tpr_rat_dros = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat_dros auc=0.530 error=0.376\n",
      "Strict error rat_dros auc=0.534 error=0.378\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.555 error=0.379\n",
      "Gen error rat_dros auc=0.547 error=0.381\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.528 error=0.377\n",
      "BE error rat_dros auc=0.528 error=0.378\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.597 error=0.258\n",
      "Strict error rat_dros auc=0.596 error=0.259\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.607 error=0.254\n",
      "Gen error rat_dros auc=0.606 error=0.256\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.622 error=0.254\n",
      "BE error rat_dros auc=0.624 error=0.257\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.622 error=0.277\n",
      "Strict error rat_dros auc=0.624 error=0.279\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.637 error=0.278\n",
      "Gen error rat_dros auc=0.640 error=0.276\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.628 error=0.278\n",
      "BE error rat_dros auc=0.627 error=0.279\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.627 error=0.301\n",
      "Strict error rat_dros auc=0.622 error=0.300\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.648 error=0.296\n",
      "Gen error rat_dros auc=0.651 error=0.295\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.641 error=0.291\n",
      "BE error rat_dros auc=0.642 error=0.291\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.661 error=0.199\n",
      "Strict error rat_dros auc=0.654 error=0.198\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.668 error=0.198\n",
      "Gen error rat_dros auc=0.669 error=0.198\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.653 error=0.200\n",
      "BE error rat_dros auc=0.651 error=0.200\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.578 error=0.327\n",
      "Strict error rat_dros auc=0.581 error=0.327\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.595 error=0.323\n",
      "Gen error rat_dros auc=0.599 error=0.323\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.601 error=0.321\n",
      "BE error rat_dros auc=0.599 error=0.321\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.669 error=0.291\n",
      "Strict error rat_dros auc=0.666 error=0.287\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.682 error=0.292\n",
      "Gen error rat_dros auc=0.681 error=0.290\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.675 error=0.288\n",
      "BE error rat_dros auc=0.668 error=0.288\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.644 error=0.345\n",
      "Strict error rat_dros auc=0.640 error=0.346\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.657 error=0.340\n",
      "Gen error rat_dros auc=0.651 error=0.339\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.646 error=0.337\n",
      "BE error rat_dros auc=0.641 error=0.338\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.654 error=0.242\n",
      "Strict error rat_dros auc=0.660 error=0.245\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.663 error=0.240\n",
      "Gen error rat_dros auc=0.664 error=0.236\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.656 error=0.240\n",
      "BE error rat_dros auc=0.664 error=0.241\n",
      "\n",
      "\n",
      "Strict error rat_dros auc=0.630 error=0.233\n",
      "Strict error rat_dros auc=0.631 error=0.229\n",
      "\n",
      "\n",
      "Gen error rat_dros auc=0.674 error=0.228\n",
      "Gen error rat_dros auc=0.674 error=0.225\n",
      "\n",
      "\n",
      "BE error rat_dros auc=0.657 error=0.230\n",
      "BE error rat_dros auc=0.657 error=0.233\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_dros_strict = []\n",
    "mean_auc_rat_dros_strict = []\n",
    "mean_err_rat_dros_gen = []\n",
    "mean_auc_rat_dros_gen = []\n",
    "mean_err_rat_dros_be = []\n",
    "mean_auc_rat_dros_be = []\n",
    "for e, f, t in zip(errors_rat_dros, fpr_rat_dros, tpr_rat_dros):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat_dros']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_dros_strict.append(error_item)\n",
    "                    mean_auc_rat_dros_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_dros_gen.append(error_item)\n",
    "                    mean_auc_rat_dros_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_dros_be.append(error_item)\n",
    "                    mean_auc_rat_dros_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_dros_org_strict = mean_err_rat_dros_strict[0::2]\n",
    "mean_err_rat_dros_fs_strict = mean_err_rat_dros_strict[1::2]\n",
    "mean_auc_rat_dros_org_strict = mean_auc_rat_dros_strict[0::2]\n",
    "mean_auc_rat_dros_fs_strict = mean_auc_rat_dros_strict[1::2]\n",
    "\n",
    "mean_err_rat_dros_org_gen = mean_err_rat_dros_gen[0::2]\n",
    "mean_err_rat_dros_fs_gen = mean_err_rat_dros_gen[1::2]\n",
    "mean_auc_rat_dros_org_gen = mean_auc_rat_dros_gen[0::2]\n",
    "mean_auc_rat_dros_fs_gen = mean_auc_rat_dros_gen[1::2]\n",
    "\n",
    "mean_err_rat_dros_org_be = mean_err_rat_dros_be[0::2]\n",
    "mean_err_rat_dros_fs_be = mean_err_rat_dros_be[1::2]\n",
    "mean_auc_rat_dros_org_be = mean_auc_rat_dros_be[0::2]\n",
    "mean_auc_rat_dros_fs_be = mean_auc_rat_dros_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat_dros mean strict error original -  0.284711811624\n",
      "rat_dros mean strict error feature selection -  0.284904164502\n",
      "rat_dros mean strict AUC original -  0.621159619608\n",
      "rat_dros mean strict AUC feature selection -  0.620824628834\n",
      "\n",
      "\n",
      "rat_dros mean gen error original -  0.282702060402\n",
      "rat_dros mean gen error feature selection -  0.281940573478\n",
      "rat_dros mean gen AUC original -  0.638587884944\n",
      "rat_dros mean gen AUC feature selection -  0.638198445161\n",
      "\n",
      "\n",
      "rat_dros mean BE error original -  0.281697925886\n",
      "rat_dros mean BE error feature selection -  0.282685902074\n",
      "rat_dros mean BE AUC original -  0.630632059762\n",
      "rat_dros mean BE AUC feature selection -  0.630051080922\n"
     ]
    }
   ],
   "source": [
    "print('rat_dros mean strict error original - ', np.mean(mean_err_rat_dros_org_strict))\n",
    "print('rat_dros mean strict error feature selection - ', np.mean(mean_err_rat_dros_fs_strict))\n",
    "print('rat_dros mean strict AUC original - ', np.mean(mean_auc_rat_dros_org_strict))\n",
    "print('rat_dros mean strict AUC feature selection - ', np.mean(mean_auc_rat_dros_fs_strict))\n",
    "print('\\n')\n",
    "print('rat_dros mean gen error original - ', np.mean(mean_err_rat_dros_org_gen))\n",
    "print('rat_dros mean gen error feature selection - ', np.mean(mean_err_rat_dros_fs_gen))\n",
    "print('rat_dros mean gen AUC original - ', np.mean(mean_auc_rat_dros_org_gen))\n",
    "print('rat_dros mean gen AUC feature selection - ', np.mean(mean_auc_rat_dros_fs_gen))\n",
    "print('\\n')\n",
    "print('rat_dros mean BE error original - ', np.mean(mean_err_rat_dros_org_be))\n",
    "print('rat_dros mean BE error feature selection - ', np.mean(mean_err_rat_dros_fs_be))\n",
    "print('rat_dros mean BE AUC original - ', np.mean(mean_auc_rat_dros_org_be))\n",
    "print('rat_dros mean BE AUC feature selection - ', np.mean(mean_auc_rat_dros_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 10:28:40,165 : INFO : loading Word2Vec object from Results/rat_dros/Seeded/Results/rat_dros_SR_model\n",
      "2017-04-25 10:28:40,325 : INFO : loading wv recursively from Results/rat_dros/Seeded/Results/rat_dros_SR_model.wv.* with mmap=None\n",
      "2017-04-25 10:28:40,327 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 10:28:40,327 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 10:28:40,328 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 10:28:40,328 : INFO : loaded Results/rat_dros/Seeded/Results/rat_dros_SR_model\n",
      "2017-04-25 10:28:40,351 : INFO : training model with 4 workers on 10523 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 10:28:40,351 : INFO : expecting 45044 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 10:28:41,148 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 10:28:41,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 10:28:41,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 10:28:41,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 10:28:41,161 : INFO : training on 942490 raw words (651099 effective words) took 0.8s, 811719 effective words/s\n",
      "2017-04-25 10:28:41,161 : WARNING : supplied example count (35725) did not equal expected count (225220)\n",
      "2017-04-25 10:28:41,162 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 10:28:41,220 : INFO : saving Word2Vec object under Results/rat_dros_yeast_SR_model, separately None\n",
      "2017-04-25 10:28:41,221 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 10:28:41,221 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 10:28:41,222 : INFO : not storing attribute cum_table\n",
      "2017-04-25 10:28:41,436 : INFO : saved Results/rat_dros_yeast_SR_model\n",
      "2017-04-25 10:28:42,505 : INFO : loading Word2Vec object from Results/rat_dros/Seeded/Results/rat_dros_GEN_model\n",
      "2017-04-25 10:28:42,804 : INFO : loading wv recursively from Results/rat_dros/Seeded/Results/rat_dros_GEN_model.wv.* with mmap=None\n",
      "2017-04-25 10:28:42,808 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 10:28:42,809 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 10:28:42,810 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 10:28:42,810 : INFO : loaded Results/rat_dros/Seeded/Results/rat_dros_GEN_model\n",
      "2017-04-25 10:28:42,854 : INFO : training model with 4 workers on 19441 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 10:28:42,855 : INFO : expecting 179219 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 10:28:43,883 : INFO : PROGRESS: at 4.54% examples, 706446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:44,888 : INFO : PROGRESS: at 9.39% examples, 737644 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:45,894 : INFO : PROGRESS: at 14.74% examples, 774266 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 10:28:46,900 : INFO : PROGRESS: at 19.82% examples, 781995 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:47,909 : INFO : PROGRESS: at 24.81% examples, 783140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:48,213 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 10:28:48,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 10:28:48,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 10:28:48,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 10:28:48,230 : INFO : training on 5840885 raw words (4227971 effective words) took 5.4s, 787279 effective words/s\n",
      "2017-04-25 10:28:48,231 : WARNING : supplied example count (237680) did not equal expected count (896095)\n",
      "2017-04-25 10:28:48,232 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 10:28:48,347 : INFO : saving Word2Vec object under Results/rat_dros_yeast_GEN_model, separately None\n",
      "2017-04-25 10:28:48,347 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 10:28:48,348 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 10:28:48,349 : INFO : not storing attribute cum_table\n",
      "2017-04-25 10:28:48,810 : INFO : saved Results/rat_dros_yeast_GEN_model\n",
      "2017-04-25 10:28:52,437 : INFO : loading Word2Vec object from Results/rat_dros/Seeded/Results/rat_dros_BE_model\n",
      "2017-04-25 10:28:52,504 : INFO : loading wv recursively from Results/rat_dros/Seeded/Results/rat_dros_BE_model.wv.* with mmap=None\n",
      "2017-04-25 10:28:52,509 : INFO : loading syn0 from Results/rat_dros/Seeded/Results/rat_dros_BE_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 10:28:52,536 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 10:28:52,537 : INFO : loading syn1neg from Results/rat_dros/Seeded/Results/rat_dros_BE_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 10:28:52,593 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 10:28:52,595 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 10:28:52,596 : INFO : loaded Results/rat_dros/Seeded/Results/rat_dros_BE_model\n",
      "2017-04-25 10:28:52,692 : INFO : training model with 4 workers on 47220 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 10:28:52,693 : INFO : expecting 1250009 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 10:28:53,712 : INFO : PROGRESS: at 0.67% examples, 734817 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 10:28:54,715 : INFO : PROGRESS: at 1.38% examples, 758231 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:55,718 : INFO : PROGRESS: at 2.08% examples, 763096 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 10:28:56,723 : INFO : PROGRESS: at 2.77% examples, 761558 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:57,726 : INFO : PROGRESS: at 3.47% examples, 764026 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 10:28:58,733 : INFO : PROGRESS: at 4.15% examples, 761323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:28:59,742 : INFO : PROGRESS: at 4.86% examples, 764696 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:00,749 : INFO : PROGRESS: at 5.43% examples, 747656 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:01,752 : INFO : PROGRESS: at 5.96% examples, 728904 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:02,754 : INFO : PROGRESS: at 6.49% examples, 714757 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:03,755 : INFO : PROGRESS: at 7.01% examples, 702528 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:04,765 : INFO : PROGRESS: at 7.51% examples, 689294 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 10:29:05,768 : INFO : PROGRESS: at 8.04% examples, 681951 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:06,771 : INFO : PROGRESS: at 8.64% examples, 680420 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:07,772 : INFO : PROGRESS: at 9.31% examples, 684222 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:08,775 : INFO : PROGRESS: at 9.96% examples, 686522 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:09,786 : INFO : PROGRESS: at 10.65% examples, 690483 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:10,791 : INFO : PROGRESS: at 11.24% examples, 688328 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:11,795 : INFO : PROGRESS: at 11.97% examples, 694345 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 10:29:12,796 : INFO : PROGRESS: at 12.61% examples, 695387 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 10:29:13,817 : INFO : PROGRESS: at 13.11% examples, 687787 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:14,826 : INFO : PROGRESS: at 13.64% examples, 683367 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 10:29:15,830 : INFO : PROGRESS: at 14.21% examples, 680754 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:16,834 : INFO : PROGRESS: at 14.73% examples, 676440 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 10:29:17,852 : INFO : PROGRESS: at 15.28% examples, 673023 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 10:29:18,311 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 10:29:18,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 10:29:18,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 10:29:18,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 10:29:18,338 : INFO : training on 22856325 raw words (17243755 effective words) took 25.6s, 672512 effective words/s\n",
      "2017-04-25 10:29:18,339 : WARNING : supplied example count (972535) did not equal expected count (6250045)\n",
      "2017-04-25 10:29:18,340 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 10:29:18,827 : INFO : saving Word2Vec object under Results/rat_dros_yeast_BE_model, separately None\n",
      "2017-04-25 10:29:18,828 : INFO : storing np array 'syn0' to Results/rat_dros_yeast_BE_model.wv.syn0.npy\n",
      "2017-04-25 10:29:18,871 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 10:29:18,872 : INFO : storing np array 'syn1neg' to Results/rat_dros_yeast_BE_model.syn1neg.npy\n",
      "2017-04-25 10:29:18,920 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 10:29:18,921 : INFO : not storing attribute cum_table\n",
      "2017-04-25 10:29:19,083 : INFO : saved Results/rat_dros_yeast_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "rat_dros_old_SR_model = 'Results/rat_dros/Seeded/Results/rat_dros_SR_model'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "rat_dros_yeast_SR_model = add_sentences_to_model(rat_dros_old_SR_model, yeast_SR_sentences_pkl, 'rat_dros_yeast_SR_model')\n",
    "\n",
    "#Gen model\n",
    "rat_dros_old_GEN_model = 'Results/rat_dros/Seeded/Results/rat_dros_GEN_model'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "rat_dros_yeast_GEN_model = add_sentences_to_model(rat_dros_old_GEN_model, yeast_GEN_sentences_pkl, 'rat_dros_yeast_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "rat_dros_old_BE_model = 'Results/rat_dros/Seeded/Results/rat_dros_BE_model'\n",
    "yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "rat_dros_yeast_BE_model = add_sentences_to_model(rat_dros_old_BE_model, yeast_BE_sentences_pkl, 'rat_dros_yeast_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "rat_strict_real = pickle.load(open('Results/rat/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_SR_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_GEN_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_BE_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/rat_dros_yeast_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/rat_dros_yeast_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/rat_dros_yeast_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat_dros_yeast/Seeded/Results/'\n",
    "errors_rat_dros_yeast = mult_open(drct, '_errors_')\n",
    "fpr_rat_dros_yeast = mult_open(drct, '_fpr_')\n",
    "tpr_rat_dros_yeast = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat_dros_yeast auc=0.532 error=0.376\n",
      "Strict error rat_dros_yeast auc=0.542 error=0.374\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.543 error=0.375\n",
      "Gen error rat_dros_yeast auc=0.546 error=0.378\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.533 error=0.376\n",
      "BE error rat_dros_yeast auc=0.526 error=0.379\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.596 error=0.258\n",
      "Strict error rat_dros_yeast auc=0.591 error=0.259\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.615 error=0.260\n",
      "Gen error rat_dros_yeast auc=0.603 error=0.263\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.614 error=0.260\n",
      "BE error rat_dros_yeast auc=0.600 error=0.262\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.613 error=0.275\n",
      "Strict error rat_dros_yeast auc=0.617 error=0.273\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.603 error=0.287\n",
      "Gen error rat_dros_yeast auc=0.607 error=0.283\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.608 error=0.279\n",
      "BE error rat_dros_yeast auc=0.605 error=0.282\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.627 error=0.299\n",
      "Strict error rat_dros_yeast auc=0.620 error=0.299\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.643 error=0.298\n",
      "Gen error rat_dros_yeast auc=0.644 error=0.300\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.638 error=0.293\n",
      "BE error rat_dros_yeast auc=0.630 error=0.296\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.659 error=0.197\n",
      "Strict error rat_dros_yeast auc=0.656 error=0.197\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.667 error=0.196\n",
      "Gen error rat_dros_yeast auc=0.663 error=0.199\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.667 error=0.196\n",
      "BE error rat_dros_yeast auc=0.660 error=0.199\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.573 error=0.325\n",
      "Strict error rat_dros_yeast auc=0.578 error=0.323\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.586 error=0.325\n",
      "Gen error rat_dros_yeast auc=0.585 error=0.325\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.585 error=0.322\n",
      "BE error rat_dros_yeast auc=0.588 error=0.323\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.672 error=0.291\n",
      "Strict error rat_dros_yeast auc=0.670 error=0.292\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.670 error=0.292\n",
      "Gen error rat_dros_yeast auc=0.671 error=0.294\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.682 error=0.292\n",
      "BE error rat_dros_yeast auc=0.680 error=0.287\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.635 error=0.339\n",
      "Strict error rat_dros_yeast auc=0.627 error=0.339\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.656 error=0.340\n",
      "Gen error rat_dros_yeast auc=0.655 error=0.336\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.642 error=0.342\n",
      "BE error rat_dros_yeast auc=0.647 error=0.341\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.652 error=0.240\n",
      "Strict error rat_dros_yeast auc=0.651 error=0.239\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.640 error=0.242\n",
      "Gen error rat_dros_yeast auc=0.651 error=0.242\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.650 error=0.244\n",
      "BE error rat_dros_yeast auc=0.651 error=0.243\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast auc=0.632 error=0.229\n",
      "Strict error rat_dros_yeast auc=0.642 error=0.231\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast auc=0.653 error=0.230\n",
      "Gen error rat_dros_yeast auc=0.655 error=0.229\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast auc=0.646 error=0.230\n",
      "BE error rat_dros_yeast auc=0.642 error=0.228\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_dros_yeast_strict = []\n",
    "mean_auc_rat_dros_yeast_strict = []\n",
    "mean_err_rat_dros_yeast_gen = []\n",
    "mean_auc_rat_dros_yeast_gen = []\n",
    "mean_err_rat_dros_yeast_be = []\n",
    "mean_auc_rat_dros_yeast_be = []\n",
    "for e, f, t in zip(errors_rat_dros_yeast, fpr_rat_dros_yeast, tpr_rat_dros_yeast):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat_dros_yeast']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_dros_yeast_strict.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_dros_yeast_gen.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_dros_yeast_be.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_dros_yeast_org_strict = mean_err_rat_dros_yeast_strict[0::2]\n",
    "mean_err_rat_dros_yeast_fs_strict = mean_err_rat_dros_yeast_strict[1::2]\n",
    "mean_auc_rat_dros_yeast_org_strict = mean_auc_rat_dros_yeast_strict[0::2]\n",
    "mean_auc_rat_dros_yeast_fs_strict = mean_auc_rat_dros_yeast_strict[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_org_gen = mean_err_rat_dros_yeast_gen[0::2]\n",
    "mean_err_rat_dros_yeast_fs_gen = mean_err_rat_dros_yeast_gen[1::2]\n",
    "mean_auc_rat_dros_yeast_org_gen = mean_auc_rat_dros_yeast_gen[0::2]\n",
    "mean_auc_rat_dros_yeast_fs_gen = mean_auc_rat_dros_yeast_gen[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_org_be = mean_err_rat_dros_yeast_be[0::2]\n",
    "mean_err_rat_dros_yeast_fs_be = mean_err_rat_dros_yeast_be[1::2]\n",
    "mean_auc_rat_dros_yeast_org_be = mean_auc_rat_dros_yeast_be[0::2]\n",
    "mean_auc_rat_dros_yeast_fs_be = mean_auc_rat_dros_yeast_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat_dros_yeast mean strict error original -  0.28278087257\n",
      "rat_dros_yeast mean strict error feature selection -  0.282581473327\n",
      "rat_dros_yeast mean strict AUC original -  0.619239870738\n",
      "rat_dros_yeast mean strict AUC feature selection -  0.619453643726\n",
      "\n",
      "\n",
      "rat_dros_yeast mean gen error original -  0.284502276665\n",
      "rat_dros_yeast mean gen error feature selection -  0.285048944936\n",
      "rat_dros_yeast mean gen AUC original -  0.627465078406\n",
      "rat_dros_yeast mean gen AUC feature selection -  0.627878151813\n",
      "\n",
      "\n",
      "rat_dros_yeast mean BE error original -  0.283293594129\n",
      "rat_dros_yeast mean BE error feature selection -  0.28393721726\n",
      "rat_dros_yeast mean BE AUC original -  0.626384949223\n",
      "rat_dros_yeast mean BE AUC feature selection -  0.622802719263\n"
     ]
    }
   ],
   "source": [
    "print('rat_dros_yeast mean strict error original - ', np.mean(mean_err_rat_dros_yeast_org_strict))\n",
    "print('rat_dros_yeast mean strict error feature selection - ', np.mean(mean_err_rat_dros_yeast_fs_strict))\n",
    "print('rat_dros_yeast mean strict AUC original - ', np.mean(mean_auc_rat_dros_yeast_org_strict))\n",
    "print('rat_dros_yeast mean strict AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_fs_strict))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast mean gen error original - ', np.mean(mean_err_rat_dros_yeast_org_gen))\n",
    "print('rat_dros_yeast mean gen error feature selection - ', np.mean(mean_err_rat_dros_yeast_fs_gen))\n",
    "print('rat_dros_yeast mean gen AUC original - ', np.mean(mean_auc_rat_dros_yeast_org_gen))\n",
    "print('rat_dros_yeast mean gen AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_fs_gen))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast mean BE error original - ', np.mean(mean_err_rat_dros_yeast_org_be))\n",
    "print('rat_dros_yeast mean BE error feature selection - ', np.mean(mean_err_rat_dros_yeast_fs_be))\n",
    "print('rat_dros_yeast mean BE AUC original - ', np.mean(mean_auc_rat_dros_yeast_org_be))\n",
    "print('rat_dros_yeast mean BE AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 11:35:57,611 : INFO : loading Word2Vec object from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_SR_model\n",
      "2017-04-25 11:36:01,400 : INFO : loading wv recursively from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_SR_model.wv.* with mmap=None\n",
      "2017-04-25 11:36:01,400 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 11:36:01,401 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 11:36:01,403 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 11:36:01,403 : INFO : loaded Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_SR_model\n",
      "2017-04-25 11:36:01,424 : INFO : training model with 4 workers on 10523 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 11:36:01,425 : INFO : expecting 45044 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 11:36:02,434 : INFO : PROGRESS: at 13.61% examples, 605267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:03,435 : INFO : PROGRESS: at 27.92% examples, 620203 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:04,460 : INFO : PROGRESS: at 41.20% examples, 605767 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:36:05,467 : INFO : PROGRESS: at 51.86% examples, 572325 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:06,497 : INFO : PROGRESS: at 67.81% examples, 595939 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:07,516 : INFO : PROGRESS: at 80.77% examples, 591066 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:08,517 : INFO : PROGRESS: at 93.24% examples, 585996 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:09,520 : INFO : PROGRESS: at 105.90% examples, 582877 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:36:10,533 : INFO : PROGRESS: at 120.67% examples, 590314 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:11,551 : INFO : PROGRESS: at 136.25% examples, 599533 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:12,555 : INFO : PROGRESS: at 148.90% examples, 596047 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:13,566 : INFO : PROGRESS: at 161.55% examples, 592791 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:14,576 : INFO : PROGRESS: at 174.02% examples, 589510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:15,586 : INFO : PROGRESS: at 187.31% examples, 589273 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:16,038 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 11:36:16,052 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 11:36:16,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 11:36:16,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 11:36:16,066 : INFO : training on 11843775 raw words (8672674 effective words) took 14.6s, 592547 effective words/s\n",
      "2017-04-25 11:36:16,067 : WARNING : supplied example count (438615) did not equal expected count (225220)\n",
      "2017-04-25 11:36:16,068 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 11:36:16,137 : INFO : saving Word2Vec object under Results/rat_dros_yeast_mouse_SR_model, separately None\n",
      "2017-04-25 11:36:16,139 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 11:36:16,142 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 11:36:16,144 : INFO : not storing attribute cum_table\n",
      "2017-04-25 11:36:16,422 : INFO : saved Results/rat_dros_yeast_mouse_SR_model\n",
      "2017-04-25 11:36:37,342 : INFO : loading Word2Vec object from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_GEN_model\n",
      "2017-04-25 11:36:42,958 : INFO : loading wv recursively from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_GEN_model.wv.* with mmap=None\n",
      "2017-04-25 11:36:42,960 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 11:36:42,961 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 11:36:42,961 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 11:36:42,962 : INFO : loaded Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_GEN_model\n",
      "2017-04-25 11:36:43,007 : INFO : training model with 4 workers on 19441 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 11:36:43,010 : INFO : expecting 179219 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 11:36:44,052 : INFO : PROGRESS: at 3.06% examples, 517830 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:45,068 : INFO : PROGRESS: at 6.70% examples, 569537 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:46,070 : INFO : PROGRESS: at 10.66% examples, 608878 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:47,073 : INFO : PROGRESS: at 14.49% examples, 623033 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:48,074 : INFO : PROGRESS: at 18.18% examples, 627646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:49,077 : INFO : PROGRESS: at 21.71% examples, 625402 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:50,084 : INFO : PROGRESS: at 25.25% examples, 623633 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:51,094 : INFO : PROGRESS: at 28.79% examples, 622154 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:52,098 : INFO : PROGRESS: at 31.93% examples, 613746 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:53,102 : INFO : PROGRESS: at 35.77% examples, 619004 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:54,108 : INFO : PROGRESS: at 39.42% examples, 620517 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:55,138 : INFO : PROGRESS: at 42.31% examples, 609421 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:56,166 : INFO : PROGRESS: at 44.99% examples, 597250 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:57,173 : INFO : PROGRESS: at 47.70% examples, 588201 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:58,183 : INFO : PROGRESS: at 51.16% examples, 588732 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:36:59,192 : INFO : PROGRESS: at 54.11% examples, 583592 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:00,212 : INFO : PROGRESS: at 57.03% examples, 578710 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:01,216 : INFO : PROGRESS: at 60.11% examples, 576117 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:02,229 : INFO : PROGRESS: at 63.30% examples, 574657 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:03,234 : INFO : PROGRESS: at 66.27% examples, 571757 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:04,250 : INFO : PROGRESS: at 69.37% examples, 569863 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:05,252 : INFO : PROGRESS: at 72.76% examples, 570875 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:06,259 : INFO : PROGRESS: at 76.07% examples, 571058 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:07,275 : INFO : PROGRESS: at 79.40% examples, 571036 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:08,281 : INFO : PROGRESS: at 82.98% examples, 573004 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:37:09,293 : INFO : PROGRESS: at 85.91% examples, 570411 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:37:10,337 : INFO : PROGRESS: at 88.97% examples, 568175 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:11,361 : INFO : PROGRESS: at 92.29% examples, 568065 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:12,371 : INFO : PROGRESS: at 95.51% examples, 567739 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:13,387 : INFO : PROGRESS: at 98.75% examples, 567343 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:14,398 : INFO : PROGRESS: at 102.11% examples, 567741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:15,407 : INFO : PROGRESS: at 105.40% examples, 567705 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:16,410 : INFO : PROGRESS: at 108.52% examples, 566887 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 11:37:17,417 : INFO : PROGRESS: at 112.05% examples, 568231 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:18,428 : INFO : PROGRESS: at 115.22% examples, 567494 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:19,429 : INFO : PROGRESS: at 118.27% examples, 566534 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:20,450 : INFO : PROGRESS: at 121.50% examples, 566140 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:21,465 : INFO : PROGRESS: at 124.77% examples, 566025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:22,482 : INFO : PROGRESS: at 127.86% examples, 565154 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:23,508 : INFO : PROGRESS: at 131.05% examples, 564591 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:24,517 : INFO : PROGRESS: at 134.29% examples, 564465 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:25,550 : INFO : PROGRESS: at 137.47% examples, 563860 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:26,556 : INFO : PROGRESS: at 140.54% examples, 563087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:27,559 : INFO : PROGRESS: at 143.68% examples, 562738 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:28,578 : INFO : PROGRESS: at 146.91% examples, 562520 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:29,592 : INFO : PROGRESS: at 150.01% examples, 561919 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:30,600 : INFO : PROGRESS: at 153.12% examples, 561407 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:31,616 : INFO : PROGRESS: at 156.31% examples, 561116 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:32,643 : INFO : PROGRESS: at 159.77% examples, 561631 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:33,656 : INFO : PROGRESS: at 162.67% examples, 560361 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:34,683 : INFO : PROGRESS: at 165.95% examples, 560277 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:35,701 : INFO : PROGRESS: at 169.19% examples, 560159 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:36,709 : INFO : PROGRESS: at 172.46% examples, 560285 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:37,712 : INFO : PROGRESS: at 175.99% examples, 561274 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:37:38,713 : INFO : PROGRESS: at 179.73% examples, 562920 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:39,716 : INFO : PROGRESS: at 182.57% examples, 561708 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:40,758 : INFO : PROGRESS: at 185.94% examples, 561735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:41,766 : INFO : PROGRESS: at 189.13% examples, 561569 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:42,768 : INFO : PROGRESS: at 192.19% examples, 561083 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 11:37:43,790 : INFO : PROGRESS: at 195.38% examples, 560798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:44,800 : INFO : PROGRESS: at 198.78% examples, 561249 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:37:45,818 : INFO : PROGRESS: at 201.96% examples, 561023 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:37:46,833 : INFO : PROGRESS: at 205.16% examples, 560820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:47,847 : INFO : PROGRESS: at 208.48% examples, 560981 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:48,851 : INFO : PROGRESS: at 211.37% examples, 560079 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:49,854 : INFO : PROGRESS: at 214.49% examples, 559780 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:50,871 : INFO : PROGRESS: at 217.64% examples, 559476 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:51,878 : INFO : PROGRESS: at 220.06% examples, 557405 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:52,893 : INFO : PROGRESS: at 223.74% examples, 558451 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:53,905 : INFO : PROGRESS: at 227.01% examples, 558537 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:37:54,917 : INFO : PROGRESS: at 230.67% examples, 559562 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:55,926 : INFO : PROGRESS: at 233.85% examples, 559444 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:56,927 : INFO : PROGRESS: at 237.23% examples, 559899 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:57,933 : INFO : PROGRESS: at 240.57% examples, 560109 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:37:58,972 : INFO : PROGRESS: at 243.76% examples, 559786 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:00,001 : INFO : PROGRESS: at 247.12% examples, 559910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:01,003 : INFO : PROGRESS: at 250.35% examples, 559945 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:02,004 : INFO : PROGRESS: at 252.89% examples, 558465 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:38:03,010 : INFO : PROGRESS: at 256.07% examples, 558399 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:04,025 : INFO : PROGRESS: at 259.61% examples, 559022 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:05,049 : INFO : PROGRESS: at 262.81% examples, 558830 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:06,056 : INFO : PROGRESS: at 265.95% examples, 558661 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:07,061 : INFO : PROGRESS: at 269.50% examples, 559322 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:38:07,353 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 11:38:07,357 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 11:38:07,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 11:38:07,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 11:38:07,369 : INFO : training on 62678565 raw words (47201686 effective words) took 84.3s, 559603 effective words/s\n",
      "2017-04-25 11:38:07,370 : WARNING : supplied example count (2425125) did not equal expected count (896095)\n",
      "2017-04-25 11:38:07,370 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 11:38:07,494 : INFO : saving Word2Vec object under Results/rat_dros_yeast_mouse_GEN_model, separately None\n",
      "2017-04-25 11:38:07,495 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 11:38:07,496 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 11:38:07,496 : INFO : not storing attribute cum_table\n",
      "2017-04-25 11:38:08,826 : INFO : saved Results/rat_dros_yeast_mouse_GEN_model\n",
      "2017-04-25 11:39:04,145 : INFO : loading Word2Vec object from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_BE_model\n",
      "2017-04-25 11:39:04,302 : INFO : loading wv recursively from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_BE_model.wv.* with mmap=None\n",
      "2017-04-25 11:39:04,305 : INFO : loading syn0 from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_BE_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 11:39:05,414 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 11:39:05,415 : INFO : loading syn1neg from Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_BE_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 11:39:06,972 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 11:39:06,973 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 11:39:06,974 : INFO : loaded Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_BE_model\n",
      "2017-04-25 11:39:07,139 : INFO : training model with 4 workers on 47220 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 11:39:07,140 : INFO : expecting 1250009 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 11:39:08,190 : INFO : PROGRESS: at 0.35% examples, 388382 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:09,220 : INFO : PROGRESS: at 0.76% examples, 426806 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:39:10,237 : INFO : PROGRESS: at 1.14% examples, 426420 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:11,238 : INFO : PROGRESS: at 1.58% examples, 446860 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:12,271 : INFO : PROGRESS: at 1.97% examples, 445710 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:13,275 : INFO : PROGRESS: at 2.35% examples, 444594 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:14,293 : INFO : PROGRESS: at 2.76% examples, 447204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:15,327 : INFO : PROGRESS: at 3.23% examples, 456839 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:16,343 : INFO : PROGRESS: at 3.70% examples, 466032 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 11:39:17,350 : INFO : PROGRESS: at 4.15% examples, 470655 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 11:39:18,376 : INFO : PROGRESS: at 4.55% examples, 468973 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:39:19,408 : INFO : PROGRESS: at 4.99% examples, 471102 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:20,426 : INFO : PROGRESS: at 5.45% examples, 475195 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:21,450 : INFO : PROGRESS: at 5.87% examples, 475213 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:22,450 : INFO : PROGRESS: at 6.35% examples, 480560 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:23,498 : INFO : PROGRESS: at 6.80% examples, 481906 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:24,521 : INFO : PROGRESS: at 7.28% examples, 485520 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:25,524 : INFO : PROGRESS: at 7.72% examples, 486362 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:39:26,550 : INFO : PROGRESS: at 8.15% examples, 486133 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:39:27,551 : INFO : PROGRESS: at 8.56% examples, 485757 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:28,576 : INFO : PROGRESS: at 8.90% examples, 480872 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:29,579 : INFO : PROGRESS: at 9.24% examples, 476614 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:30,593 : INFO : PROGRESS: at 9.63% examples, 475462 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:31,617 : INFO : PROGRESS: at 9.97% examples, 471673 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:39:32,649 : INFO : PROGRESS: at 10.31% examples, 468045 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:33,662 : INFO : PROGRESS: at 10.70% examples, 466758 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 11:39:34,726 : INFO : PROGRESS: at 11.08% examples, 465002 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:39:35,747 : INFO : PROGRESS: at 11.47% examples, 464072 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:36,782 : INFO : PROGRESS: at 11.94% examples, 466103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:37,788 : INFO : PROGRESS: at 12.42% examples, 468986 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:38,800 : INFO : PROGRESS: at 12.91% examples, 471834 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:39,840 : INFO : PROGRESS: at 13.36% examples, 472905 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 11:39:40,879 : INFO : PROGRESS: at 13.80% examples, 473471 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 11:39:41,899 : INFO : PROGRESS: at 14.29% examples, 475810 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:42,921 : INFO : PROGRESS: at 14.76% examples, 477571 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:43,933 : INFO : PROGRESS: at 15.18% examples, 477661 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:44,948 : INFO : PROGRESS: at 15.66% examples, 479355 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:39:45,968 : INFO : PROGRESS: at 16.16% examples, 481903 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:47,002 : INFO : PROGRESS: at 16.62% examples, 482796 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:39:48,026 : INFO : PROGRESS: at 17.11% examples, 484486 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:39:49,029 : INFO : PROGRESS: at 17.56% examples, 485239 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:39:50,067 : INFO : PROGRESS: at 17.99% examples, 485028 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 11:39:51,071 : INFO : PROGRESS: at 18.45% examples, 486088 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:52,078 : INFO : PROGRESS: at 18.90% examples, 486880 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:53,081 : INFO : PROGRESS: at 19.38% examples, 488199 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:54,086 : INFO : PROGRESS: at 19.82% examples, 488779 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:55,093 : INFO : PROGRESS: at 20.31% examples, 490275 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:56,099 : INFO : PROGRESS: at 20.82% examples, 492205 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:57,101 : INFO : PROGRESS: at 21.27% examples, 492697 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:58,108 : INFO : PROGRESS: at 21.72% examples, 493261 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:39:59,122 : INFO : PROGRESS: at 22.21% examples, 494491 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:00,125 : INFO : PROGRESS: at 22.68% examples, 495480 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:01,157 : INFO : PROGRESS: at 23.13% examples, 495591 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:02,158 : INFO : PROGRESS: at 23.59% examples, 496139 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:03,165 : INFO : PROGRESS: at 24.02% examples, 496189 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:04,204 : INFO : PROGRESS: at 24.46% examples, 495952 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:05,207 : INFO : PROGRESS: at 24.81% examples, 494442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:06,216 : INFO : PROGRESS: at 25.21% examples, 493847 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:07,225 : INFO : PROGRESS: at 25.67% examples, 494291 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:08,231 : INFO : PROGRESS: at 26.09% examples, 494249 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:40:09,252 : INFO : PROGRESS: at 26.54% examples, 494333 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:10,252 : INFO : PROGRESS: at 27.01% examples, 495196 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:11,275 : INFO : PROGRESS: at 27.49% examples, 495972 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:12,279 : INFO : PROGRESS: at 27.97% examples, 496751 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:40:13,313 : INFO : PROGRESS: at 28.43% examples, 497044 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:14,334 : INFO : PROGRESS: at 28.88% examples, 497315 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 11:40:15,334 : INFO : PROGRESS: at 29.32% examples, 497390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:16,346 : INFO : PROGRESS: at 29.74% examples, 497263 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:17,383 : INFO : PROGRESS: at 30.22% examples, 497841 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:18,385 : INFO : PROGRESS: at 30.65% examples, 497783 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:40:19,398 : INFO : PROGRESS: at 31.11% examples, 498176 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:20,408 : INFO : PROGRESS: at 31.55% examples, 498275 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:21,414 : INFO : PROGRESS: at 32.02% examples, 498815 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 11:40:22,451 : INFO : PROGRESS: at 32.47% examples, 498828 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:23,460 : INFO : PROGRESS: at 32.88% examples, 498519 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:40:24,474 : INFO : PROGRESS: at 33.34% examples, 498772 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:25,497 : INFO : PROGRESS: at 33.79% examples, 498864 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:26,498 : INFO : PROGRESS: at 34.21% examples, 498707 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:27,507 : INFO : PROGRESS: at 34.68% examples, 499178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:28,515 : INFO : PROGRESS: at 35.08% examples, 498700 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:29,516 : INFO : PROGRESS: at 35.52% examples, 498828 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:30,529 : INFO : PROGRESS: at 35.97% examples, 499079 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:40:31,532 : INFO : PROGRESS: at 36.38% examples, 498739 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:32,545 : INFO : PROGRESS: at 36.87% examples, 499431 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:33,561 : INFO : PROGRESS: at 37.27% examples, 498928 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:34,564 : INFO : PROGRESS: at 37.69% examples, 498764 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:35,613 : INFO : PROGRESS: at 38.11% examples, 498345 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:36,624 : INFO : PROGRESS: at 38.56% examples, 498591 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:37,664 : INFO : PROGRESS: at 39.06% examples, 499261 words/s, in_qsize 8, out_qsize 3\n",
      "2017-04-25 11:40:38,710 : INFO : PROGRESS: at 39.49% examples, 498873 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:39,744 : INFO : PROGRESS: at 39.97% examples, 499309 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:40,752 : INFO : PROGRESS: at 40.37% examples, 498889 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:41,771 : INFO : PROGRESS: at 40.79% examples, 498657 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:40:42,786 : INFO : PROGRESS: at 41.23% examples, 498700 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:43,797 : INFO : PROGRESS: at 41.69% examples, 498995 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:44,798 : INFO : PROGRESS: at 42.13% examples, 499101 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:45,810 : INFO : PROGRESS: at 42.54% examples, 498764 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:46,841 : INFO : PROGRESS: at 43.05% examples, 499567 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:40:47,863 : INFO : PROGRESS: at 43.51% examples, 499796 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:48,869 : INFO : PROGRESS: at 43.96% examples, 499950 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:40:49,890 : INFO : PROGRESS: at 44.42% examples, 500173 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:40:50,891 : INFO : PROGRESS: at 44.85% examples, 500187 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:51,894 : INFO : PROGRESS: at 45.29% examples, 500182 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:52,924 : INFO : PROGRESS: at 45.77% examples, 500648 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:53,930 : INFO : PROGRESS: at 46.22% examples, 500783 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:54,963 : INFO : PROGRESS: at 46.69% examples, 500997 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-25 11:40:55,964 : INFO : PROGRESS: at 47.14% examples, 501080 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 11:40:56,965 : INFO : PROGRESS: at 47.58% examples, 501157 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:57,966 : INFO : PROGRESS: at 47.99% examples, 500953 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:58,980 : INFO : PROGRESS: at 48.42% examples, 500836 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:40:59,993 : INFO : PROGRESS: at 48.91% examples, 501337 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:00,994 : INFO : PROGRESS: at 49.36% examples, 501471 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:01,999 : INFO : PROGRESS: at 49.80% examples, 501590 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:03,014 : INFO : PROGRESS: at 50.30% examples, 502135 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:04,033 : INFO : PROGRESS: at 50.74% examples, 502121 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:05,054 : INFO : PROGRESS: at 51.24% examples, 502755 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:06,078 : INFO : PROGRESS: at 51.69% examples, 502782 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:07,093 : INFO : PROGRESS: at 52.10% examples, 502524 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:41:08,101 : INFO : PROGRESS: at 52.60% examples, 503062 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:41:09,107 : INFO : PROGRESS: at 53.05% examples, 503225 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:10,108 : INFO : PROGRESS: at 53.57% examples, 503976 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:11,123 : INFO : PROGRESS: at 54.06% examples, 504456 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:12,149 : INFO : PROGRESS: at 54.55% examples, 504897 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:13,154 : INFO : PROGRESS: at 54.90% examples, 504058 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:14,163 : INFO : PROGRESS: at 55.38% examples, 504432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:15,183 : INFO : PROGRESS: at 55.85% examples, 504638 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:16,188 : INFO : PROGRESS: at 56.28% examples, 504540 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:17,199 : INFO : PROGRESS: at 56.75% examples, 504835 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:18,200 : INFO : PROGRESS: at 57.25% examples, 505337 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:19,219 : INFO : PROGRESS: at 57.69% examples, 505302 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:20,278 : INFO : PROGRESS: at 58.13% examples, 505111 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 11:41:21,283 : INFO : PROGRESS: at 58.54% examples, 504898 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:22,290 : INFO : PROGRESS: at 58.94% examples, 504565 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:23,320 : INFO : PROGRESS: at 59.42% examples, 504832 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:24,325 : INFO : PROGRESS: at 59.89% examples, 505078 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:25,361 : INFO : PROGRESS: at 60.38% examples, 505434 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 11:41:26,370 : INFO : PROGRESS: at 60.81% examples, 505319 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:27,399 : INFO : PROGRESS: at 61.29% examples, 505526 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:28,419 : INFO : PROGRESS: at 61.76% examples, 505707 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:29,445 : INFO : PROGRESS: at 62.27% examples, 506242 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:30,447 : INFO : PROGRESS: at 62.69% examples, 506050 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:31,460 : INFO : PROGRESS: at 63.12% examples, 505928 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:32,461 : INFO : PROGRESS: at 63.55% examples, 505900 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:33,479 : INFO : PROGRESS: at 63.97% examples, 505705 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:34,522 : INFO : PROGRESS: at 64.41% examples, 505581 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:35,534 : INFO : PROGRESS: at 64.88% examples, 505783 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:36,543 : INFO : PROGRESS: at 65.27% examples, 505364 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:37,553 : INFO : PROGRESS: at 65.76% examples, 505772 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:38,564 : INFO : PROGRESS: at 66.19% examples, 505662 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:39,564 : INFO : PROGRESS: at 66.63% examples, 505640 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:40,571 : INFO : PROGRESS: at 67.10% examples, 505896 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:41,596 : INFO : PROGRESS: at 67.49% examples, 505491 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:42,652 : INFO : PROGRESS: at 67.97% examples, 505582 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:43,704 : INFO : PROGRESS: at 68.48% examples, 505990 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:44,717 : INFO : PROGRESS: at 68.96% examples, 506266 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:45,732 : INFO : PROGRESS: at 69.43% examples, 506439 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:41:46,746 : INFO : PROGRESS: at 69.90% examples, 506614 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:47,764 : INFO : PROGRESS: at 70.34% examples, 506579 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:48,775 : INFO : PROGRESS: at 70.77% examples, 506523 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:41:49,793 : INFO : PROGRESS: at 71.18% examples, 506249 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:41:50,821 : INFO : PROGRESS: at 71.66% examples, 506472 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:51,824 : INFO : PROGRESS: at 72.12% examples, 506624 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:52,830 : INFO : PROGRESS: at 72.55% examples, 506487 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:53,841 : INFO : PROGRESS: at 72.95% examples, 506200 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:54,854 : INFO : PROGRESS: at 73.28% examples, 505446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:55,868 : INFO : PROGRESS: at 73.60% examples, 504612 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:56,877 : INFO : PROGRESS: at 74.04% examples, 504617 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:41:57,879 : INFO : PROGRESS: at 74.49% examples, 504735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:41:58,890 : INFO : PROGRESS: at 74.86% examples, 504240 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:41:59,902 : INFO : PROGRESS: at 75.21% examples, 503564 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:00,910 : INFO : PROGRESS: at 75.66% examples, 503665 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:01,920 : INFO : PROGRESS: at 76.17% examples, 504159 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:42:02,951 : INFO : PROGRESS: at 76.64% examples, 504276 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:42:03,974 : INFO : PROGRESS: at 77.04% examples, 503980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:04,982 : INFO : PROGRESS: at 77.42% examples, 503560 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:05,983 : INFO : PROGRESS: at 77.76% examples, 502944 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:06,991 : INFO : PROGRESS: at 78.22% examples, 503131 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:07,991 : INFO : PROGRESS: at 78.66% examples, 503167 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:08,997 : INFO : PROGRESS: at 79.13% examples, 503359 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:10,025 : INFO : PROGRESS: at 79.59% examples, 503442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:11,029 : INFO : PROGRESS: at 80.14% examples, 504141 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:12,048 : INFO : PROGRESS: at 80.63% examples, 504457 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:13,051 : INFO : PROGRESS: at 81.12% examples, 504770 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:14,063 : INFO : PROGRESS: at 81.57% examples, 504808 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:15,079 : INFO : PROGRESS: at 81.98% examples, 504632 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:16,080 : INFO : PROGRESS: at 82.37% examples, 504374 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:17,094 : INFO : PROGRESS: at 82.73% examples, 503833 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:18,114 : INFO : PROGRESS: at 83.19% examples, 503931 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:19,135 : INFO : PROGRESS: at 83.65% examples, 504027 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:20,136 : INFO : PROGRESS: at 84.18% examples, 504580 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:21,138 : INFO : PROGRESS: at 84.66% examples, 504799 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:22,149 : INFO : PROGRESS: at 85.10% examples, 504800 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:23,165 : INFO : PROGRESS: at 85.64% examples, 505375 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:24,195 : INFO : PROGRESS: at 86.15% examples, 505752 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:25,204 : INFO : PROGRESS: at 86.68% examples, 506220 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:26,248 : INFO : PROGRESS: at 87.14% examples, 506279 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:27,252 : INFO : PROGRESS: at 87.62% examples, 506480 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:28,259 : INFO : PROGRESS: at 88.03% examples, 506326 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:29,270 : INFO : PROGRESS: at 88.44% examples, 506126 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:30,274 : INFO : PROGRESS: at 88.88% examples, 506136 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:31,275 : INFO : PROGRESS: at 89.40% examples, 506643 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:32,277 : INFO : PROGRESS: at 89.92% examples, 507070 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:33,283 : INFO : PROGRESS: at 90.43% examples, 507482 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:42:34,292 : INFO : PROGRESS: at 90.98% examples, 508069 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:35,300 : INFO : PROGRESS: at 91.48% examples, 508396 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:36,321 : INFO : PROGRESS: at 91.97% examples, 508609 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 11:42:37,323 : INFO : PROGRESS: at 92.46% examples, 508871 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:38,338 : INFO : PROGRESS: at 92.97% examples, 509243 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:39,354 : INFO : PROGRESS: at 93.56% examples, 510006 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:40,362 : INFO : PROGRESS: at 94.12% examples, 510640 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:41,369 : INFO : PROGRESS: at 94.72% examples, 511484 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:42,371 : INFO : PROGRESS: at 95.25% examples, 511939 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:43,380 : INFO : PROGRESS: at 95.67% examples, 511800 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:44,382 : INFO : PROGRESS: at 96.06% examples, 511536 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:45,393 : INFO : PROGRESS: at 96.43% examples, 511116 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:42:46,402 : INFO : PROGRESS: at 96.90% examples, 511264 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:47,436 : INFO : PROGRESS: at 97.34% examples, 511143 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:48,437 : INFO : PROGRESS: at 97.83% examples, 511414 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:42:49,437 : INFO : PROGRESS: at 98.38% examples, 511962 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:50,453 : INFO : PROGRESS: at 98.84% examples, 511987 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:51,456 : INFO : PROGRESS: at 99.34% examples, 512285 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:42:52,464 : INFO : PROGRESS: at 99.82% examples, 512429 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:53,472 : INFO : PROGRESS: at 100.27% examples, 512502 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:54,481 : INFO : PROGRESS: at 100.76% examples, 512710 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:55,482 : INFO : PROGRESS: at 101.26% examples, 512999 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:56,496 : INFO : PROGRESS: at 101.75% examples, 513156 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:57,520 : INFO : PROGRESS: at 102.24% examples, 513357 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:42:58,547 : INFO : PROGRESS: at 102.72% examples, 513451 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:42:59,557 : INFO : PROGRESS: at 103.28% examples, 514010 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:43:00,564 : INFO : PROGRESS: at 104.03% examples, 515533 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:01,569 : INFO : PROGRESS: at 104.81% examples, 517149 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:02,574 : INFO : PROGRESS: at 105.58% examples, 518746 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:03,580 : INFO : PROGRESS: at 106.35% examples, 520329 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:04,584 : INFO : PROGRESS: at 107.14% examples, 521970 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:05,588 : INFO : PROGRESS: at 107.90% examples, 523469 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:06,591 : INFO : PROGRESS: at 108.65% examples, 524862 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:07,591 : INFO : PROGRESS: at 109.41% examples, 526340 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:08,594 : INFO : PROGRESS: at 110.19% examples, 527897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:09,602 : INFO : PROGRESS: at 110.95% examples, 529305 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:10,611 : INFO : PROGRESS: at 111.70% examples, 530706 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:11,646 : INFO : PROGRESS: at 112.26% examples, 531083 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:12,671 : INFO : PROGRESS: at 112.85% examples, 531667 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:13,674 : INFO : PROGRESS: at 113.43% examples, 532198 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:14,692 : INFO : PROGRESS: at 113.98% examples, 532601 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:15,697 : INFO : PROGRESS: at 114.75% examples, 534021 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:16,721 : INFO : PROGRESS: at 115.45% examples, 535082 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:17,725 : INFO : PROGRESS: at 116.11% examples, 535959 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:18,742 : INFO : PROGRESS: at 116.72% examples, 536618 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:19,765 : INFO : PROGRESS: at 117.36% examples, 537378 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:20,784 : INFO : PROGRESS: at 117.94% examples, 537838 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:21,797 : INFO : PROGRESS: at 118.54% examples, 538459 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:22,801 : INFO : PROGRESS: at 119.06% examples, 538673 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:23,803 : INFO : PROGRESS: at 119.72% examples, 539582 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:24,825 : INFO : PROGRESS: at 120.27% examples, 539902 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:25,841 : INFO : PROGRESS: at 120.84% examples, 540347 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:43:26,882 : INFO : PROGRESS: at 121.33% examples, 540325 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:27,886 : INFO : PROGRESS: at 121.83% examples, 540468 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:28,893 : INFO : PROGRESS: at 122.32% examples, 540541 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:29,903 : INFO : PROGRESS: at 122.83% examples, 540699 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:30,918 : INFO : PROGRESS: at 123.46% examples, 541403 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:31,943 : INFO : PROGRESS: at 124.02% examples, 541727 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:32,950 : INFO : PROGRESS: at 124.56% examples, 542030 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:43:33,955 : INFO : PROGRESS: at 125.09% examples, 542277 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:34,960 : INFO : PROGRESS: at 125.63% examples, 542609 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:35,967 : INFO : PROGRESS: at 126.23% examples, 543138 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:36,971 : INFO : PROGRESS: at 126.80% examples, 543582 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:37,972 : INFO : PROGRESS: at 127.47% examples, 544425 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:38,973 : INFO : PROGRESS: at 128.04% examples, 544867 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:39,981 : INFO : PROGRESS: at 128.60% examples, 545206 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:40,987 : INFO : PROGRESS: at 129.14% examples, 545490 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:41,996 : INFO : PROGRESS: at 129.65% examples, 545652 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:43,015 : INFO : PROGRESS: at 130.12% examples, 545599 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:44,041 : INFO : PROGRESS: at 130.63% examples, 545699 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:45,047 : INFO : PROGRESS: at 131.17% examples, 545975 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:46,054 : INFO : PROGRESS: at 131.73% examples, 546331 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:47,067 : INFO : PROGRESS: at 132.33% examples, 546838 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:48,072 : INFO : PROGRESS: at 132.92% examples, 547328 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:49,079 : INFO : PROGRESS: at 133.56% examples, 547978 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:50,083 : INFO : PROGRESS: at 134.19% examples, 548629 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:51,088 : INFO : PROGRESS: at 134.81% examples, 549190 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:52,090 : INFO : PROGRESS: at 135.42% examples, 549752 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:53,110 : INFO : PROGRESS: at 136.09% examples, 550494 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:54,112 : INFO : PROGRESS: at 136.73% examples, 551153 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:55,127 : INFO : PROGRESS: at 137.31% examples, 551522 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:43:56,136 : INFO : PROGRESS: at 137.87% examples, 551843 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:57,148 : INFO : PROGRESS: at 138.41% examples, 552050 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:43:58,174 : INFO : PROGRESS: at 138.98% examples, 552390 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:43:59,182 : INFO : PROGRESS: at 139.53% examples, 552651 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:00,186 : INFO : PROGRESS: at 140.03% examples, 552737 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:01,194 : INFO : PROGRESS: at 140.40% examples, 552287 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:02,212 : INFO : PROGRESS: at 140.77% examples, 551823 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:03,219 : INFO : PROGRESS: at 141.13% examples, 551381 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:04,223 : INFO : PROGRESS: at 141.57% examples, 551208 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:05,243 : INFO : PROGRESS: at 142.11% examples, 551421 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:06,249 : INFO : PROGRESS: at 142.70% examples, 551840 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:07,265 : INFO : PROGRESS: at 143.25% examples, 552110 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:08,291 : INFO : PROGRESS: at 143.80% examples, 552356 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:09,294 : INFO : PROGRESS: at 144.38% examples, 552748 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:10,295 : INFO : PROGRESS: at 144.97% examples, 553144 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:11,319 : INFO : PROGRESS: at 145.54% examples, 553469 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:12,322 : INFO : PROGRESS: at 146.18% examples, 554081 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:13,323 : INFO : PROGRESS: at 146.83% examples, 554716 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:14,333 : INFO : PROGRESS: at 147.34% examples, 554805 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:15,359 : INFO : PROGRESS: at 147.80% examples, 554661 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:16,370 : INFO : PROGRESS: at 148.27% examples, 554623 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:17,375 : INFO : PROGRESS: at 148.71% examples, 554470 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:18,382 : INFO : PROGRESS: at 149.29% examples, 554815 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:19,397 : INFO : PROGRESS: at 150.00% examples, 555660 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:20,399 : INFO : PROGRESS: at 150.59% examples, 556056 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:21,404 : INFO : PROGRESS: at 151.16% examples, 556366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:22,424 : INFO : PROGRESS: at 151.71% examples, 556576 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:23,433 : INFO : PROGRESS: at 152.27% examples, 556876 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:24,434 : INFO : PROGRESS: at 152.93% examples, 557530 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:25,437 : INFO : PROGRESS: at 153.57% examples, 558102 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:26,452 : INFO : PROGRESS: at 154.10% examples, 558239 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:44:27,476 : INFO : PROGRESS: at 154.66% examples, 558457 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:28,486 : INFO : PROGRESS: at 155.21% examples, 558672 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:29,487 : INFO : PROGRESS: at 155.84% examples, 559213 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:30,493 : INFO : PROGRESS: at 156.47% examples, 559742 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:31,495 : INFO : PROGRESS: at 157.08% examples, 560184 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:32,512 : INFO : PROGRESS: at 157.51% examples, 559955 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:33,527 : INFO : PROGRESS: at 158.00% examples, 559989 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:34,539 : INFO : PROGRESS: at 158.42% examples, 559721 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:35,590 : INFO : PROGRESS: at 158.83% examples, 559387 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:44:36,620 : INFO : PROGRESS: at 159.18% examples, 558835 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:37,673 : INFO : PROGRESS: at 159.62% examples, 558622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:38,679 : INFO : PROGRESS: at 160.19% examples, 558906 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:39,694 : INFO : PROGRESS: at 160.76% examples, 559153 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:40,709 : INFO : PROGRESS: at 161.34% examples, 559490 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:44:41,713 : INFO : PROGRESS: at 161.97% examples, 559980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:42,724 : INFO : PROGRESS: at 162.47% examples, 559997 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:43,729 : INFO : PROGRESS: at 162.98% examples, 560068 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:44,755 : INFO : PROGRESS: at 163.63% examples, 560610 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:45,762 : INFO : PROGRESS: at 164.28% examples, 561158 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:46,776 : INFO : PROGRESS: at 164.74% examples, 561053 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:47,798 : INFO : PROGRESS: at 165.16% examples, 560822 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:44:48,799 : INFO : PROGRESS: at 165.68% examples, 560921 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:49,807 : INFO : PROGRESS: at 166.21% examples, 561074 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:50,808 : INFO : PROGRESS: at 166.75% examples, 561263 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:51,808 : INFO : PROGRESS: at 167.47% examples, 562055 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:52,825 : INFO : PROGRESS: at 168.20% examples, 562838 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:53,826 : INFO : PROGRESS: at 168.86% examples, 563397 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:54,846 : INFO : PROGRESS: at 169.45% examples, 563724 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:44:55,855 : INFO : PROGRESS: at 169.92% examples, 563666 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:56,872 : INFO : PROGRESS: at 170.32% examples, 563329 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:57,874 : INFO : PROGRESS: at 170.71% examples, 562998 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:58,879 : INFO : PROGRESS: at 171.28% examples, 563278 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:44:59,881 : INFO : PROGRESS: at 171.90% examples, 563715 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:00,884 : INFO : PROGRESS: at 172.64% examples, 564519 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:01,891 : INFO : PROGRESS: at 173.41% examples, 565442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:02,897 : INFO : PROGRESS: at 174.15% examples, 566252 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:03,902 : INFO : PROGRESS: at 174.90% examples, 567084 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:04,902 : INFO : PROGRESS: at 175.67% examples, 567961 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:05,909 : INFO : PROGRESS: at 176.40% examples, 568739 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:45:06,910 : INFO : PROGRESS: at 177.12% examples, 569474 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:07,911 : INFO : PROGRESS: at 177.81% examples, 570100 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:08,915 : INFO : PROGRESS: at 178.57% examples, 570931 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:09,924 : INFO : PROGRESS: at 179.25% examples, 571515 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 11:45:10,940 : INFO : PROGRESS: at 179.92% examples, 572045 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:11,954 : INFO : PROGRESS: at 180.44% examples, 572106 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:12,973 : INFO : PROGRESS: at 180.95% examples, 572139 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:45:13,980 : INFO : PROGRESS: at 181.43% examples, 572084 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:45:14,988 : INFO : PROGRESS: at 181.99% examples, 572281 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:15,990 : INFO : PROGRESS: at 182.71% examples, 572989 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:17,027 : INFO : PROGRESS: at 183.38% examples, 573454 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 11:45:18,029 : INFO : PROGRESS: at 183.96% examples, 573718 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:19,065 : INFO : PROGRESS: at 184.51% examples, 573822 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 11:45:20,067 : INFO : PROGRESS: at 185.04% examples, 573917 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:21,074 : INFO : PROGRESS: at 185.80% examples, 574730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:22,076 : INFO : PROGRESS: at 186.56% examples, 575547 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:23,077 : INFO : PROGRESS: at 187.24% examples, 576113 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:24,078 : INFO : PROGRESS: at 187.83% examples, 576388 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 11:45:25,088 : INFO : PROGRESS: at 188.42% examples, 576668 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 11:45:25,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 11:45:25,909 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 11:45:25,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 11:45:25,929 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 11:45:25,930 : INFO : training on 282383820 raw words (218523499 effective words) took 378.8s, 576922 effective words/s\n",
      "2017-04-25 11:45:25,931 : WARNING : supplied example count (11808085) did not equal expected count (6250045)\n",
      "2017-04-25 11:45:25,932 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 11:45:26,461 : INFO : saving Word2Vec object under Results/rat_dros_yeast_mouse_BE_model, separately None\n",
      "2017-04-25 11:45:26,501 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 11:45:26,502 : INFO : storing np array 'syn0' to Results/rat_dros_yeast_mouse_BE_model.wv.syn0.npy\n",
      "2017-04-25 11:45:26,590 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 11:45:26,591 : INFO : not storing attribute cum_table\n",
      "2017-04-25 11:45:26,592 : INFO : storing np array 'syn1neg' to Results/rat_dros_yeast_mouse_BE_model.syn1neg.npy\n",
      "2017-04-25 11:45:27,686 : INFO : saved Results/rat_dros_yeast_mouse_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "rat_dros_yeast_old_SR_model = 'Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_SR_model'\n",
    "mouse_SR_sentences_pkl = 'Results/mouse/strict_real.pkl'\n",
    "rat_dros_yeast_mouse_SR_model = add_sentences_to_model(rat_dros_yeast_old_SR_model, mouse_SR_sentences_pkl, 'rat_dros_yeast_mouse_SR_model')\n",
    "\n",
    "#Gen model\n",
    "rat_dros_yeast_old_GEN_model = 'Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_GEN_model'\n",
    "mouse_GEN_sentences_pkl = 'Results/mouse/gen_real.pkl'\n",
    "rat_dros_yeast_mouse_GEN_model = add_sentences_to_model(rat_dros_yeast_old_GEN_model, mouse_GEN_sentences_pkl, 'rat_dros_yeast_mouse_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "rat_dros_yeast_old_BE_model = 'Results/rat_dros_yeast/Seeded/Results/rat_dros_yeast_BE_model'\n",
    "mouse_BE_sentences_pkl = 'Results/mouse/be_real.pkl'\n",
    "rat_dros_yeast_mouse_BE_model = add_sentences_to_model(rat_dros_yeast_old_BE_model, mouse_BE_sentences_pkl, 'rat_dros_yeast_mouse_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "rat_strict_real = pickle.load(open('Results/rat/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_mouse_SR_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_mouse_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_mouse_GEN_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_mouse_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_mouse_BE_merger_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_mouse_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/rat_dros_yeast_mouse_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/rat_dros_yeast_mouse_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/rat_dros_yeast_mouse_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat_dros_yeast_mouse/Seeded/Results/'\n",
    "errors_rat_dros_yeast_mouse = mult_open(drct, '_errors_')\n",
    "fpr_rat_dros_yeast_mouse = mult_open(drct, '_fpr_')\n",
    "tpr_rat_dros_yeast_mouse = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat_dros_yeast_mouse auc=0.693 error=0.232\n",
      "Strict error rat_dros_yeast_mouse auc=0.698 error=0.229\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.697 error=0.234\n",
      "Gen error rat_dros_yeast_mouse auc=0.699 error=0.234\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.724 error=0.231\n",
      "BE error rat_dros_yeast_mouse auc=0.723 error=0.230\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.668 error=0.290\n",
      "Strict error rat_dros_yeast_mouse auc=0.661 error=0.291\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.665 error=0.290\n",
      "Gen error rat_dros_yeast_mouse auc=0.663 error=0.289\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.651 error=0.296\n",
      "BE error rat_dros_yeast_mouse auc=0.648 error=0.298\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.617 error=0.251\n",
      "Strict error rat_dros_yeast_mouse auc=0.616 error=0.249\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.623 error=0.235\n",
      "Gen error rat_dros_yeast_mouse auc=0.628 error=0.235\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.618 error=0.238\n",
      "BE error rat_dros_yeast_mouse auc=0.614 error=0.244\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.583 error=0.252\n",
      "Strict error rat_dros_yeast_mouse auc=0.583 error=0.249\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.600 error=0.244\n",
      "Gen error rat_dros_yeast_mouse auc=0.594 error=0.248\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.593 error=0.248\n",
      "BE error rat_dros_yeast_mouse auc=0.590 error=0.253\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.647 error=0.296\n",
      "Strict error rat_dros_yeast_mouse auc=0.640 error=0.297\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.661 error=0.291\n",
      "Gen error rat_dros_yeast_mouse auc=0.653 error=0.293\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.653 error=0.295\n",
      "BE error rat_dros_yeast_mouse auc=0.650 error=0.299\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.638 error=0.291\n",
      "Strict error rat_dros_yeast_mouse auc=0.637 error=0.287\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.641 error=0.292\n",
      "Gen error rat_dros_yeast_mouse auc=0.637 error=0.292\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.653 error=0.290\n",
      "BE error rat_dros_yeast_mouse auc=0.642 error=0.289\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.695 error=0.306\n",
      "Strict error rat_dros_yeast_mouse auc=0.697 error=0.308\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.684 error=0.304\n",
      "Gen error rat_dros_yeast_mouse auc=0.675 error=0.307\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.688 error=0.305\n",
      "BE error rat_dros_yeast_mouse auc=0.689 error=0.307\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.635 error=0.237\n",
      "Strict error rat_dros_yeast_mouse auc=0.635 error=0.239\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.635 error=0.239\n",
      "Gen error rat_dros_yeast_mouse auc=0.640 error=0.234\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.642 error=0.232\n",
      "BE error rat_dros_yeast_mouse auc=0.636 error=0.234\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.586 error=0.307\n",
      "Strict error rat_dros_yeast_mouse auc=0.582 error=0.310\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.627 error=0.306\n",
      "Gen error rat_dros_yeast_mouse auc=0.623 error=0.307\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.619 error=0.303\n",
      "BE error rat_dros_yeast_mouse auc=0.615 error=0.305\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse auc=0.667 error=0.283\n",
      "Strict error rat_dros_yeast_mouse auc=0.665 error=0.284\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse auc=0.662 error=0.280\n",
      "Gen error rat_dros_yeast_mouse auc=0.664 error=0.282\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse auc=0.665 error=0.280\n",
      "BE error rat_dros_yeast_mouse auc=0.662 error=0.285\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_dros_yeast_mouse_strict = []\n",
    "mean_auc_rat_dros_yeast_mouse_strict = []\n",
    "mean_err_rat_dros_yeast_mouse_gen = []\n",
    "mean_auc_rat_dros_yeast_mouse_gen = []\n",
    "mean_err_rat_dros_yeast_mouse_be = []\n",
    "mean_auc_rat_dros_yeast_mouse_be = []\n",
    "for e, f, t in zip(errors_rat_dros_yeast_mouse, fpr_rat_dros_yeast_mouse, tpr_rat_dros_yeast_mouse):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat_dros_yeast_mouse']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_dros_yeast_mouse_strict.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_mouse_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_dros_yeast_mouse_gen.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_mouse_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_dros_yeast_mouse_be.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_mouse_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_dros_yeast_mouse_org_strict = mean_err_rat_dros_yeast_mouse_strict[0::2]\n",
    "mean_err_rat_dros_yeast_mouse_fs_strict = mean_err_rat_dros_yeast_mouse_strict[1::2]\n",
    "mean_auc_rat_dros_yeast_mouse_org_strict = mean_auc_rat_dros_yeast_mouse_strict[0::2]\n",
    "mean_auc_rat_dros_yeast_mouse_fs_strict = mean_auc_rat_dros_yeast_mouse_strict[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_mouse_org_gen = mean_err_rat_dros_yeast_mouse_gen[0::2]\n",
    "mean_err_rat_dros_yeast_mouse_fs_gen = mean_err_rat_dros_yeast_mouse_gen[1::2]\n",
    "mean_auc_rat_dros_yeast_mouse_org_gen = mean_auc_rat_dros_yeast_mouse_gen[0::2]\n",
    "mean_auc_rat_dros_yeast_mouse_fs_gen = mean_auc_rat_dros_yeast_mouse_gen[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_mouse_org_be = mean_err_rat_dros_yeast_mouse_be[0::2]\n",
    "mean_err_rat_dros_yeast_mouse_fs_be = mean_err_rat_dros_yeast_mouse_be[1::2]\n",
    "mean_auc_rat_dros_yeast_mouse_org_be = mean_auc_rat_dros_yeast_mouse_be[0::2]\n",
    "mean_auc_rat_dros_yeast_mouse_fs_be = mean_auc_rat_dros_yeast_mouse_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat_dros_yeast_mouse mean strict error original -  0.274549555319\n",
      "rat_dros_yeast_mouse mean strict error feature selection -  0.274262120801\n",
      "rat_dros_yeast_mouse mean strict AUC original -  0.642884624472\n",
      "rat_dros_yeast_mouse mean strict AUC feature selection -  0.641485067514\n",
      "\n",
      "\n",
      "rat_dros_yeast_mouse mean gen error original -  0.271497469092\n",
      "rat_dros_yeast_mouse mean gen error feature selection -  0.271950487905\n",
      "rat_dros_yeast_mouse mean gen AUC original -  0.649377573528\n",
      "rat_dros_yeast_mouse mean gen AUC feature selection -  0.647713223987\n",
      "\n",
      "\n",
      "rat_dros_yeast_mouse mean BE error original -  0.271910374784\n",
      "rat_dros_yeast_mouse mean BE error feature selection -  0.274350361409\n",
      "rat_dros_yeast_mouse mean BE AUC original -  0.650603006233\n",
      "rat_dros_yeast_mouse mean BE AUC feature selection -  0.646883940935\n"
     ]
    }
   ],
   "source": [
    "print('rat_dros_yeast_mouse mean strict error original - ', np.mean(mean_err_rat_dros_yeast_mouse_org_strict))\n",
    "print('rat_dros_yeast_mouse mean strict error feature selection - ', np.mean(mean_err_rat_dros_yeast_mouse_fs_strict))\n",
    "print('rat_dros_yeast_mouse mean strict AUC original - ', np.mean(mean_auc_rat_dros_yeast_mouse_org_strict))\n",
    "print('rat_dros_yeast_mouse mean strict AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_mouse_fs_strict))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast_mouse mean gen error original - ', np.mean(mean_err_rat_dros_yeast_mouse_org_gen))\n",
    "print('rat_dros_yeast_mouse mean gen error feature selection - ', np.mean(mean_err_rat_dros_yeast_mouse_fs_gen))\n",
    "print('rat_dros_yeast_mouse mean gen AUC original - ', np.mean(mean_auc_rat_dros_yeast_mouse_org_gen))\n",
    "print('rat_dros_yeast_mouse mean gen AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_mouse_fs_gen))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast_mouse mean BE error original - ', np.mean(mean_err_rat_dros_yeast_mouse_org_be))\n",
    "print('rat_dros_yeast_mouse mean BE error feature selection - ', np.mean(mean_err_rat_dros_yeast_mouse_fs_be))\n",
    "print('rat_dros_yeast_mouse mean BE AUC original - ', np.mean(mean_auc_rat_dros_yeast_mouse_org_be))\n",
    "print('rat_dros_yeast_mouse mean BE AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_mouse_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 15:55:27,638 : INFO : collecting all words and their counts\n",
      "2017-04-25 15:55:27,638 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-25 15:55:27,698 : INFO : PROGRESS: at sentence #10000, processed 279217 words, keeping 16391 word types\n",
      "2017-04-25 15:55:27,754 : INFO : PROGRESS: at sentence #20000, processed 558524 words, keeping 22824 word types\n",
      "2017-04-25 15:55:27,806 : INFO : PROGRESS: at sentence #30000, processed 838858 words, keeping 27488 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 15:55:27,858 : INFO : PROGRESS: at sentence #40000, processed 1117831 words, keeping 31144 word types\n",
      "2017-04-25 15:55:27,917 : INFO : PROGRESS: at sentence #50000, processed 1386056 words, keeping 36123 word types\n",
      "2017-04-25 15:55:27,931 : INFO : collected 37297 word types from a corpus of 1444949 raw words and 52315 sentences\n",
      "2017-04-25 15:55:27,933 : INFO : Loading a fresh vocabulary\n",
      "2017-04-25 15:55:28,059 : INFO : min_count=5 retains 11791 unique words (31% of original 37297, drops 25506)\n",
      "2017-04-25 15:55:28,060 : INFO : min_count=5 leaves 1403793 word corpus (97% of original 1444949, drops 41156)\n",
      "2017-04-25 15:55:28,086 : INFO : deleting the raw counts dictionary of 37297 items\n",
      "2017-04-25 15:55:28,089 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2017-04-25 15:55:28,089 : INFO : downsampling leaves estimated 1077195 word corpus (76.7% of prior 1403793)\n",
      "2017-04-25 15:55:28,090 : INFO : estimated required memory for 11791 words and 300 dimensions: 34193900 bytes\n",
      "2017-04-25 15:55:28,140 : INFO : resetting layer weights\n",
      "2017-04-25 15:55:28,278 : INFO : training model with 4 workers on 11791 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 15:55:28,278 : INFO : expecting 52315 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 15:55:29,289 : INFO : PROGRESS: at 12.98% examples, 706097 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:55:30,299 : INFO : PROGRESS: at 27.70% examples, 743304 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:31,300 : INFO : PROGRESS: at 38.74% examples, 694154 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:32,310 : INFO : PROGRESS: at 52.22% examples, 701203 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:33,313 : INFO : PROGRESS: at 64.34% examples, 689968 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:34,319 : INFO : PROGRESS: at 79.87% examples, 713090 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:35,344 : INFO : PROGRESS: at 95.73% examples, 732163 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:55:35,672 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 15:55:35,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 15:55:35,685 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 15:55:35,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 15:55:35,688 : INFO : training on 7224745 raw words (5386809 effective words) took 7.4s, 727603 effective words/s\n",
      "2017-04-25 15:55:35,689 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 15:55:35,746 : INFO : saving Word2Vec object under Results/rat_dros_SR_comb_model, separately None\n",
      "2017-04-25 15:55:35,747 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 15:55:35,748 : INFO : not storing attribute cum_table\n",
      "2017-04-25 15:55:36,002 : INFO : saved Results/rat_dros_SR_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 15:55:40,808 : INFO : collecting all words and their counts\n",
      "2017-04-25 15:55:40,809 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-25 15:55:40,864 : INFO : PROGRESS: at sentence #10000, processed 270834 words, keeping 15327 word types\n",
      "2017-04-25 15:55:40,921 : INFO : PROGRESS: at sentence #20000, processed 541358 words, keeping 21158 word types\n",
      "2017-04-25 15:55:40,981 : INFO : PROGRESS: at sentence #30000, processed 811820 words, keeping 25426 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 15:55:41,043 : INFO : PROGRESS: at sentence #40000, processed 1080966 words, keeping 28804 word types\n",
      "2017-04-25 15:55:41,109 : INFO : PROGRESS: at sentence #50000, processed 1349889 words, keeping 31699 word types\n",
      "2017-04-25 15:55:41,167 : INFO : PROGRESS: at sentence #60000, processed 1621470 words, keeping 34211 word types\n",
      "2017-04-25 15:55:41,227 : INFO : PROGRESS: at sentence #70000, processed 1889101 words, keeping 36473 word types\n",
      "2017-04-25 15:55:41,288 : INFO : PROGRESS: at sentence #80000, processed 2159741 words, keeping 38643 word types\n",
      "2017-04-25 15:55:41,349 : INFO : PROGRESS: at sentence #90000, processed 2431797 words, keeping 40561 word types\n",
      "2017-04-25 15:55:41,424 : INFO : PROGRESS: at sentence #100000, processed 2701873 words, keeping 42384 word types\n",
      "2017-04-25 15:55:41,515 : INFO : PROGRESS: at sentence #110000, processed 2973268 words, keeping 44140 word types\n",
      "2017-04-25 15:55:41,586 : INFO : PROGRESS: at sentence #120000, processed 3241964 words, keeping 45768 word types\n",
      "2017-04-25 15:55:41,669 : INFO : PROGRESS: at sentence #130000, processed 3510265 words, keeping 47368 word types\n",
      "2017-04-25 15:55:41,727 : INFO : PROGRESS: at sentence #140000, processed 3780923 words, keeping 48806 word types\n",
      "2017-04-25 15:55:41,784 : INFO : PROGRESS: at sentence #150000, processed 4050132 words, keeping 50212 word types\n",
      "2017-04-25 15:55:41,847 : INFO : PROGRESS: at sentence #160000, processed 4319485 words, keeping 51534 word types\n",
      "2017-04-25 15:55:41,919 : INFO : PROGRESS: at sentence #170000, processed 4589419 words, keeping 52857 word types\n",
      "2017-04-25 15:55:41,983 : INFO : PROGRESS: at sentence #180000, processed 4857325 words, keeping 54448 word types\n",
      "2017-04-25 15:55:42,049 : INFO : PROGRESS: at sentence #190000, processed 5099965 words, keeping 57643 word types\n",
      "2017-04-25 15:55:42,098 : INFO : PROGRESS: at sentence #200000, processed 5343441 words, keeping 59766 word types\n",
      "2017-04-25 15:55:42,147 : INFO : PROGRESS: at sentence #210000, processed 5588301 words, keeping 61407 word types\n",
      "2017-04-25 15:55:42,186 : INFO : collected 62334 word types from a corpus of 5740004 raw words and 216236 sentences\n",
      "2017-04-25 15:55:42,186 : INFO : Loading a fresh vocabulary\n",
      "2017-04-25 15:55:42,269 : INFO : min_count=5 retains 22295 unique words (35% of original 62334, drops 40039)\n",
      "2017-04-25 15:55:42,270 : INFO : min_count=5 leaves 5674098 word corpus (98% of original 5740004, drops 65906)\n",
      "2017-04-25 15:55:42,326 : INFO : deleting the raw counts dictionary of 62334 items\n",
      "2017-04-25 15:55:42,331 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2017-04-25 15:55:42,331 : INFO : downsampling leaves estimated 4338033 word corpus (76.5% of prior 5674098)\n",
      "2017-04-25 15:55:42,332 : INFO : estimated required memory for 22295 words and 300 dimensions: 64655500 bytes\n",
      "2017-04-25 15:55:42,435 : INFO : resetting layer weights\n",
      "2017-04-25 15:55:42,682 : INFO : training model with 4 workers on 22295 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 15:55:42,683 : INFO : expecting 216236 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 15:55:43,726 : INFO : PROGRESS: at 3.04% examples, 647055 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:44,729 : INFO : PROGRESS: at 5.88% examples, 635983 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:45,735 : INFO : PROGRESS: at 8.20% examples, 594762 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:46,746 : INFO : PROGRESS: at 10.83% examples, 589814 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:47,755 : INFO : PROGRESS: at 13.47% examples, 587187 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:55:48,761 : INFO : PROGRESS: at 16.52% examples, 600425 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-25 15:55:49,776 : INFO : PROGRESS: at 19.97% examples, 610942 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:55:50,794 : INFO : PROGRESS: at 22.60% examples, 605911 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:51,806 : INFO : PROGRESS: at 25.81% examples, 616568 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:52,812 : INFO : PROGRESS: at 28.89% examples, 622432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:53,819 : INFO : PROGRESS: at 32.52% examples, 638109 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:54,829 : INFO : PROGRESS: at 35.84% examples, 645279 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:55,846 : INFO : PROGRESS: at 38.38% examples, 634876 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:56,847 : INFO : PROGRESS: at 41.30% examples, 633098 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:57,858 : INFO : PROGRESS: at 44.49% examples, 637196 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:58,885 : INFO : PROGRESS: at 47.12% examples, 632650 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:55:59,904 : INFO : PROGRESS: at 50.29% examples, 635995 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:00,907 : INFO : PROGRESS: at 53.17% examples, 635812 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:01,911 : INFO : PROGRESS: at 56.71% examples, 643056 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:56:02,918 : INFO : PROGRESS: at 60.93% examples, 653491 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:03,919 : INFO : PROGRESS: at 64.63% examples, 661124 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:04,925 : INFO : PROGRESS: at 68.35% examples, 668238 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:05,927 : INFO : PROGRESS: at 72.46% examples, 678413 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:06,950 : INFO : PROGRESS: at 76.20% examples, 683732 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:07,978 : INFO : PROGRESS: at 79.26% examples, 680346 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:56:08,989 : INFO : PROGRESS: at 82.06% examples, 677111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:09,993 : INFO : PROGRESS: at 85.04% examples, 676272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:11,006 : INFO : PROGRESS: at 88.22% examples, 676906 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:56:12,008 : INFO : PROGRESS: at 91.64% examples, 679537 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:13,017 : INFO : PROGRESS: at 95.41% examples, 684336 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:14,028 : INFO : PROGRESS: at 99.68% examples, 690103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:14,071 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 15:56:14,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 15:56:14,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 15:56:14,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 15:56:14,099 : INFO : training on 28700020 raw words (21691896 effective words) took 31.4s, 690571 effective words/s\n",
      "2017-04-25 15:56:14,100 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 15:56:14,234 : INFO : saving Word2Vec object under Results/rat_dros_GEN_comb_model, separately None\n",
      "2017-04-25 15:56:14,234 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 15:56:14,235 : INFO : not storing attribute cum_table\n",
      "2017-04-25 15:56:14,734 : INFO : saved Results/rat_dros_GEN_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 15:56:40,390 : INFO : collecting all words and their counts\n",
      "2017-04-25 15:56:40,391 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-25 15:56:40,438 : INFO : PROGRESS: at sentence #10000, processed 246604 words, keeping 15734 word types\n",
      "2017-04-25 15:56:40,486 : INFO : PROGRESS: at sentence #20000, processed 494902 words, keeping 21792 word types\n",
      "2017-04-25 15:56:40,531 : INFO : PROGRESS: at sentence #30000, processed 741567 words, keeping 26147 word types\n",
      "2017-04-25 15:56:40,578 : INFO : PROGRESS: at sentence #40000, processed 990109 words, keeping 29769 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 15:56:40,625 : INFO : PROGRESS: at sentence #50000, processed 1237508 words, keeping 32782 word types\n",
      "2017-04-25 15:56:40,677 : INFO : PROGRESS: at sentence #60000, processed 1485701 words, keeping 35587 word types\n",
      "2017-04-25 15:56:40,720 : INFO : PROGRESS: at sentence #70000, processed 1734289 words, keeping 38100 word types\n",
      "2017-04-25 15:56:40,769 : INFO : PROGRESS: at sentence #80000, processed 1981482 words, keeping 40470 word types\n",
      "2017-04-25 15:56:40,816 : INFO : PROGRESS: at sentence #90000, processed 2229900 words, keeping 42730 word types\n",
      "2017-04-25 15:56:40,865 : INFO : PROGRESS: at sentence #100000, processed 2476782 words, keeping 44750 word types\n",
      "2017-04-25 15:56:40,911 : INFO : PROGRESS: at sentence #110000, processed 2722762 words, keeping 46642 word types\n",
      "2017-04-25 15:56:40,959 : INFO : PROGRESS: at sentence #120000, processed 2970565 words, keeping 48480 word types\n",
      "2017-04-25 15:56:41,006 : INFO : PROGRESS: at sentence #130000, processed 3218523 words, keeping 50194 word types\n",
      "2017-04-25 15:56:41,054 : INFO : PROGRESS: at sentence #140000, processed 3464712 words, keeping 51798 word types\n",
      "2017-04-25 15:56:41,100 : INFO : PROGRESS: at sentence #150000, processed 3711850 words, keeping 53394 word types\n",
      "2017-04-25 15:56:41,148 : INFO : PROGRESS: at sentence #160000, processed 3958206 words, keeping 54893 word types\n",
      "2017-04-25 15:56:41,196 : INFO : PROGRESS: at sentence #170000, processed 4205866 words, keeping 56340 word types\n",
      "2017-04-25 15:56:41,244 : INFO : PROGRESS: at sentence #180000, processed 4453291 words, keeping 57752 word types\n",
      "2017-04-25 15:56:41,292 : INFO : PROGRESS: at sentence #190000, processed 4700835 words, keeping 59143 word types\n",
      "2017-04-25 15:56:41,340 : INFO : PROGRESS: at sentence #200000, processed 4946034 words, keeping 60502 word types\n",
      "2017-04-25 15:56:41,390 : INFO : PROGRESS: at sentence #210000, processed 5192260 words, keeping 61781 word types\n",
      "2017-04-25 15:56:41,438 : INFO : PROGRESS: at sentence #220000, processed 5441291 words, keeping 63028 word types\n",
      "2017-04-25 15:56:41,487 : INFO : PROGRESS: at sentence #230000, processed 5690180 words, keeping 64263 word types\n",
      "2017-04-25 15:56:41,535 : INFO : PROGRESS: at sentence #240000, processed 5937318 words, keeping 65457 word types\n",
      "2017-04-25 15:56:41,583 : INFO : PROGRESS: at sentence #250000, processed 6185868 words, keeping 66593 word types\n",
      "2017-04-25 15:56:41,631 : INFO : PROGRESS: at sentence #260000, processed 6432307 words, keeping 67732 word types\n",
      "2017-04-25 15:56:41,679 : INFO : PROGRESS: at sentence #270000, processed 6679434 words, keeping 68808 word types\n",
      "2017-04-25 15:56:41,727 : INFO : PROGRESS: at sentence #280000, processed 6925044 words, keeping 69792 word types\n",
      "2017-04-25 15:56:41,776 : INFO : PROGRESS: at sentence #290000, processed 7173860 words, keeping 70902 word types\n",
      "2017-04-25 15:56:41,824 : INFO : PROGRESS: at sentence #300000, processed 7421296 words, keeping 71966 word types\n",
      "2017-04-25 15:56:41,872 : INFO : PROGRESS: at sentence #310000, processed 7669440 words, keeping 72958 word types\n",
      "2017-04-25 15:56:41,920 : INFO : PROGRESS: at sentence #320000, processed 7915929 words, keeping 73920 word types\n",
      "2017-04-25 15:56:41,968 : INFO : PROGRESS: at sentence #330000, processed 8163019 words, keeping 74882 word types\n",
      "2017-04-25 15:56:42,016 : INFO : PROGRESS: at sentence #340000, processed 8411814 words, keeping 75831 word types\n",
      "2017-04-25 15:56:42,065 : INFO : PROGRESS: at sentence #350000, processed 8660691 words, keeping 76803 word types\n",
      "2017-04-25 15:56:42,112 : INFO : PROGRESS: at sentence #360000, processed 8907402 words, keeping 77741 word types\n",
      "2017-04-25 15:56:42,161 : INFO : PROGRESS: at sentence #370000, processed 9154863 words, keeping 78611 word types\n",
      "2017-04-25 15:56:42,210 : INFO : PROGRESS: at sentence #380000, processed 9403227 words, keeping 79542 word types\n",
      "2017-04-25 15:56:42,258 : INFO : PROGRESS: at sentence #390000, processed 9650985 words, keeping 80371 word types\n",
      "2017-04-25 15:56:42,312 : INFO : PROGRESS: at sentence #400000, processed 9898741 words, keeping 81259 word types\n",
      "2017-04-25 15:56:42,363 : INFO : PROGRESS: at sentence #410000, processed 10147408 words, keeping 82113 word types\n",
      "2017-04-25 15:56:42,411 : INFO : PROGRESS: at sentence #420000, processed 10395496 words, keeping 82954 word types\n",
      "2017-04-25 15:56:42,459 : INFO : PROGRESS: at sentence #430000, processed 10643001 words, keeping 83756 word types\n",
      "2017-04-25 15:56:42,508 : INFO : PROGRESS: at sentence #440000, processed 10890656 words, keeping 84644 word types\n",
      "2017-04-25 15:56:42,556 : INFO : PROGRESS: at sentence #450000, processed 11140028 words, keeping 85459 word types\n",
      "2017-04-25 15:56:42,605 : INFO : PROGRESS: at sentence #460000, processed 11386747 words, keeping 86254 word types\n",
      "2017-04-25 15:56:42,653 : INFO : PROGRESS: at sentence #470000, processed 11634007 words, keeping 87000 word types\n",
      "2017-04-25 15:56:42,706 : INFO : PROGRESS: at sentence #480000, processed 11879592 words, keeping 87728 word types\n",
      "2017-04-25 15:56:42,762 : INFO : PROGRESS: at sentence #490000, processed 12127580 words, keeping 88493 word types\n",
      "2017-04-25 15:56:42,813 : INFO : PROGRESS: at sentence #500000, processed 12375340 words, keeping 89313 word types\n",
      "2017-04-25 15:56:42,863 : INFO : PROGRESS: at sentence #510000, processed 12621994 words, keeping 90072 word types\n",
      "2017-04-25 15:56:42,918 : INFO : PROGRESS: at sentence #520000, processed 12869708 words, keeping 90879 word types\n",
      "2017-04-25 15:56:42,989 : INFO : PROGRESS: at sentence #530000, processed 13116669 words, keeping 91649 word types\n",
      "2017-04-25 15:56:43,035 : INFO : PROGRESS: at sentence #540000, processed 13364444 words, keeping 92415 word types\n",
      "2017-04-25 15:56:43,084 : INFO : PROGRESS: at sentence #550000, processed 13611625 words, keeping 93182 word types\n",
      "2017-04-25 15:56:43,132 : INFO : PROGRESS: at sentence #560000, processed 13858410 words, keeping 93865 word types\n",
      "2017-04-25 15:56:43,182 : INFO : PROGRESS: at sentence #570000, processed 14105793 words, keeping 94549 word types\n",
      "2017-04-25 15:56:43,246 : INFO : PROGRESS: at sentence #580000, processed 14352326 words, keeping 95254 word types\n",
      "2017-04-25 15:56:43,302 : INFO : PROGRESS: at sentence #590000, processed 14599515 words, keeping 95909 word types\n",
      "2017-04-25 15:56:43,360 : INFO : PROGRESS: at sentence #600000, processed 14847734 words, keeping 96598 word types\n",
      "2017-04-25 15:56:43,416 : INFO : PROGRESS: at sentence #610000, processed 15094719 words, keeping 97256 word types\n",
      "2017-04-25 15:56:43,465 : INFO : PROGRESS: at sentence #620000, processed 15342195 words, keeping 97914 word types\n",
      "2017-04-25 15:56:43,518 : INFO : PROGRESS: at sentence #630000, processed 15589032 words, keeping 98569 word types\n",
      "2017-04-25 15:56:43,569 : INFO : PROGRESS: at sentence #640000, processed 15839024 words, keeping 99248 word types\n",
      "2017-04-25 15:56:43,619 : INFO : PROGRESS: at sentence #650000, processed 16087720 words, keeping 99929 word types\n",
      "2017-04-25 15:56:43,669 : INFO : PROGRESS: at sentence #660000, processed 16335611 words, keeping 100550 word types\n",
      "2017-04-25 15:56:43,720 : INFO : PROGRESS: at sentence #670000, processed 16583784 words, keeping 101216 word types\n",
      "2017-04-25 15:56:43,777 : INFO : PROGRESS: at sentence #680000, processed 16831479 words, keeping 101833 word types\n",
      "2017-04-25 15:56:43,829 : INFO : PROGRESS: at sentence #690000, processed 17078830 words, keeping 102470 word types\n",
      "2017-04-25 15:56:43,891 : INFO : PROGRESS: at sentence #700000, processed 17326139 words, keeping 103083 word types\n",
      "2017-04-25 15:56:43,944 : INFO : PROGRESS: at sentence #710000, processed 17573522 words, keeping 103717 word types\n",
      "2017-04-25 15:56:43,994 : INFO : PROGRESS: at sentence #720000, processed 17822215 words, keeping 104345 word types\n",
      "2017-04-25 15:56:44,045 : INFO : PROGRESS: at sentence #730000, processed 18071441 words, keeping 104962 word types\n",
      "2017-04-25 15:56:44,095 : INFO : PROGRESS: at sentence #740000, processed 18318759 words, keeping 105563 word types\n",
      "2017-04-25 15:56:44,144 : INFO : PROGRESS: at sentence #750000, processed 18565418 words, keeping 106114 word types\n",
      "2017-04-25 15:56:44,194 : INFO : PROGRESS: at sentence #760000, processed 18812129 words, keeping 106751 word types\n",
      "2017-04-25 15:56:44,244 : INFO : PROGRESS: at sentence #770000, processed 19059722 words, keeping 107282 word types\n",
      "2017-04-25 15:56:44,294 : INFO : PROGRESS: at sentence #780000, processed 19306534 words, keeping 107834 word types\n",
      "2017-04-25 15:56:44,344 : INFO : PROGRESS: at sentence #790000, processed 19553923 words, keeping 108385 word types\n",
      "2017-04-25 15:56:44,394 : INFO : PROGRESS: at sentence #800000, processed 19799693 words, keeping 108930 word types\n",
      "2017-04-25 15:56:44,445 : INFO : PROGRESS: at sentence #810000, processed 20047848 words, keeping 109488 word types\n",
      "2017-04-25 15:56:44,508 : INFO : PROGRESS: at sentence #820000, processed 20294437 words, keeping 110035 word types\n",
      "2017-04-25 15:56:44,556 : INFO : PROGRESS: at sentence #830000, processed 20543369 words, keeping 110610 word types\n",
      "2017-04-25 15:56:44,606 : INFO : PROGRESS: at sentence #840000, processed 20790700 words, keeping 111079 word types\n",
      "2017-04-25 15:56:44,656 : INFO : PROGRESS: at sentence #850000, processed 21036705 words, keeping 111639 word types\n",
      "2017-04-25 15:56:44,706 : INFO : PROGRESS: at sentence #860000, processed 21285326 words, keeping 112210 word types\n",
      "2017-04-25 15:56:44,757 : INFO : PROGRESS: at sentence #870000, processed 21534248 words, keeping 112784 word types\n",
      "2017-04-25 15:56:44,808 : INFO : PROGRESS: at sentence #880000, processed 21782967 words, keeping 113299 word types\n",
      "2017-04-25 15:56:44,858 : INFO : PROGRESS: at sentence #890000, processed 22028120 words, keeping 113834 word types\n",
      "2017-04-25 15:56:44,908 : INFO : PROGRESS: at sentence #900000, processed 22274444 words, keeping 114293 word types\n",
      "2017-04-25 15:56:44,959 : INFO : PROGRESS: at sentence #910000, processed 22521376 words, keeping 114856 word types\n",
      "2017-04-25 15:56:45,009 : INFO : PROGRESS: at sentence #920000, processed 22768368 words, keeping 115363 word types\n",
      "2017-04-25 15:56:45,060 : INFO : PROGRESS: at sentence #930000, processed 23014887 words, keeping 115839 word types\n",
      "2017-04-25 15:56:45,111 : INFO : PROGRESS: at sentence #940000, processed 23261946 words, keeping 116350 word types\n",
      "2017-04-25 15:56:45,161 : INFO : PROGRESS: at sentence #950000, processed 23509129 words, keeping 116857 word types\n",
      "2017-04-25 15:56:45,212 : INFO : PROGRESS: at sentence #960000, processed 23756322 words, keeping 117388 word types\n",
      "2017-04-25 15:56:45,271 : INFO : PROGRESS: at sentence #970000, processed 24002486 words, keeping 117917 word types\n",
      "2017-04-25 15:56:45,324 : INFO : PROGRESS: at sentence #980000, processed 24248756 words, keeping 118364 word types\n",
      "2017-04-25 15:56:45,380 : INFO : PROGRESS: at sentence #990000, processed 24495681 words, keeping 118854 word types\n",
      "2017-04-25 15:56:45,441 : INFO : PROGRESS: at sentence #1000000, processed 24742097 words, keeping 119365 word types\n",
      "2017-04-25 15:56:45,498 : INFO : PROGRESS: at sentence #1010000, processed 24988707 words, keeping 119856 word types\n",
      "2017-04-25 15:56:45,551 : INFO : PROGRESS: at sentence #1020000, processed 25235983 words, keeping 120347 word types\n",
      "2017-04-25 15:56:45,604 : INFO : PROGRESS: at sentence #1030000, processed 25484165 words, keeping 120834 word types\n",
      "2017-04-25 15:56:45,656 : INFO : PROGRESS: at sentence #1040000, processed 25731728 words, keeping 121329 word types\n",
      "2017-04-25 15:56:45,709 : INFO : PROGRESS: at sentence #1050000, processed 25979508 words, keeping 121792 word types\n",
      "2017-04-25 15:56:45,763 : INFO : PROGRESS: at sentence #1060000, processed 26228131 words, keeping 122227 word types\n",
      "2017-04-25 15:56:45,816 : INFO : PROGRESS: at sentence #1070000, processed 26474915 words, keeping 122696 word types\n",
      "2017-04-25 15:56:45,868 : INFO : PROGRESS: at sentence #1080000, processed 26722325 words, keeping 123142 word types\n",
      "2017-04-25 15:56:45,919 : INFO : PROGRESS: at sentence #1090000, processed 26971155 words, keeping 123613 word types\n",
      "2017-04-25 15:56:45,971 : INFO : PROGRESS: at sentence #1100000, processed 27217421 words, keeping 124044 word types\n",
      "2017-04-25 15:56:46,022 : INFO : PROGRESS: at sentence #1110000, processed 27464374 words, keeping 124461 word types\n",
      "2017-04-25 15:56:46,073 : INFO : PROGRESS: at sentence #1120000, processed 27711953 words, keeping 124880 word types\n",
      "2017-04-25 15:56:46,124 : INFO : PROGRESS: at sentence #1130000, processed 27960346 words, keeping 125323 word types\n",
      "2017-04-25 15:56:46,175 : INFO : PROGRESS: at sentence #1140000, processed 28206256 words, keeping 125756 word types\n",
      "2017-04-25 15:56:46,225 : INFO : PROGRESS: at sentence #1150000, processed 28453479 words, keeping 126230 word types\n",
      "2017-04-25 15:56:46,277 : INFO : PROGRESS: at sentence #1160000, processed 28701108 words, keeping 126698 word types\n",
      "2017-04-25 15:56:46,331 : INFO : PROGRESS: at sentence #1170000, processed 28948961 words, keeping 127168 word types\n",
      "2017-04-25 15:56:46,383 : INFO : PROGRESS: at sentence #1180000, processed 29196339 words, keeping 127601 word types\n",
      "2017-04-25 15:56:46,436 : INFO : PROGRESS: at sentence #1190000, processed 29445165 words, keeping 128053 word types\n",
      "2017-04-25 15:56:46,487 : INFO : PROGRESS: at sentence #1200000, processed 29693082 words, keeping 128430 word types\n",
      "2017-04-25 15:56:46,538 : INFO : PROGRESS: at sentence #1210000, processed 29939342 words, keeping 128846 word types\n",
      "2017-04-25 15:56:46,589 : INFO : PROGRESS: at sentence #1220000, processed 30185302 words, keeping 129245 word types\n",
      "2017-04-25 15:56:46,640 : INFO : PROGRESS: at sentence #1230000, processed 30431428 words, keeping 129686 word types\n",
      "2017-04-25 15:56:46,690 : INFO : PROGRESS: at sentence #1240000, processed 30679491 words, keeping 130100 word types\n",
      "2017-04-25 15:56:46,740 : INFO : PROGRESS: at sentence #1250000, processed 30926639 words, keeping 130555 word types\n",
      "2017-04-25 15:56:46,792 : INFO : PROGRESS: at sentence #1260000, processed 31155573 words, keeping 132841 word types\n",
      "2017-04-25 15:56:46,842 : INFO : PROGRESS: at sentence #1270000, processed 31384931 words, keeping 134522 word types\n",
      "2017-04-25 15:56:46,892 : INFO : PROGRESS: at sentence #1280000, processed 31616395 words, keeping 135874 word types\n",
      "2017-04-25 15:56:46,942 : INFO : PROGRESS: at sentence #1290000, processed 31847905 words, keeping 137137 word types\n",
      "2017-04-25 15:56:46,991 : INFO : PROGRESS: at sentence #1300000, processed 32078178 words, keeping 138249 word types\n",
      "2017-04-25 15:56:47,040 : INFO : PROGRESS: at sentence #1310000, processed 32309871 words, keeping 139278 word types\n",
      "2017-04-25 15:56:47,089 : INFO : PROGRESS: at sentence #1320000, processed 32539250 words, keeping 140258 word types\n",
      "2017-04-25 15:56:47,138 : INFO : PROGRESS: at sentence #1330000, processed 32769481 words, keeping 141274 word types\n",
      "2017-04-25 15:56:47,187 : INFO : PROGRESS: at sentence #1340000, processed 32999430 words, keeping 142167 word types\n",
      "2017-04-25 15:56:47,238 : INFO : PROGRESS: at sentence #1350000, processed 33231592 words, keeping 143003 word types\n",
      "2017-04-25 15:56:47,289 : INFO : PROGRESS: at sentence #1360000, processed 33462101 words, keeping 143871 word types\n",
      "2017-04-25 15:56:47,338 : INFO : PROGRESS: at sentence #1370000, processed 33691795 words, keeping 144608 word types\n",
      "2017-04-25 15:56:47,388 : INFO : PROGRESS: at sentence #1380000, processed 33922952 words, keeping 145326 word types\n",
      "2017-04-25 15:56:47,437 : INFO : PROGRESS: at sentence #1390000, processed 34154031 words, keeping 146051 word types\n",
      "2017-04-25 15:56:47,492 : INFO : PROGRESS: at sentence #1400000, processed 34383653 words, keeping 146801 word types\n",
      "2017-04-25 15:56:47,542 : INFO : PROGRESS: at sentence #1410000, processed 34616058 words, keeping 147507 word types\n",
      "2017-04-25 15:56:47,598 : INFO : PROGRESS: at sentence #1420000, processed 34846469 words, keeping 148174 word types\n",
      "2017-04-25 15:56:47,646 : INFO : collected 148778 word types from a corpus of 35068682 raw words and 1429582 sentences\n",
      "2017-04-25 15:56:47,647 : INFO : Loading a fresh vocabulary\n",
      "2017-04-25 15:56:47,802 : INFO : min_count=5 retains 53091 unique words (35% of original 148778, drops 95687)\n",
      "2017-04-25 15:56:47,803 : INFO : min_count=5 leaves 34911287 word corpus (99% of original 35068682, drops 157395)\n",
      "2017-04-25 15:56:47,922 : INFO : deleting the raw counts dictionary of 148778 items\n",
      "2017-04-25 15:56:47,931 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2017-04-25 15:56:47,932 : INFO : downsampling leaves estimated 27009416 word corpus (77.4% of prior 34911287)\n",
      "2017-04-25 15:56:47,933 : INFO : estimated required memory for 53091 words and 300 dimensions: 153963900 bytes\n",
      "2017-04-25 15:56:48,123 : INFO : resetting layer weights\n",
      "2017-04-25 15:56:48,710 : INFO : training model with 4 workers on 53091 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 15:56:48,711 : INFO : expecting 1429582 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 15:56:49,731 : INFO : PROGRESS: at 0.53% examples, 704524 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:56:50,732 : INFO : PROGRESS: at 1.14% examples, 774726 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:51,735 : INFO : PROGRESS: at 1.76% examples, 795255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:52,743 : INFO : PROGRESS: at 2.39% examples, 808009 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:53,749 : INFO : PROGRESS: at 3.02% examples, 817651 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:54,754 : INFO : PROGRESS: at 3.59% examples, 808997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:55,760 : INFO : PROGRESS: at 4.07% examples, 787381 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:56,779 : INFO : PROGRESS: at 4.53% examples, 765063 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:56:57,797 : INFO : PROGRESS: at 4.93% examples, 740329 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:56:58,814 : INFO : PROGRESS: at 5.36% examples, 723604 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:56:59,820 : INFO : PROGRESS: at 5.93% examples, 728063 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:00,822 : INFO : PROGRESS: at 6.51% examples, 733261 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:01,825 : INFO : PROGRESS: at 7.09% examples, 736994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:02,830 : INFO : PROGRESS: at 7.67% examples, 740128 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:03,831 : INFO : PROGRESS: at 8.29% examples, 747580 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:04,846 : INFO : PROGRESS: at 8.86% examples, 748248 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:05,854 : INFO : PROGRESS: at 9.46% examples, 752229 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:06,862 : INFO : PROGRESS: at 10.02% examples, 752406 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:07,880 : INFO : PROGRESS: at 10.45% examples, 742935 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:08,890 : INFO : PROGRESS: at 10.82% examples, 730910 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 15:57:09,894 : INFO : PROGRESS: at 11.22% examples, 722048 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:10,896 : INFO : PROGRESS: at 11.63% examples, 714432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:11,919 : INFO : PROGRESS: at 12.11% examples, 711150 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:57:12,930 : INFO : PROGRESS: at 12.68% examples, 713533 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-25 15:57:13,946 : INFO : PROGRESS: at 13.24% examples, 714995 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:14,958 : INFO : PROGRESS: at 13.85% examples, 719122 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:15,960 : INFO : PROGRESS: at 14.32% examples, 716409 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:16,965 : INFO : PROGRESS: at 14.81% examples, 714610 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:17,968 : INFO : PROGRESS: at 15.25% examples, 710620 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:18,974 : INFO : PROGRESS: at 15.76% examples, 709909 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:19,981 : INFO : PROGRESS: at 16.28% examples, 709443 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:20,983 : INFO : PROGRESS: at 16.67% examples, 703844 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 15:57:21,990 : INFO : PROGRESS: at 17.09% examples, 699873 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:23,009 : INFO : PROGRESS: at 17.52% examples, 696126 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:24,025 : INFO : PROGRESS: at 18.11% examples, 696938 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:25,044 : INFO : PROGRESS: at 18.67% examples, 697026 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:26,051 : INFO : PROGRESS: at 19.06% examples, 691563 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:57:27,064 : INFO : PROGRESS: at 19.46% examples, 686513 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:28,070 : INFO : PROGRESS: at 19.86% examples, 681634 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:29,089 : INFO : PROGRESS: at 20.22% examples, 676403 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 15:57:30,104 : INFO : PROGRESS: at 20.64% examples, 673563 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:31,106 : INFO : PROGRESS: at 21.07% examples, 671439 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:32,116 : INFO : PROGRESS: at 21.48% examples, 668954 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:33,123 : INFO : PROGRESS: at 22.00% examples, 669554 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:34,133 : INFO : PROGRESS: at 22.52% examples, 670230 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:35,146 : INFO : PROGRESS: at 23.02% examples, 670357 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:36,161 : INFO : PROGRESS: at 23.58% examples, 672077 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:37,162 : INFO : PROGRESS: at 24.11% examples, 672955 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:38,164 : INFO : PROGRESS: at 24.66% examples, 674725 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:39,164 : INFO : PROGRESS: at 25.23% examples, 676744 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:57:40,166 : INFO : PROGRESS: at 25.77% examples, 677929 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:41,172 : INFO : PROGRESS: at 26.34% examples, 679741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:42,175 : INFO : PROGRESS: at 26.92% examples, 681520 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:43,177 : INFO : PROGRESS: at 27.49% examples, 683250 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:44,187 : INFO : PROGRESS: at 27.90% examples, 680929 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:57:45,197 : INFO : PROGRESS: at 28.33% examples, 679116 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:46,219 : INFO : PROGRESS: at 28.71% examples, 676136 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:57:47,226 : INFO : PROGRESS: at 29.19% examples, 675669 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:48,233 : INFO : PROGRESS: at 29.80% examples, 678211 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:49,234 : INFO : PROGRESS: at 30.36% examples, 679572 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:50,271 : INFO : PROGRESS: at 30.87% examples, 679491 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:51,273 : INFO : PROGRESS: at 31.36% examples, 679321 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:52,280 : INFO : PROGRESS: at 31.95% examples, 681147 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:53,297 : INFO : PROGRESS: at 32.50% examples, 682095 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:54,304 : INFO : PROGRESS: at 33.06% examples, 683233 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:55,316 : INFO : PROGRESS: at 33.60% examples, 683710 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:56,329 : INFO : PROGRESS: at 33.94% examples, 680414 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:57:57,350 : INFO : PROGRESS: at 34.36% examples, 678710 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:57:58,363 : INFO : PROGRESS: at 34.79% examples, 677230 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:57:59,367 : INFO : PROGRESS: at 35.21% examples, 675661 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:00,368 : INFO : PROGRESS: at 35.73% examples, 676009 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:01,376 : INFO : PROGRESS: at 36.30% examples, 677326 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:02,378 : INFO : PROGRESS: at 36.88% examples, 678870 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:03,384 : INFO : PROGRESS: at 37.45% examples, 680126 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:04,399 : INFO : PROGRESS: at 38.11% examples, 682059 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:05,403 : INFO : PROGRESS: at 38.71% examples, 683028 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:06,408 : INFO : PROGRESS: at 39.37% examples, 685065 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:07,408 : INFO : PROGRESS: at 40.00% examples, 686391 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:08,418 : INFO : PROGRESS: at 40.46% examples, 685696 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:58:09,430 : INFO : PROGRESS: at 40.89% examples, 684261 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:10,451 : INFO : PROGRESS: at 41.30% examples, 682686 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:11,456 : INFO : PROGRESS: at 41.79% examples, 682389 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:12,459 : INFO : PROGRESS: at 42.35% examples, 683307 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:13,466 : INFO : PROGRESS: at 42.92% examples, 684365 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:14,473 : INFO : PROGRESS: at 43.51% examples, 685740 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:15,479 : INFO : PROGRESS: at 44.06% examples, 686305 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:16,487 : INFO : PROGRESS: at 44.62% examples, 687102 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:17,495 : INFO : PROGRESS: at 45.23% examples, 688746 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:18,504 : INFO : PROGRESS: at 45.84% examples, 690266 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:19,511 : INFO : PROGRESS: at 46.43% examples, 691583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:20,515 : INFO : PROGRESS: at 46.97% examples, 691990 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:21,533 : INFO : PROGRESS: at 47.51% examples, 692269 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:22,535 : INFO : PROGRESS: at 48.03% examples, 692417 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:23,541 : INFO : PROGRESS: at 48.50% examples, 691893 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:58:24,546 : INFO : PROGRESS: at 48.86% examples, 689691 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:58:25,560 : INFO : PROGRESS: at 49.20% examples, 687234 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 15:58:26,601 : INFO : PROGRESS: at 49.56% examples, 685031 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:58:27,605 : INFO : PROGRESS: at 49.99% examples, 683994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:28,614 : INFO : PROGRESS: at 50.55% examples, 684781 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:29,615 : INFO : PROGRESS: at 51.09% examples, 685151 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:30,627 : INFO : PROGRESS: at 51.66% examples, 686048 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 15:58:31,628 : INFO : PROGRESS: at 52.17% examples, 686179 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:32,637 : INFO : PROGRESS: at 52.74% examples, 686916 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:58:33,646 : INFO : PROGRESS: at 53.36% examples, 688314 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:34,653 : INFO : PROGRESS: at 53.97% examples, 689613 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:35,677 : INFO : PROGRESS: at 54.49% examples, 689634 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:36,685 : INFO : PROGRESS: at 54.87% examples, 687969 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:37,689 : INFO : PROGRESS: at 55.24% examples, 686289 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:38,702 : INFO : PROGRESS: at 55.62% examples, 684664 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:39,706 : INFO : PROGRESS: at 56.10% examples, 684369 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:40,711 : INFO : PROGRESS: at 56.59% examples, 684265 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:41,720 : INFO : PROGRESS: at 57.17% examples, 685107 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:42,745 : INFO : PROGRESS: at 57.58% examples, 683730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:43,784 : INFO : PROGRESS: at 58.16% examples, 683888 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 15:58:44,808 : INFO : PROGRESS: at 58.74% examples, 684193 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:45,824 : INFO : PROGRESS: at 59.33% examples, 684676 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:46,831 : INFO : PROGRESS: at 59.91% examples, 685012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:47,842 : INFO : PROGRESS: at 60.32% examples, 683902 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:48,860 : INFO : PROGRESS: at 60.74% examples, 682851 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:49,869 : INFO : PROGRESS: at 61.15% examples, 681738 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:58:50,889 : INFO : PROGRESS: at 61.56% examples, 680643 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:58:51,901 : INFO : PROGRESS: at 62.06% examples, 680548 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:52,908 : INFO : PROGRESS: at 62.53% examples, 680228 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:53,917 : INFO : PROGRESS: at 63.02% examples, 680095 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:58:54,926 : INFO : PROGRESS: at 63.57% examples, 680570 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:55,928 : INFO : PROGRESS: at 64.10% examples, 680896 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:58:56,933 : INFO : PROGRESS: at 64.61% examples, 680964 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:57,936 : INFO : PROGRESS: at 65.21% examples, 682049 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:58,937 : INFO : PROGRESS: at 65.80% examples, 682953 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:58:59,942 : INFO : PROGRESS: at 66.31% examples, 682997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:00,946 : INFO : PROGRESS: at 66.80% examples, 682931 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:01,947 : INFO : PROGRESS: at 67.32% examples, 683052 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:02,950 : INFO : PROGRESS: at 67.84% examples, 683218 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:03,951 : INFO : PROGRESS: at 68.40% examples, 683795 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:04,953 : INFO : PROGRESS: at 68.98% examples, 684633 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:05,956 : INFO : PROGRESS: at 69.48% examples, 684621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:06,964 : INFO : PROGRESS: at 70.05% examples, 685194 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:07,968 : INFO : PROGRESS: at 70.61% examples, 685719 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:59:08,974 : INFO : PROGRESS: at 71.11% examples, 685690 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:59:09,983 : INFO : PROGRESS: at 71.67% examples, 686240 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:10,984 : INFO : PROGRESS: at 72.26% examples, 687040 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:11,993 : INFO : PROGRESS: at 72.82% examples, 687468 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:13,007 : INFO : PROGRESS: at 73.37% examples, 687862 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:14,015 : INFO : PROGRESS: at 73.92% examples, 688228 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:15,021 : INFO : PROGRESS: at 74.46% examples, 688544 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:16,022 : INFO : PROGRESS: at 75.03% examples, 689138 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:17,028 : INFO : PROGRESS: at 75.53% examples, 689085 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:18,031 : INFO : PROGRESS: at 76.12% examples, 689819 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:19,067 : INFO : PROGRESS: at 76.62% examples, 689617 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:20,073 : INFO : PROGRESS: at 77.16% examples, 689813 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:21,078 : INFO : PROGRESS: at 77.71% examples, 690101 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:22,079 : INFO : PROGRESS: at 78.24% examples, 689949 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:23,090 : INFO : PROGRESS: at 78.82% examples, 690200 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:24,097 : INFO : PROGRESS: at 79.44% examples, 690762 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:25,117 : INFO : PROGRESS: at 80.02% examples, 690965 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:26,124 : INFO : PROGRESS: at 80.54% examples, 691081 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:27,128 : INFO : PROGRESS: at 81.02% examples, 690835 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:59:28,150 : INFO : PROGRESS: at 81.49% examples, 690367 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:29,159 : INFO : PROGRESS: at 81.97% examples, 690103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:30,161 : INFO : PROGRESS: at 82.51% examples, 690390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:31,166 : INFO : PROGRESS: at 83.07% examples, 690809 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:32,189 : INFO : PROGRESS: at 83.54% examples, 690439 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:59:33,197 : INFO : PROGRESS: at 84.09% examples, 690744 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:34,211 : INFO : PROGRESS: at 84.64% examples, 691020 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:35,216 : INFO : PROGRESS: at 85.14% examples, 690959 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:36,220 : INFO : PROGRESS: at 85.65% examples, 690997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:37,222 : INFO : PROGRESS: at 86.19% examples, 691228 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:38,233 : INFO : PROGRESS: at 86.74% examples, 691555 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:39,251 : INFO : PROGRESS: at 87.27% examples, 691664 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:59:40,263 : INFO : PROGRESS: at 87.83% examples, 691976 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:41,270 : INFO : PROGRESS: at 88.19% examples, 690841 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:42,282 : INFO : PROGRESS: at 88.70% examples, 690801 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:43,286 : INFO : PROGRESS: at 89.24% examples, 691060 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:59:44,306 : INFO : PROGRESS: at 89.62% examples, 689981 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 15:59:45,308 : INFO : PROGRESS: at 89.96% examples, 688724 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:46,330 : INFO : PROGRESS: at 90.39% examples, 688049 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:59:47,340 : INFO : PROGRESS: at 90.95% examples, 688378 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:48,345 : INFO : PROGRESS: at 91.46% examples, 688428 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:49,374 : INFO : PROGRESS: at 91.92% examples, 687958 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:50,383 : INFO : PROGRESS: at 92.44% examples, 688032 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:51,393 : INFO : PROGRESS: at 92.95% examples, 688058 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:52,401 : INFO : PROGRESS: at 93.47% examples, 688138 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-25 15:59:53,414 : INFO : PROGRESS: at 94.02% examples, 688405 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:54,418 : INFO : PROGRESS: at 94.42% examples, 687625 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:55,420 : INFO : PROGRESS: at 94.98% examples, 687972 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 15:59:56,449 : INFO : PROGRESS: at 95.49% examples, 687972 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 15:59:57,456 : INFO : PROGRESS: at 96.01% examples, 688015 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:59:58,465 : INFO : PROGRESS: at 96.53% examples, 688085 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 15:59:59,467 : INFO : PROGRESS: at 97.01% examples, 687902 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 16:00:00,478 : INFO : PROGRESS: at 97.39% examples, 687003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 16:00:01,487 : INFO : PROGRESS: at 97.79% examples, 686036 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 16:00:02,514 : INFO : PROGRESS: at 98.19% examples, 685012 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 16:00:03,529 : INFO : PROGRESS: at 98.59% examples, 684042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 16:00:04,541 : INFO : PROGRESS: at 99.16% examples, 684228 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-25 16:00:05,545 : INFO : PROGRESS: at 99.80% examples, 684832 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 16:00:05,869 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 16:00:05,877 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 16:00:05,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 16:00:05,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 16:00:05,888 : INFO : training on 175343410 raw words (135051650 effective words) took 197.2s, 684945 effective words/s\n",
      "2017-04-25 16:00:05,888 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 16:00:06,148 : INFO : saving Word2Vec object under Results/rat_dros_BE_comb_model, separately None\n",
      "2017-04-25 16:00:06,149 : INFO : storing np array 'syn0' to Results/rat_dros_BE_comb_model.wv.syn0.npy\n",
      "2017-04-25 16:00:06,179 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 16:00:06,180 : INFO : not storing attribute cum_table\n",
      "2017-04-25 16:00:06,180 : INFO : storing np array 'syn1neg' to Results/rat_dros_BE_comb_model.syn1neg.npy\n",
      "2017-04-25 16:00:06,331 : INFO : saved Results/rat_dros_BE_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "rat_old_SR_sentence_pkl = 'Results/rat/strict_real.pkl'\n",
    "dros_SR_sentences_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "data_list = [rat_old_SR_sentence_pkl, dros_SR_sentences_pkl]\n",
    "rat_dros_SR_comb_model = make_w2v_model(data_list, 'rat_dros_SR_comb_model')\n",
    "\n",
    "#Gen model\n",
    "rat_old_GEN_sentence_pkl = 'Results/rat/gen_real.pkl'\n",
    "dros_GEN_sentences_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "data_list = [rat_old_GEN_sentence_pkl, dros_GEN_sentences_pkl]\n",
    "rat_dros_GEN_comb_model = make_w2v_model(data_list, 'rat_dros_GEN_comb_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "rat_old_BE_sentence_pkl = 'Results/rat/be_real.pkl'\n",
    "dros_BE_sentences_pkl = 'Results/drosophila/be_real.pkl'\n",
    "data_list = [rat_old_BE_sentence_pkl, dros_BE_sentences_pkl]\n",
    "rat_dros_BE_comb_model = make_w2v_model(data_list, 'rat_dros_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "rat_strict_real = pickle.load(open('Results/rat/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_SR_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_GEN_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_BE_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/rat_dros_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/rat_dros_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/rat_dros_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat_dros_comb/Seeded/Results/'\n",
    "errors_rat_dros_comb = mult_open(drct, '_errors_')\n",
    "fpr_rat_dros_comb = mult_open(drct, '_fpr_')\n",
    "tpr_rat_dros_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat_dros_comb auc=0.615 error=0.319\n",
      "Strict error rat_dros_comb auc=0.618 error=0.313\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.629 error=0.318\n",
      "Gen error rat_dros_comb auc=0.614 error=0.317\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.611 error=0.317\n",
      "BE error rat_dros_comb auc=0.618 error=0.317\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.636 error=0.198\n",
      "Strict error rat_dros_comb auc=0.636 error=0.196\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.648 error=0.200\n",
      "Gen error rat_dros_comb auc=0.639 error=0.197\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.642 error=0.196\n",
      "BE error rat_dros_comb auc=0.640 error=0.198\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.670 error=0.293\n",
      "Strict error rat_dros_comb auc=0.668 error=0.297\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.680 error=0.288\n",
      "Gen error rat_dros_comb auc=0.681 error=0.289\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.687 error=0.291\n",
      "BE error rat_dros_comb auc=0.681 error=0.290\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.656 error=0.297\n",
      "Strict error rat_dros_comb auc=0.654 error=0.299\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.668 error=0.300\n",
      "Gen error rat_dros_comb auc=0.668 error=0.299\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.669 error=0.297\n",
      "BE error rat_dros_comb auc=0.661 error=0.297\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.622 error=0.252\n",
      "Strict error rat_dros_comb auc=0.626 error=0.254\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.641 error=0.246\n",
      "Gen error rat_dros_comb auc=0.629 error=0.250\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.649 error=0.250\n",
      "BE error rat_dros_comb auc=0.647 error=0.255\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.613 error=0.259\n",
      "Strict error rat_dros_comb auc=0.621 error=0.259\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.631 error=0.252\n",
      "Gen error rat_dros_comb auc=0.629 error=0.254\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.643 error=0.249\n",
      "BE error rat_dros_comb auc=0.640 error=0.250\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.659 error=0.258\n",
      "Strict error rat_dros_comb auc=0.657 error=0.258\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.645 error=0.258\n",
      "Gen error rat_dros_comb auc=0.643 error=0.259\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.677 error=0.255\n",
      "BE error rat_dros_comb auc=0.671 error=0.257\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.615 error=0.219\n",
      "Strict error rat_dros_comb auc=0.625 error=0.214\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.628 error=0.221\n",
      "Gen error rat_dros_comb auc=0.619 error=0.225\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.606 error=0.224\n",
      "BE error rat_dros_comb auc=0.600 error=0.234\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.594 error=0.369\n",
      "Strict error rat_dros_comb auc=0.597 error=0.370\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.601 error=0.371\n",
      "Gen error rat_dros_comb auc=0.598 error=0.372\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.591 error=0.371\n",
      "BE error rat_dros_comb auc=0.592 error=0.373\n",
      "\n",
      "\n",
      "Strict error rat_dros_comb auc=0.683 error=0.275\n",
      "Strict error rat_dros_comb auc=0.677 error=0.275\n",
      "\n",
      "\n",
      "Gen error rat_dros_comb auc=0.672 error=0.276\n",
      "Gen error rat_dros_comb auc=0.680 error=0.275\n",
      "\n",
      "\n",
      "BE error rat_dros_comb auc=0.666 error=0.274\n",
      "BE error rat_dros_comb auc=0.677 error=0.274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_dros_comb_strict = []\n",
    "mean_auc_rat_dros_comb_strict = []\n",
    "mean_err_rat_dros_comb_gen = []\n",
    "mean_auc_rat_dros_comb_gen = []\n",
    "mean_err_rat_dros_comb_be = []\n",
    "mean_auc_rat_dros_comb_be = []\n",
    "for e, f, t in zip(errors_rat_dros_comb, fpr_rat_dros_comb, tpr_rat_dros_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat_dros_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_dros_comb_strict.append(error_item)\n",
    "                    mean_auc_rat_dros_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_dros_comb_gen.append(error_item)\n",
    "                    mean_auc_rat_dros_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_dros_comb_be.append(error_item)\n",
    "                    mean_auc_rat_dros_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_dros_comb_org_strict = mean_err_rat_dros_comb_strict[0::2]\n",
    "mean_err_rat_dros_comb_fs_strict = mean_err_rat_dros_comb_strict[1::2]\n",
    "mean_auc_rat_dros_comb_org_strict = mean_auc_rat_dros_comb_strict[0::2]\n",
    "mean_auc_rat_dros_comb_fs_strict = mean_auc_rat_dros_comb_strict[1::2]\n",
    "\n",
    "mean_err_rat_dros_comb_org_gen = mean_err_rat_dros_comb_gen[0::2]\n",
    "mean_err_rat_dros_comb_fs_gen = mean_err_rat_dros_comb_gen[1::2]\n",
    "mean_auc_rat_dros_comb_org_gen = mean_auc_rat_dros_comb_gen[0::2]\n",
    "mean_auc_rat_dros_comb_fs_gen = mean_auc_rat_dros_comb_gen[1::2]\n",
    "\n",
    "mean_err_rat_dros_comb_org_be = mean_err_rat_dros_comb_be[0::2]\n",
    "mean_err_rat_dros_comb_fs_be = mean_err_rat_dros_comb_be[1::2]\n",
    "mean_auc_rat_dros_comb_org_be = mean_auc_rat_dros_comb_be[0::2]\n",
    "mean_auc_rat_dros_comb_fs_be = mean_auc_rat_dros_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat_dros_comb mean strict error original -  0.273882474953\n",
      "rat_dros_comb mean strict error feature selection -  0.273448066299\n",
      "rat_dros_comb mean strict AUC original -  0.636350404463\n",
      "rat_dros_comb mean strict AUC feature selection -  0.637863625298\n",
      "\n",
      "\n",
      "rat_dros_comb mean gen error original -  0.272954472923\n",
      "rat_dros_comb mean gen error feature selection -  0.273739846806\n",
      "rat_dros_comb mean gen AUC original -  0.644303823169\n",
      "rat_dros_comb mean gen AUC feature selection -  0.640032162524\n",
      "\n",
      "\n",
      "rat_dros_comb mean BE error original -  0.272450257811\n",
      "rat_dros_comb mean BE error feature selection -  0.274578479618\n",
      "rat_dros_comb mean BE AUC original -  0.644096623528\n",
      "rat_dros_comb mean BE AUC feature selection -  0.642692740152\n"
     ]
    }
   ],
   "source": [
    "print('rat_dros_comb mean strict error original - ', np.mean(mean_err_rat_dros_comb_org_strict))\n",
    "print('rat_dros_comb mean strict error feature selection - ', np.mean(mean_err_rat_dros_comb_fs_strict))\n",
    "print('rat_dros_comb mean strict AUC original - ', np.mean(mean_auc_rat_dros_comb_org_strict))\n",
    "print('rat_dros_comb mean strict AUC feature selection - ', np.mean(mean_auc_rat_dros_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('rat_dros_comb mean gen error original - ', np.mean(mean_err_rat_dros_comb_org_gen))\n",
    "print('rat_dros_comb mean gen error feature selection - ', np.mean(mean_err_rat_dros_comb_fs_gen))\n",
    "print('rat_dros_comb mean gen AUC original - ', np.mean(mean_auc_rat_dros_comb_org_gen))\n",
    "print('rat_dros_comb mean gen AUC feature selection - ', np.mean(mean_auc_rat_dros_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('rat_dros_comb mean BE error original - ', np.mean(mean_err_rat_dros_comb_org_be))\n",
    "print('rat_dros_comb mean BE error feature selection - ', np.mean(mean_err_rat_dros_comb_fs_be))\n",
    "print('rat_dros_comb mean BE AUC original - ', np.mean(mean_auc_rat_dros_comb_org_be))\n",
    "print('rat_dros_comb mean BE AUC feature selection - ', np.mean(mean_auc_rat_dros_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 16:02:34,320 : INFO : loading Word2Vec object from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_SR_comb_model\n",
      "2017-04-25 16:02:35,329 : INFO : loading wv recursively from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_SR_comb_model.wv.* with mmap=None\n",
      "2017-04-25 16:02:35,330 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 16:02:35,331 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 16:02:35,331 : INFO : loaded Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_SR_comb_model\n",
      "2017-04-25 16:02:35,358 : INFO : loading Word2Vec object from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_GEN_comb_model\n",
      "2017-04-25 16:02:37,054 : INFO : loading wv recursively from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_GEN_comb_model.wv.* with mmap=None\n",
      "2017-04-25 16:02:37,056 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 16:02:37,057 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 16:02:37,057 : INFO : loaded Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_GEN_comb_model\n",
      "2017-04-25 16:02:37,117 : INFO : loading Word2Vec object from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model\n",
      "2017-04-25 16:02:37,251 : INFO : loading wv recursively from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model.wv.* with mmap=None\n",
      "2017-04-25 16:02:37,254 : INFO : loading syn0 from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 16:02:38,304 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 16:02:38,305 : INFO : loading syn1neg from Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 16:02:39,371 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 16:02:39,372 : INFO : loaded Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model\n",
      "2017-04-25 16:02:39,501 : INFO : loading Word2Vec object from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model\n",
      "2017-04-25 16:02:40,867 : INFO : loading wv recursively from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model.wv.* with mmap=None\n",
      "2017-04-25 16:02:40,869 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 16:02:40,869 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 16:02:40,870 : INFO : loaded Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model\n",
      "2017-04-25 16:02:40,919 : INFO : loading Word2Vec object from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model\n",
      "2017-04-25 16:02:41,014 : INFO : loading wv recursively from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model.wv.* with mmap=None\n",
      "2017-04-25 16:02:41,017 : INFO : loading syn0 from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 16:02:41,717 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 16:02:41,719 : INFO : loading syn1neg from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 16:02:42,421 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 16:02:42,421 : INFO : loaded Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model\n",
      "2017-04-25 16:02:42,515 : INFO : loading Word2Vec object from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model\n",
      "2017-04-25 16:02:42,812 : INFO : loading wv recursively from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model.wv.* with mmap=None\n",
      "2017-04-25 16:02:42,817 : INFO : loading syn0 from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 16:02:44,240 : INFO : loading syn1neg from Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 16:02:45,741 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 16:02:45,742 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 16:02:45,743 : INFO : loaded Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model\n"
     ]
    }
   ],
   "source": [
    "rat_dros_yeast_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_SR_comb_model')\n",
    "rat_dros_yeast_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_GEN_comb_model')\n",
    "rat_dros_yeast_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_comb/Seeded/Results/dros_yeast_rat_BE_comb_model')\n",
    "\n",
    "rat_dros_yeast_mouse_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model')\n",
    "rat_dros_yeast_mouse_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model')\n",
    "rat_dros_yeast_mouse_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "rat_strict_real = pickle.load(open('Results/rat/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_SR_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_GEN_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_BE_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/rat_dros_yeast_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/rat_dros_yeast_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/rat_dros_yeast_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat_dros_yeast_comb/Seeded/Results/'\n",
    "errors_rat_dros_yeast_comb = mult_open(drct, '_errors_')\n",
    "fpr_rat_dros_yeast_comb = mult_open(drct, '_fpr_')\n",
    "tpr_rat_dros_yeast_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat_dros_yeast_comb auc=0.622 error=0.313\n",
      "Strict error rat_dros_yeast_comb auc=0.623 error=0.311\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.633 error=0.309\n",
      "Gen error rat_dros_yeast_comb auc=0.628 error=0.306\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.623 error=0.311\n",
      "BE error rat_dros_yeast_comb auc=0.627 error=0.312\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.636 error=0.196\n",
      "Strict error rat_dros_yeast_comb auc=0.639 error=0.195\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.637 error=0.199\n",
      "Gen error rat_dros_yeast_comb auc=0.624 error=0.198\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.634 error=0.195\n",
      "BE error rat_dros_yeast_comb auc=0.631 error=0.194\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.679 error=0.295\n",
      "Strict error rat_dros_yeast_comb auc=0.673 error=0.291\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.675 error=0.287\n",
      "Gen error rat_dros_yeast_comb auc=0.664 error=0.288\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.687 error=0.293\n",
      "BE error rat_dros_yeast_comb auc=0.681 error=0.292\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.652 error=0.297\n",
      "Strict error rat_dros_yeast_comb auc=0.648 error=0.296\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.659 error=0.299\n",
      "Gen error rat_dros_yeast_comb auc=0.662 error=0.301\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.646 error=0.301\n",
      "BE error rat_dros_yeast_comb auc=0.645 error=0.300\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.636 error=0.252\n",
      "Strict error rat_dros_yeast_comb auc=0.631 error=0.252\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.653 error=0.250\n",
      "Gen error rat_dros_yeast_comb auc=0.646 error=0.252\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.650 error=0.247\n",
      "BE error rat_dros_yeast_comb auc=0.650 error=0.253\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.626 error=0.252\n",
      "Strict error rat_dros_yeast_comb auc=0.629 error=0.255\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.626 error=0.261\n",
      "Gen error rat_dros_yeast_comb auc=0.623 error=0.258\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.633 error=0.255\n",
      "BE error rat_dros_yeast_comb auc=0.629 error=0.258\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.660 error=0.256\n",
      "Strict error rat_dros_yeast_comb auc=0.664 error=0.253\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.658 error=0.260\n",
      "Gen error rat_dros_yeast_comb auc=0.664 error=0.257\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.673 error=0.254\n",
      "BE error rat_dros_yeast_comb auc=0.670 error=0.253\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.617 error=0.220\n",
      "Strict error rat_dros_yeast_comb auc=0.615 error=0.221\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.637 error=0.225\n",
      "Gen error rat_dros_yeast_comb auc=0.631 error=0.227\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.630 error=0.219\n",
      "BE error rat_dros_yeast_comb auc=0.628 error=0.221\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.601 error=0.369\n",
      "Strict error rat_dros_yeast_comb auc=0.597 error=0.370\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.609 error=0.372\n",
      "Gen error rat_dros_yeast_comb auc=0.608 error=0.370\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.592 error=0.375\n",
      "BE error rat_dros_yeast_comb auc=0.585 error=0.375\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_comb auc=0.678 error=0.275\n",
      "Strict error rat_dros_yeast_comb auc=0.675 error=0.273\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_comb auc=0.668 error=0.274\n",
      "Gen error rat_dros_yeast_comb auc=0.667 error=0.276\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_comb auc=0.661 error=0.276\n",
      "BE error rat_dros_yeast_comb auc=0.661 error=0.276\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_dros_yeast_comb_strict = []\n",
    "mean_auc_rat_dros_yeast_comb_strict = []\n",
    "mean_err_rat_dros_yeast_comb_gen = []\n",
    "mean_auc_rat_dros_yeast_comb_gen = []\n",
    "mean_err_rat_dros_yeast_comb_be = []\n",
    "mean_auc_rat_dros_yeast_comb_be = []\n",
    "for e, f, t in zip(errors_rat_dros_yeast_comb, fpr_rat_dros_yeast_comb, tpr_rat_dros_yeast_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat_dros_yeast_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_dros_yeast_comb_strict.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_dros_yeast_comb_gen.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_dros_yeast_comb_be.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_dros_yeast_comb_org_strict = mean_err_rat_dros_yeast_comb_strict[0::2]\n",
    "mean_err_rat_dros_yeast_comb_fs_strict = mean_err_rat_dros_yeast_comb_strict[1::2]\n",
    "mean_auc_rat_dros_yeast_comb_org_strict = mean_auc_rat_dros_yeast_comb_strict[0::2]\n",
    "mean_auc_rat_dros_yeast_comb_fs_strict = mean_auc_rat_dros_yeast_comb_strict[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_comb_org_gen = mean_err_rat_dros_yeast_comb_gen[0::2]\n",
    "mean_err_rat_dros_yeast_comb_fs_gen = mean_err_rat_dros_yeast_comb_gen[1::2]\n",
    "mean_auc_rat_dros_yeast_comb_org_gen = mean_auc_rat_dros_yeast_comb_gen[0::2]\n",
    "mean_auc_rat_dros_yeast_comb_fs_gen = mean_auc_rat_dros_yeast_comb_gen[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_comb_org_be = mean_err_rat_dros_yeast_comb_be[0::2]\n",
    "mean_err_rat_dros_yeast_comb_fs_be = mean_err_rat_dros_yeast_comb_be[1::2]\n",
    "mean_auc_rat_dros_yeast_comb_org_be = mean_auc_rat_dros_yeast_comb_be[0::2]\n",
    "mean_auc_rat_dros_yeast_comb_fs_be = mean_auc_rat_dros_yeast_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat_dros_yeast_comb mean strict error original -  0.272476430971\n",
      "rat_dros_yeast_comb mean strict error feature selection -  0.271659202678\n",
      "rat_dros_yeast_comb mean strict AUC original -  0.640765973243\n",
      "rat_dros_yeast_comb mean strict AUC feature selection -  0.639427249169\n",
      "\n",
      "\n",
      "rat_dros_yeast_comb mean gen error original -  0.273492538289\n",
      "rat_dros_yeast_comb mean gen error feature selection -  0.273234327694\n",
      "rat_dros_yeast_comb mean gen AUC original -  0.645507259418\n",
      "rat_dros_yeast_comb mean gen AUC feature selection -  0.641603568746\n",
      "\n",
      "\n",
      "rat_dros_yeast_comb mean BE error original -  0.272530434964\n",
      "rat_dros_yeast_comb mean BE error feature selection -  0.273426528131\n",
      "rat_dros_yeast_comb mean BE AUC original -  0.642659828719\n",
      "rat_dros_yeast_comb mean BE AUC feature selection -  0.640714848544\n"
     ]
    }
   ],
   "source": [
    "print('rat_dros_yeast_comb mean strict error original - ', np.mean(mean_err_rat_dros_yeast_comb_org_strict))\n",
    "print('rat_dros_yeast_comb mean strict error feature selection - ', np.mean(mean_err_rat_dros_yeast_comb_fs_strict))\n",
    "print('rat_dros_yeast_comb mean strict AUC original - ', np.mean(mean_auc_rat_dros_yeast_comb_org_strict))\n",
    "print('rat_dros_yeast_comb mean strict AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast_comb mean gen error original - ', np.mean(mean_err_rat_dros_yeast_comb_org_gen))\n",
    "print('rat_dros_yeast_comb mean gen error feature selection - ', np.mean(mean_err_rat_dros_yeast_comb_fs_gen))\n",
    "print('rat_dros_yeast_comb mean gen AUC original - ', np.mean(mean_auc_rat_dros_yeast_comb_org_gen))\n",
    "print('rat_dros_yeast_comb mean gen AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast_comb mean BE error original - ', np.mean(mean_err_rat_dros_yeast_comb_org_be))\n",
    "print('rat_dros_yeast_comb mean BE error feature selection - ', np.mean(mean_err_rat_dros_yeast_comb_fs_be))\n",
    "print('rat_dros_yeast_comb mean BE AUC original - ', np.mean(mean_auc_rat_dros_yeast_comb_org_be))\n",
    "print('rat_dros_yeast_comb mean BE AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "rat_strict_real = pickle.load(open('Results/rat/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_mouse_SR_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_mouse_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_mouse_GEN_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_mouse_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(rat_strict_real, \n",
    "                                             'rat_dros_yeast_mouse_BE_comb_'+str(seed),\n",
    "                                             prev_model=rat_dros_yeast_mouse_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/rat_dros_yeast_mouse_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/rat_dros_yeast_mouse_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/rat_dros_yeast_mouse_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/rat_dros_yeast_mouse_comb/Seeded/Results/'\n",
    "errors_rat_dros_yeast_mouse_comb = mult_open(drct, '_errors_')\n",
    "fpr_rat_dros_yeast_mouse_comb = mult_open(drct, '_fpr_')\n",
    "tpr_rat_dros_yeast_mouse_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error rat_dros_yeast_mouse_comb auc=0.615 error=0.319\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.617 error=0.315\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.618 error=0.312\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.623 error=0.312\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.644 error=0.316\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.631 error=0.317\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.647 error=0.197\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.649 error=0.199\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.654 error=0.198\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.647 error=0.200\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.651 error=0.197\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.655 error=0.201\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.688 error=0.291\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.686 error=0.291\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.691 error=0.293\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.694 error=0.289\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.684 error=0.292\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.685 error=0.292\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.667 error=0.297\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.670 error=0.299\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.656 error=0.304\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.664 error=0.302\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.661 error=0.300\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.652 error=0.302\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.648 error=0.252\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.639 error=0.253\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.637 error=0.252\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.637 error=0.250\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.663 error=0.252\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.666 error=0.255\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.623 error=0.254\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.632 error=0.252\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.642 error=0.246\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.641 error=0.246\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.635 error=0.257\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.632 error=0.256\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.666 error=0.257\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.664 error=0.262\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.648 error=0.260\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.649 error=0.261\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.674 error=0.253\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.671 error=0.256\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.638 error=0.218\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.634 error=0.223\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.622 error=0.221\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.618 error=0.227\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.617 error=0.229\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.609 error=0.234\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.593 error=0.372\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.590 error=0.373\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.598 error=0.375\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.598 error=0.374\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.589 error=0.370\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.577 error=0.370\n",
      "\n",
      "\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.671 error=0.275\n",
      "Strict error rat_dros_yeast_mouse_comb auc=0.671 error=0.276\n",
      "\n",
      "\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.663 error=0.275\n",
      "Gen error rat_dros_yeast_mouse_comb auc=0.668 error=0.276\n",
      "\n",
      "\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.670 error=0.273\n",
      "BE error rat_dros_yeast_mouse_comb auc=0.669 error=0.273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_rat_dros_yeast_mouse_comb_strict = []\n",
    "mean_auc_rat_dros_yeast_mouse_comb_strict = []\n",
    "mean_err_rat_dros_yeast_mouse_comb_gen = []\n",
    "mean_auc_rat_dros_yeast_mouse_comb_gen = []\n",
    "mean_err_rat_dros_yeast_mouse_comb_be = []\n",
    "mean_auc_rat_dros_yeast_mouse_comb_be = []\n",
    "for e, f, t in zip(errors_rat_dros_yeast_mouse_comb, fpr_rat_dros_yeast_mouse_comb, tpr_rat_dros_yeast_mouse_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['rat_dros_yeast_mouse_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_rat_dros_yeast_mouse_comb_strict.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_mouse_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_rat_dros_yeast_mouse_comb_gen.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_mouse_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_rat_dros_yeast_mouse_comb_be.append(error_item)\n",
    "                    mean_auc_rat_dros_yeast_mouse_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_rat_dros_yeast_mouse_comb_org_strict = mean_err_rat_dros_yeast_mouse_comb_strict[0::2]\n",
    "mean_err_rat_dros_yeast_mouse_comb_fs_strict = mean_err_rat_dros_yeast_mouse_comb_strict[1::2]\n",
    "mean_auc_rat_dros_yeast_mouse_comb_org_strict = mean_auc_rat_dros_yeast_mouse_comb_strict[0::2]\n",
    "mean_auc_rat_dros_yeast_mouse_comb_fs_strict = mean_auc_rat_dros_yeast_mouse_comb_strict[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_mouse_comb_org_gen = mean_err_rat_dros_yeast_mouse_comb_gen[0::2]\n",
    "mean_err_rat_dros_yeast_mouse_comb_fs_gen = mean_err_rat_dros_yeast_mouse_comb_gen[1::2]\n",
    "mean_auc_rat_dros_yeast_mouse_comb_org_gen = mean_auc_rat_dros_yeast_mouse_comb_gen[0::2]\n",
    "mean_auc_rat_dros_yeast_mouse_comb_fs_gen = mean_auc_rat_dros_yeast_mouse_comb_gen[1::2]\n",
    "\n",
    "mean_err_rat_dros_yeast_mouse_comb_org_be = mean_err_rat_dros_yeast_mouse_comb_be[0::2]\n",
    "mean_err_rat_dros_yeast_mouse_comb_fs_be = mean_err_rat_dros_yeast_mouse_comb_be[1::2]\n",
    "mean_auc_rat_dros_yeast_mouse_comb_org_be = mean_auc_rat_dros_yeast_mouse_comb_be[0::2]\n",
    "mean_auc_rat_dros_yeast_mouse_comb_fs_be = mean_auc_rat_dros_yeast_mouse_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rat_dros_yeast_mouse_comb mean strict error original -  0.27318454099\n",
      "rat_dros_yeast_mouse_comb mean strict error feature selection -  0.274437102035\n",
      "rat_dros_yeast_mouse_comb mean strict AUC original -  0.645459570116\n",
      "rat_dros_yeast_mouse_comb mean strict AUC feature selection -  0.645094084067\n",
      "\n",
      "\n",
      "rat_dros_yeast_mouse_comb mean gen error original -  0.273566483054\n",
      "rat_dros_yeast_mouse_comb mean gen error feature selection -  0.27380731779\n",
      "rat_dros_yeast_mouse_comb mean gen AUC original -  0.642975338553\n",
      "rat_dros_yeast_mouse_comb mean gen AUC feature selection -  0.643889326577\n",
      "\n",
      "\n",
      "rat_dros_yeast_mouse_comb mean BE error original -  0.273909280087\n",
      "rat_dros_yeast_mouse_comb mean BE error feature selection -  0.275505501367\n",
      "rat_dros_yeast_mouse_comb mean BE AUC original -  0.648797568756\n",
      "rat_dros_yeast_mouse_comb mean BE AUC feature selection -  0.644629451115\n"
     ]
    }
   ],
   "source": [
    "print('rat_dros_yeast_mouse_comb mean strict error original - ', np.mean(mean_err_rat_dros_yeast_mouse_comb_org_strict))\n",
    "print('rat_dros_yeast_mouse_comb mean strict error feature selection - ', np.mean(mean_err_rat_dros_yeast_mouse_comb_fs_strict))\n",
    "print('rat_dros_yeast_mouse_comb mean strict AUC original - ', np.mean(mean_auc_rat_dros_yeast_mouse_comb_org_strict))\n",
    "print('rat_dros_yeast_mouse_comb mean strict AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_mouse_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast_mouse_comb mean gen error original - ', np.mean(mean_err_rat_dros_yeast_mouse_comb_org_gen))\n",
    "print('rat_dros_yeast_mouse_comb mean gen error feature selection - ', np.mean(mean_err_rat_dros_yeast_mouse_comb_fs_gen))\n",
    "print('rat_dros_yeast_mouse_comb mean gen AUC original - ', np.mean(mean_auc_rat_dros_yeast_mouse_comb_org_gen))\n",
    "print('rat_dros_yeast_mouse_comb mean gen AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_mouse_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('rat_dros_yeast_mouse_comb mean BE error original - ', np.mean(mean_err_rat_dros_yeast_mouse_comb_org_be))\n",
    "print('rat_dros_yeast_mouse_comb mean BE error feature selection - ', np.mean(mean_err_rat_dros_yeast_mouse_comb_fs_be))\n",
    "print('rat_dros_yeast_mouse_comb mean BE AUC original - ', np.mean(mean_auc_rat_dros_yeast_mouse_comb_org_be))\n",
    "print('rat_dros_yeast_mouse_comb mean BE AUC feature selection - ', np.mean(mean_auc_rat_dros_yeast_mouse_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 18:52:32,652 : INFO : loading Word2Vec object from Results/mouse/Seeded/Results/mouse_strict_real_model\n",
      "2017-04-25 18:52:33,807 : INFO : loading wv recursively from Results/mouse/Seeded/Results/mouse_strict_real_model.wv.* with mmap=None\n",
      "2017-04-25 18:52:33,808 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 18:52:33,808 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 18:52:33,809 : INFO : loaded Results/mouse/Seeded/Results/mouse_strict_real_model\n",
      "2017-04-25 18:52:33,841 : INFO : training model with 4 workers on 14788 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 18:52:33,842 : INFO : expecting 87723 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 18:52:34,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 18:52:34,617 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 18:52:34,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 18:52:34,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 18:52:34,629 : INFO : training on 928405 raw words (667709 effective words) took 0.8s, 853909 effective words/s\n",
      "2017-04-25 18:52:34,630 : WARNING : supplied example count (36355) did not equal expected count (438615)\n",
      "2017-04-25 18:52:34,630 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 18:52:34,707 : INFO : saving Word2Vec object under Results/mouse_dros_SR_model, separately None\n",
      "2017-04-25 18:52:34,708 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 18:52:34,709 : INFO : not storing attribute cum_table\n",
      "2017-04-25 18:52:34,709 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 18:52:34,984 : INFO : saved Results/mouse_dros_SR_model\n",
      "2017-04-25 18:52:35,638 : INFO : loading Word2Vec object from Results/mouse/Seeded/Results/mouse_gen_real_model\n",
      "2017-04-25 18:52:37,765 : INFO : loading wv recursively from Results/mouse/Seeded/Results/mouse_gen_real_model.wv.* with mmap=None\n",
      "2017-04-25 18:52:37,767 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 18:52:37,768 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 18:52:37,768 : INFO : loaded Results/mouse/Seeded/Results/mouse_gen_real_model\n",
      "2017-04-25 18:52:37,834 : INFO : training model with 4 workers on 30392 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 18:52:37,835 : INFO : expecting 485025 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 18:52:38,845 : INFO : PROGRESS: at 1.89% examples, 820552 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:39,851 : INFO : PROGRESS: at 3.65% examples, 791552 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:40,852 : INFO : PROGRESS: at 4.90% examples, 709578 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:41,881 : INFO : PROGRESS: at 6.26% examples, 674805 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 18:52:42,737 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 18:52:42,740 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 18:52:42,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 18:52:42,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 18:52:42,747 : INFO : training on 4507620 raw words (3327225 effective words) took 4.9s, 677968 effective words/s\n",
      "2017-04-25 18:52:42,748 : WARNING : supplied example count (185085) did not equal expected count (2425125)\n",
      "2017-04-25 18:52:42,748 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 18:52:42,903 : INFO : saving Word2Vec object under Results/mouse_dros_GEN_model, separately None\n",
      "2017-04-25 18:52:42,904 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 18:52:42,905 : INFO : not storing attribute cum_table\n",
      "2017-04-25 18:52:42,905 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 18:52:43,483 : INFO : saved Results/mouse_dros_GEN_model\n",
      "2017-04-25 18:52:46,640 : INFO : loading Word2Vec object from Results/mouse/Seeded/Results/mouse_both_ents_model\n",
      "2017-04-25 18:52:47,157 : INFO : loading wv recursively from Results/mouse/Seeded/Results/mouse_both_ents_model.wv.* with mmap=None\n",
      "2017-04-25 18:52:47,161 : INFO : loading syn0 from Results/mouse/Seeded/Results/mouse_both_ents_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 18:52:48,292 : INFO : loading syn1neg from Results/mouse/Seeded/Results/mouse_both_ents_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 18:52:49,451 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 18:52:49,451 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 18:52:49,452 : INFO : loaded Results/mouse/Seeded/Results/mouse_both_ents_model\n",
      "2017-04-25 18:52:49,596 : INFO : training model with 4 workers on 64474 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 18:52:49,596 : INFO : expecting 2361617 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 18:52:50,610 : INFO : PROGRESS: at 0.32% examples, 643642 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:51,616 : INFO : PROGRESS: at 0.65% examples, 667193 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:52,625 : INFO : PROGRESS: at 1.02% examples, 694003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:53,630 : INFO : PROGRESS: at 1.35% examples, 687545 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:54,632 : INFO : PROGRESS: at 1.71% examples, 697606 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:55,640 : INFO : PROGRESS: at 2.09% examples, 711192 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:52:56,652 : INFO : PROGRESS: at 2.50% examples, 730021 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 18:52:57,660 : INFO : PROGRESS: at 2.87% examples, 733269 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 18:52:58,686 : INFO : PROGRESS: at 3.25% examples, 736871 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 18:52:59,699 : INFO : PROGRESS: at 3.63% examples, 740759 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:00,701 : INFO : PROGRESS: at 3.97% examples, 736400 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 18:53:01,719 : INFO : PROGRESS: at 4.36% examples, 740578 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 18:53:02,731 : INFO : PROGRESS: at 4.74% examples, 743248 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:03,736 : INFO : PROGRESS: at 5.13% examples, 747054 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:04,738 : INFO : PROGRESS: at 5.47% examples, 744484 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 18:53:05,753 : INFO : PROGRESS: at 5.82% examples, 741131 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-25 18:53:06,759 : INFO : PROGRESS: at 6.19% examples, 742079 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:07,767 : INFO : PROGRESS: at 6.48% examples, 734589 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:08,811 : INFO : PROGRESS: at 6.77% examples, 725713 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:09,836 : INFO : PROGRESS: at 7.03% examples, 715006 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 18:53:10,842 : INFO : PROGRESS: at 7.28% examples, 705650 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 18:53:11,852 : INFO : PROGRESS: at 7.54% examples, 697371 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 18:53:12,076 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 18:53:12,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 18:53:12,092 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 18:53:12,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 18:53:12,098 : INFO : training on 20708940 raw words (15650041 effective words) took 22.5s, 695664 effective words/s\n",
      "2017-04-25 18:53:12,099 : WARNING : supplied example count (897865) did not equal expected count (11808085)\n",
      "2017-04-25 18:53:12,100 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 18:53:12,470 : INFO : saving Word2Vec object under Results/mouse_dros_BE_model, separately None\n",
      "2017-04-25 18:53:12,471 : INFO : storing np array 'syn0' to Results/mouse_dros_BE_model.wv.syn0.npy\n",
      "2017-04-25 18:53:12,511 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 18:53:12,512 : INFO : not storing attribute cum_table\n",
      "2017-04-25 18:53:12,512 : INFO : storing np array 'syn1neg' to Results/mouse_dros_BE_model.syn1neg.npy\n",
      "2017-04-25 18:53:12,548 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 18:53:12,681 : INFO : saved Results/mouse_dros_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "mouse_old_SR_model = 'Results/mouse/Seeded/Results/mouse_strict_real_model'\n",
    "dros_SR_sentences_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "mouse_dros_SR_model = add_sentences_to_model(mouse_old_SR_model, dros_SR_sentences_pkl, 'mouse_dros_SR_model')\n",
    "\n",
    "#Gen model\n",
    "mouse_old_GEN_model = 'Results/mouse/Seeded/Results/mouse_gen_real_model'\n",
    "dros_GEN_sentences_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "mouse_dros_GEN_model = add_sentences_to_model(mouse_old_GEN_model, dros_GEN_sentences_pkl, 'mouse_dros_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "mouse_old_BE_model = 'Results/mouse/Seeded/Results/mouse_both_ents_model'\n",
    "dros_BE_sentences_pkl = 'Results/drosophila/be_real.pkl'\n",
    "mouse_dros_BE_model = add_sentences_to_model(mouse_old_BE_model, dros_BE_sentences_pkl, 'mouse_dros_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "mouse_strict_real = pickle.load(open('Results/mouse/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_SR_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_GEN_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_BE_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/mouse_dros_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/mouse_dros_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/mouse_dros_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse_dros/Seeded/Results/'\n",
    "errors_mouse_dros = mult_open(drct, '_errors_')\n",
    "fpr_mouse_dros = mult_open(drct, '_fpr_')\n",
    "tpr_mouse_dros = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse_dros auc=0.650 error=0.230\n",
      "Strict error mouse_dros auc=0.644 error=0.231\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.660 error=0.228\n",
      "Gen error mouse_dros auc=0.653 error=0.230\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.652 error=0.231\n",
      "BE error mouse_dros auc=0.653 error=0.231\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.652 error=0.282\n",
      "Strict error mouse_dros auc=0.648 error=0.282\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.666 error=0.281\n",
      "Gen error mouse_dros auc=0.665 error=0.283\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.661 error=0.281\n",
      "BE error mouse_dros auc=0.657 error=0.279\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.645 error=0.285\n",
      "Strict error mouse_dros auc=0.637 error=0.284\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.648 error=0.286\n",
      "Gen error mouse_dros auc=0.641 error=0.286\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.647 error=0.285\n",
      "BE error mouse_dros auc=0.641 error=0.285\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.672 error=0.239\n",
      "Strict error mouse_dros auc=0.667 error=0.239\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.691 error=0.235\n",
      "Gen error mouse_dros auc=0.688 error=0.237\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.691 error=0.236\n",
      "BE error mouse_dros auc=0.683 error=0.238\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.605 error=0.287\n",
      "Strict error mouse_dros auc=0.604 error=0.290\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.628 error=0.284\n",
      "Gen error mouse_dros auc=0.627 error=0.287\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.618 error=0.283\n",
      "BE error mouse_dros auc=0.613 error=0.288\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.658 error=0.278\n",
      "Strict error mouse_dros auc=0.660 error=0.278\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.667 error=0.278\n",
      "Gen error mouse_dros auc=0.665 error=0.278\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.665 error=0.274\n",
      "BE error mouse_dros auc=0.662 error=0.274\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.689 error=0.256\n",
      "Strict error mouse_dros auc=0.690 error=0.257\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.696 error=0.249\n",
      "Gen error mouse_dros auc=0.695 error=0.251\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.690 error=0.252\n",
      "BE error mouse_dros auc=0.688 error=0.251\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.667 error=0.292\n",
      "Strict error mouse_dros auc=0.667 error=0.293\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.685 error=0.288\n",
      "Gen error mouse_dros auc=0.683 error=0.287\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.670 error=0.290\n",
      "BE error mouse_dros auc=0.666 error=0.294\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.636 error=0.201\n",
      "Strict error mouse_dros auc=0.633 error=0.199\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.640 error=0.197\n",
      "Gen error mouse_dros auc=0.640 error=0.199\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.635 error=0.198\n",
      "BE error mouse_dros auc=0.634 error=0.201\n",
      "\n",
      "\n",
      "Strict error mouse_dros auc=0.710 error=0.203\n",
      "Strict error mouse_dros auc=0.707 error=0.204\n",
      "\n",
      "\n",
      "Gen error mouse_dros auc=0.710 error=0.200\n",
      "Gen error mouse_dros auc=0.711 error=0.201\n",
      "\n",
      "\n",
      "BE error mouse_dros auc=0.705 error=0.200\n",
      "BE error mouse_dros auc=0.696 error=0.202\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_dros_strict = []\n",
    "mean_auc_mouse_dros_strict = []\n",
    "mean_err_mouse_dros_gen = []\n",
    "mean_auc_mouse_dros_gen = []\n",
    "mean_err_mouse_dros_be = []\n",
    "mean_auc_mouse_dros_be = []\n",
    "for e, f, t in zip(errors_mouse_dros, fpr_mouse_dros, tpr_mouse_dros):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse_dros']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_dros_strict.append(error_item)\n",
    "                    mean_auc_mouse_dros_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_dros_gen.append(error_item)\n",
    "                    mean_auc_mouse_dros_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_dros_be.append(error_item)\n",
    "                    mean_auc_mouse_dros_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_dros_org_strict = mean_err_mouse_dros_strict[0::2]\n",
    "mean_err_mouse_dros_fs_strict = mean_err_mouse_dros_strict[1::2]\n",
    "mean_auc_mouse_dros_org_strict = mean_auc_mouse_dros_strict[0::2]\n",
    "mean_auc_mouse_dros_fs_strict = mean_auc_mouse_dros_strict[1::2]\n",
    "\n",
    "mean_err_mouse_dros_org_gen = mean_err_mouse_dros_gen[0::2]\n",
    "mean_err_mouse_dros_fs_gen = mean_err_mouse_dros_gen[1::2]\n",
    "mean_auc_mouse_dros_org_gen = mean_auc_mouse_dros_gen[0::2]\n",
    "mean_auc_mouse_dros_fs_gen = mean_auc_mouse_dros_gen[1::2]\n",
    "\n",
    "mean_err_mouse_dros_org_be = mean_err_mouse_dros_be[0::2]\n",
    "mean_err_mouse_dros_fs_be = mean_err_mouse_dros_be[1::2]\n",
    "mean_auc_mouse_dros_org_be = mean_auc_mouse_dros_be[0::2]\n",
    "mean_auc_mouse_dros_fs_be = mean_auc_mouse_dros_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_dros mean strict error original -  0.255117533731\n",
      "mouse_dros mean strict error feature selection -  0.255699839702\n",
      "mouse_dros mean strict AUC original -  0.658516057519\n",
      "mouse_dros mean strict AUC feature selection -  0.655724162094\n",
      "\n",
      "\n",
      "mouse_dros mean gen error original -  0.252717538878\n",
      "mouse_dros mean gen error feature selection -  0.253797107873\n",
      "mouse_dros mean gen AUC original -  0.668952502258\n",
      "mouse_dros mean gen AUC feature selection -  0.666872165132\n",
      "\n",
      "\n",
      "mouse_dros mean BE error original -  0.252945453469\n",
      "mouse_dros mean BE error feature selection -  0.25429827822\n",
      "mouse_dros mean BE AUC original -  0.663358007244\n",
      "mouse_dros mean BE AUC feature selection -  0.659118903207\n"
     ]
    }
   ],
   "source": [
    "print('mouse_dros mean strict error original - ', np.mean(mean_err_mouse_dros_org_strict))\n",
    "print('mouse_dros mean strict error feature selection - ', np.mean(mean_err_mouse_dros_fs_strict))\n",
    "print('mouse_dros mean strict AUC original - ', np.mean(mean_auc_mouse_dros_org_strict))\n",
    "print('mouse_dros mean strict AUC feature selection - ', np.mean(mean_auc_mouse_dros_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse_dros mean gen error original - ', np.mean(mean_err_mouse_dros_org_gen))\n",
    "print('mouse_dros mean gen error feature selection - ', np.mean(mean_err_mouse_dros_fs_gen))\n",
    "print('mouse_dros mean gen AUC original - ', np.mean(mean_auc_mouse_dros_org_gen))\n",
    "print('mouse_dros mean gen AUC feature selection - ', np.mean(mean_auc_mouse_dros_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse_dros mean BE error original - ', np.mean(mean_err_mouse_dros_org_be))\n",
    "print('mouse_dros mean BE error feature selection - ', np.mean(mean_err_mouse_dros_fs_be))\n",
    "print('mouse_dros mean BE AUC original - ', np.mean(mean_auc_mouse_dros_org_be))\n",
    "print('mouse_dros mean BE AUC feature selection - ', np.mean(mean_auc_mouse_dros_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-25 20:28:55,404 : INFO : loading Word2Vec object from Results/mouse_dros/Seeded/Results/mouse_dros_SR_model\n",
      "2017-04-25 20:28:56,288 : INFO : loading wv recursively from Results/mouse_dros/Seeded/Results/mouse_dros_SR_model.wv.* with mmap=None\n",
      "2017-04-25 20:28:56,290 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 20:28:56,291 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 20:28:56,291 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 20:28:56,292 : INFO : loaded Results/mouse_dros/Seeded/Results/mouse_dros_SR_model\n",
      "2017-04-25 20:28:56,323 : INFO : training model with 4 workers on 14788 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 20:28:56,323 : INFO : expecting 87723 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 20:28:57,141 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 20:28:57,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 20:28:57,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 20:28:57,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 20:28:57,149 : INFO : training on 942490 raw words (679958 effective words) took 0.8s, 828184 effective words/s\n",
      "2017-04-25 20:28:57,150 : WARNING : supplied example count (35725) did not equal expected count (438615)\n",
      "2017-04-25 20:28:57,150 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 20:28:57,231 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_SR_model, separately None\n",
      "2017-04-25 20:28:57,232 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 20:28:57,233 : INFO : not storing attribute cum_table\n",
      "2017-04-25 20:28:57,234 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 20:28:57,523 : INFO : saved Results/mouse_dros_yeast_SR_model\n",
      "2017-04-25 20:28:58,589 : INFO : loading Word2Vec object from Results/mouse_dros/Seeded/Results/mouse_dros_GEN_model\n",
      "2017-04-25 20:29:00,220 : INFO : loading wv recursively from Results/mouse_dros/Seeded/Results/mouse_dros_GEN_model.wv.* with mmap=None\n",
      "2017-04-25 20:29:00,222 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 20:29:00,222 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 20:29:00,223 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 20:29:00,224 : INFO : loaded Results/mouse_dros/Seeded/Results/mouse_dros_GEN_model\n",
      "2017-04-25 20:29:00,294 : INFO : training model with 4 workers on 30392 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 20:29:00,295 : INFO : expecting 485025 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 20:29:01,307 : INFO : PROGRESS: at 1.74% examples, 764475 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:02,308 : INFO : PROGRESS: at 3.62% examples, 796488 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:03,318 : INFO : PROGRESS: at 5.48% examples, 802149 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:04,325 : INFO : PROGRESS: at 7.42% examples, 814813 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:05,341 : INFO : PROGRESS: at 9.35% examples, 819454 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 20:29:05,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 20:29:05,554 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 20:29:05,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 20:29:05,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 20:29:05,571 : INFO : training on 5840885 raw words (4330771 effective words) took 5.3s, 821619 effective words/s\n",
      "2017-04-25 20:29:05,571 : WARNING : supplied example count (237680) did not equal expected count (2425125)\n",
      "2017-04-25 20:29:05,572 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 20:29:05,730 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_GEN_model, separately None\n",
      "2017-04-25 20:29:05,731 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 20:29:05,732 : INFO : not storing attribute cum_table\n",
      "2017-04-25 20:29:05,732 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 20:29:06,535 : INFO : saved Results/mouse_dros_yeast_GEN_model\n",
      "2017-04-25 20:29:10,411 : INFO : loading Word2Vec object from Results/mouse_dros/Seeded/Results/mouse_dros_BE_model\n",
      "2017-04-25 20:29:10,536 : INFO : loading wv recursively from Results/mouse_dros/Seeded/Results/mouse_dros_BE_model.wv.* with mmap=None\n",
      "2017-04-25 20:29:10,540 : INFO : loading syn0 from Results/mouse_dros/Seeded/Results/mouse_dros_BE_model.wv.syn0.npy with mmap=None\n",
      "2017-04-25 20:29:11,824 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 20:29:11,825 : INFO : loading syn1neg from Results/mouse_dros/Seeded/Results/mouse_dros_BE_model.syn1neg.npy with mmap=None\n",
      "2017-04-25 20:29:13,036 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-25 20:29:13,037 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-25 20:29:13,038 : INFO : loaded Results/mouse_dros/Seeded/Results/mouse_dros_BE_model\n",
      "2017-04-25 20:29:13,170 : INFO : training model with 4 workers on 64474 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-25 20:29:13,171 : INFO : expecting 2361617 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-25 20:29:14,197 : INFO : PROGRESS: at 0.30% examples, 609267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:15,203 : INFO : PROGRESS: at 0.64% examples, 666117 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:16,203 : INFO : PROGRESS: at 1.01% examples, 701650 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 20:29:17,206 : INFO : PROGRESS: at 1.37% examples, 719235 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-25 20:29:18,206 : INFO : PROGRESS: at 1.73% examples, 727001 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:19,207 : INFO : PROGRESS: at 2.11% examples, 738434 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 20:29:20,220 : INFO : PROGRESS: at 2.48% examples, 742087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:21,222 : INFO : PROGRESS: at 2.84% examples, 744901 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:22,227 : INFO : PROGRESS: at 3.26% examples, 758574 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:23,229 : INFO : PROGRESS: at 3.69% examples, 772775 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:24,239 : INFO : PROGRESS: at 4.10% examples, 781779 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:25,246 : INFO : PROGRESS: at 4.42% examples, 771186 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:26,249 : INFO : PROGRESS: at 4.73% examples, 761956 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-25 20:29:27,253 : INFO : PROGRESS: at 5.03% examples, 753911 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:28,254 : INFO : PROGRESS: at 5.42% examples, 757214 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:29,273 : INFO : PROGRESS: at 5.74% examples, 752188 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:30,298 : INFO : PROGRESS: at 6.02% examples, 741715 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:31,300 : INFO : PROGRESS: at 6.36% examples, 740062 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:32,313 : INFO : PROGRESS: at 6.68% examples, 735734 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 20:29:33,314 : INFO : PROGRESS: at 7.00% examples, 733092 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 20:29:34,320 : INFO : PROGRESS: at 7.24% examples, 721888 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:35,331 : INFO : PROGRESS: at 7.48% examples, 711872 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-25 20:29:36,355 : INFO : PROGRESS: at 7.71% examples, 701363 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 20:29:37,393 : INFO : PROGRESS: at 7.91% examples, 688863 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-25 20:29:38,393 : INFO : PROGRESS: at 8.20% examples, 685287 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-25 20:29:38,513 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-25 20:29:38,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-25 20:29:38,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-25 20:29:38,565 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-25 20:29:38,567 : INFO : training on 22856325 raw words (17361248 effective words) took 25.4s, 683770 effective words/s\n",
      "2017-04-25 20:29:38,568 : WARNING : supplied example count (972535) did not equal expected count (11808085)\n",
      "2017-04-25 20:29:38,569 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-25 20:29:38,997 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_BE_model, separately None\n",
      "2017-04-25 20:29:38,998 : INFO : storing np array 'syn0' to Results/mouse_dros_yeast_BE_model.wv.syn0.npy\n",
      "2017-04-25 20:29:39,048 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 20:29:39,049 : INFO : not storing attribute cum_table\n",
      "2017-04-25 20:29:39,049 : INFO : storing np array 'syn1neg' to Results/mouse_dros_yeast_BE_model.syn1neg.npy\n",
      "2017-04-25 20:29:39,090 : INFO : not storing attribute syn0norm\n",
      "2017-04-25 20:29:39,310 : INFO : saved Results/mouse_dros_yeast_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "mouse_dros_old_SR_model = 'Results/mouse_dros/Seeded/Results/mouse_dros_SR_model'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "mouse_dros_yeast_SR_model = add_sentences_to_model(mouse_dros_old_SR_model, yeast_SR_sentences_pkl, 'mouse_dros_yeast_SR_model')\n",
    "\n",
    "#Gen model\n",
    "mouse_dros_old_GEN_model = 'Results/mouse_dros/Seeded/Results/mouse_dros_GEN_model'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "mouse_dros_yeast_GEN_model = add_sentences_to_model(mouse_dros_old_GEN_model, yeast_GEN_sentences_pkl, 'mouse_dros_yeast_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "mouse_dros_old_BE_model = 'Results/mouse_dros/Seeded/Results/mouse_dros_BE_model'\n",
    "yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "mouse_dros_yeast_BE_model = add_sentences_to_model(mouse_dros_old_BE_model, yeast_BE_sentences_pkl, 'mouse_dros_yeast_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "mouse_strict_real = pickle.load(open('Results/mouse/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_SR_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_GEN_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_BE_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/mouse_dros_yeast_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/mouse_dros_yeast_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/mouse_dros_yeast_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse_dros_yeast/Seeded/Results/'\n",
    "errors_mouse_dros_yeast = mult_open(drct, '_errors_')\n",
    "fpr_mouse_dros_yeast = mult_open(drct, '_fpr_')\n",
    "tpr_mouse_dros_yeast = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse_dros_yeast auc=0.648 error=0.230\n",
      "Strict error mouse_dros_yeast auc=0.646 error=0.228\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.650 error=0.226\n",
      "Gen error mouse_dros_yeast auc=0.649 error=0.225\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.644 error=0.225\n",
      "BE error mouse_dros_yeast auc=0.647 error=0.226\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.641 error=0.283\n",
      "Strict error mouse_dros_yeast auc=0.635 error=0.284\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.651 error=0.279\n",
      "Gen error mouse_dros_yeast auc=0.646 error=0.279\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.650 error=0.279\n",
      "BE error mouse_dros_yeast auc=0.644 error=0.281\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.641 error=0.285\n",
      "Strict error mouse_dros_yeast auc=0.637 error=0.286\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.645 error=0.283\n",
      "Gen error mouse_dros_yeast auc=0.637 error=0.284\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.650 error=0.286\n",
      "BE error mouse_dros_yeast auc=0.644 error=0.285\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.671 error=0.239\n",
      "Strict error mouse_dros_yeast auc=0.669 error=0.240\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.681 error=0.240\n",
      "Gen error mouse_dros_yeast auc=0.678 error=0.238\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.675 error=0.239\n",
      "BE error mouse_dros_yeast auc=0.667 error=0.241\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.603 error=0.288\n",
      "Strict error mouse_dros_yeast auc=0.599 error=0.289\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.621 error=0.281\n",
      "Gen error mouse_dros_yeast auc=0.623 error=0.285\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.618 error=0.282\n",
      "BE error mouse_dros_yeast auc=0.612 error=0.287\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.665 error=0.276\n",
      "Strict error mouse_dros_yeast auc=0.662 error=0.279\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.665 error=0.279\n",
      "Gen error mouse_dros_yeast auc=0.654 error=0.283\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.663 error=0.279\n",
      "BE error mouse_dros_yeast auc=0.662 error=0.279\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.678 error=0.253\n",
      "Strict error mouse_dros_yeast auc=0.682 error=0.253\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.692 error=0.252\n",
      "Gen error mouse_dros_yeast auc=0.694 error=0.251\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.686 error=0.254\n",
      "BE error mouse_dros_yeast auc=0.682 error=0.257\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.666 error=0.292\n",
      "Strict error mouse_dros_yeast auc=0.666 error=0.289\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.675 error=0.291\n",
      "Gen error mouse_dros_yeast auc=0.673 error=0.291\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.665 error=0.291\n",
      "BE error mouse_dros_yeast auc=0.662 error=0.291\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.618 error=0.200\n",
      "Strict error mouse_dros_yeast auc=0.618 error=0.203\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.628 error=0.200\n",
      "Gen error mouse_dros_yeast auc=0.628 error=0.201\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.631 error=0.198\n",
      "BE error mouse_dros_yeast auc=0.630 error=0.199\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast auc=0.699 error=0.201\n",
      "Strict error mouse_dros_yeast auc=0.696 error=0.202\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast auc=0.700 error=0.197\n",
      "Gen error mouse_dros_yeast auc=0.702 error=0.199\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast auc=0.698 error=0.201\n",
      "BE error mouse_dros_yeast auc=0.692 error=0.203\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_dros_yeast_strict = []\n",
    "mean_auc_mouse_dros_yeast_strict = []\n",
    "mean_err_mouse_dros_yeast_gen = []\n",
    "mean_auc_mouse_dros_yeast_gen = []\n",
    "mean_err_mouse_dros_yeast_be = []\n",
    "mean_auc_mouse_dros_yeast_be = []\n",
    "for e, f, t in zip(errors_mouse_dros_yeast, fpr_mouse_dros_yeast, tpr_mouse_dros_yeast):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse_dros_yeast']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_dros_yeast_strict.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_dros_yeast_gen.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_dros_yeast_be.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_dros_yeast_org_strict = mean_err_mouse_dros_yeast_strict[0::2]\n",
    "mean_err_mouse_dros_yeast_fs_strict = mean_err_mouse_dros_yeast_strict[1::2]\n",
    "mean_auc_mouse_dros_yeast_org_strict = mean_auc_mouse_dros_yeast_strict[0::2]\n",
    "mean_auc_mouse_dros_yeast_fs_strict = mean_auc_mouse_dros_yeast_strict[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_org_gen = mean_err_mouse_dros_yeast_gen[0::2]\n",
    "mean_err_mouse_dros_yeast_fs_gen = mean_err_mouse_dros_yeast_gen[1::2]\n",
    "mean_auc_mouse_dros_yeast_org_gen = mean_auc_mouse_dros_yeast_gen[0::2]\n",
    "mean_auc_mouse_dros_yeast_fs_gen = mean_auc_mouse_dros_yeast_gen[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_org_be = mean_err_mouse_dros_yeast_be[0::2]\n",
    "mean_err_mouse_dros_yeast_fs_be = mean_err_mouse_dros_yeast_be[1::2]\n",
    "mean_auc_mouse_dros_yeast_org_be = mean_auc_mouse_dros_yeast_be[0::2]\n",
    "mean_auc_mouse_dros_yeast_fs_be = mean_auc_mouse_dros_yeast_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_dros_yeast mean strict error original -  0.254635946009\n",
      "mouse_dros_yeast mean strict error feature selection -  0.255413852752\n",
      "mouse_dros_yeast mean strict AUC original -  0.652884307558\n",
      "mouse_dros_yeast mean strict AUC feature selection -  0.651049388263\n",
      "\n",
      "\n",
      "mouse_dros_yeast mean gen error original -  0.252868631666\n",
      "mouse_dros_yeast mean gen error feature selection -  0.253714061506\n",
      "mouse_dros_yeast mean gen AUC original -  0.660851285822\n",
      "mouse_dros_yeast mean gen AUC feature selection -  0.658527858463\n",
      "\n",
      "\n",
      "mouse_dros_yeast mean BE error original -  0.253338017233\n",
      "mouse_dros_yeast mean BE error feature selection -  0.254988759226\n",
      "mouse_dros_yeast mean BE AUC original -  0.657953790648\n",
      "mouse_dros_yeast mean BE AUC feature selection -  0.654217360146\n"
     ]
    }
   ],
   "source": [
    "print('mouse_dros_yeast mean strict error original - ', np.mean(mean_err_mouse_dros_yeast_org_strict))\n",
    "print('mouse_dros_yeast mean strict error feature selection - ', np.mean(mean_err_mouse_dros_yeast_fs_strict))\n",
    "print('mouse_dros_yeast mean strict AUC original - ', np.mean(mean_auc_mouse_dros_yeast_org_strict))\n",
    "print('mouse_dros_yeast mean strict AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast mean gen error original - ', np.mean(mean_err_mouse_dros_yeast_org_gen))\n",
    "print('mouse_dros_yeast mean gen error feature selection - ', np.mean(mean_err_mouse_dros_yeast_fs_gen))\n",
    "print('mouse_dros_yeast mean gen AUC original - ', np.mean(mean_auc_mouse_dros_yeast_org_gen))\n",
    "print('mouse_dros_yeast mean gen AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast mean BE error original - ', np.mean(mean_err_mouse_dros_yeast_org_be))\n",
    "print('mouse_dros_yeast mean BE error feature selection - ', np.mean(mean_err_mouse_dros_yeast_fs_be))\n",
    "print('mouse_dros_yeast mean BE AUC original - ', np.mean(mean_auc_mouse_dros_yeast_org_be))\n",
    "print('mouse_dros_yeast mean BE AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 07:28:45,108 : INFO : loading Word2Vec object from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_SR_model\n",
      "2017-04-26 07:28:46,345 : INFO : loading wv recursively from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_SR_model.wv.* with mmap=None\n",
      "2017-04-26 07:28:46,346 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-26 07:28:46,347 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-26 07:28:46,347 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-26 07:28:46,348 : INFO : loaded Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_SR_model\n",
      "2017-04-26 07:28:46,379 : INFO : training model with 4 workers on 14788 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 07:28:46,380 : INFO : expecting 87723 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 07:28:47,409 : INFO : PROGRESS: at 9.44% examples, 845975 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 07:28:48,412 : INFO : PROGRESS: at 19.46% examples, 880301 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:28:49,412 : INFO : PROGRESS: at 29.47% examples, 892748 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:28:50,425 : INFO : PROGRESS: at 39.32% examples, 892585 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 07:28:51,425 : INFO : PROGRESS: at 49.41% examples, 899019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:28:51,608 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 07:28:51,610 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 07:28:51,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 07:28:51,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 07:28:51,621 : INFO : training on 6296340 raw words (4707581 effective words) took 5.2s, 899123 effective words/s\n",
      "2017-04-26 07:28:51,621 : WARNING : supplied example count (225220) did not equal expected count (438615)\n",
      "2017-04-26 07:28:51,622 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 07:28:51,698 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_rat_SR_model, separately None\n",
      "2017-04-26 07:28:51,699 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 07:28:51,699 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 07:28:51,700 : INFO : not storing attribute cum_table\n",
      "2017-04-26 07:28:52,022 : INFO : saved Results/mouse_dros_yeast_rat_SR_model\n",
      "2017-04-26 07:28:55,222 : INFO : loading Word2Vec object from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_GEN_model\n",
      "2017-04-26 07:28:57,466 : INFO : loading wv recursively from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_GEN_model.wv.* with mmap=None\n",
      "2017-04-26 07:28:57,468 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-26 07:28:57,468 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-26 07:28:57,469 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-26 07:28:57,469 : INFO : loaded Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_GEN_model\n",
      "2017-04-26 07:28:57,535 : INFO : training model with 4 workers on 30392 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 07:28:57,536 : INFO : expecting 485025 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 07:28:58,547 : INFO : PROGRESS: at 1.81% examples, 896822 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:28:59,554 : INFO : PROGRESS: at 3.51% examples, 866283 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:00,560 : INFO : PROGRESS: at 5.41% examples, 891094 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:01,562 : INFO : PROGRESS: at 7.26% examples, 897196 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:02,568 : INFO : PROGRESS: at 8.97% examples, 886616 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:03,576 : INFO : PROGRESS: at 10.84% examples, 892931 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:04,581 : INFO : PROGRESS: at 12.65% examples, 893620 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:05,586 : INFO : PROGRESS: at 14.40% examples, 889393 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:06,592 : INFO : PROGRESS: at 16.16% examples, 887694 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:07,594 : INFO : PROGRESS: at 17.96% examples, 888117 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:08,597 : INFO : PROGRESS: at 19.61% examples, 881529 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:09,598 : INFO : PROGRESS: at 21.49% examples, 885632 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:10,605 : INFO : PROGRESS: at 23.10% examples, 878875 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:11,613 : INFO : PROGRESS: at 24.79% examples, 875697 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:12,624 : INFO : PROGRESS: at 26.46% examples, 871741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:13,624 : INFO : PROGRESS: at 28.14% examples, 869339 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:14,628 : INFO : PROGRESS: at 29.86% examples, 868442 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:29:15,633 : INFO : PROGRESS: at 31.61% examples, 868384 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:29:16,640 : INFO : PROGRESS: at 33.16% examples, 863077 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:17,645 : INFO : PROGRESS: at 34.43% examples, 851217 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:29:18,664 : INFO : PROGRESS: at 35.68% examples, 839564 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:29:19,621 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 07:29:19,625 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 07:29:19,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 07:29:19,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 07:29:19,641 : INFO : training on 24192400 raw words (18364659 effective words) took 22.1s, 830993 effective words/s\n",
      "2017-04-26 07:29:19,642 : WARNING : supplied example count (896095) did not equal expected count (2425125)\n",
      "2017-04-26 07:29:19,643 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 07:29:19,922 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_rat_GEN_model, separately None\n",
      "2017-04-26 07:29:19,923 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 07:29:19,924 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 07:29:19,925 : INFO : not storing attribute cum_table\n",
      "2017-04-26 07:29:20,697 : INFO : saved Results/mouse_dros_yeast_rat_GEN_model\n",
      "2017-04-26 07:29:43,193 : INFO : loading Word2Vec object from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_BE_model\n",
      "2017-04-26 07:29:43,332 : INFO : loading wv recursively from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_BE_model.wv.* with mmap=None\n",
      "2017-04-26 07:29:43,337 : INFO : loading syn0 from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_BE_model.wv.syn0.npy with mmap=None\n",
      "2017-04-26 07:29:44,621 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-26 07:29:44,622 : INFO : loading syn1neg from Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_BE_model.syn1neg.npy with mmap=None\n",
      "2017-04-26 07:29:45,956 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-26 07:29:45,956 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-26 07:29:45,957 : INFO : loaded Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_BE_model\n",
      "2017-04-26 07:29:46,082 : INFO : training model with 4 workers on 64474 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 07:29:46,083 : INFO : expecting 2361617 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 07:29:47,100 : INFO : PROGRESS: at 0.34% examples, 763185 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-26 07:29:48,100 : INFO : PROGRESS: at 0.70% examples, 783054 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:49,103 : INFO : PROGRESS: at 1.08% examples, 809383 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:50,108 : INFO : PROGRESS: at 1.47% examples, 828164 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:51,115 : INFO : PROGRESS: at 1.87% examples, 840708 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:52,118 : INFO : PROGRESS: at 2.26% examples, 846791 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:53,120 : INFO : PROGRESS: at 2.62% examples, 842791 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:54,124 : INFO : PROGRESS: at 2.97% examples, 834638 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:55,133 : INFO : PROGRESS: at 3.31% examples, 826056 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:56,141 : INFO : PROGRESS: at 3.70% examples, 831593 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:29:57,144 : INFO : PROGRESS: at 4.05% examples, 827431 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-26 07:29:58,155 : INFO : PROGRESS: at 4.40% examples, 824020 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 07:29:59,161 : INFO : PROGRESS: at 4.76% examples, 823228 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:30:00,162 : INFO : PROGRESS: at 5.10% examples, 819577 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:01,175 : INFO : PROGRESS: at 5.37% examples, 805010 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 07:30:02,176 : INFO : PROGRESS: at 5.69% examples, 798586 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:03,184 : INFO : PROGRESS: at 5.98% examples, 790838 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:04,186 : INFO : PROGRESS: at 6.30% examples, 786755 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:05,190 : INFO : PROGRESS: at 6.69% examples, 791872 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:06,198 : INFO : PROGRESS: at 7.05% examples, 791771 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:07,202 : INFO : PROGRESS: at 7.40% examples, 792206 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:08,209 : INFO : PROGRESS: at 7.76% examples, 793140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:09,214 : INFO : PROGRESS: at 8.11% examples, 793061 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 07:30:10,223 : INFO : PROGRESS: at 8.46% examples, 792197 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:11,223 : INFO : PROGRESS: at 8.79% examples, 790472 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:12,235 : INFO : PROGRESS: at 9.15% examples, 790907 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:13,243 : INFO : PROGRESS: at 9.43% examples, 784585 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:14,251 : INFO : PROGRESS: at 9.74% examples, 782023 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:15,261 : INFO : PROGRESS: at 10.06% examples, 779579 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:16,267 : INFO : PROGRESS: at 10.36% examples, 775621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:17,267 : INFO : PROGRESS: at 10.69% examples, 775046 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 07:30:18,275 : INFO : PROGRESS: at 11.08% examples, 778127 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:19,298 : INFO : PROGRESS: at 11.44% examples, 778578 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:30:20,308 : INFO : PROGRESS: at 11.72% examples, 774103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:21,314 : INFO : PROGRESS: at 12.00% examples, 770001 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:22,321 : INFO : PROGRESS: at 12.34% examples, 769515 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:23,333 : INFO : PROGRESS: at 12.69% examples, 769971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:24,338 : INFO : PROGRESS: at 13.04% examples, 770152 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:30:25,344 : INFO : PROGRESS: at 13.32% examples, 766557 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:26,347 : INFO : PROGRESS: at 13.59% examples, 762801 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:27,349 : INFO : PROGRESS: at 13.91% examples, 762055 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:28,357 : INFO : PROGRESS: at 14.24% examples, 761622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:29,359 : INFO : PROGRESS: at 14.64% examples, 764513 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:30,361 : INFO : PROGRESS: at 15.03% examples, 767442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:31,370 : INFO : PROGRESS: at 15.40% examples, 768931 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:32,381 : INFO : PROGRESS: at 15.78% examples, 770343 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:33,393 : INFO : PROGRESS: at 16.13% examples, 770509 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:30:34,396 : INFO : PROGRESS: at 16.47% examples, 770344 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:35,400 : INFO : PROGRESS: at 16.84% examples, 771576 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:36,405 : INFO : PROGRESS: at 17.22% examples, 773208 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:37,422 : INFO : PROGRESS: at 17.54% examples, 772187 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:38,436 : INFO : PROGRESS: at 17.85% examples, 770813 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:39,439 : INFO : PROGRESS: at 18.16% examples, 769485 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:30:40,445 : INFO : PROGRESS: at 18.50% examples, 769300 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:41,447 : INFO : PROGRESS: at 18.89% examples, 771296 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:42,455 : INFO : PROGRESS: at 19.24% examples, 771468 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:43,458 : INFO : PROGRESS: at 19.57% examples, 771053 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 07:30:44,466 : INFO : PROGRESS: at 19.93% examples, 771620 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:30:45,474 : INFO : PROGRESS: at 20.28% examples, 771927 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:46,477 : INFO : PROGRESS: at 20.65% examples, 773040 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:47,477 : INFO : PROGRESS: at 21.03% examples, 774414 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:48,488 : INFO : PROGRESS: at 21.40% examples, 775002 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:49,493 : INFO : PROGRESS: at 21.74% examples, 774790 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:50,504 : INFO : PROGRESS: at 22.08% examples, 774861 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:51,519 : INFO : PROGRESS: at 22.44% examples, 775003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:52,529 : INFO : PROGRESS: at 22.79% examples, 775089 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 07:30:53,530 : INFO : PROGRESS: at 23.15% examples, 775837 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:54,534 : INFO : PROGRESS: at 23.50% examples, 775868 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:55,538 : INFO : PROGRESS: at 23.85% examples, 776110 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:56,554 : INFO : PROGRESS: at 24.20% examples, 776311 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:57,557 : INFO : PROGRESS: at 24.58% examples, 777302 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:58,560 : INFO : PROGRESS: at 24.96% examples, 778264 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:30:59,565 : INFO : PROGRESS: at 25.33% examples, 779190 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:00,565 : INFO : PROGRESS: at 25.70% examples, 780026 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:01,569 : INFO : PROGRESS: at 26.06% examples, 780284 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:02,580 : INFO : PROGRESS: at 26.41% examples, 780372 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:03,591 : INFO : PROGRESS: at 26.79% examples, 781255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:04,593 : INFO : PROGRESS: at 27.15% examples, 781717 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:05,594 : INFO : PROGRESS: at 27.51% examples, 782075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:06,601 : INFO : PROGRESS: at 27.88% examples, 782560 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:07,604 : INFO : PROGRESS: at 28.24% examples, 782976 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:08,616 : INFO : PROGRESS: at 28.58% examples, 782649 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 07:31:09,623 : INFO : PROGRESS: at 28.86% examples, 780884 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:10,632 : INFO : PROGRESS: at 29.15% examples, 779331 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:11,634 : INFO : PROGRESS: at 29.45% examples, 778145 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:12,641 : INFO : PROGRESS: at 29.80% examples, 778279 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:13,647 : INFO : PROGRESS: at 30.16% examples, 778607 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 07:31:14,650 : INFO : PROGRESS: at 30.54% examples, 779292 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:15,651 : INFO : PROGRESS: at 30.91% examples, 780075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:16,676 : INFO : PROGRESS: at 31.26% examples, 779856 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:17,694 : INFO : PROGRESS: at 31.61% examples, 779798 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:18,695 : INFO : PROGRESS: at 31.94% examples, 779634 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:19,705 : INFO : PROGRESS: at 32.29% examples, 779645 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:20,712 : INFO : PROGRESS: at 32.65% examples, 779925 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:21,713 : INFO : PROGRESS: at 32.94% examples, 778464 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:22,722 : INFO : PROGRESS: at 33.21% examples, 776653 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 07:31:23,738 : INFO : PROGRESS: at 33.49% examples, 775139 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:24,754 : INFO : PROGRESS: at 33.79% examples, 774052 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:25,759 : INFO : PROGRESS: at 34.12% examples, 773766 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 07:31:26,762 : INFO : PROGRESS: at 34.48% examples, 774117 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 07:31:27,777 : INFO : PROGRESS: at 34.84% examples, 774444 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-26 07:31:28,805 : INFO : PROGRESS: at 35.20% examples, 774592 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:29,809 : INFO : PROGRESS: at 35.56% examples, 774847 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:30,826 : INFO : PROGRESS: at 35.91% examples, 774918 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:31,830 : INFO : PROGRESS: at 36.27% examples, 775370 words/s, in_qsize 5, out_qsize 1\n",
      "2017-04-26 07:31:32,840 : INFO : PROGRESS: at 36.57% examples, 774260 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:33,853 : INFO : PROGRESS: at 36.81% examples, 771925 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:34,879 : INFO : PROGRESS: at 37.07% examples, 770187 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:35,888 : INFO : PROGRESS: at 37.39% examples, 769646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:36,896 : INFO : PROGRESS: at 37.75% examples, 770040 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:37,898 : INFO : PROGRESS: at 38.13% examples, 770748 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:38,902 : INFO : PROGRESS: at 38.50% examples, 771350 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:39,908 : INFO : PROGRESS: at 38.88% examples, 772063 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:40,914 : INFO : PROGRESS: at 39.22% examples, 772101 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:41,928 : INFO : PROGRESS: at 39.57% examples, 772070 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:42,933 : INFO : PROGRESS: at 39.93% examples, 772433 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:43,940 : INFO : PROGRESS: at 40.29% examples, 772718 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:44,956 : INFO : PROGRESS: at 40.58% examples, 771646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:45,971 : INFO : PROGRESS: at 40.86% examples, 770330 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:31:46,980 : INFO : PROGRESS: at 41.14% examples, 769076 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:31:47,984 : INFO : PROGRESS: at 41.41% examples, 767814 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:48,988 : INFO : PROGRESS: at 41.73% examples, 767382 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:49,995 : INFO : PROGRESS: at 42.06% examples, 767257 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:31:51,007 : INFO : PROGRESS: at 42.43% examples, 767668 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:31:52,012 : INFO : PROGRESS: at 42.77% examples, 767730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:53,019 : INFO : PROGRESS: at 43.13% examples, 768031 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:54,024 : INFO : PROGRESS: at 43.47% examples, 767913 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:31:55,033 : INFO : PROGRESS: at 43.82% examples, 768136 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:56,054 : INFO : PROGRESS: at 44.16% examples, 767985 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:31:57,060 : INFO : PROGRESS: at 44.47% examples, 767337 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:31:58,081 : INFO : PROGRESS: at 44.76% examples, 766444 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 07:31:59,084 : INFO : PROGRESS: at 45.08% examples, 766069 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:00,084 : INFO : PROGRESS: at 45.34% examples, 764847 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:01,097 : INFO : PROGRESS: at 45.67% examples, 764546 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:02,105 : INFO : PROGRESS: at 46.02% examples, 764732 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:03,108 : INFO : PROGRESS: at 46.37% examples, 764885 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:32:04,111 : INFO : PROGRESS: at 46.72% examples, 765141 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:32:05,113 : INFO : PROGRESS: at 47.07% examples, 765286 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:32:06,114 : INFO : PROGRESS: at 47.43% examples, 765665 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:32:07,120 : INFO : PROGRESS: at 47.78% examples, 765735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:08,121 : INFO : PROGRESS: at 48.12% examples, 765662 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:32:09,136 : INFO : PROGRESS: at 48.46% examples, 765687 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:10,136 : INFO : PROGRESS: at 48.81% examples, 765894 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 07:32:11,140 : INFO : PROGRESS: at 49.12% examples, 765384 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 07:32:12,143 : INFO : PROGRESS: at 49.48% examples, 765631 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:13,157 : INFO : PROGRESS: at 49.83% examples, 765812 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:14,166 : INFO : PROGRESS: at 50.20% examples, 766171 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 07:32:15,182 : INFO : PROGRESS: at 50.53% examples, 766027 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:16,199 : INFO : PROGRESS: at 50.87% examples, 765982 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:17,208 : INFO : PROGRESS: at 51.18% examples, 765421 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 07:32:18,209 : INFO : PROGRESS: at 51.46% examples, 764650 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:19,221 : INFO : PROGRESS: at 51.79% examples, 764337 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:20,227 : INFO : PROGRESS: at 52.10% examples, 764012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:21,237 : INFO : PROGRESS: at 52.45% examples, 764019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:22,244 : INFO : PROGRESS: at 52.79% examples, 764088 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 07:32:22,620 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 07:32:22,621 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 07:32:22,637 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 07:32:22,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 07:32:22,639 : INFO : training on 154634470 raw words (119633784 effective words) took 156.6s, 764178 effective words/s\n",
      "2017-04-26 07:32:22,640 : WARNING : supplied example count (6250045) did not equal expected count (11808085)\n",
      "2017-04-26 07:32:22,641 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 07:32:23,015 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_rat_BE_model, separately None\n",
      "2017-04-26 07:32:23,016 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 07:32:23,016 : INFO : storing np array 'syn0' to Results/mouse_dros_yeast_rat_BE_model.wv.syn0.npy\n",
      "2017-04-26 07:32:23,056 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 07:32:23,057 : INFO : not storing attribute cum_table\n",
      "2017-04-26 07:32:23,058 : INFO : storing np array 'syn1neg' to Results/mouse_dros_yeast_rat_BE_model.syn1neg.npy\n",
      "2017-04-26 07:32:23,253 : INFO : saved Results/mouse_dros_yeast_rat_BE_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "mouse_dros_yeast_old_SR_model = 'Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_SR_model'\n",
    "rat_SR_sentences_pkl = 'Results/rat/strict_real.pkl'\n",
    "mouse_dros_yeast_rat_SR_model = add_sentences_to_model(mouse_dros_yeast_old_SR_model, rat_SR_sentences_pkl, 'mouse_dros_yeast_rat_SR_model')\n",
    "\n",
    "#Gen model\n",
    "mouse_dros_yeast_old_GEN_model = 'Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_GEN_model'\n",
    "rat_GEN_sentences_pkl = 'Results/rat/gen_real.pkl'\n",
    "mouse_dros_yeast_rat_GEN_model = add_sentences_to_model(mouse_dros_yeast_old_GEN_model, rat_GEN_sentences_pkl, 'mouse_dros_yeast_rat_GEN_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "mouse_dros_yeast_old_BE_model = 'Results/mouse_dros_yeast/Seeded/Results/mouse_dros_yeast_BE_model'\n",
    "rat_BE_sentences_pkl = 'Results/rat/be_real.pkl'\n",
    "mouse_dros_yeast_rat_BE_model = add_sentences_to_model(mouse_dros_yeast_old_BE_model, rat_BE_sentences_pkl, 'mouse_dros_yeast_rat_BE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "mouse_strict_real = pickle.load(open('Results/mouse/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_rat_SR_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_rat_SR_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_rat_GEN_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_rat_GEN_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_merger = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_rat_BE_merger_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_rat_BE_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_merger, \n",
    "                         strict_list_GEN_merger, \n",
    "                         strict_list_BE_merger]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/mouse_dros_yeast_rat_merger_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/mouse_dros_yeast_rat_merger_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/mouse_dros_yeast_rat_merger_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse_dros_yeast_rat/Seeded/Results/'\n",
    "errors_mouse_dros_yeast_rat = mult_open(drct, '_errors_')\n",
    "fpr_mouse_dros_yeast_rat = mult_open(drct, '_fpr_')\n",
    "tpr_mouse_dros_yeast_rat = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse_dros_yeast_rat auc=0.618 error=0.392\n",
      "Strict error mouse_dros_yeast_rat auc=0.615 error=0.391\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.626 error=0.386\n",
      "Gen error mouse_dros_yeast_rat auc=0.615 error=0.389\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.628 error=0.386\n",
      "BE error mouse_dros_yeast_rat auc=0.619 error=0.389\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.675 error=0.303\n",
      "Strict error mouse_dros_yeast_rat auc=0.670 error=0.305\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.676 error=0.306\n",
      "Gen error mouse_dros_yeast_rat auc=0.673 error=0.305\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.673 error=0.309\n",
      "BE error mouse_dros_yeast_rat auc=0.673 error=0.303\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.672 error=0.258\n",
      "Strict error mouse_dros_yeast_rat auc=0.669 error=0.262\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.674 error=0.260\n",
      "Gen error mouse_dros_yeast_rat auc=0.671 error=0.263\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.677 error=0.259\n",
      "BE error mouse_dros_yeast_rat auc=0.676 error=0.259\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.592 error=0.308\n",
      "Strict error mouse_dros_yeast_rat auc=0.592 error=0.304\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.596 error=0.304\n",
      "Gen error mouse_dros_yeast_rat auc=0.595 error=0.304\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.586 error=0.311\n",
      "BE error mouse_dros_yeast_rat auc=0.582 error=0.311\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.652 error=0.342\n",
      "Strict error mouse_dros_yeast_rat auc=0.647 error=0.340\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.662 error=0.336\n",
      "Gen error mouse_dros_yeast_rat auc=0.655 error=0.336\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.654 error=0.341\n",
      "BE error mouse_dros_yeast_rat auc=0.648 error=0.339\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.692 error=0.331\n",
      "Strict error mouse_dros_yeast_rat auc=0.689 error=0.333\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.701 error=0.331\n",
      "Gen error mouse_dros_yeast_rat auc=0.696 error=0.332\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.687 error=0.331\n",
      "BE error mouse_dros_yeast_rat auc=0.680 error=0.331\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.638 error=0.309\n",
      "Strict error mouse_dros_yeast_rat auc=0.638 error=0.309\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.650 error=0.307\n",
      "Gen error mouse_dros_yeast_rat auc=0.646 error=0.308\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.648 error=0.306\n",
      "BE error mouse_dros_yeast_rat auc=0.645 error=0.308\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.727 error=0.185\n",
      "Strict error mouse_dros_yeast_rat auc=0.727 error=0.183\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.721 error=0.182\n",
      "Gen error mouse_dros_yeast_rat auc=0.722 error=0.182\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.727 error=0.184\n",
      "BE error mouse_dros_yeast_rat auc=0.725 error=0.184\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.662 error=0.353\n",
      "Strict error mouse_dros_yeast_rat auc=0.662 error=0.351\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.682 error=0.343\n",
      "Gen error mouse_dros_yeast_rat auc=0.680 error=0.343\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.682 error=0.345\n",
      "BE error mouse_dros_yeast_rat auc=0.675 error=0.344\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat auc=0.695 error=0.244\n",
      "Strict error mouse_dros_yeast_rat auc=0.690 error=0.246\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat auc=0.694 error=0.244\n",
      "Gen error mouse_dros_yeast_rat auc=0.695 error=0.247\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat auc=0.692 error=0.246\n",
      "BE error mouse_dros_yeast_rat auc=0.687 error=0.246\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_dros_yeast_rat_strict = []\n",
    "mean_auc_mouse_dros_yeast_rat_strict = []\n",
    "mean_err_mouse_dros_yeast_rat_gen = []\n",
    "mean_auc_mouse_dros_yeast_rat_gen = []\n",
    "mean_err_mouse_dros_yeast_rat_be = []\n",
    "mean_auc_mouse_dros_yeast_rat_be = []\n",
    "for e, f, t in zip(errors_mouse_dros_yeast_rat, fpr_mouse_dros_yeast_rat, tpr_mouse_dros_yeast_rat):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse_dros_yeast_rat']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_dros_yeast_rat_strict.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_rat_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_dros_yeast_rat_gen.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_rat_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_dros_yeast_rat_be.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_rat_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_dros_yeast_rat_org_strict = mean_err_mouse_dros_yeast_rat_strict[0::2]\n",
    "mean_err_mouse_dros_yeast_rat_fs_strict = mean_err_mouse_dros_yeast_rat_strict[1::2]\n",
    "mean_auc_mouse_dros_yeast_rat_org_strict = mean_auc_mouse_dros_yeast_rat_strict[0::2]\n",
    "mean_auc_mouse_dros_yeast_rat_fs_strict = mean_auc_mouse_dros_yeast_rat_strict[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_rat_org_gen = mean_err_mouse_dros_yeast_rat_gen[0::2]\n",
    "mean_err_mouse_dros_yeast_rat_fs_gen = mean_err_mouse_dros_yeast_rat_gen[1::2]\n",
    "mean_auc_mouse_dros_yeast_rat_org_gen = mean_auc_mouse_dros_yeast_rat_gen[0::2]\n",
    "mean_auc_mouse_dros_yeast_rat_fs_gen = mean_auc_mouse_dros_yeast_rat_gen[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_rat_org_be = mean_err_mouse_dros_yeast_rat_be[0::2]\n",
    "mean_err_mouse_dros_yeast_rat_fs_be = mean_err_mouse_dros_yeast_rat_be[1::2]\n",
    "mean_auc_mouse_dros_yeast_rat_org_be = mean_auc_mouse_dros_yeast_rat_be[0::2]\n",
    "mean_auc_mouse_dros_yeast_rat_fs_be = mean_auc_mouse_dros_yeast_rat_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_dros_yeast_rat mean strict error original -  0.30261353062\n",
      "mouse_dros_yeast_rat mean strict error feature selection -  0.302456729326\n",
      "mouse_dros_yeast_rat mean strict AUC original -  0.662256013476\n",
      "mouse_dros_yeast_rat mean strict AUC feature selection -  0.659919624834\n",
      "\n",
      "\n",
      "mouse_dros_yeast_rat mean gen error original -  0.299834541801\n",
      "mouse_dros_yeast_rat mean gen error feature selection -  0.300926981872\n",
      "mouse_dros_yeast_rat mean gen AUC original -  0.668107156797\n",
      "mouse_dros_yeast_rat mean gen AUC feature selection -  0.664706326996\n",
      "\n",
      "\n",
      "mouse_dros_yeast_rat mean BE error original -  0.301784777453\n",
      "mouse_dros_yeast_rat mean BE error feature selection -  0.301401520341\n",
      "mouse_dros_yeast_rat mean BE AUC original -  0.665265260023\n",
      "mouse_dros_yeast_rat mean BE AUC feature selection -  0.660879945684\n"
     ]
    }
   ],
   "source": [
    "print('mouse_dros_yeast_rat mean strict error original - ', np.mean(mean_err_mouse_dros_yeast_rat_org_strict))\n",
    "print('mouse_dros_yeast_rat mean strict error feature selection - ', np.mean(mean_err_mouse_dros_yeast_rat_fs_strict))\n",
    "print('mouse_dros_yeast_rat mean strict AUC original - ', np.mean(mean_auc_mouse_dros_yeast_rat_org_strict))\n",
    "print('mouse_dros_yeast_rat mean strict AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_rat_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast_rat mean gen error original - ', np.mean(mean_err_mouse_dros_yeast_rat_org_gen))\n",
    "print('mouse_dros_yeast_rat mean gen error feature selection - ', np.mean(mean_err_mouse_dros_yeast_rat_fs_gen))\n",
    "print('mouse_dros_yeast_rat mean gen AUC original - ', np.mean(mean_auc_mouse_dros_yeast_rat_org_gen))\n",
    "print('mouse_dros_yeast_rat mean gen AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_rat_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast_rat mean BE error original - ', np.mean(mean_err_mouse_dros_yeast_rat_org_be))\n",
    "print('mouse_dros_yeast_rat mean BE error feature selection - ', np.mean(mean_err_mouse_dros_yeast_rat_fs_be))\n",
    "print('mouse_dros_yeast_rat mean BE AUC original - ', np.mean(mean_auc_mouse_dros_yeast_rat_org_be))\n",
    "print('mouse_dros_yeast_rat mean BE AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_rat_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 11:18:59,628 : INFO : collecting all words and their counts\n",
      "2017-04-26 11:18:59,629 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-26 11:18:59,683 : INFO : PROGRESS: at sentence #10000, processed 269789 words, keeping 16716 word types\n",
      "2017-04-26 11:18:59,736 : INFO : PROGRESS: at sentence #20000, processed 542207 words, keeping 23363 word types\n",
      "2017-04-26 11:18:59,789 : INFO : PROGRESS: at sentence #30000, processed 812578 words, keeping 28247 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 11:18:59,839 : INFO : PROGRESS: at sentence #40000, processed 1081566 words, keeping 32229 word types\n",
      "2017-04-26 11:18:59,906 : INFO : PROGRESS: at sentence #50000, processed 1351116 words, keeping 35713 word types\n",
      "2017-04-26 11:18:59,958 : INFO : PROGRESS: at sentence #60000, processed 1620004 words, keeping 38860 word types\n",
      "2017-04-26 11:19:00,012 : INFO : PROGRESS: at sentence #70000, processed 1890201 words, keeping 41626 word types\n",
      "2017-04-26 11:19:00,071 : INFO : PROGRESS: at sentence #80000, processed 2160110 words, keeping 44267 word types\n",
      "2017-04-26 11:19:00,130 : INFO : PROGRESS: at sentence #90000, processed 2427196 words, keeping 47375 word types\n",
      "2017-04-26 11:19:00,161 : INFO : collected 49369 word types from a corpus of 2554436 raw words and 94994 sentences\n",
      "2017-04-26 11:19:00,161 : INFO : Loading a fresh vocabulary\n",
      "2017-04-26 11:19:00,217 : INFO : min_count=5 retains 15664 unique words (31% of original 49369, drops 33705)\n",
      "2017-04-26 11:19:00,218 : INFO : min_count=5 leaves 2500884 word corpus (97% of original 2554436, drops 53552)\n",
      "2017-04-26 11:19:00,254 : INFO : deleting the raw counts dictionary of 49369 items\n",
      "2017-04-26 11:19:00,258 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2017-04-26 11:19:00,258 : INFO : downsampling leaves estimated 1920249 word corpus (76.8% of prior 2500884)\n",
      "2017-04-26 11:19:00,259 : INFO : estimated required memory for 15664 words and 300 dimensions: 45425600 bytes\n",
      "2017-04-26 11:19:00,318 : INFO : resetting layer weights\n",
      "2017-04-26 11:19:00,540 : INFO : training model with 4 workers on 15664 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 11:19:00,540 : INFO : expecting 94994 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 11:19:01,549 : INFO : PROGRESS: at 8.71% examples, 837868 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:02,552 : INFO : PROGRESS: at 17.75% examples, 853815 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:03,553 : INFO : PROGRESS: at 26.77% examples, 856081 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:04,559 : INFO : PROGRESS: at 35.04% examples, 840163 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:05,571 : INFO : PROGRESS: at 42.75% examples, 816957 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:06,579 : INFO : PROGRESS: at 51.77% examples, 825138 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:07,583 : INFO : PROGRESS: at 60.12% examples, 820279 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:08,584 : INFO : PROGRESS: at 67.35% examples, 804997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:09,594 : INFO : PROGRESS: at 74.45% examples, 790749 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:10,622 : INFO : PROGRESS: at 80.91% examples, 770993 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:19:11,633 : INFO : PROGRESS: at 86.81% examples, 752175 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:12,634 : INFO : PROGRESS: at 93.52% examples, 743422 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 11:19:13,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 11:19:13,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 11:19:13,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 11:19:13,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 11:19:13,468 : INFO : training on 12772180 raw words (9601437 effective words) took 12.9s, 742966 effective words/s\n",
      "2017-04-26 11:19:13,469 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 11:19:13,545 : INFO : saving Word2Vec object under Results/mouse_dros_SR_comb_model, separately None\n",
      "2017-04-26 11:19:13,546 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 11:19:13,546 : INFO : not storing attribute cum_table\n",
      "2017-04-26 11:19:13,844 : INFO : saved Results/mouse_dros_SR_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 11:19:24,294 : INFO : collecting all words and their counts\n",
      "2017-04-26 11:19:24,295 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-26 11:19:24,341 : INFO : PROGRESS: at sentence #10000, processed 258398 words, keeping 15392 word types\n",
      "2017-04-26 11:19:24,388 : INFO : PROGRESS: at sentence #20000, processed 514724 words, keeping 21105 word types\n",
      "2017-04-26 11:19:24,437 : INFO : PROGRESS: at sentence #30000, processed 773467 words, keeping 25447 word types\n",
      "2017-04-26 11:19:24,485 : INFO : PROGRESS: at sentence #40000, processed 1033384 words, keeping 29056 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 11:19:24,535 : INFO : PROGRESS: at sentence #50000, processed 1291025 words, keeping 32043 word types\n",
      "2017-04-26 11:19:24,584 : INFO : PROGRESS: at sentence #60000, processed 1550163 words, keeping 34739 word types\n",
      "2017-04-26 11:19:24,632 : INFO : PROGRESS: at sentence #70000, processed 1808287 words, keeping 37113 word types\n",
      "2017-04-26 11:19:24,681 : INFO : PROGRESS: at sentence #80000, processed 2067200 words, keeping 39317 word types\n",
      "2017-04-26 11:19:24,730 : INFO : PROGRESS: at sentence #90000, processed 2324506 words, keeping 41429 word types\n",
      "2017-04-26 11:19:24,779 : INFO : PROGRESS: at sentence #100000, processed 2583873 words, keeping 43383 word types\n",
      "2017-04-26 11:19:24,831 : INFO : PROGRESS: at sentence #110000, processed 2841003 words, keeping 45209 word types\n",
      "2017-04-26 11:19:24,881 : INFO : PROGRESS: at sentence #120000, processed 3099823 words, keeping 46934 word types\n",
      "2017-04-26 11:19:24,933 : INFO : PROGRESS: at sentence #130000, processed 3359249 words, keeping 48596 word types\n",
      "2017-04-26 11:19:24,984 : INFO : PROGRESS: at sentence #140000, processed 3617839 words, keeping 50200 word types\n",
      "2017-04-26 11:19:25,034 : INFO : PROGRESS: at sentence #150000, processed 3876151 words, keeping 51680 word types\n",
      "2017-04-26 11:19:25,081 : INFO : PROGRESS: at sentence #160000, processed 4134335 words, keeping 53119 word types\n",
      "2017-04-26 11:19:25,129 : INFO : PROGRESS: at sentence #170000, processed 4394838 words, keeping 54490 word types\n",
      "2017-04-26 11:19:25,176 : INFO : PROGRESS: at sentence #180000, processed 4650562 words, keeping 55884 word types\n",
      "2017-04-26 11:19:25,223 : INFO : PROGRESS: at sentence #190000, processed 4910131 words, keeping 57181 word types\n",
      "2017-04-26 11:19:25,270 : INFO : PROGRESS: at sentence #200000, processed 5168205 words, keeping 58410 word types\n",
      "2017-04-26 11:19:25,317 : INFO : PROGRESS: at sentence #210000, processed 5425935 words, keeping 59635 word types\n",
      "2017-04-26 11:19:25,364 : INFO : PROGRESS: at sentence #220000, processed 5682571 words, keeping 60858 word types\n",
      "2017-04-26 11:19:25,411 : INFO : PROGRESS: at sentence #230000, processed 5939745 words, keeping 61986 word types\n",
      "2017-04-26 11:19:25,458 : INFO : PROGRESS: at sentence #240000, processed 6197294 words, keeping 63084 word types\n",
      "2017-04-26 11:19:25,506 : INFO : PROGRESS: at sentence #250000, processed 6455493 words, keeping 64204 word types\n",
      "2017-04-26 11:19:25,554 : INFO : PROGRESS: at sentence #260000, processed 6714305 words, keeping 65313 word types\n",
      "2017-04-26 11:19:25,601 : INFO : PROGRESS: at sentence #270000, processed 6974828 words, keeping 66277 word types\n",
      "2017-04-26 11:19:25,649 : INFO : PROGRESS: at sentence #280000, processed 7234074 words, keeping 67319 word types\n",
      "2017-04-26 11:19:25,696 : INFO : PROGRESS: at sentence #290000, processed 7491827 words, keeping 68285 word types\n",
      "2017-04-26 11:19:25,752 : INFO : PROGRESS: at sentence #300000, processed 7751263 words, keeping 69203 word types\n",
      "2017-04-26 11:19:25,799 : INFO : PROGRESS: at sentence #310000, processed 8008265 words, keeping 70162 word types\n",
      "2017-04-26 11:19:25,847 : INFO : PROGRESS: at sentence #320000, processed 8267359 words, keeping 71099 word types\n",
      "2017-04-26 11:19:25,895 : INFO : PROGRESS: at sentence #330000, processed 8525624 words, keeping 71952 word types\n",
      "2017-04-26 11:19:25,943 : INFO : PROGRESS: at sentence #340000, processed 8786023 words, keeping 72823 word types\n",
      "2017-04-26 11:19:25,991 : INFO : PROGRESS: at sentence #350000, processed 9046842 words, keeping 73706 word types\n",
      "2017-04-26 11:19:26,038 : INFO : PROGRESS: at sentence #360000, processed 9305877 words, keeping 74581 word types\n",
      "2017-04-26 11:19:26,086 : INFO : PROGRESS: at sentence #370000, processed 9564092 words, keeping 75419 word types\n",
      "2017-04-26 11:19:26,134 : INFO : PROGRESS: at sentence #380000, processed 9822483 words, keeping 76230 word types\n",
      "2017-04-26 11:19:26,181 : INFO : PROGRESS: at sentence #390000, processed 10079063 words, keeping 77103 word types\n",
      "2017-04-26 11:19:26,236 : INFO : PROGRESS: at sentence #400000, processed 10336854 words, keeping 77934 word types\n",
      "2017-04-26 11:19:26,290 : INFO : PROGRESS: at sentence #410000, processed 10597060 words, keeping 78709 word types\n",
      "2017-04-26 11:19:26,351 : INFO : PROGRESS: at sentence #420000, processed 10856360 words, keeping 79490 word types\n",
      "2017-04-26 11:19:26,405 : INFO : PROGRESS: at sentence #430000, processed 11114301 words, keeping 80277 word types\n",
      "2017-04-26 11:19:26,461 : INFO : PROGRESS: at sentence #440000, processed 11370527 words, keeping 81055 word types\n",
      "2017-04-26 11:19:26,511 : INFO : PROGRESS: at sentence #450000, processed 11630104 words, keeping 81836 word types\n",
      "2017-04-26 11:19:26,559 : INFO : PROGRESS: at sentence #460000, processed 11889176 words, keeping 82574 word types\n",
      "2017-04-26 11:19:26,606 : INFO : PROGRESS: at sentence #470000, processed 12148479 words, keeping 83296 word types\n",
      "2017-04-26 11:19:26,655 : INFO : PROGRESS: at sentence #480000, processed 12406430 words, keeping 84035 word types\n",
      "2017-04-26 11:19:26,703 : INFO : PROGRESS: at sentence #490000, processed 12656564 words, keeping 85642 word types\n",
      "2017-04-26 11:19:26,752 : INFO : PROGRESS: at sentence #500000, processed 12899946 words, keeping 87351 word types\n",
      "2017-04-26 11:19:26,801 : INFO : PROGRESS: at sentence #510000, processed 13144712 words, keeping 88717 word types\n",
      "2017-04-26 11:19:26,848 : INFO : PROGRESS: at sentence #520000, processed 13388109 words, keeping 89916 word types\n",
      "2017-04-26 11:19:26,860 : INFO : collected 90171 word types from a corpus of 13437237 raw words and 522042 sentences\n",
      "2017-04-26 11:19:26,861 : INFO : Loading a fresh vocabulary\n",
      "2017-04-26 11:19:26,956 : INFO : min_count=5 retains 32214 unique words (35% of original 90171, drops 57957)\n",
      "2017-04-26 11:19:26,956 : INFO : min_count=5 leaves 13341716 word corpus (99% of original 13437237, drops 95521)\n",
      "2017-04-26 11:19:27,024 : INFO : deleting the raw counts dictionary of 90171 items\n",
      "2017-04-26 11:19:27,029 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2017-04-26 11:19:27,030 : INFO : downsampling leaves estimated 10218482 word corpus (76.6% of prior 13341716)\n",
      "2017-04-26 11:19:27,031 : INFO : estimated required memory for 32214 words and 300 dimensions: 93420600 bytes\n",
      "2017-04-26 11:19:27,141 : INFO : resetting layer weights\n",
      "2017-04-26 11:19:27,493 : INFO : training model with 4 workers on 32214 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 11:19:27,493 : INFO : expecting 522042 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 11:19:28,501 : INFO : PROGRESS: at 1.44% examples, 734456 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:19:29,506 : INFO : PROGRESS: at 2.92% examples, 746075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:30,509 : INFO : PROGRESS: at 4.58% examples, 780245 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:31,512 : INFO : PROGRESS: at 6.11% examples, 781916 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:19:32,514 : INFO : PROGRESS: at 7.79% examples, 797025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:33,519 : INFO : PROGRESS: at 9.38% examples, 799079 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:34,545 : INFO : PROGRESS: at 10.90% examples, 793792 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:35,546 : INFO : PROGRESS: at 12.47% examples, 795042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:36,549 : INFO : PROGRESS: at 14.01% examples, 795100 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:37,559 : INFO : PROGRESS: at 15.63% examples, 797569 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:38,571 : INFO : PROGRESS: at 16.96% examples, 786342 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:39,574 : INFO : PROGRESS: at 18.35% examples, 780157 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:40,582 : INFO : PROGRESS: at 19.78% examples, 773045 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:41,587 : INFO : PROGRESS: at 21.37% examples, 774921 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:42,599 : INFO : PROGRESS: at 22.99% examples, 778407 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:43,621 : INFO : PROGRESS: at 24.48% examples, 776169 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:44,631 : INFO : PROGRESS: at 25.97% examples, 775235 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:45,634 : INFO : PROGRESS: at 27.61% examples, 778865 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:46,644 : INFO : PROGRESS: at 29.16% examples, 779048 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:19:47,646 : INFO : PROGRESS: at 30.86% examples, 783683 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:48,649 : INFO : PROGRESS: at 32.49% examples, 786008 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:49,653 : INFO : PROGRESS: at 33.99% examples, 785398 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:19:50,656 : INFO : PROGRESS: at 35.68% examples, 788752 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:51,658 : INFO : PROGRESS: at 37.31% examples, 790635 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:52,661 : INFO : PROGRESS: at 39.04% examples, 793753 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:53,664 : INFO : PROGRESS: at 40.47% examples, 790174 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:54,670 : INFO : PROGRESS: at 41.68% examples, 783798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:55,681 : INFO : PROGRESS: at 42.70% examples, 774310 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:56,683 : INFO : PROGRESS: at 43.72% examples, 765686 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:57,709 : INFO : PROGRESS: at 45.06% examples, 762327 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 11:19:58,714 : INFO : PROGRESS: at 46.76% examples, 765786 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:19:59,715 : INFO : PROGRESS: at 48.36% examples, 767471 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:00,717 : INFO : PROGRESS: at 49.98% examples, 769232 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:01,724 : INFO : PROGRESS: at 51.47% examples, 769018 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:02,732 : INFO : PROGRESS: at 53.12% examples, 771166 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:03,740 : INFO : PROGRESS: at 54.76% examples, 772980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:04,743 : INFO : PROGRESS: at 56.45% examples, 775417 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:05,752 : INFO : PROGRESS: at 57.89% examples, 774229 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:06,754 : INFO : PROGRESS: at 59.15% examples, 770461 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:07,772 : INFO : PROGRESS: at 60.34% examples, 765409 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 11:20:08,788 : INFO : PROGRESS: at 61.52% examples, 761281 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:09,793 : INFO : PROGRESS: at 62.90% examples, 759932 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:10,803 : INFO : PROGRESS: at 64.38% examples, 759746 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:20:11,811 : INFO : PROGRESS: at 66.02% examples, 761488 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:12,819 : INFO : PROGRESS: at 67.50% examples, 761332 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:13,826 : INFO : PROGRESS: at 69.02% examples, 761502 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:14,835 : INFO : PROGRESS: at 70.57% examples, 762137 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:20:15,860 : INFO : PROGRESS: at 72.17% examples, 762941 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:16,863 : INFO : PROGRESS: at 73.70% examples, 763446 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 11:20:17,863 : INFO : PROGRESS: at 75.26% examples, 764126 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:20:18,868 : INFO : PROGRESS: at 76.81% examples, 764717 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:19,873 : INFO : PROGRESS: at 78.33% examples, 764975 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:20:20,875 : INFO : PROGRESS: at 79.91% examples, 764883 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:21,884 : INFO : PROGRESS: at 81.51% examples, 765770 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:22,891 : INFO : PROGRESS: at 83.02% examples, 765864 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:23,896 : INFO : PROGRESS: at 84.67% examples, 767176 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:24,905 : INFO : PROGRESS: at 86.32% examples, 768515 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:25,912 : INFO : PROGRESS: at 87.88% examples, 768915 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:26,915 : INFO : PROGRESS: at 89.54% examples, 770272 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:20:27,917 : INFO : PROGRESS: at 91.23% examples, 771836 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:28,925 : INFO : PROGRESS: at 92.84% examples, 772651 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:29,932 : INFO : PROGRESS: at 94.04% examples, 770170 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:30,942 : INFO : PROGRESS: at 95.17% examples, 767000 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:31,952 : INFO : PROGRESS: at 96.25% examples, 763589 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:32,953 : INFO : PROGRESS: at 97.32% examples, 760253 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:33,960 : INFO : PROGRESS: at 98.61% examples, 758681 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:20:34,894 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 11:20:34,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 11:20:34,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 11:20:34,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 11:20:34,915 : INFO : training on 67186185 raw words (51090412 effective words) took 67.4s, 757827 effective words/s\n",
      "2017-04-26 11:20:34,916 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 11:20:35,224 : INFO : saving Word2Vec object under Results/mouse_dros_GEN_comb_model, separately None\n",
      "2017-04-26 11:20:35,225 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 11:20:35,226 : INFO : not storing attribute cum_table\n",
      "2017-04-26 11:20:36,768 : INFO : saved Results/mouse_dros_GEN_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 11:22:23,816 : INFO : collecting all words and their counts\n",
      "2017-04-26 11:22:24,622 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-26 11:22:24,674 : INFO : PROGRESS: at sentence #10000, processed 238241 words, keeping 15816 word types\n",
      "2017-04-26 11:22:24,716 : INFO : PROGRESS: at sentence #20000, processed 478973 words, keeping 21988 word types\n",
      "2017-04-26 11:22:24,758 : INFO : PROGRESS: at sentence #30000, processed 717276 words, keeping 26555 word types\n",
      "2017-04-26 11:22:24,800 : INFO : PROGRESS: at sentence #40000, processed 955496 words, keeping 30327 word types\n",
      "2017-04-26 11:22:24,842 : INFO : PROGRESS: at sentence #50000, processed 1194847 words, keeping 33562 word types\n",
      "2017-04-26 11:22:24,884 : INFO : PROGRESS: at sentence #60000, processed 1433921 words, keeping 36450 word types\n",
      "2017-04-26 11:22:24,926 : INFO : PROGRESS: at sentence #70000, processed 1672948 words, keeping 39141 word types\n",
      "2017-04-26 11:22:24,968 : INFO : PROGRESS: at sentence #80000, processed 1912779 words, keeping 41526 word types\n",
      "2017-04-26 11:22:25,012 : INFO : PROGRESS: at sentence #90000, processed 2153473 words, keeping 43788 word types\n",
      "2017-04-26 11:22:25,055 : INFO : PROGRESS: at sentence #100000, processed 2391990 words, keeping 45916 word types\n",
      "2017-04-26 11:22:25,097 : INFO : PROGRESS: at sentence #110000, processed 2630206 words, keeping 47860 word types\n",
      "2017-04-26 11:22:25,139 : INFO : PROGRESS: at sentence #120000, processed 2870369 words, keeping 49839 word types\n",
      "2017-04-26 11:22:25,182 : INFO : PROGRESS: at sentence #130000, processed 3110005 words, keeping 51722 word types\n",
      "2017-04-26 11:22:25,226 : INFO : PROGRESS: at sentence #140000, processed 3348731 words, keeping 53437 word types\n",
      "2017-04-26 11:22:25,269 : INFO : PROGRESS: at sentence #150000, processed 3587810 words, keeping 55089 word types\n",
      "2017-04-26 11:22:25,311 : INFO : PROGRESS: at sentence #160000, processed 3827104 words, keeping 56674 word types\n",
      "2017-04-26 11:22:25,354 : INFO : PROGRESS: at sentence #170000, processed 4066652 words, keeping 58115 word types\n",
      "2017-04-26 11:22:25,397 : INFO : PROGRESS: at sentence #180000, processed 4303687 words, keeping 59614 word types\n",
      "2017-04-26 11:22:25,440 : INFO : PROGRESS: at sentence #190000, processed 4542556 words, keeping 61077 word types\n",
      "2017-04-26 11:22:25,482 : INFO : PROGRESS: at sentence #200000, processed 4781381 words, keeping 62451 word types\n",
      "2017-04-26 11:22:25,525 : INFO : PROGRESS: at sentence #210000, processed 5021381 words, keeping 63868 word types\n",
      "2017-04-26 11:22:25,568 : INFO : PROGRESS: at sentence #220000, processed 5260576 words, keeping 65211 word types\n",
      "2017-04-26 11:22:25,611 : INFO : PROGRESS: at sentence #230000, processed 5500570 words, keeping 66494 word types\n",
      "2017-04-26 11:22:25,654 : INFO : PROGRESS: at sentence #240000, processed 5738929 words, keeping 67657 word types\n",
      "2017-04-26 11:22:25,698 : INFO : PROGRESS: at sentence #250000, processed 5978236 words, keeping 68903 word types\n",
      "2017-04-26 11:22:25,742 : INFO : PROGRESS: at sentence #260000, processed 6218725 words, keeping 70071 word types\n",
      "2017-04-26 11:22:25,786 : INFO : PROGRESS: at sentence #270000, processed 6458056 words, keeping 71243 word types\n",
      "2017-04-26 11:22:25,830 : INFO : PROGRESS: at sentence #280000, processed 6698862 words, keeping 72362 word types\n",
      "2017-04-26 11:22:25,873 : INFO : PROGRESS: at sentence #290000, processed 6938853 words, keeping 73563 word types\n",
      "2017-04-26 11:22:25,917 : INFO : PROGRESS: at sentence #300000, processed 7178020 words, keeping 74673 word types\n",
      "2017-04-26 11:22:25,961 : INFO : PROGRESS: at sentence #310000, processed 7415896 words, keeping 75726 word types\n",
      "2017-04-26 11:22:26,005 : INFO : PROGRESS: at sentence #320000, processed 7656467 words, keeping 76762 word types\n",
      "2017-04-26 11:22:26,049 : INFO : PROGRESS: at sentence #330000, processed 7895544 words, keeping 77847 word types\n",
      "2017-04-26 11:22:26,094 : INFO : PROGRESS: at sentence #340000, processed 8134471 words, keeping 78902 word types\n",
      "2017-04-26 11:22:26,139 : INFO : PROGRESS: at sentence #350000, processed 8373410 words, keeping 79907 word types\n",
      "2017-04-26 11:22:26,184 : INFO : PROGRESS: at sentence #360000, processed 8613184 words, keeping 80878 word types\n",
      "2017-04-26 11:22:26,229 : INFO : PROGRESS: at sentence #370000, processed 8853217 words, keeping 81887 word types\n",
      "2017-04-26 11:22:26,272 : INFO : PROGRESS: at sentence #380000, processed 9092271 words, keeping 82864 word types\n",
      "2017-04-26 11:22:26,316 : INFO : PROGRESS: at sentence #390000, processed 9331227 words, keeping 83804 word types\n",
      "2017-04-26 11:22:26,360 : INFO : PROGRESS: at sentence #400000, processed 9571558 words, keeping 84706 word types\n",
      "2017-04-26 11:22:26,405 : INFO : PROGRESS: at sentence #410000, processed 9810816 words, keeping 85643 word types\n",
      "2017-04-26 11:22:26,449 : INFO : PROGRESS: at sentence #420000, processed 10050134 words, keeping 86557 word types\n",
      "2017-04-26 11:22:26,497 : INFO : PROGRESS: at sentence #430000, processed 10289559 words, keeping 87410 word types\n",
      "2017-04-26 11:22:26,543 : INFO : PROGRESS: at sentence #440000, processed 10527359 words, keeping 88290 word types\n",
      "2017-04-26 11:22:26,588 : INFO : PROGRESS: at sentence #450000, processed 10767140 words, keeping 89163 word types\n",
      "2017-04-26 11:22:26,632 : INFO : PROGRESS: at sentence #460000, processed 11007357 words, keeping 90023 word types\n",
      "2017-04-26 11:22:26,676 : INFO : PROGRESS: at sentence #470000, processed 11245149 words, keeping 90846 word types\n",
      "2017-04-26 11:22:26,722 : INFO : PROGRESS: at sentence #480000, processed 11484060 words, keeping 91713 word types\n",
      "2017-04-26 11:22:26,769 : INFO : PROGRESS: at sentence #490000, processed 11724592 words, keeping 92472 word types\n",
      "2017-04-26 11:22:26,814 : INFO : PROGRESS: at sentence #500000, processed 11964844 words, keeping 93360 word types\n",
      "2017-04-26 11:22:26,858 : INFO : PROGRESS: at sentence #510000, processed 12203714 words, keeping 94141 word types\n",
      "2017-04-26 11:22:26,902 : INFO : PROGRESS: at sentence #520000, processed 12442217 words, keeping 94972 word types\n",
      "2017-04-26 11:22:26,947 : INFO : PROGRESS: at sentence #530000, processed 12681607 words, keeping 95771 word types\n",
      "2017-04-26 11:22:26,991 : INFO : PROGRESS: at sentence #540000, processed 12921347 words, keeping 96547 word types\n",
      "2017-04-26 11:22:27,036 : INFO : PROGRESS: at sentence #550000, processed 13161558 words, keeping 97294 word types\n",
      "2017-04-26 11:22:27,080 : INFO : PROGRESS: at sentence #560000, processed 13401037 words, keeping 98091 word types\n",
      "2017-04-26 11:22:27,125 : INFO : PROGRESS: at sentence #570000, processed 13640620 words, keeping 98835 word types\n",
      "2017-04-26 11:22:27,169 : INFO : PROGRESS: at sentence #580000, processed 13879525 words, keeping 99583 word types\n",
      "2017-04-26 11:22:27,214 : INFO : PROGRESS: at sentence #590000, processed 14119691 words, keeping 100331 word types\n",
      "2017-04-26 11:22:27,258 : INFO : PROGRESS: at sentence #600000, processed 14359882 words, keeping 101053 word types\n",
      "2017-04-26 11:22:27,302 : INFO : PROGRESS: at sentence #610000, processed 14598119 words, keeping 101777 word types\n",
      "2017-04-26 11:22:27,346 : INFO : PROGRESS: at sentence #620000, processed 14837474 words, keeping 102522 word types\n",
      "2017-04-26 11:22:27,390 : INFO : PROGRESS: at sentence #630000, processed 15076032 words, keeping 103296 word types\n",
      "2017-04-26 11:22:27,435 : INFO : PROGRESS: at sentence #640000, processed 15316005 words, keeping 103987 word types\n",
      "2017-04-26 11:22:27,479 : INFO : PROGRESS: at sentence #650000, processed 15555365 words, keeping 104699 word types\n",
      "2017-04-26 11:22:27,523 : INFO : PROGRESS: at sentence #660000, processed 15793890 words, keeping 105431 word types\n",
      "2017-04-26 11:22:27,567 : INFO : PROGRESS: at sentence #670000, processed 16033765 words, keeping 106103 word types\n",
      "2017-04-26 11:22:27,611 : INFO : PROGRESS: at sentence #680000, processed 16270250 words, keeping 106766 word types\n",
      "2017-04-26 11:22:27,655 : INFO : PROGRESS: at sentence #690000, processed 16509400 words, keeping 107427 word types\n",
      "2017-04-26 11:22:27,700 : INFO : PROGRESS: at sentence #700000, processed 16749746 words, keeping 108086 word types\n",
      "2017-04-26 11:22:27,744 : INFO : PROGRESS: at sentence #710000, processed 16987235 words, keeping 108718 word types\n",
      "2017-04-26 11:22:27,790 : INFO : PROGRESS: at sentence #720000, processed 17225549 words, keeping 109369 word types\n",
      "2017-04-26 11:22:27,835 : INFO : PROGRESS: at sentence #730000, processed 17464095 words, keeping 110028 word types\n",
      "2017-04-26 11:22:27,880 : INFO : PROGRESS: at sentence #740000, processed 17702060 words, keeping 110707 word types\n",
      "2017-04-26 11:22:27,925 : INFO : PROGRESS: at sentence #750000, processed 17942050 words, keeping 111338 word types\n",
      "2017-04-26 11:22:27,969 : INFO : PROGRESS: at sentence #760000, processed 18181349 words, keeping 111984 word types\n",
      "2017-04-26 11:22:28,014 : INFO : PROGRESS: at sentence #770000, processed 18420647 words, keeping 112637 word types\n",
      "2017-04-26 11:22:28,059 : INFO : PROGRESS: at sentence #780000, processed 18659494 words, keeping 113281 word types\n",
      "2017-04-26 11:22:28,104 : INFO : PROGRESS: at sentence #790000, processed 18899793 words, keeping 113940 word types\n",
      "2017-04-26 11:22:28,148 : INFO : PROGRESS: at sentence #800000, processed 19138988 words, keeping 114589 word types\n",
      "2017-04-26 11:22:28,193 : INFO : PROGRESS: at sentence #810000, processed 19376536 words, keeping 115194 word types\n",
      "2017-04-26 11:22:28,238 : INFO : PROGRESS: at sentence #820000, processed 19615966 words, keeping 115753 word types\n",
      "2017-04-26 11:22:28,282 : INFO : PROGRESS: at sentence #830000, processed 19854806 words, keeping 116347 word types\n",
      "2017-04-26 11:22:28,327 : INFO : PROGRESS: at sentence #840000, processed 20092336 words, keeping 116882 word types\n",
      "2017-04-26 11:22:28,371 : INFO : PROGRESS: at sentence #850000, processed 20331719 words, keeping 117411 word types\n",
      "2017-04-26 11:22:28,416 : INFO : PROGRESS: at sentence #860000, processed 20570425 words, keeping 118012 word types\n",
      "2017-04-26 11:22:28,460 : INFO : PROGRESS: at sentence #870000, processed 20809542 words, keeping 118605 word types\n",
      "2017-04-26 11:22:28,506 : INFO : PROGRESS: at sentence #880000, processed 21049788 words, keeping 119244 word types\n",
      "2017-04-26 11:22:28,551 : INFO : PROGRESS: at sentence #890000, processed 21288469 words, keeping 119819 word types\n",
      "2017-04-26 11:22:28,596 : INFO : PROGRESS: at sentence #900000, processed 21527574 words, keeping 120391 word types\n",
      "2017-04-26 11:22:28,641 : INFO : PROGRESS: at sentence #910000, processed 21768403 words, keeping 120898 word types\n",
      "2017-04-26 11:22:28,687 : INFO : PROGRESS: at sentence #920000, processed 22007876 words, keeping 121464 word types\n",
      "2017-04-26 11:22:28,732 : INFO : PROGRESS: at sentence #930000, processed 22247528 words, keeping 121988 word types\n",
      "2017-04-26 11:22:28,777 : INFO : PROGRESS: at sentence #940000, processed 22486435 words, keeping 122446 word types\n",
      "2017-04-26 11:22:28,822 : INFO : PROGRESS: at sentence #950000, processed 22724615 words, keeping 123020 word types\n",
      "2017-04-26 11:22:28,867 : INFO : PROGRESS: at sentence #960000, processed 22965525 words, keeping 123573 word types\n",
      "2017-04-26 11:22:28,912 : INFO : PROGRESS: at sentence #970000, processed 23203725 words, keeping 124063 word types\n",
      "2017-04-26 11:22:28,956 : INFO : PROGRESS: at sentence #980000, processed 23440226 words, keeping 124608 word types\n",
      "2017-04-26 11:22:29,001 : INFO : PROGRESS: at sentence #990000, processed 23679037 words, keeping 125117 word types\n",
      "2017-04-26 11:22:29,045 : INFO : PROGRESS: at sentence #1000000, processed 23917180 words, keeping 125637 word types\n",
      "2017-04-26 11:22:29,090 : INFO : PROGRESS: at sentence #1010000, processed 24155856 words, keeping 126148 word types\n",
      "2017-04-26 11:22:29,135 : INFO : PROGRESS: at sentence #1020000, processed 24395479 words, keeping 126644 word types\n",
      "2017-04-26 11:22:29,181 : INFO : PROGRESS: at sentence #1030000, processed 24635194 words, keeping 127159 word types\n",
      "2017-04-26 11:22:29,226 : INFO : PROGRESS: at sentence #1040000, processed 24873295 words, keeping 127663 word types\n",
      "2017-04-26 11:22:29,271 : INFO : PROGRESS: at sentence #1050000, processed 25111760 words, keeping 128133 word types\n",
      "2017-04-26 11:22:29,316 : INFO : PROGRESS: at sentence #1060000, processed 25349970 words, keeping 128660 word types\n",
      "2017-04-26 11:22:29,362 : INFO : PROGRESS: at sentence #1070000, processed 25589330 words, keeping 129160 word types\n",
      "2017-04-26 11:22:29,407 : INFO : PROGRESS: at sentence #1080000, processed 25828381 words, keeping 129691 word types\n",
      "2017-04-26 11:22:29,452 : INFO : PROGRESS: at sentence #1090000, processed 26068184 words, keeping 130176 word types\n",
      "2017-04-26 11:22:29,497 : INFO : PROGRESS: at sentence #1100000, processed 26308462 words, keeping 130684 word types\n",
      "2017-04-26 11:22:29,542 : INFO : PROGRESS: at sentence #1110000, processed 26548376 words, keeping 131174 word types\n",
      "2017-04-26 11:22:29,587 : INFO : PROGRESS: at sentence #1120000, processed 26787672 words, keeping 131700 word types\n",
      "2017-04-26 11:22:29,633 : INFO : PROGRESS: at sentence #1130000, processed 27025974 words, keeping 132179 word types\n",
      "2017-04-26 11:22:29,678 : INFO : PROGRESS: at sentence #1140000, processed 27265514 words, keeping 132638 word types\n",
      "2017-04-26 11:22:29,723 : INFO : PROGRESS: at sentence #1150000, processed 27505537 words, keeping 133123 word types\n",
      "2017-04-26 11:22:29,768 : INFO : PROGRESS: at sentence #1160000, processed 27742526 words, keeping 133632 word types\n",
      "2017-04-26 11:22:29,813 : INFO : PROGRESS: at sentence #1170000, processed 27981173 words, keeping 134117 word types\n",
      "2017-04-26 11:22:29,859 : INFO : PROGRESS: at sentence #1180000, processed 28219827 words, keeping 134627 word types\n",
      "2017-04-26 11:22:29,904 : INFO : PROGRESS: at sentence #1190000, processed 28458875 words, keeping 135088 word types\n",
      "2017-04-26 11:22:29,949 : INFO : PROGRESS: at sentence #1200000, processed 28697457 words, keeping 135595 word types\n",
      "2017-04-26 11:22:29,994 : INFO : PROGRESS: at sentence #1210000, processed 28936964 words, keeping 136082 word types\n",
      "2017-04-26 11:22:30,040 : INFO : PROGRESS: at sentence #1220000, processed 29175535 words, keeping 136550 word types\n",
      "2017-04-26 11:22:30,086 : INFO : PROGRESS: at sentence #1230000, processed 29414656 words, keeping 136996 word types\n",
      "2017-04-26 11:22:30,132 : INFO : PROGRESS: at sentence #1240000, processed 29652911 words, keeping 137428 word types\n",
      "2017-04-26 11:22:30,177 : INFO : PROGRESS: at sentence #1250000, processed 29892830 words, keeping 137902 word types\n",
      "2017-04-26 11:22:30,224 : INFO : PROGRESS: at sentence #1260000, processed 30131410 words, keeping 138346 word types\n",
      "2017-04-26 11:22:30,272 : INFO : PROGRESS: at sentence #1270000, processed 30370660 words, keeping 138811 word types\n",
      "2017-04-26 11:22:30,318 : INFO : PROGRESS: at sentence #1280000, processed 30608761 words, keeping 139220 word types\n",
      "2017-04-26 11:22:30,364 : INFO : PROGRESS: at sentence #1290000, processed 30846832 words, keeping 139635 word types\n",
      "2017-04-26 11:22:30,410 : INFO : PROGRESS: at sentence #1300000, processed 31085887 words, keeping 140114 word types\n",
      "2017-04-26 11:22:30,455 : INFO : PROGRESS: at sentence #1310000, processed 31325106 words, keeping 140498 word types\n",
      "2017-04-26 11:22:30,501 : INFO : PROGRESS: at sentence #1320000, processed 31567327 words, keeping 140998 word types\n",
      "2017-04-26 11:22:30,546 : INFO : PROGRESS: at sentence #1330000, processed 31806712 words, keeping 141459 word types\n",
      "2017-04-26 11:22:30,592 : INFO : PROGRESS: at sentence #1340000, processed 32048062 words, keeping 141890 word types\n",
      "2017-04-26 11:22:30,637 : INFO : PROGRESS: at sentence #1350000, processed 32287072 words, keeping 142337 word types\n",
      "2017-04-26 11:22:30,688 : INFO : PROGRESS: at sentence #1360000, processed 32525739 words, keeping 142789 word types\n",
      "2017-04-26 11:22:30,733 : INFO : PROGRESS: at sentence #1370000, processed 32764088 words, keeping 143258 word types\n",
      "2017-04-26 11:22:30,779 : INFO : PROGRESS: at sentence #1380000, processed 33004903 words, keeping 143648 word types\n",
      "2017-04-26 11:22:30,824 : INFO : PROGRESS: at sentence #1390000, processed 33243916 words, keeping 144071 word types\n",
      "2017-04-26 11:22:30,869 : INFO : PROGRESS: at sentence #1400000, processed 33483682 words, keeping 144493 word types\n",
      "2017-04-26 11:22:30,914 : INFO : PROGRESS: at sentence #1410000, processed 33724116 words, keeping 144860 word types\n",
      "2017-04-26 11:22:30,965 : INFO : PROGRESS: at sentence #1420000, processed 33962843 words, keeping 145285 word types\n",
      "2017-04-26 11:22:31,010 : INFO : PROGRESS: at sentence #1430000, processed 34200119 words, keeping 145709 word types\n",
      "2017-04-26 11:22:31,055 : INFO : PROGRESS: at sentence #1440000, processed 34439322 words, keeping 146126 word types\n",
      "2017-04-26 11:22:31,100 : INFO : PROGRESS: at sentence #1450000, processed 34679416 words, keeping 146550 word types\n",
      "2017-04-26 11:22:31,146 : INFO : PROGRESS: at sentence #1460000, processed 34921300 words, keeping 146952 word types\n",
      "2017-04-26 11:22:31,190 : INFO : PROGRESS: at sentence #1470000, processed 35160597 words, keeping 147385 word types\n",
      "2017-04-26 11:22:31,235 : INFO : PROGRESS: at sentence #1480000, processed 35398470 words, keeping 147797 word types\n",
      "2017-04-26 11:22:31,281 : INFO : PROGRESS: at sentence #1490000, processed 35638474 words, keeping 148211 word types\n",
      "2017-04-26 11:22:31,326 : INFO : PROGRESS: at sentence #1500000, processed 35877579 words, keeping 148625 word types\n",
      "2017-04-26 11:22:31,372 : INFO : PROGRESS: at sentence #1510000, processed 36117986 words, keeping 149046 word types\n",
      "2017-04-26 11:22:31,418 : INFO : PROGRESS: at sentence #1520000, processed 36356014 words, keeping 149453 word types\n",
      "2017-04-26 11:22:31,465 : INFO : PROGRESS: at sentence #1530000, processed 36595274 words, keeping 149862 word types\n",
      "2017-04-26 11:22:31,511 : INFO : PROGRESS: at sentence #1540000, processed 36834289 words, keeping 150258 word types\n",
      "2017-04-26 11:22:31,556 : INFO : PROGRESS: at sentence #1550000, processed 37072173 words, keeping 150666 word types\n",
      "2017-04-26 11:22:31,601 : INFO : PROGRESS: at sentence #1560000, processed 37311035 words, keeping 151093 word types\n",
      "2017-04-26 11:22:31,646 : INFO : PROGRESS: at sentence #1570000, processed 37550320 words, keeping 151450 word types\n",
      "2017-04-26 11:22:31,691 : INFO : PROGRESS: at sentence #1580000, processed 37789069 words, keeping 151845 word types\n",
      "2017-04-26 11:22:31,739 : INFO : PROGRESS: at sentence #1590000, processed 38028915 words, keeping 152251 word types\n",
      "2017-04-26 11:22:31,787 : INFO : PROGRESS: at sentence #1600000, processed 38269010 words, keeping 152646 word types\n",
      "2017-04-26 11:22:31,833 : INFO : PROGRESS: at sentence #1610000, processed 38509518 words, keeping 153055 word types\n",
      "2017-04-26 11:22:31,878 : INFO : PROGRESS: at sentence #1620000, processed 38748734 words, keeping 153410 word types\n",
      "2017-04-26 11:22:31,923 : INFO : PROGRESS: at sentence #1630000, processed 38987309 words, keeping 153803 word types\n",
      "2017-04-26 11:22:31,968 : INFO : PROGRESS: at sentence #1640000, processed 39227401 words, keeping 154192 word types\n",
      "2017-04-26 11:22:32,013 : INFO : PROGRESS: at sentence #1650000, processed 39466777 words, keeping 154584 word types\n",
      "2017-04-26 11:22:32,058 : INFO : PROGRESS: at sentence #1660000, processed 39705046 words, keeping 154909 word types\n",
      "2017-04-26 11:22:32,103 : INFO : PROGRESS: at sentence #1670000, processed 39943750 words, keeping 155267 word types\n",
      "2017-04-26 11:22:32,148 : INFO : PROGRESS: at sentence #1680000, processed 40181126 words, keeping 155633 word types\n",
      "2017-04-26 11:22:32,193 : INFO : PROGRESS: at sentence #1690000, processed 40420214 words, keeping 155990 word types\n",
      "2017-04-26 11:22:32,238 : INFO : PROGRESS: at sentence #1700000, processed 40660806 words, keeping 156409 word types\n",
      "2017-04-26 11:22:32,284 : INFO : PROGRESS: at sentence #1710000, processed 40899766 words, keeping 156816 word types\n",
      "2017-04-26 11:22:32,330 : INFO : PROGRESS: at sentence #1720000, processed 41137774 words, keeping 157253 word types\n",
      "2017-04-26 11:22:32,376 : INFO : PROGRESS: at sentence #1730000, processed 41377491 words, keeping 157622 word types\n",
      "2017-04-26 11:22:32,422 : INFO : PROGRESS: at sentence #1740000, processed 41616482 words, keeping 157992 word types\n",
      "2017-04-26 11:22:32,467 : INFO : PROGRESS: at sentence #1750000, processed 41855257 words, keeping 158355 word types\n",
      "2017-04-26 11:22:32,513 : INFO : PROGRESS: at sentence #1760000, processed 42095317 words, keeping 158762 word types\n",
      "2017-04-26 11:22:32,557 : INFO : PROGRESS: at sentence #1770000, processed 42334502 words, keeping 159120 word types\n",
      "2017-04-26 11:22:32,603 : INFO : PROGRESS: at sentence #1780000, processed 42572475 words, keeping 159524 word types\n",
      "2017-04-26 11:22:32,647 : INFO : PROGRESS: at sentence #1790000, processed 42810812 words, keeping 159867 word types\n",
      "2017-04-26 11:22:32,693 : INFO : PROGRESS: at sentence #1800000, processed 43049500 words, keeping 160177 word types\n",
      "2017-04-26 11:22:32,739 : INFO : PROGRESS: at sentence #1810000, processed 43287411 words, keeping 160531 word types\n",
      "2017-04-26 11:22:32,784 : INFO : PROGRESS: at sentence #1820000, processed 43525676 words, keeping 160898 word types\n",
      "2017-04-26 11:22:32,832 : INFO : PROGRESS: at sentence #1830000, processed 43764962 words, keeping 161249 word types\n",
      "2017-04-26 11:22:32,881 : INFO : PROGRESS: at sentence #1840000, processed 44006217 words, keeping 161622 word types\n",
      "2017-04-26 11:22:32,928 : INFO : PROGRESS: at sentence #1850000, processed 44245201 words, keeping 161992 word types\n",
      "2017-04-26 11:22:32,973 : INFO : PROGRESS: at sentence #1860000, processed 44483636 words, keeping 162337 word types\n",
      "2017-04-26 11:22:33,019 : INFO : PROGRESS: at sentence #1870000, processed 44722622 words, keeping 162695 word types\n",
      "2017-04-26 11:22:33,064 : INFO : PROGRESS: at sentence #1880000, processed 44962030 words, keeping 163090 word types\n",
      "2017-04-26 11:22:33,110 : INFO : PROGRESS: at sentence #1890000, processed 45200330 words, keeping 163446 word types\n",
      "2017-04-26 11:22:33,155 : INFO : PROGRESS: at sentence #1900000, processed 45438168 words, keeping 163826 word types\n",
      "2017-04-26 11:22:33,201 : INFO : PROGRESS: at sentence #1910000, processed 45678633 words, keeping 164128 word types\n",
      "2017-04-26 11:22:33,246 : INFO : PROGRESS: at sentence #1920000, processed 45916243 words, keeping 164444 word types\n",
      "2017-04-26 11:22:33,291 : INFO : PROGRESS: at sentence #1930000, processed 46156612 words, keeping 164772 word types\n",
      "2017-04-26 11:22:33,336 : INFO : PROGRESS: at sentence #1940000, processed 46395028 words, keeping 165071 word types\n",
      "2017-04-26 11:22:33,382 : INFO : PROGRESS: at sentence #1950000, processed 46634921 words, keeping 165389 word types\n",
      "2017-04-26 11:22:33,427 : INFO : PROGRESS: at sentence #1960000, processed 46874522 words, keeping 165741 word types\n",
      "2017-04-26 11:22:33,472 : INFO : PROGRESS: at sentence #1970000, processed 47113244 words, keeping 166106 word types\n",
      "2017-04-26 11:22:33,518 : INFO : PROGRESS: at sentence #1980000, processed 47352243 words, keeping 166426 word types\n",
      "2017-04-26 11:22:33,564 : INFO : PROGRESS: at sentence #1990000, processed 47591737 words, keeping 166722 word types\n",
      "2017-04-26 11:22:33,610 : INFO : PROGRESS: at sentence #2000000, processed 47830982 words, keeping 167071 word types\n",
      "2017-04-26 11:22:33,656 : INFO : PROGRESS: at sentence #2010000, processed 48069614 words, keeping 167358 word types\n",
      "2017-04-26 11:22:33,701 : INFO : PROGRESS: at sentence #2020000, processed 48307789 words, keeping 167672 word types\n",
      "2017-04-26 11:22:33,746 : INFO : PROGRESS: at sentence #2030000, processed 48545344 words, keeping 167982 word types\n",
      "2017-04-26 11:22:33,792 : INFO : PROGRESS: at sentence #2040000, processed 48783767 words, keeping 168298 word types\n",
      "2017-04-26 11:22:33,837 : INFO : PROGRESS: at sentence #2050000, processed 49023155 words, keeping 168633 word types\n",
      "2017-04-26 11:22:33,882 : INFO : PROGRESS: at sentence #2060000, processed 49260792 words, keeping 168965 word types\n",
      "2017-04-26 11:22:33,928 : INFO : PROGRESS: at sentence #2070000, processed 49500618 words, keeping 169282 word types\n",
      "2017-04-26 11:22:33,974 : INFO : PROGRESS: at sentence #2080000, processed 49738571 words, keeping 169591 word types\n",
      "2017-04-26 11:22:34,019 : INFO : PROGRESS: at sentence #2090000, processed 49976967 words, keeping 169893 word types\n",
      "2017-04-26 11:22:34,065 : INFO : PROGRESS: at sentence #2100000, processed 50214596 words, keeping 170230 word types\n",
      "2017-04-26 11:22:34,111 : INFO : PROGRESS: at sentence #2110000, processed 50454396 words, keeping 170570 word types\n",
      "2017-04-26 11:22:34,156 : INFO : PROGRESS: at sentence #2120000, processed 50693134 words, keeping 170869 word types\n",
      "2017-04-26 11:22:34,202 : INFO : PROGRESS: at sentence #2130000, processed 50931440 words, keeping 171157 word types\n",
      "2017-04-26 11:22:34,248 : INFO : PROGRESS: at sentence #2140000, processed 51171701 words, keeping 171478 word types\n",
      "2017-04-26 11:22:34,294 : INFO : PROGRESS: at sentence #2150000, processed 51410846 words, keeping 171798 word types\n",
      "2017-04-26 11:22:34,340 : INFO : PROGRESS: at sentence #2160000, processed 51649989 words, keeping 172101 word types\n",
      "2017-04-26 11:22:34,386 : INFO : PROGRESS: at sentence #2170000, processed 51888598 words, keeping 172386 word types\n",
      "2017-04-26 11:22:34,432 : INFO : PROGRESS: at sentence #2180000, processed 52127651 words, keeping 172680 word types\n",
      "2017-04-26 11:22:34,478 : INFO : PROGRESS: at sentence #2190000, processed 52368080 words, keeping 173016 word types\n",
      "2017-04-26 11:22:34,523 : INFO : PROGRESS: at sentence #2200000, processed 52607463 words, keeping 173330 word types\n",
      "2017-04-26 11:22:34,569 : INFO : PROGRESS: at sentence #2210000, processed 52846045 words, keeping 173656 word types\n",
      "2017-04-26 11:22:34,614 : INFO : PROGRESS: at sentence #2220000, processed 53085741 words, keeping 173952 word types\n",
      "2017-04-26 11:22:34,660 : INFO : PROGRESS: at sentence #2230000, processed 53326381 words, keeping 174302 word types\n",
      "2017-04-26 11:22:34,705 : INFO : PROGRESS: at sentence #2240000, processed 53566539 words, keeping 174593 word types\n",
      "2017-04-26 11:22:34,760 : INFO : PROGRESS: at sentence #2250000, processed 53806065 words, keeping 174948 word types\n",
      "2017-04-26 11:22:34,809 : INFO : PROGRESS: at sentence #2260000, processed 54046354 words, keeping 175298 word types\n",
      "2017-04-26 11:22:34,857 : INFO : PROGRESS: at sentence #2270000, processed 54284130 words, keeping 175604 word types\n",
      "2017-04-26 11:22:34,906 : INFO : PROGRESS: at sentence #2280000, processed 54525289 words, keeping 175879 word types\n",
      "2017-04-26 11:22:34,954 : INFO : PROGRESS: at sentence #2290000, processed 54763683 words, keeping 176196 word types\n",
      "2017-04-26 11:22:35,004 : INFO : PROGRESS: at sentence #2300000, processed 55003513 words, keeping 176493 word types\n",
      "2017-04-26 11:22:35,054 : INFO : PROGRESS: at sentence #2310000, processed 55242379 words, keeping 176803 word types\n",
      "2017-04-26 11:22:35,103 : INFO : PROGRESS: at sentence #2320000, processed 55481107 words, keeping 177082 word types\n",
      "2017-04-26 11:22:35,151 : INFO : PROGRESS: at sentence #2330000, processed 55720427 words, keeping 177333 word types\n",
      "2017-04-26 11:22:35,199 : INFO : PROGRESS: at sentence #2340000, processed 55958527 words, keeping 177642 word types\n",
      "2017-04-26 11:22:35,248 : INFO : PROGRESS: at sentence #2350000, processed 56198380 words, keeping 177909 word types\n",
      "2017-04-26 11:22:35,296 : INFO : PROGRESS: at sentence #2360000, processed 56437306 words, keeping 178198 word types\n",
      "2017-04-26 11:22:35,346 : INFO : PROGRESS: at sentence #2370000, processed 56669592 words, keeping 179564 word types\n",
      "2017-04-26 11:22:35,397 : INFO : PROGRESS: at sentence #2380000, processed 56899466 words, keeping 180765 word types\n",
      "2017-04-26 11:22:35,449 : INFO : PROGRESS: at sentence #2390000, processed 57131118 words, keeping 181818 word types\n",
      "2017-04-26 11:22:35,499 : INFO : PROGRESS: at sentence #2400000, processed 57360050 words, keeping 182746 word types\n",
      "2017-04-26 11:22:35,550 : INFO : PROGRESS: at sentence #2410000, processed 57591286 words, keeping 183612 word types\n",
      "2017-04-26 11:22:35,601 : INFO : PROGRESS: at sentence #2420000, processed 57821591 words, keeping 184429 word types\n",
      "2017-04-26 11:22:35,652 : INFO : PROGRESS: at sentence #2430000, processed 58051381 words, keeping 185226 word types\n",
      "2017-04-26 11:22:35,701 : INFO : PROGRESS: at sentence #2440000, processed 58284381 words, keeping 185943 word types\n",
      "2017-04-26 11:22:35,750 : INFO : PROGRESS: at sentence #2450000, processed 58514608 words, keeping 186660 word types\n",
      "2017-04-26 11:22:35,798 : INFO : PROGRESS: at sentence #2460000, processed 58746111 words, keeping 187348 word types\n",
      "2017-04-26 11:22:35,845 : INFO : PROGRESS: at sentence #2470000, processed 58976974 words, keeping 187984 word types\n",
      "2017-04-26 11:22:35,892 : INFO : PROGRESS: at sentence #2480000, processed 59206156 words, keeping 188579 word types\n",
      "2017-04-26 11:22:35,940 : INFO : PROGRESS: at sentence #2490000, processed 59438367 words, keeping 189216 word types\n",
      "2017-04-26 11:22:35,995 : INFO : PROGRESS: at sentence #2500000, processed 59669463 words, keeping 189802 word types\n",
      "2017-04-26 11:22:36,049 : INFO : PROGRESS: at sentence #2510000, processed 59898595 words, keeping 190306 word types\n",
      "2017-04-26 11:22:36,108 : INFO : PROGRESS: at sentence #2520000, processed 60127083 words, keeping 190824 word types\n",
      "2017-04-26 11:22:36,167 : INFO : PROGRESS: at sentence #2530000, processed 60359310 words, keeping 191355 word types\n",
      "2017-04-26 11:22:36,215 : INFO : PROGRESS: at sentence #2540000, processed 60591109 words, keeping 191911 word types\n",
      "2017-04-26 11:22:36,225 : INFO : collected 191997 word types from a corpus of 60618552 raw words and 2541190 sentences\n",
      "2017-04-26 11:22:36,226 : INFO : Loading a fresh vocabulary\n",
      "2017-04-26 11:22:36,416 : INFO : min_count=5 retains 68713 unique words (35% of original 191997, drops 123284)\n",
      "2017-04-26 11:22:36,417 : INFO : min_count=5 leaves 60414001 word corpus (99% of original 60618552, drops 204551)\n",
      "2017-04-26 11:22:37,782 : INFO : deleting the raw counts dictionary of 191997 items\n",
      "2017-04-26 11:22:37,794 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2017-04-26 11:22:37,795 : INFO : downsampling leaves estimated 46746973 word corpus (77.4% of prior 60414001)\n",
      "2017-04-26 11:22:37,839 : INFO : estimated required memory for 68713 words and 300 dimensions: 199267700 bytes\n",
      "2017-04-26 11:22:38,216 : INFO : resetting layer weights\n",
      "2017-04-26 11:22:39,084 : INFO : training model with 4 workers on 68713 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 11:22:39,085 : INFO : expecting 2541190 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 11:22:40,418 : INFO : PROGRESS: at 0.32% examples, 749290 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:41,433 : INFO : PROGRESS: at 0.64% examples, 743257 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:22:42,439 : INFO : PROGRESS: at 0.85% examples, 659140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:43,445 : INFO : PROGRESS: at 1.17% examples, 681689 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:44,458 : INFO : PROGRESS: at 1.48% examples, 685379 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:22:45,461 : INFO : PROGRESS: at 1.80% examples, 697892 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:46,465 : INFO : PROGRESS: at 2.12% examples, 704519 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:47,470 : INFO : PROGRESS: at 2.35% examples, 683619 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:48,489 : INFO : PROGRESS: at 2.58% examples, 665559 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:49,499 : INFO : PROGRESS: at 2.80% examples, 650861 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:50,500 : INFO : PROGRESS: at 3.02% examples, 638638 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:51,511 : INFO : PROGRESS: at 3.25% examples, 630470 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:22:52,527 : INFO : PROGRESS: at 3.49% examples, 623932 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:22:53,528 : INFO : PROGRESS: at 3.73% examples, 619507 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:22:54,559 : INFO : PROGRESS: at 3.91% examples, 605338 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:22:55,568 : INFO : PROGRESS: at 4.12% examples, 598544 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:56,588 : INFO : PROGRESS: at 4.34% examples, 593073 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:22:57,596 : INFO : PROGRESS: at 4.56% examples, 588598 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:58,608 : INFO : PROGRESS: at 4.78% examples, 584902 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:22:59,609 : INFO : PROGRESS: at 5.08% examples, 590220 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:00,642 : INFO : PROGRESS: at 5.31% examples, 586535 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:23:01,660 : INFO : PROGRESS: at 5.53% examples, 583603 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:02,692 : INFO : PROGRESS: at 5.77% examples, 581223 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:23:03,700 : INFO : PROGRESS: at 5.98% examples, 577072 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:04,711 : INFO : PROGRESS: at 6.17% examples, 571683 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:23:05,733 : INFO : PROGRESS: at 6.35% examples, 565883 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:06,752 : INFO : PROGRESS: at 6.54% examples, 561140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:07,768 : INFO : PROGRESS: at 6.75% examples, 558422 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:23:08,768 : INFO : PROGRESS: at 6.97% examples, 556714 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:09,781 : INFO : PROGRESS: at 7.20% examples, 555928 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:23:10,782 : INFO : PROGRESS: at 7.43% examples, 555122 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:11,786 : INFO : PROGRESS: at 7.65% examples, 554098 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:12,799 : INFO : PROGRESS: at 7.89% examples, 554351 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:13,804 : INFO : PROGRESS: at 8.15% examples, 555644 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:14,808 : INFO : PROGRESS: at 8.40% examples, 556658 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:15,808 : INFO : PROGRESS: at 8.64% examples, 556814 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:16,819 : INFO : PROGRESS: at 8.88% examples, 556808 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:17,821 : INFO : PROGRESS: at 9.14% examples, 558133 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:18,836 : INFO : PROGRESS: at 9.41% examples, 559405 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:23:19,854 : INFO : PROGRESS: at 9.67% examples, 560753 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:20,856 : INFO : PROGRESS: at 9.94% examples, 562623 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:21,875 : INFO : PROGRESS: at 10.21% examples, 563629 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:22,878 : INFO : PROGRESS: at 10.48% examples, 565340 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:23,883 : INFO : PROGRESS: at 10.77% examples, 567809 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:24,901 : INFO : PROGRESS: at 10.98% examples, 565785 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:23:25,906 : INFO : PROGRESS: at 11.29% examples, 569300 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:26,921 : INFO : PROGRESS: at 11.59% examples, 571895 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:27,925 : INFO : PROGRESS: at 11.88% examples, 574521 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:28,939 : INFO : PROGRESS: at 12.11% examples, 573327 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:29,952 : INFO : PROGRESS: at 12.41% examples, 576021 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:30,953 : INFO : PROGRESS: at 12.76% examples, 580366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:31,956 : INFO : PROGRESS: at 13.06% examples, 582769 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:32,957 : INFO : PROGRESS: at 13.35% examples, 584675 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:33,963 : INFO : PROGRESS: at 13.68% examples, 588007 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:34,970 : INFO : PROGRESS: at 14.02% examples, 591637 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:35,975 : INFO : PROGRESS: at 14.34% examples, 594202 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:23:36,976 : INFO : PROGRESS: at 14.65% examples, 596720 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:37,978 : INFO : PROGRESS: at 15.00% examples, 600600 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:38,996 : INFO : PROGRESS: at 15.33% examples, 603267 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:23:40,004 : INFO : PROGRESS: at 15.67% examples, 606190 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:41,010 : INFO : PROGRESS: at 16.00% examples, 608926 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:42,012 : INFO : PROGRESS: at 16.32% examples, 611369 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:43,019 : INFO : PROGRESS: at 16.67% examples, 614304 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:44,030 : INFO : PROGRESS: at 16.94% examples, 614585 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:45,041 : INFO : PROGRESS: at 17.18% examples, 613559 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:46,048 : INFO : PROGRESS: at 17.43% examples, 613087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:47,050 : INFO : PROGRESS: at 17.67% examples, 612436 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:48,053 : INFO : PROGRESS: at 17.95% examples, 613136 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:49,073 : INFO : PROGRESS: at 18.24% examples, 613786 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:50,074 : INFO : PROGRESS: at 18.52% examples, 614360 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:51,077 : INFO : PROGRESS: at 18.74% examples, 612718 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:52,079 : INFO : PROGRESS: at 19.04% examples, 613731 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:53,086 : INFO : PROGRESS: at 19.37% examples, 615306 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:54,093 : INFO : PROGRESS: at 19.70% examples, 616825 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:55,109 : INFO : PROGRESS: at 20.00% examples, 617637 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:56,113 : INFO : PROGRESS: at 20.32% examples, 619094 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:23:57,123 : INFO : PROGRESS: at 20.62% examples, 620184 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:23:58,136 : INFO : PROGRESS: at 20.92% examples, 621114 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:23:59,149 : INFO : PROGRESS: at 21.20% examples, 621431 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:00,157 : INFO : PROGRESS: at 21.41% examples, 619970 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:01,159 : INFO : PROGRESS: at 21.68% examples, 620094 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:02,191 : INFO : PROGRESS: at 21.96% examples, 620278 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:03,196 : INFO : PROGRESS: at 22.24% examples, 620568 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:04,199 : INFO : PROGRESS: at 22.53% examples, 621230 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:05,212 : INFO : PROGRESS: at 22.83% examples, 622254 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:06,215 : INFO : PROGRESS: at 23.16% examples, 624024 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:07,216 : INFO : PROGRESS: at 23.49% examples, 625602 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:08,240 : INFO : PROGRESS: at 23.80% examples, 626626 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:09,251 : INFO : PROGRESS: at 24.11% examples, 627640 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:10,262 : INFO : PROGRESS: at 24.39% examples, 627874 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:11,264 : INFO : PROGRESS: at 24.61% examples, 626808 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:12,272 : INFO : PROGRESS: at 24.88% examples, 626812 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:13,308 : INFO : PROGRESS: at 25.11% examples, 625479 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:24:14,320 : INFO : PROGRESS: at 25.39% examples, 625871 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:15,320 : INFO : PROGRESS: at 25.63% examples, 625214 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:16,329 : INFO : PROGRESS: at 25.94% examples, 626096 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:17,329 : INFO : PROGRESS: at 26.19% examples, 625675 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:24:18,337 : INFO : PROGRESS: at 26.45% examples, 625540 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:19,339 : INFO : PROGRESS: at 26.77% examples, 626586 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:20,354 : INFO : PROGRESS: at 27.05% examples, 626928 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:21,355 : INFO : PROGRESS: at 27.35% examples, 627733 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:22,376 : INFO : PROGRESS: at 27.65% examples, 628244 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:23,380 : INFO : PROGRESS: at 27.93% examples, 628470 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:24,384 : INFO : PROGRESS: at 28.13% examples, 626943 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:25,405 : INFO : PROGRESS: at 28.33% examples, 625336 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:26,426 : INFO : PROGRESS: at 28.54% examples, 623908 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:27,452 : INFO : PROGRESS: at 28.77% examples, 623049 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:28,455 : INFO : PROGRESS: at 29.02% examples, 622614 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:29,485 : INFO : PROGRESS: at 29.26% examples, 622032 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:30,491 : INFO : PROGRESS: at 29.51% examples, 621603 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:31,502 : INFO : PROGRESS: at 29.78% examples, 621563 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:32,525 : INFO : PROGRESS: at 30.07% examples, 622005 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:33,539 : INFO : PROGRESS: at 30.37% examples, 622628 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:34,553 : INFO : PROGRESS: at 30.67% examples, 623368 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:24:35,555 : INFO : PROGRESS: at 31.01% examples, 624829 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:36,561 : INFO : PROGRESS: at 31.37% examples, 626559 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:37,561 : INFO : PROGRESS: at 31.69% examples, 627710 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:38,568 : INFO : PROGRESS: at 32.04% examples, 629323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:39,575 : INFO : PROGRESS: at 32.39% examples, 630913 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:40,576 : INFO : PROGRESS: at 32.72% examples, 631926 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:41,590 : INFO : PROGRESS: at 33.04% examples, 632925 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:42,595 : INFO : PROGRESS: at 33.34% examples, 633451 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:43,602 : INFO : PROGRESS: at 33.66% examples, 634264 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:24:44,624 : INFO : PROGRESS: at 33.97% examples, 634935 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:45,627 : INFO : PROGRESS: at 34.32% examples, 636302 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:46,634 : INFO : PROGRESS: at 34.65% examples, 637387 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:47,636 : INFO : PROGRESS: at 34.96% examples, 638055 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:24:48,654 : INFO : PROGRESS: at 35.28% examples, 638936 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:49,654 : INFO : PROGRESS: at 35.58% examples, 639347 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:50,661 : INFO : PROGRESS: at 35.88% examples, 639785 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:51,683 : INFO : PROGRESS: at 36.19% examples, 640372 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 11:24:52,688 : INFO : PROGRESS: at 36.52% examples, 641269 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:53,694 : INFO : PROGRESS: at 36.85% examples, 642371 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:54,695 : INFO : PROGRESS: at 37.16% examples, 642971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:55,701 : INFO : PROGRESS: at 37.49% examples, 643884 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:56,703 : INFO : PROGRESS: at 37.80% examples, 644522 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:24:57,703 : INFO : PROGRESS: at 38.10% examples, 644986 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:24:58,709 : INFO : PROGRESS: at 38.41% examples, 645421 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:24:59,722 : INFO : PROGRESS: at 38.70% examples, 645522 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:00,723 : INFO : PROGRESS: at 38.93% examples, 644631 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:01,735 : INFO : PROGRESS: at 39.15% examples, 643538 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:02,743 : INFO : PROGRESS: at 39.37% examples, 642475 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:03,747 : INFO : PROGRESS: at 39.61% examples, 641763 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:04,751 : INFO : PROGRESS: at 39.87% examples, 641322 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:05,752 : INFO : PROGRESS: at 40.12% examples, 640819 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:06,779 : INFO : PROGRESS: at 40.37% examples, 640329 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:07,782 : INFO : PROGRESS: at 40.65% examples, 640413 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:08,802 : INFO : PROGRESS: at 40.95% examples, 640739 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:09,809 : INFO : PROGRESS: at 41.26% examples, 641366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:10,825 : INFO : PROGRESS: at 41.57% examples, 641846 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:11,830 : INFO : PROGRESS: at 41.90% examples, 642675 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:12,840 : INFO : PROGRESS: at 42.23% examples, 643411 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:13,864 : INFO : PROGRESS: at 42.55% examples, 644092 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:14,865 : INFO : PROGRESS: at 42.87% examples, 644806 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:15,865 : INFO : PROGRESS: at 43.18% examples, 645309 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:16,871 : INFO : PROGRESS: at 43.49% examples, 645741 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:17,881 : INFO : PROGRESS: at 43.79% examples, 646091 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:18,883 : INFO : PROGRESS: at 44.11% examples, 646820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:19,884 : INFO : PROGRESS: at 44.45% examples, 647735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:20,896 : INFO : PROGRESS: at 44.70% examples, 647304 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:21,901 : INFO : PROGRESS: at 44.93% examples, 646520 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:22,905 : INFO : PROGRESS: at 45.13% examples, 645516 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:23,912 : INFO : PROGRESS: at 45.39% examples, 645173 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:24,929 : INFO : PROGRESS: at 45.67% examples, 645257 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:25,946 : INFO : PROGRESS: at 45.96% examples, 645387 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:26,984 : INFO : PROGRESS: at 46.21% examples, 644928 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:27,997 : INFO : PROGRESS: at 46.51% examples, 645164 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:29,009 : INFO : PROGRESS: at 46.81% examples, 645498 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:30,019 : INFO : PROGRESS: at 47.12% examples, 645920 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:31,041 : INFO : PROGRESS: at 47.42% examples, 646159 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:32,047 : INFO : PROGRESS: at 47.75% examples, 646807 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 11:25:33,056 : INFO : PROGRESS: at 48.07% examples, 647440 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:34,060 : INFO : PROGRESS: at 48.43% examples, 648481 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:35,069 : INFO : PROGRESS: at 48.79% examples, 649538 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:36,070 : INFO : PROGRESS: at 49.09% examples, 649914 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:37,075 : INFO : PROGRESS: at 49.39% examples, 650227 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:38,105 : INFO : PROGRESS: at 49.71% examples, 650577 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:39,115 : INFO : PROGRESS: at 50.05% examples, 651338 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:40,119 : INFO : PROGRESS: at 50.40% examples, 652323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:41,127 : INFO : PROGRESS: at 50.72% examples, 652819 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:42,131 : INFO : PROGRESS: at 51.07% examples, 653705 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:43,139 : INFO : PROGRESS: at 51.43% examples, 654730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:44,147 : INFO : PROGRESS: at 51.78% examples, 655583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:45,151 : INFO : PROGRESS: at 52.12% examples, 656352 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:46,159 : INFO : PROGRESS: at 52.46% examples, 657148 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:47,163 : INFO : PROGRESS: at 52.80% examples, 657900 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:48,172 : INFO : PROGRESS: at 53.02% examples, 657079 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:49,191 : INFO : PROGRESS: at 53.24% examples, 656187 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:50,193 : INFO : PROGRESS: at 53.45% examples, 655366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:51,203 : INFO : PROGRESS: at 53.66% examples, 654446 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:52,209 : INFO : PROGRESS: at 53.90% examples, 653946 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:25:53,210 : INFO : PROGRESS: at 54.13% examples, 653394 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:25:54,230 : INFO : PROGRESS: at 54.38% examples, 652939 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:55,261 : INFO : PROGRESS: at 54.63% examples, 652529 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:56,266 : INFO : PROGRESS: at 54.93% examples, 652759 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:57,271 : INFO : PROGRESS: at 55.22% examples, 652914 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:25:58,288 : INFO : PROGRESS: at 55.53% examples, 653255 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:25:59,308 : INFO : PROGRESS: at 55.85% examples, 653582 words/s, in_qsize 7, out_qsize 2\n",
      "2017-04-26 11:26:00,308 : INFO : PROGRESS: at 56.20% examples, 654433 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:01,310 : INFO : PROGRESS: at 56.55% examples, 655271 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:02,314 : INFO : PROGRESS: at 56.90% examples, 656052 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:03,319 : INFO : PROGRESS: at 57.25% examples, 656822 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:04,324 : INFO : PROGRESS: at 57.55% examples, 657103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:05,346 : INFO : PROGRESS: at 57.86% examples, 657286 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:06,351 : INFO : PROGRESS: at 58.16% examples, 657591 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:07,362 : INFO : PROGRESS: at 58.48% examples, 657992 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:08,369 : INFO : PROGRESS: at 58.81% examples, 658377 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 11:26:09,393 : INFO : PROGRESS: at 59.15% examples, 658806 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:10,401 : INFO : PROGRESS: at 59.49% examples, 659280 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:11,412 : INFO : PROGRESS: at 59.82% examples, 659630 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:12,423 : INFO : PROGRESS: at 60.14% examples, 659918 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:13,423 : INFO : PROGRESS: at 60.43% examples, 660001 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:14,437 : INFO : PROGRESS: at 60.71% examples, 660006 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:15,456 : INFO : PROGRESS: at 61.02% examples, 660176 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:16,464 : INFO : PROGRESS: at 61.23% examples, 659413 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:17,472 : INFO : PROGRESS: at 61.45% examples, 658770 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:18,497 : INFO : PROGRESS: at 61.66% examples, 657903 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:19,504 : INFO : PROGRESS: at 61.90% examples, 657418 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:20,505 : INFO : PROGRESS: at 62.22% examples, 657889 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:21,509 : INFO : PROGRESS: at 62.57% examples, 658630 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:22,513 : INFO : PROGRESS: at 62.92% examples, 659327 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:23,539 : INFO : PROGRESS: at 63.25% examples, 659712 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:24,545 : INFO : PROGRESS: at 63.57% examples, 660085 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:25,555 : INFO : PROGRESS: at 63.84% examples, 660031 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:26,555 : INFO : PROGRESS: at 64.14% examples, 660145 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:27,559 : INFO : PROGRESS: at 64.39% examples, 659809 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:28,561 : INFO : PROGRESS: at 64.57% examples, 658839 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:29,601 : INFO : PROGRESS: at 64.81% examples, 658240 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:26:30,609 : INFO : PROGRESS: at 65.03% examples, 657634 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:31,617 : INFO : PROGRESS: at 65.29% examples, 657366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:32,617 : INFO : PROGRESS: at 65.51% examples, 656794 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:33,622 : INFO : PROGRESS: at 65.79% examples, 656774 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:34,627 : INFO : PROGRESS: at 66.02% examples, 656259 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:26:35,628 : INFO : PROGRESS: at 66.28% examples, 656024 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:36,640 : INFO : PROGRESS: at 66.52% examples, 655595 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:26:37,640 : INFO : PROGRESS: at 66.76% examples, 655204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:38,649 : INFO : PROGRESS: at 67.00% examples, 654854 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:39,652 : INFO : PROGRESS: at 67.27% examples, 654720 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:40,655 : INFO : PROGRESS: at 67.54% examples, 654646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:41,662 : INFO : PROGRESS: at 67.85% examples, 654885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:42,679 : INFO : PROGRESS: at 68.15% examples, 655059 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:43,685 : INFO : PROGRESS: at 68.41% examples, 654791 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:44,689 : INFO : PROGRESS: at 68.64% examples, 654372 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:45,690 : INFO : PROGRESS: at 68.86% examples, 653841 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:46,696 : INFO : PROGRESS: at 69.14% examples, 653829 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:47,703 : INFO : PROGRESS: at 69.40% examples, 653597 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:48,709 : INFO : PROGRESS: at 69.69% examples, 653679 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:49,715 : INFO : PROGRESS: at 69.98% examples, 653730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:50,723 : INFO : PROGRESS: at 70.31% examples, 654235 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:51,742 : INFO : PROGRESS: at 70.63% examples, 654587 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:52,751 : INFO : PROGRESS: at 70.93% examples, 654779 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:26:53,768 : INFO : PROGRESS: at 71.25% examples, 655098 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:54,774 : INFO : PROGRESS: at 71.58% examples, 655566 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:55,777 : INFO : PROGRESS: at 71.89% examples, 655825 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:56,788 : INFO : PROGRESS: at 72.18% examples, 655824 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:26:57,793 : INFO : PROGRESS: at 72.48% examples, 656047 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:58,798 : INFO : PROGRESS: at 72.80% examples, 656353 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:26:59,806 : INFO : PROGRESS: at 73.13% examples, 656802 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:00,813 : INFO : PROGRESS: at 73.44% examples, 657040 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:01,822 : INFO : PROGRESS: at 73.78% examples, 657540 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:02,829 : INFO : PROGRESS: at 74.08% examples, 657718 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:03,844 : INFO : PROGRESS: at 74.38% examples, 657873 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:27:04,850 : INFO : PROGRESS: at 74.69% examples, 658081 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:05,862 : INFO : PROGRESS: at 75.02% examples, 658529 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:06,870 : INFO : PROGRESS: at 75.35% examples, 658868 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:07,879 : INFO : PROGRESS: at 75.63% examples, 658859 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:08,881 : INFO : PROGRESS: at 75.84% examples, 658267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:09,886 : INFO : PROGRESS: at 76.10% examples, 658015 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:10,897 : INFO : PROGRESS: at 76.35% examples, 657750 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:11,906 : INFO : PROGRESS: at 76.62% examples, 657605 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:12,914 : INFO : PROGRESS: at 76.86% examples, 657237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:13,949 : INFO : PROGRESS: at 77.08% examples, 656640 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 11:27:14,974 : INFO : PROGRESS: at 77.30% examples, 656072 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:27:15,988 : INFO : PROGRESS: at 77.57% examples, 655983 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:27:16,996 : INFO : PROGRESS: at 77.86% examples, 656071 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:18,005 : INFO : PROGRESS: at 78.17% examples, 656325 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:19,012 : INFO : PROGRESS: at 78.51% examples, 656800 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:20,017 : INFO : PROGRESS: at 78.87% examples, 657309 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:21,018 : INFO : PROGRESS: at 79.22% examples, 657798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:22,020 : INFO : PROGRESS: at 79.58% examples, 658303 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:23,026 : INFO : PROGRESS: at 79.92% examples, 658659 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:24,040 : INFO : PROGRESS: at 80.25% examples, 659015 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:25,047 : INFO : PROGRESS: at 80.56% examples, 659256 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:26,050 : INFO : PROGRESS: at 80.86% examples, 659368 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:27,051 : INFO : PROGRESS: at 81.16% examples, 659565 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:27:28,091 : INFO : PROGRESS: at 81.39% examples, 659006 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:29,101 : INFO : PROGRESS: at 81.59% examples, 658303 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:27:30,131 : INFO : PROGRESS: at 81.78% examples, 657535 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:31,147 : INFO : PROGRESS: at 81.96% examples, 656673 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:32,154 : INFO : PROGRESS: at 82.25% examples, 656756 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:33,159 : INFO : PROGRESS: at 82.54% examples, 656874 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:34,170 : INFO : PROGRESS: at 82.86% examples, 657105 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:27:35,173 : INFO : PROGRESS: at 83.18% examples, 657453 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:36,177 : INFO : PROGRESS: at 83.51% examples, 657799 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:37,183 : INFO : PROGRESS: at 83.84% examples, 658191 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:38,188 : INFO : PROGRESS: at 84.17% examples, 658583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:39,197 : INFO : PROGRESS: at 84.49% examples, 658910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:40,198 : INFO : PROGRESS: at 84.74% examples, 658613 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:41,204 : INFO : PROGRESS: at 84.96% examples, 658179 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:42,206 : INFO : PROGRESS: at 85.19% examples, 657757 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:43,216 : INFO : PROGRESS: at 85.41% examples, 657271 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:44,222 : INFO : PROGRESS: at 85.67% examples, 657125 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:45,230 : INFO : PROGRESS: at 85.95% examples, 657074 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:46,235 : INFO : PROGRESS: at 86.26% examples, 657257 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:47,241 : INFO : PROGRESS: at 86.60% examples, 657739 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:48,250 : INFO : PROGRESS: at 86.88% examples, 657661 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:27:49,258 : INFO : PROGRESS: at 87.11% examples, 657310 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:50,274 : INFO : PROGRESS: at 87.36% examples, 657044 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:51,294 : INFO : PROGRESS: at 87.62% examples, 656871 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:52,301 : INFO : PROGRESS: at 87.95% examples, 657194 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:53,302 : INFO : PROGRESS: at 88.25% examples, 657357 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:54,308 : INFO : PROGRESS: at 88.57% examples, 657609 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:55,310 : INFO : PROGRESS: at 88.90% examples, 657986 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:56,311 : INFO : PROGRESS: at 89.18% examples, 657950 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:57,324 : INFO : PROGRESS: at 89.41% examples, 657551 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:27:58,361 : INFO : PROGRESS: at 89.64% examples, 657128 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:27:59,372 : INFO : PROGRESS: at 89.88% examples, 656810 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 11:28:00,374 : INFO : PROGRESS: at 90.20% examples, 657064 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:01,377 : INFO : PROGRESS: at 90.50% examples, 657219 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 11:28:02,379 : INFO : PROGRESS: at 90.80% examples, 657351 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:28:03,381 : INFO : PROGRESS: at 91.08% examples, 657364 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:04,418 : INFO : PROGRESS: at 91.35% examples, 657208 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:28:05,428 : INFO : PROGRESS: at 91.57% examples, 656803 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:06,429 : INFO : PROGRESS: at 91.79% examples, 656347 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:07,438 : INFO : PROGRESS: at 92.06% examples, 656255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:08,449 : INFO : PROGRESS: at 92.39% examples, 656581 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:28:09,454 : INFO : PROGRESS: at 92.71% examples, 656868 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:10,460 : INFO : PROGRESS: at 93.04% examples, 657220 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:11,471 : INFO : PROGRESS: at 93.35% examples, 657376 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:12,481 : INFO : PROGRESS: at 93.64% examples, 657394 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:13,509 : INFO : PROGRESS: at 93.87% examples, 657032 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 11:28:14,513 : INFO : PROGRESS: at 94.05% examples, 656282 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:28:15,517 : INFO : PROGRESS: at 94.28% examples, 655973 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:16,524 : INFO : PROGRESS: at 94.58% examples, 656092 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:28:17,550 : INFO : PROGRESS: at 94.89% examples, 656201 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 11:28:18,551 : INFO : PROGRESS: at 95.23% examples, 656627 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:19,558 : INFO : PROGRESS: at 95.56% examples, 656947 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:20,569 : INFO : PROGRESS: at 95.87% examples, 657168 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:28:21,573 : INFO : PROGRESS: at 96.22% examples, 657583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:22,576 : INFO : PROGRESS: at 96.55% examples, 657930 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:23,582 : INFO : PROGRESS: at 96.85% examples, 658063 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:28:24,586 : INFO : PROGRESS: at 97.11% examples, 657933 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:25,597 : INFO : PROGRESS: at 97.41% examples, 658063 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:28:26,599 : INFO : PROGRESS: at 97.71% examples, 658182 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:28:27,613 : INFO : PROGRESS: at 98.02% examples, 658324 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 11:28:28,629 : INFO : PROGRESS: at 98.25% examples, 657975 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:28:29,630 : INFO : PROGRESS: at 98.46% examples, 657481 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:30,640 : INFO : PROGRESS: at 98.70% examples, 657143 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:31,647 : INFO : PROGRESS: at 98.97% examples, 657000 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:32,650 : INFO : PROGRESS: at 99.27% examples, 657017 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 11:28:33,665 : INFO : PROGRESS: at 99.55% examples, 656968 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 11:28:34,684 : INFO : PROGRESS: at 99.81% examples, 656695 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 11:28:35,381 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 11:28:35,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 11:28:35,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 11:28:35,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 11:28:35,404 : INFO : training on 303092760 raw words (233731936 effective words) took 356.0s, 656564 effective words/s\n",
      "2017-04-26 11:28:35,404 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 11:28:35,831 : INFO : saving Word2Vec object under Results/mouse_dros_BE_comb_model, separately None\n",
      "2017-04-26 11:28:35,832 : INFO : storing np array 'syn0' to Results/mouse_dros_BE_comb_model.wv.syn0.npy\n",
      "2017-04-26 11:28:36,056 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 11:28:36,057 : INFO : not storing attribute cum_table\n",
      "2017-04-26 11:28:36,058 : INFO : storing np array 'syn1neg' to Results/mouse_dros_BE_comb_model.syn1neg.npy\n",
      "2017-04-26 11:28:40,381 : INFO : saved Results/mouse_dros_BE_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "mouse_old_SR_sentence_pkl = 'Results/mouse/strict_real.pkl'\n",
    "dros_SR_sentences_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "data_list = [mouse_old_SR_sentence_pkl, dros_SR_sentences_pkl]\n",
    "mouse_dros_SR_comb_model = make_w2v_model(data_list, 'mouse_dros_SR_comb_model')\n",
    "\n",
    "#Gen model\n",
    "mouse_old_GEN_sentence_pkl = 'Results/mouse/gen_real.pkl'\n",
    "dros_GEN_sentences_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "data_list = [mouse_old_GEN_sentence_pkl, dros_GEN_sentences_pkl]\n",
    "mouse_dros_GEN_comb_model = make_w2v_model(data_list, 'mouse_dros_GEN_comb_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "mouse_old_BE_sentence_pkl = 'Results/mouse/be_real.pkl'\n",
    "dros_BE_sentences_pkl = 'Results/drosophila/be_real.pkl'\n",
    "data_list = [mouse_old_BE_sentence_pkl, dros_BE_sentences_pkl]\n",
    "mouse_dros_BE_comb_model = make_w2v_model(data_list, 'mouse_dros_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mouse_dros_SR_comb_model = word2vec.Word2Vec.load('Results/mouse_dros_SR_comb_model')\n",
    "mouse_dros_GEN_comb_model = word2vec.Word2Vec.load('Results/mouse_dros_GEN_comb_model')\n",
    "mouse_dros_BE_comb_model = word2vec.Word2Vec.load('Results/mouse_dros_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "mouse_strict_real = pickle.load(open('Results/mouse/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_SR_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_GEN_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_BE_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/mouse_dros_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/mouse_dros_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/mouse_dros_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse_dros_comb/Seeded/Results/'\n",
    "errors_mouse_dros_comb = mult_open(drct, '_errors_')\n",
    "fpr_mouse_dros_comb = mult_open(drct, '_fpr_')\n",
    "tpr_mouse_dros_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse_dros_comb auc=0.681 error=0.211\n",
      "Strict error mouse_dros_comb auc=0.686 error=0.212\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.680 error=0.211\n",
      "Gen error mouse_dros_comb auc=0.691 error=0.211\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.698 error=0.207\n",
      "BE error mouse_dros_comb auc=0.698 error=0.208\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.731 error=0.250\n",
      "Strict error mouse_dros_comb auc=0.733 error=0.253\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.744 error=0.247\n",
      "Gen error mouse_dros_comb auc=0.741 error=0.250\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.745 error=0.248\n",
      "BE error mouse_dros_comb auc=0.742 error=0.246\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.659 error=0.231\n",
      "Strict error mouse_dros_comb auc=0.654 error=0.232\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.670 error=0.230\n",
      "Gen error mouse_dros_comb auc=0.675 error=0.232\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.683 error=0.228\n",
      "BE error mouse_dros_comb auc=0.683 error=0.229\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.720 error=0.241\n",
      "Strict error mouse_dros_comb auc=0.723 error=0.242\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.727 error=0.241\n",
      "Gen error mouse_dros_comb auc=0.723 error=0.241\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.724 error=0.243\n",
      "BE error mouse_dros_comb auc=0.716 error=0.245\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.642 error=0.329\n",
      "Strict error mouse_dros_comb auc=0.636 error=0.334\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.657 error=0.329\n",
      "Gen error mouse_dros_comb auc=0.651 error=0.331\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.658 error=0.327\n",
      "BE error mouse_dros_comb auc=0.650 error=0.331\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.724 error=0.203\n",
      "Strict error mouse_dros_comb auc=0.724 error=0.203\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.734 error=0.199\n",
      "Gen error mouse_dros_comb auc=0.730 error=0.199\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.729 error=0.198\n",
      "BE error mouse_dros_comb auc=0.728 error=0.200\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.641 error=0.285\n",
      "Strict error mouse_dros_comb auc=0.634 error=0.286\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.652 error=0.279\n",
      "Gen error mouse_dros_comb auc=0.647 error=0.281\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.649 error=0.284\n",
      "BE error mouse_dros_comb auc=0.646 error=0.284\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.663 error=0.282\n",
      "Strict error mouse_dros_comb auc=0.662 error=0.281\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.667 error=0.283\n",
      "Gen error mouse_dros_comb auc=0.663 error=0.285\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.674 error=0.286\n",
      "BE error mouse_dros_comb auc=0.669 error=0.288\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.579 error=0.312\n",
      "Strict error mouse_dros_comb auc=0.579 error=0.313\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.589 error=0.315\n",
      "Gen error mouse_dros_comb auc=0.588 error=0.317\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.586 error=0.312\n",
      "BE error mouse_dros_comb auc=0.580 error=0.316\n",
      "\n",
      "\n",
      "Strict error mouse_dros_comb auc=0.568 error=0.345\n",
      "Strict error mouse_dros_comb auc=0.568 error=0.343\n",
      "\n",
      "\n",
      "Gen error mouse_dros_comb auc=0.572 error=0.339\n",
      "Gen error mouse_dros_comb auc=0.574 error=0.342\n",
      "\n",
      "\n",
      "BE error mouse_dros_comb auc=0.573 error=0.343\n",
      "BE error mouse_dros_comb auc=0.568 error=0.342\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_dros_comb_strict = []\n",
    "mean_auc_mouse_dros_comb_strict = []\n",
    "mean_err_mouse_dros_comb_gen = []\n",
    "mean_auc_mouse_dros_comb_gen = []\n",
    "mean_err_mouse_dros_comb_be = []\n",
    "mean_auc_mouse_dros_comb_be = []\n",
    "for e, f, t in zip(errors_mouse_dros_comb, fpr_mouse_dros_comb, tpr_mouse_dros_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse_dros_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_dros_comb_strict.append(error_item)\n",
    "                    mean_auc_mouse_dros_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_dros_comb_gen.append(error_item)\n",
    "                    mean_auc_mouse_dros_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_dros_comb_be.append(error_item)\n",
    "                    mean_auc_mouse_dros_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_dros_comb_org_strict = mean_err_mouse_dros_comb_strict[0::2]\n",
    "mean_err_mouse_dros_comb_fs_strict = mean_err_mouse_dros_comb_strict[1::2]\n",
    "mean_auc_mouse_dros_comb_org_strict = mean_auc_mouse_dros_comb_strict[0::2]\n",
    "mean_auc_mouse_dros_comb_fs_strict = mean_auc_mouse_dros_comb_strict[1::2]\n",
    "\n",
    "mean_err_mouse_dros_comb_org_gen = mean_err_mouse_dros_comb_gen[0::2]\n",
    "mean_err_mouse_dros_comb_fs_gen = mean_err_mouse_dros_comb_gen[1::2]\n",
    "mean_auc_mouse_dros_comb_org_gen = mean_auc_mouse_dros_comb_gen[0::2]\n",
    "mean_auc_mouse_dros_comb_fs_gen = mean_auc_mouse_dros_comb_gen[1::2]\n",
    "\n",
    "mean_err_mouse_dros_comb_org_be = mean_err_mouse_dros_comb_be[0::2]\n",
    "mean_err_mouse_dros_comb_fs_be = mean_err_mouse_dros_comb_be[1::2]\n",
    "mean_auc_mouse_dros_comb_org_be = mean_auc_mouse_dros_comb_be[0::2]\n",
    "mean_auc_mouse_dros_comb_fs_be = mean_auc_mouse_dros_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_dros_comb mean strict error original -  0.269060610217\n",
      "mouse_dros_comb mean strict error feature selection -  0.269976106951\n",
      "mouse_dros_comb mean strict AUC original -  0.660808227691\n",
      "mouse_dros_comb mean strict AUC feature selection -  0.659800999976\n",
      "\n",
      "\n",
      "mouse_dros_comb mean gen error original -  0.267393193331\n",
      "mouse_dros_comb mean gen error feature selection -  0.268903742526\n",
      "mouse_dros_comb mean gen AUC original -  0.669206506637\n",
      "mouse_dros_comb mean gen AUC feature selection -  0.668126732071\n",
      "\n",
      "\n",
      "mouse_dros_comb mean BE error original -  0.267524882968\n",
      "mouse_dros_comb mean BE error feature selection -  0.268893216208\n",
      "mouse_dros_comb mean BE AUC original -  0.671889037998\n",
      "mouse_dros_comb mean BE AUC feature selection -  0.66793535735\n"
     ]
    }
   ],
   "source": [
    "print('mouse_dros_comb mean strict error original - ', np.mean(mean_err_mouse_dros_comb_org_strict))\n",
    "print('mouse_dros_comb mean strict error feature selection - ', np.mean(mean_err_mouse_dros_comb_fs_strict))\n",
    "print('mouse_dros_comb mean strict AUC original - ', np.mean(mean_auc_mouse_dros_comb_org_strict))\n",
    "print('mouse_dros_comb mean strict AUC feature selection - ', np.mean(mean_auc_mouse_dros_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse_dros_comb mean gen error original - ', np.mean(mean_err_mouse_dros_comb_org_gen))\n",
    "print('mouse_dros_comb mean gen error feature selection - ', np.mean(mean_err_mouse_dros_comb_fs_gen))\n",
    "print('mouse_dros_comb mean gen AUC original - ', np.mean(mean_auc_mouse_dros_comb_org_gen))\n",
    "print('mouse_dros_comb mean gen AUC feature selection - ', np.mean(mean_auc_mouse_dros_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse_dros_comb mean BE error original - ', np.mean(mean_err_mouse_dros_comb_org_be))\n",
    "print('mouse_dros_comb mean BE error feature selection - ', np.mean(mean_err_mouse_dros_comb_fs_be))\n",
    "print('mouse_dros_comb mean BE AUC original - ', np.mean(mean_auc_mouse_dros_comb_org_be))\n",
    "print('mouse_dros_comb mean BE AUC feature selection - ', np.mean(mean_auc_mouse_dros_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 14:54:31,205 : INFO : collecting all words and their counts\n",
      "2017-04-26 14:54:31,206 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-26 14:54:31,257 : INFO : PROGRESS: at sentence #10000, processed 270015 words, keeping 16825 word types\n",
      "2017-04-26 14:54:31,305 : INFO : PROGRESS: at sentence #20000, processed 538823 words, keeping 23225 word types\n",
      "2017-04-26 14:54:31,358 : INFO : PROGRESS: at sentence #30000, processed 809116 words, keeping 27965 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 14:54:31,413 : INFO : PROGRESS: at sentence #40000, processed 1079448 words, keeping 32029 word types\n",
      "2017-04-26 14:54:31,475 : INFO : PROGRESS: at sentence #50000, processed 1348776 words, keeping 35481 word types\n",
      "2017-04-26 14:54:31,530 : INFO : PROGRESS: at sentence #60000, processed 1619812 words, keeping 38605 word types\n",
      "2017-04-26 14:54:31,584 : INFO : PROGRESS: at sentence #70000, processed 1890276 words, keeping 41477 word types\n",
      "2017-04-26 14:54:31,640 : INFO : PROGRESS: at sentence #80000, processed 2160777 words, keeping 44192 word types\n",
      "2017-04-26 14:54:31,694 : INFO : PROGRESS: at sentence #90000, processed 2427823 words, keeping 47411 word types\n",
      "2017-04-26 14:54:31,748 : INFO : PROGRESS: at sentence #100000, processed 2685420 words, keeping 51283 word types\n",
      "2017-04-26 14:54:31,762 : INFO : collected 51961 word types from a corpus of 2742934 raw words and 102139 sentences\n",
      "2017-04-26 14:54:31,764 : INFO : Loading a fresh vocabulary\n",
      "2017-04-26 14:54:31,821 : INFO : min_count=5 retains 16463 unique words (31% of original 51961, drops 35498)\n",
      "2017-04-26 14:54:31,822 : INFO : min_count=5 leaves 2686640 word corpus (97% of original 2742934, drops 56294)\n",
      "2017-04-26 14:54:31,865 : INFO : deleting the raw counts dictionary of 51961 items\n",
      "2017-04-26 14:54:31,868 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2017-04-26 14:54:31,869 : INFO : downsampling leaves estimated 2063971 word corpus (76.8% of prior 2686640)\n",
      "2017-04-26 14:54:31,869 : INFO : estimated required memory for 16463 words and 300 dimensions: 47742700 bytes\n",
      "2017-04-26 14:54:31,940 : INFO : resetting layer weights\n",
      "2017-04-26 14:54:32,128 : INFO : training model with 4 workers on 16463 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 14:54:32,129 : INFO : expecting 102139 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 14:54:33,152 : INFO : PROGRESS: at 7.61% examples, 776835 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:34,152 : INFO : PROGRESS: at 14.69% examples, 757409 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:35,156 : INFO : PROGRESS: at 22.12% examples, 755840 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:36,164 : INFO : PROGRESS: at 28.28% examples, 725674 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:37,181 : INFO : PROGRESS: at 34.57% examples, 709397 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:38,189 : INFO : PROGRESS: at 40.78% examples, 694942 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 14:54:39,198 : INFO : PROGRESS: at 48.37% examples, 707446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:40,204 : INFO : PROGRESS: at 56.26% examples, 720980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:41,206 : INFO : PROGRESS: at 63.47% examples, 722169 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:42,211 : INFO : PROGRESS: at 70.21% examples, 719679 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:43,217 : INFO : PROGRESS: at 76.78% examples, 716185 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:44,223 : INFO : PROGRESS: at 83.86% examples, 715935 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:45,225 : INFO : PROGRESS: at 91.89% examples, 725030 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:54:46,172 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 14:54:46,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 14:54:46,184 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 14:54:46,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 14:54:46,187 : INFO : training on 13714670 raw words (10319619 effective words) took 14.1s, 734321 effective words/s\n",
      "2017-04-26 14:54:46,187 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 14:54:46,267 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_SR_comb_model, separately None\n",
      "2017-04-26 14:54:46,267 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 14:54:46,268 : INFO : not storing attribute cum_table\n",
      "2017-04-26 14:54:46,583 : INFO : saved Results/mouse_dros_yeast_SR_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 14:54:57,479 : INFO : collecting all words and their counts\n",
      "2017-04-26 14:54:57,479 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-26 14:54:57,524 : INFO : PROGRESS: at sentence #10000, processed 259160 words, keeping 15302 word types\n",
      "2017-04-26 14:54:57,571 : INFO : PROGRESS: at sentence #20000, processed 517471 words, keeping 21201 word types\n",
      "2017-04-26 14:54:57,621 : INFO : PROGRESS: at sentence #30000, processed 776367 words, keeping 25525 word types\n",
      "2017-04-26 14:54:57,669 : INFO : PROGRESS: at sentence #40000, processed 1035554 words, keeping 29021 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 14:54:57,718 : INFO : PROGRESS: at sentence #50000, processed 1292135 words, keeping 31930 word types\n",
      "2017-04-26 14:54:57,770 : INFO : PROGRESS: at sentence #60000, processed 1547618 words, keeping 34566 word types\n",
      "2017-04-26 14:54:57,818 : INFO : PROGRESS: at sentence #70000, processed 1806195 words, keeping 36976 word types\n",
      "2017-04-26 14:54:57,866 : INFO : PROGRESS: at sentence #80000, processed 2065110 words, keeping 39099 word types\n",
      "2017-04-26 14:54:57,916 : INFO : PROGRESS: at sentence #90000, processed 2325244 words, keeping 41166 word types\n",
      "2017-04-26 14:54:57,965 : INFO : PROGRESS: at sentence #100000, processed 2584926 words, keeping 43114 word types\n",
      "2017-04-26 14:54:58,015 : INFO : PROGRESS: at sentence #110000, processed 2843943 words, keeping 44976 word types\n",
      "2017-04-26 14:54:58,064 : INFO : PROGRESS: at sentence #120000, processed 3100847 words, keeping 46734 word types\n",
      "2017-04-26 14:54:58,112 : INFO : PROGRESS: at sentence #130000, processed 3356160 words, keeping 48421 word types\n",
      "2017-04-26 14:54:58,162 : INFO : PROGRESS: at sentence #140000, processed 3615777 words, keeping 50022 word types\n",
      "2017-04-26 14:54:58,211 : INFO : PROGRESS: at sentence #150000, processed 3872551 words, keeping 51432 word types\n",
      "2017-04-26 14:54:58,260 : INFO : PROGRESS: at sentence #160000, processed 4130594 words, keeping 52843 word types\n",
      "2017-04-26 14:54:58,310 : INFO : PROGRESS: at sentence #170000, processed 4390035 words, keeping 54299 word types\n",
      "2017-04-26 14:54:58,360 : INFO : PROGRESS: at sentence #180000, processed 4648217 words, keeping 55633 word types\n",
      "2017-04-26 14:54:58,410 : INFO : PROGRESS: at sentence #190000, processed 4906004 words, keeping 56939 word types\n",
      "2017-04-26 14:54:58,459 : INFO : PROGRESS: at sentence #200000, processed 5165976 words, keeping 58215 word types\n",
      "2017-04-26 14:54:58,509 : INFO : PROGRESS: at sentence #210000, processed 5424019 words, keeping 59387 word types\n",
      "2017-04-26 14:54:58,559 : INFO : PROGRESS: at sentence #220000, processed 5681994 words, keeping 60588 word types\n",
      "2017-04-26 14:54:58,609 : INFO : PROGRESS: at sentence #230000, processed 5939799 words, keeping 61758 word types\n",
      "2017-04-26 14:54:58,659 : INFO : PROGRESS: at sentence #240000, processed 6200551 words, keeping 62958 word types\n",
      "2017-04-26 14:54:58,709 : INFO : PROGRESS: at sentence #250000, processed 6459409 words, keeping 64077 word types\n",
      "2017-04-26 14:54:58,759 : INFO : PROGRESS: at sentence #260000, processed 6720461 words, keeping 65107 word types\n",
      "2017-04-26 14:54:58,809 : INFO : PROGRESS: at sentence #270000, processed 6978852 words, keeping 66160 word types\n",
      "2017-04-26 14:54:58,859 : INFO : PROGRESS: at sentence #280000, processed 7238181 words, keeping 67163 word types\n",
      "2017-04-26 14:54:58,909 : INFO : PROGRESS: at sentence #290000, processed 7495839 words, keeping 68185 word types\n",
      "2017-04-26 14:54:58,958 : INFO : PROGRESS: at sentence #300000, processed 7755442 words, keeping 69161 word types\n",
      "2017-04-26 14:54:59,008 : INFO : PROGRESS: at sentence #310000, processed 8014072 words, keeping 70111 word types\n",
      "2017-04-26 14:54:59,058 : INFO : PROGRESS: at sentence #320000, processed 8272797 words, keeping 71105 word types\n",
      "2017-04-26 14:54:59,108 : INFO : PROGRESS: at sentence #330000, processed 8530742 words, keeping 72122 word types\n",
      "2017-04-26 14:54:59,158 : INFO : PROGRESS: at sentence #340000, processed 8789411 words, keeping 72964 word types\n",
      "2017-04-26 14:54:59,208 : INFO : PROGRESS: at sentence #350000, processed 9046766 words, keeping 73821 word types\n",
      "2017-04-26 14:54:59,258 : INFO : PROGRESS: at sentence #360000, processed 9305495 words, keeping 74685 word types\n",
      "2017-04-26 14:54:59,308 : INFO : PROGRESS: at sentence #370000, processed 9565737 words, keeping 75598 word types\n",
      "2017-04-26 14:54:59,358 : INFO : PROGRESS: at sentence #380000, processed 9824823 words, keeping 76424 word types\n",
      "2017-04-26 14:54:59,408 : INFO : PROGRESS: at sentence #390000, processed 10084166 words, keeping 77202 word types\n",
      "2017-04-26 14:54:59,458 : INFO : PROGRESS: at sentence #400000, processed 10342810 words, keeping 77991 word types\n",
      "2017-04-26 14:54:59,508 : INFO : PROGRESS: at sentence #410000, processed 10600323 words, keeping 78753 word types\n",
      "2017-04-26 14:54:59,560 : INFO : PROGRESS: at sentence #420000, processed 10858210 words, keeping 79542 word types\n",
      "2017-04-26 14:54:59,611 : INFO : PROGRESS: at sentence #430000, processed 11116462 words, keeping 80259 word types\n",
      "2017-04-26 14:54:59,661 : INFO : PROGRESS: at sentence #440000, processed 11372345 words, keeping 81045 word types\n",
      "2017-04-26 14:54:59,711 : INFO : PROGRESS: at sentence #450000, processed 11630322 words, keeping 81832 word types\n",
      "2017-04-26 14:54:59,762 : INFO : PROGRESS: at sentence #460000, processed 11889073 words, keeping 82579 word types\n",
      "2017-04-26 14:54:59,813 : INFO : PROGRESS: at sentence #470000, processed 12145291 words, keeping 83259 word types\n",
      "2017-04-26 14:54:59,865 : INFO : PROGRESS: at sentence #480000, processed 12405090 words, keeping 84036 word types\n",
      "2017-04-26 14:54:59,916 : INFO : PROGRESS: at sentence #490000, processed 12656960 words, keeping 85676 word types\n",
      "2017-04-26 14:54:59,971 : INFO : PROGRESS: at sentence #500000, processed 12901464 words, keeping 87548 word types\n",
      "2017-04-26 14:55:00,021 : INFO : PROGRESS: at sentence #510000, processed 13144343 words, keeping 88830 word types\n",
      "2017-04-26 14:55:00,071 : INFO : PROGRESS: at sentence #520000, processed 13386935 words, keeping 89960 word types\n",
      "2017-04-26 14:55:00,125 : INFO : PROGRESS: at sentence #530000, processed 13634214 words, keeping 91439 word types\n",
      "2017-04-26 14:55:00,174 : INFO : PROGRESS: at sentence #540000, processed 13880324 words, keeping 92674 word types\n",
      "2017-04-26 14:55:00,225 : INFO : PROGRESS: at sentence #550000, processed 14125968 words, keeping 93689 word types\n",
      "2017-04-26 14:55:00,274 : INFO : PROGRESS: at sentence #560000, processed 14371641 words, keeping 94579 word types\n",
      "2017-04-26 14:55:00,322 : INFO : collected 95340 word types from a corpus of 14605414 raw words and 569578 sentences\n",
      "2017-04-26 14:55:00,323 : INFO : Loading a fresh vocabulary\n",
      "2017-04-26 14:55:00,422 : INFO : min_count=5 retains 33967 unique words (35% of original 95340, drops 61373)\n",
      "2017-04-26 14:55:00,423 : INFO : min_count=5 leaves 14504518 word corpus (99% of original 14605414, drops 100896)\n",
      "2017-04-26 14:55:00,508 : INFO : deleting the raw counts dictionary of 95340 items\n",
      "2017-04-26 14:55:00,514 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2017-04-26 14:55:00,515 : INFO : downsampling leaves estimated 11110621 word corpus (76.6% of prior 14504518)\n",
      "2017-04-26 14:55:00,515 : INFO : estimated required memory for 33967 words and 300 dimensions: 98504300 bytes\n",
      "2017-04-26 14:55:00,642 : INFO : resetting layer weights\n",
      "2017-04-26 14:55:01,061 : INFO : training model with 4 workers on 33967 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 14:55:01,061 : INFO : expecting 569578 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 14:55:02,073 : INFO : PROGRESS: at 1.38% examples, 772424 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:03,079 : INFO : PROGRESS: at 2.76% examples, 767904 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:04,109 : INFO : PROGRESS: at 4.19% examples, 773146 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:05,113 : INFO : PROGRESS: at 5.73% examples, 793653 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:06,123 : INFO : PROGRESS: at 7.10% examples, 787065 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:07,127 : INFO : PROGRESS: at 8.35% examples, 772112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:08,128 : INFO : PROGRESS: at 9.59% examples, 761599 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:09,130 : INFO : PROGRESS: at 11.01% examples, 766107 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:10,150 : INFO : PROGRESS: at 12.57% examples, 776494 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:55:11,155 : INFO : PROGRESS: at 14.07% examples, 782841 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:12,158 : INFO : PROGRESS: at 15.64% examples, 790827 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:13,165 : INFO : PROGRESS: at 17.03% examples, 789135 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 14:55:14,176 : INFO : PROGRESS: at 18.56% examples, 789748 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:15,176 : INFO : PROGRESS: at 20.21% examples, 795846 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:16,177 : INFO : PROGRESS: at 21.77% examples, 801087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:17,178 : INFO : PROGRESS: at 22.84% examples, 788581 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:18,198 : INFO : PROGRESS: at 23.86% examples, 774936 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:19,199 : INFO : PROGRESS: at 25.07% examples, 769472 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:20,203 : INFO : PROGRESS: at 26.32% examples, 765659 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:21,218 : INFO : PROGRESS: at 27.61% examples, 762936 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:22,230 : INFO : PROGRESS: at 28.93% examples, 761642 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:23,240 : INFO : PROGRESS: at 30.29% examples, 761258 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:55:24,242 : INFO : PROGRESS: at 31.72% examples, 763105 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:25,244 : INFO : PROGRESS: at 33.29% examples, 767983 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:26,247 : INFO : PROGRESS: at 34.87% examples, 772406 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:27,252 : INFO : PROGRESS: at 36.45% examples, 776477 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:28,257 : INFO : PROGRESS: at 38.08% examples, 779990 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:29,259 : INFO : PROGRESS: at 39.75% examples, 783561 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:30,265 : INFO : PROGRESS: at 41.31% examples, 786235 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:31,268 : INFO : PROGRESS: at 42.85% examples, 788559 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:32,276 : INFO : PROGRESS: at 44.38% examples, 790636 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:33,285 : INFO : PROGRESS: at 45.40% examples, 783575 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:34,287 : INFO : PROGRESS: at 46.35% examples, 775958 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:35,289 : INFO : PROGRESS: at 47.33% examples, 769247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:36,307 : INFO : PROGRESS: at 48.33% examples, 762975 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:37,309 : INFO : PROGRESS: at 49.38% examples, 758240 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:55:38,339 : INFO : PROGRESS: at 50.48% examples, 753802 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:39,356 : INFO : PROGRESS: at 51.58% examples, 749873 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:55:40,363 : INFO : PROGRESS: at 52.65% examples, 745958 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:41,366 : INFO : PROGRESS: at 54.12% examples, 747960 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:42,369 : INFO : PROGRESS: at 55.65% examples, 750426 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:43,371 : INFO : PROGRESS: at 57.18% examples, 752770 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:44,379 : INFO : PROGRESS: at 58.80% examples, 754887 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:45,386 : INFO : PROGRESS: at 60.46% examples, 757885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:46,387 : INFO : PROGRESS: at 61.86% examples, 758421 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:47,388 : INFO : PROGRESS: at 63.28% examples, 759272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:48,402 : INFO : PROGRESS: at 64.71% examples, 759885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:49,408 : INFO : PROGRESS: at 66.11% examples, 760262 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:50,419 : INFO : PROGRESS: at 67.44% examples, 759788 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:51,421 : INFO : PROGRESS: at 68.86% examples, 760535 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:52,424 : INFO : PROGRESS: at 70.38% examples, 762248 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:53,428 : INFO : PROGRESS: at 71.95% examples, 764496 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:54,429 : INFO : PROGRESS: at 73.52% examples, 766684 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:55,429 : INFO : PROGRESS: at 75.08% examples, 768678 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:56,434 : INFO : PROGRESS: at 76.51% examples, 769153 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:57,434 : INFO : PROGRESS: at 77.90% examples, 768782 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:55:58,436 : INFO : PROGRESS: at 79.32% examples, 768361 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:55:59,452 : INFO : PROGRESS: at 80.71% examples, 767968 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 14:56:00,460 : INFO : PROGRESS: at 82.05% examples, 767617 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:01,476 : INFO : PROGRESS: at 83.02% examples, 763652 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:02,483 : INFO : PROGRESS: at 84.03% examples, 760411 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:03,488 : INFO : PROGRESS: at 85.11% examples, 757797 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:04,493 : INFO : PROGRESS: at 86.21% examples, 755507 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:05,500 : INFO : PROGRESS: at 87.47% examples, 754675 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:06,504 : INFO : PROGRESS: at 88.72% examples, 753784 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:07,509 : INFO : PROGRESS: at 89.97% examples, 753017 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:08,511 : INFO : PROGRESS: at 91.22% examples, 752217 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:09,519 : INFO : PROGRESS: at 92.75% examples, 753700 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:10,539 : INFO : PROGRESS: at 94.17% examples, 754124 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:56:11,545 : INFO : PROGRESS: at 95.60% examples, 754691 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:12,558 : INFO : PROGRESS: at 96.91% examples, 754212 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:13,562 : INFO : PROGRESS: at 98.15% examples, 752811 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:56:14,586 : INFO : PROGRESS: at 99.28% examples, 750432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:56:15,169 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 14:56:15,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 14:56:15,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 14:56:15,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 14:56:15,189 : INFO : training on 73027070 raw words (55550581 effective words) took 74.1s, 749463 effective words/s\n",
      "2017-04-26 14:56:15,189 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 14:56:15,369 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_GEN_comb_model, separately None\n",
      "2017-04-26 14:56:15,369 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 14:56:15,370 : INFO : not storing attribute cum_table\n",
      "2017-04-26 14:56:16,278 : INFO : saved Results/mouse_dros_yeast_GEN_comb_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 14:57:27,141 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-26 14:57:27,367 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-26 14:57:27,409 : INFO : PROGRESS: at sentence #10000, processed 238773 words, keeping 15835 word types\n",
      "2017-04-26 14:57:27,451 : INFO : PROGRESS: at sentence #20000, processed 477914 words, keeping 21988 word types\n",
      "2017-04-26 14:57:27,496 : INFO : PROGRESS: at sentence #30000, processed 717576 words, keeping 26790 word types\n",
      "2017-04-26 14:57:27,542 : INFO : PROGRESS: at sentence #40000, processed 958591 words, keeping 30536 word types\n",
      "2017-04-26 14:57:27,585 : INFO : PROGRESS: at sentence #50000, processed 1197796 words, keeping 33709 word types\n",
      "2017-04-26 14:57:27,630 : INFO : PROGRESS: at sentence #60000, processed 1437984 words, keeping 36640 word types\n",
      "2017-04-26 14:57:27,673 : INFO : PROGRESS: at sentence #70000, processed 1677777 words, keeping 39294 word types\n",
      "2017-04-26 14:57:27,718 : INFO : PROGRESS: at sentence #80000, processed 1915446 words, keeping 41634 word types\n",
      "2017-04-26 14:57:27,763 : INFO : PROGRESS: at sentence #90000, processed 2155511 words, keeping 43929 word types\n",
      "2017-04-26 14:57:27,808 : INFO : PROGRESS: at sentence #100000, processed 2393757 words, keeping 46053 word types\n",
      "2017-04-26 14:57:27,853 : INFO : PROGRESS: at sentence #110000, processed 2631041 words, keeping 47951 word types\n",
      "2017-04-26 14:57:27,900 : INFO : PROGRESS: at sentence #120000, processed 2869293 words, keeping 49797 word types\n",
      "2017-04-26 14:57:27,952 : INFO : PROGRESS: at sentence #130000, processed 3108700 words, keeping 51619 word types\n",
      "2017-04-26 14:57:28,002 : INFO : PROGRESS: at sentence #140000, processed 3347615 words, keeping 53338 word types\n",
      "2017-04-26 14:57:28,052 : INFO : PROGRESS: at sentence #150000, processed 3586785 words, keeping 54974 word types\n",
      "2017-04-26 14:57:28,100 : INFO : PROGRESS: at sentence #160000, processed 3826159 words, keeping 56484 word types\n",
      "2017-04-26 14:57:28,150 : INFO : PROGRESS: at sentence #170000, processed 4066476 words, keeping 58131 word types\n",
      "2017-04-26 14:57:28,199 : INFO : PROGRESS: at sentence #180000, processed 4304628 words, keeping 59606 word types\n",
      "2017-04-26 14:57:28,248 : INFO : PROGRESS: at sentence #190000, processed 4543230 words, keeping 61076 word types\n",
      "2017-04-26 14:57:28,297 : INFO : PROGRESS: at sentence #200000, processed 4781152 words, keeping 62424 word types\n",
      "2017-04-26 14:57:28,344 : INFO : PROGRESS: at sentence #210000, processed 5019676 words, keeping 63769 word types\n",
      "2017-04-26 14:57:28,393 : INFO : PROGRESS: at sentence #220000, processed 5257357 words, keeping 65050 word types\n",
      "2017-04-26 14:57:28,442 : INFO : PROGRESS: at sentence #230000, processed 5497197 words, keeping 66353 word types\n",
      "2017-04-26 14:57:28,491 : INFO : PROGRESS: at sentence #240000, processed 5736875 words, keeping 67693 word types\n",
      "2017-04-26 14:57:28,541 : INFO : PROGRESS: at sentence #250000, processed 5976145 words, keeping 68951 word types\n",
      "2017-04-26 14:57:28,590 : INFO : PROGRESS: at sentence #260000, processed 6216893 words, keeping 70106 word types\n",
      "2017-04-26 14:57:28,639 : INFO : PROGRESS: at sentence #270000, processed 6457047 words, keeping 71288 word types\n",
      "2017-04-26 14:57:28,688 : INFO : PROGRESS: at sentence #280000, processed 6694834 words, keeping 72461 word types\n",
      "2017-04-26 14:57:28,740 : INFO : PROGRESS: at sentence #290000, processed 6934927 words, keeping 73598 word types\n",
      "2017-04-26 14:57:28,795 : INFO : PROGRESS: at sentence #300000, processed 7174844 words, keeping 74677 word types\n",
      "2017-04-26 14:57:28,844 : INFO : PROGRESS: at sentence #310000, processed 7414243 words, keeping 75781 word types\n",
      "2017-04-26 14:57:28,892 : INFO : PROGRESS: at sentence #320000, processed 7652887 words, keeping 76826 word types\n",
      "2017-04-26 14:57:28,940 : INFO : PROGRESS: at sentence #330000, processed 7890555 words, keeping 77863 word types\n",
      "2017-04-26 14:57:28,989 : INFO : PROGRESS: at sentence #340000, processed 8130256 words, keeping 78887 word types\n",
      "2017-04-26 14:57:29,037 : INFO : PROGRESS: at sentence #350000, processed 8369050 words, keeping 79888 word types\n",
      "2017-04-26 14:57:29,087 : INFO : PROGRESS: at sentence #360000, processed 8609270 words, keeping 80823 word types\n",
      "2017-04-26 14:57:29,136 : INFO : PROGRESS: at sentence #370000, processed 8848489 words, keeping 81798 word types\n",
      "2017-04-26 14:57:29,185 : INFO : PROGRESS: at sentence #380000, processed 9089872 words, keeping 82802 word types\n",
      "2017-04-26 14:57:29,233 : INFO : PROGRESS: at sentence #390000, processed 9329662 words, keeping 83740 word types\n",
      "2017-04-26 14:57:29,287 : INFO : PROGRESS: at sentence #400000, processed 9569250 words, keeping 84647 word types\n",
      "2017-04-26 14:57:29,336 : INFO : PROGRESS: at sentence #410000, processed 9809063 words, keeping 85617 word types\n",
      "2017-04-26 14:57:29,384 : INFO : PROGRESS: at sentence #420000, processed 10047233 words, keeping 86482 word types\n",
      "2017-04-26 14:57:29,433 : INFO : PROGRESS: at sentence #430000, processed 10285894 words, keeping 87321 word types\n",
      "2017-04-26 14:57:29,485 : INFO : PROGRESS: at sentence #440000, processed 10525486 words, keeping 88205 word types\n",
      "2017-04-26 14:57:29,535 : INFO : PROGRESS: at sentence #450000, processed 10764967 words, keeping 89062 word types\n",
      "2017-04-26 14:57:29,585 : INFO : PROGRESS: at sentence #460000, processed 11002869 words, keeping 89954 word types\n",
      "2017-04-26 14:57:29,636 : INFO : PROGRESS: at sentence #470000, processed 11243294 words, keeping 90753 word types\n",
      "2017-04-26 14:57:29,687 : INFO : PROGRESS: at sentence #480000, processed 11484445 words, keeping 91736 word types\n",
      "2017-04-26 14:57:29,740 : INFO : PROGRESS: at sentence #490000, processed 11725149 words, keeping 92542 word types\n",
      "2017-04-26 14:57:29,794 : INFO : PROGRESS: at sentence #500000, processed 11964306 words, keeping 93324 word types\n",
      "2017-04-26 14:57:29,845 : INFO : PROGRESS: at sentence #510000, processed 12202978 words, keeping 94171 word types\n",
      "2017-04-26 14:57:29,891 : INFO : PROGRESS: at sentence #520000, processed 12441606 words, keeping 94979 word types\n",
      "2017-04-26 14:57:29,941 : INFO : PROGRESS: at sentence #530000, processed 12680418 words, keeping 95711 word types\n",
      "2017-04-26 14:57:29,990 : INFO : PROGRESS: at sentence #540000, processed 12919731 words, keeping 96507 word types\n",
      "2017-04-26 14:57:30,040 : INFO : PROGRESS: at sentence #550000, processed 13158561 words, keeping 97294 word types\n",
      "2017-04-26 14:57:30,089 : INFO : PROGRESS: at sentence #560000, processed 13396114 words, keeping 98016 word types\n",
      "2017-04-26 14:57:30,139 : INFO : PROGRESS: at sentence #570000, processed 13636080 words, keeping 98761 word types\n",
      "2017-04-26 14:57:30,189 : INFO : PROGRESS: at sentence #580000, processed 13875540 words, keeping 99506 word types\n",
      "2017-04-26 14:57:30,238 : INFO : PROGRESS: at sentence #590000, processed 14112719 words, keeping 100181 word types\n",
      "2017-04-26 14:57:30,288 : INFO : PROGRESS: at sentence #600000, processed 14353726 words, keeping 100897 word types\n",
      "2017-04-26 14:57:30,338 : INFO : PROGRESS: at sentence #610000, processed 14592630 words, keeping 101596 word types\n",
      "2017-04-26 14:57:30,388 : INFO : PROGRESS: at sentence #620000, processed 14831189 words, keeping 102310 word types\n",
      "2017-04-26 14:57:30,437 : INFO : PROGRESS: at sentence #630000, processed 15069135 words, keeping 103004 word types\n",
      "2017-04-26 14:57:30,487 : INFO : PROGRESS: at sentence #640000, processed 15307815 words, keeping 103717 word types\n",
      "2017-04-26 14:57:30,536 : INFO : PROGRESS: at sentence #650000, processed 15546092 words, keeping 104391 word types\n",
      "2017-04-26 14:57:30,586 : INFO : PROGRESS: at sentence #660000, processed 15784550 words, keeping 105071 word types\n",
      "2017-04-26 14:57:30,636 : INFO : PROGRESS: at sentence #670000, processed 16023417 words, keeping 105744 word types\n",
      "2017-04-26 14:57:30,686 : INFO : PROGRESS: at sentence #680000, processed 16260949 words, keeping 106375 word types\n",
      "2017-04-26 14:57:30,736 : INFO : PROGRESS: at sentence #690000, processed 16498874 words, keeping 107013 word types\n",
      "2017-04-26 14:57:30,785 : INFO : PROGRESS: at sentence #700000, processed 16737379 words, keeping 107643 word types\n",
      "2017-04-26 14:57:30,836 : INFO : PROGRESS: at sentence #710000, processed 16975807 words, keeping 108329 word types\n",
      "2017-04-26 14:57:30,902 : INFO : PROGRESS: at sentence #720000, processed 17216016 words, keeping 108934 word types\n",
      "2017-04-26 14:57:30,963 : INFO : PROGRESS: at sentence #730000, processed 17453522 words, keeping 109626 word types\n",
      "2017-04-26 14:57:31,024 : INFO : PROGRESS: at sentence #740000, processed 17691279 words, keeping 110253 word types\n",
      "2017-04-26 14:57:31,085 : INFO : PROGRESS: at sentence #750000, processed 17929498 words, keeping 110926 word types\n",
      "2017-04-26 14:57:31,147 : INFO : PROGRESS: at sentence #760000, processed 18169044 words, keeping 111547 word types\n",
      "2017-04-26 14:57:31,197 : INFO : PROGRESS: at sentence #770000, processed 18406597 words, keeping 112212 word types\n",
      "2017-04-26 14:57:31,242 : INFO : PROGRESS: at sentence #780000, processed 18644265 words, keeping 112865 word types\n",
      "2017-04-26 14:57:31,292 : INFO : PROGRESS: at sentence #790000, processed 18883201 words, keeping 113478 word types\n",
      "2017-04-26 14:57:31,342 : INFO : PROGRESS: at sentence #800000, processed 19121447 words, keeping 114058 word types\n",
      "2017-04-26 14:57:31,392 : INFO : PROGRESS: at sentence #810000, processed 19361943 words, keeping 114626 word types\n",
      "2017-04-26 14:57:31,442 : INFO : PROGRESS: at sentence #820000, processed 19600469 words, keeping 115226 word types\n",
      "2017-04-26 14:57:31,493 : INFO : PROGRESS: at sentence #830000, processed 19841292 words, keeping 115888 word types\n",
      "2017-04-26 14:57:31,543 : INFO : PROGRESS: at sentence #840000, processed 20082463 words, keeping 116461 word types\n",
      "2017-04-26 14:57:31,593 : INFO : PROGRESS: at sentence #850000, processed 20320755 words, keeping 117047 word types\n",
      "2017-04-26 14:57:31,643 : INFO : PROGRESS: at sentence #860000, processed 20559606 words, keeping 117629 word types\n",
      "2017-04-26 14:57:31,692 : INFO : PROGRESS: at sentence #870000, processed 20798316 words, keeping 118275 word types\n",
      "2017-04-26 14:57:31,742 : INFO : PROGRESS: at sentence #880000, processed 21036531 words, keeping 118877 word types\n",
      "2017-04-26 14:57:31,791 : INFO : PROGRESS: at sentence #890000, processed 21275424 words, keeping 119410 word types\n",
      "2017-04-26 14:57:31,841 : INFO : PROGRESS: at sentence #900000, processed 21515506 words, keeping 119969 word types\n",
      "2017-04-26 14:57:31,890 : INFO : PROGRESS: at sentence #910000, processed 21753660 words, keeping 120532 word types\n",
      "2017-04-26 14:57:31,941 : INFO : PROGRESS: at sentence #920000, processed 21994487 words, keeping 121063 word types\n",
      "2017-04-26 14:57:31,991 : INFO : PROGRESS: at sentence #930000, processed 22234103 words, keeping 121591 word types\n",
      "2017-04-26 14:57:32,040 : INFO : PROGRESS: at sentence #940000, processed 22471485 words, keeping 122159 word types\n",
      "2017-04-26 14:57:32,091 : INFO : PROGRESS: at sentence #950000, processed 22711734 words, keeping 122737 word types\n",
      "2017-04-26 14:57:32,141 : INFO : PROGRESS: at sentence #960000, processed 22952718 words, keeping 123281 word types\n",
      "2017-04-26 14:57:32,191 : INFO : PROGRESS: at sentence #970000, processed 23193361 words, keeping 123887 word types\n",
      "2017-04-26 14:57:32,247 : INFO : PROGRESS: at sentence #980000, processed 23433683 words, keeping 124419 word types\n",
      "2017-04-26 14:57:32,303 : INFO : PROGRESS: at sentence #990000, processed 23673152 words, keeping 124965 word types\n",
      "2017-04-26 14:57:32,355 : INFO : PROGRESS: at sentence #1000000, processed 23912844 words, keeping 125507 word types\n",
      "2017-04-26 14:57:32,405 : INFO : PROGRESS: at sentence #1010000, processed 24151193 words, keeping 126062 word types\n",
      "2017-04-26 14:57:32,459 : INFO : PROGRESS: at sentence #1020000, processed 24389218 words, keeping 126633 word types\n",
      "2017-04-26 14:57:32,517 : INFO : PROGRESS: at sentence #1030000, processed 24630302 words, keeping 127145 word types\n",
      "2017-04-26 14:57:32,568 : INFO : PROGRESS: at sentence #1040000, processed 24871525 words, keeping 127653 word types\n",
      "2017-04-26 14:57:32,618 : INFO : PROGRESS: at sentence #1050000, processed 25109908 words, keeping 128134 word types\n",
      "2017-04-26 14:57:32,667 : INFO : PROGRESS: at sentence #1060000, processed 25348170 words, keeping 128662 word types\n",
      "2017-04-26 14:57:32,718 : INFO : PROGRESS: at sentence #1070000, processed 25585783 words, keeping 129189 word types\n",
      "2017-04-26 14:57:32,768 : INFO : PROGRESS: at sentence #1080000, processed 25825229 words, keeping 129692 word types\n",
      "2017-04-26 14:57:32,818 : INFO : PROGRESS: at sentence #1090000, processed 26063660 words, keeping 130168 word types\n",
      "2017-04-26 14:57:32,868 : INFO : PROGRESS: at sentence #1100000, processed 26302092 words, keeping 130637 word types\n",
      "2017-04-26 14:57:32,918 : INFO : PROGRESS: at sentence #1110000, processed 26540824 words, keeping 131143 word types\n",
      "2017-04-26 14:57:32,967 : INFO : PROGRESS: at sentence #1120000, processed 26780890 words, keeping 131647 word types\n",
      "2017-04-26 14:57:33,018 : INFO : PROGRESS: at sentence #1130000, processed 27018608 words, keeping 132123 word types\n",
      "2017-04-26 14:57:33,067 : INFO : PROGRESS: at sentence #1140000, processed 27256797 words, keeping 132551 word types\n",
      "2017-04-26 14:57:33,118 : INFO : PROGRESS: at sentence #1150000, processed 27494126 words, keeping 133040 word types\n",
      "2017-04-26 14:57:33,167 : INFO : PROGRESS: at sentence #1160000, processed 27732678 words, keeping 133496 word types\n",
      "2017-04-26 14:57:33,219 : INFO : PROGRESS: at sentence #1170000, processed 27972983 words, keeping 133969 word types\n",
      "2017-04-26 14:57:33,268 : INFO : PROGRESS: at sentence #1180000, processed 28211889 words, keeping 134485 word types\n",
      "2017-04-26 14:57:33,319 : INFO : PROGRESS: at sentence #1190000, processed 28450810 words, keeping 134972 word types\n",
      "2017-04-26 14:57:33,369 : INFO : PROGRESS: at sentence #1200000, processed 28690075 words, keeping 135452 word types\n",
      "2017-04-26 14:57:33,420 : INFO : PROGRESS: at sentence #1210000, processed 28929796 words, keeping 135889 word types\n",
      "2017-04-26 14:57:33,470 : INFO : PROGRESS: at sentence #1220000, processed 29168648 words, keeping 136361 word types\n",
      "2017-04-26 14:57:33,521 : INFO : PROGRESS: at sentence #1230000, processed 29408424 words, keeping 136832 word types\n",
      "2017-04-26 14:57:33,571 : INFO : PROGRESS: at sentence #1240000, processed 29647335 words, keeping 137279 word types\n",
      "2017-04-26 14:57:33,622 : INFO : PROGRESS: at sentence #1250000, processed 29884406 words, keeping 137748 word types\n",
      "2017-04-26 14:57:33,670 : INFO : PROGRESS: at sentence #1260000, processed 30122738 words, keeping 138241 word types\n",
      "2017-04-26 14:57:33,721 : INFO : PROGRESS: at sentence #1270000, processed 30362393 words, keeping 138645 word types\n",
      "2017-04-26 14:57:33,770 : INFO : PROGRESS: at sentence #1280000, processed 30600902 words, keeping 139039 word types\n",
      "2017-04-26 14:57:33,821 : INFO : PROGRESS: at sentence #1290000, processed 30841094 words, keeping 139526 word types\n",
      "2017-04-26 14:57:33,872 : INFO : PROGRESS: at sentence #1300000, processed 31079653 words, keeping 139962 word types\n",
      "2017-04-26 14:57:33,921 : INFO : PROGRESS: at sentence #1310000, processed 31318371 words, keeping 140418 word types\n",
      "2017-04-26 14:57:33,971 : INFO : PROGRESS: at sentence #1320000, processed 31555510 words, keeping 140823 word types\n",
      "2017-04-26 14:57:34,021 : INFO : PROGRESS: at sentence #1330000, processed 31794835 words, keeping 141259 word types\n",
      "2017-04-26 14:57:34,072 : INFO : PROGRESS: at sentence #1340000, processed 32032738 words, keeping 141698 word types\n",
      "2017-04-26 14:57:34,122 : INFO : PROGRESS: at sentence #1350000, processed 32272078 words, keeping 142141 word types\n",
      "2017-04-26 14:57:34,172 : INFO : PROGRESS: at sentence #1360000, processed 32509941 words, keeping 142586 word types\n",
      "2017-04-26 14:57:34,222 : INFO : PROGRESS: at sentence #1370000, processed 32748532 words, keeping 142971 word types\n",
      "2017-04-26 14:57:34,273 : INFO : PROGRESS: at sentence #1380000, processed 32988507 words, keeping 143400 word types\n",
      "2017-04-26 14:57:34,322 : INFO : PROGRESS: at sentence #1390000, processed 33228433 words, keeping 143810 word types\n",
      "2017-04-26 14:57:34,372 : INFO : PROGRESS: at sentence #1400000, processed 33468696 words, keeping 144266 word types\n",
      "2017-04-26 14:57:34,422 : INFO : PROGRESS: at sentence #1410000, processed 33708673 words, keeping 144666 word types\n",
      "2017-04-26 14:57:34,472 : INFO : PROGRESS: at sentence #1420000, processed 33948434 words, keeping 145068 word types\n",
      "2017-04-26 14:57:34,522 : INFO : PROGRESS: at sentence #1430000, processed 34188553 words, keeping 145502 word types\n",
      "2017-04-26 14:57:34,572 : INFO : PROGRESS: at sentence #1440000, processed 34426776 words, keeping 145914 word types\n",
      "2017-04-26 14:57:34,623 : INFO : PROGRESS: at sentence #1450000, processed 34667294 words, keeping 146335 word types\n",
      "2017-04-26 14:57:34,673 : INFO : PROGRESS: at sentence #1460000, processed 34905418 words, keeping 146769 word types\n",
      "2017-04-26 14:57:34,723 : INFO : PROGRESS: at sentence #1470000, processed 35144743 words, keeping 147183 word types\n",
      "2017-04-26 14:57:34,773 : INFO : PROGRESS: at sentence #1480000, processed 35385297 words, keeping 147570 word types\n",
      "2017-04-26 14:57:34,826 : INFO : PROGRESS: at sentence #1490000, processed 35623899 words, keeping 147964 word types\n",
      "2017-04-26 14:57:34,878 : INFO : PROGRESS: at sentence #1500000, processed 35862753 words, keeping 148360 word types\n",
      "2017-04-26 14:57:34,925 : INFO : PROGRESS: at sentence #1510000, processed 36100928 words, keeping 148783 word types\n",
      "2017-04-26 14:57:34,976 : INFO : PROGRESS: at sentence #1520000, processed 36342212 words, keeping 149186 word types\n",
      "2017-04-26 14:57:35,027 : INFO : PROGRESS: at sentence #1530000, processed 36582675 words, keeping 149554 word types\n",
      "2017-04-26 14:57:35,077 : INFO : PROGRESS: at sentence #1540000, processed 36822134 words, keeping 149957 word types\n",
      "2017-04-26 14:57:35,127 : INFO : PROGRESS: at sentence #1550000, processed 37059646 words, keeping 150378 word types\n",
      "2017-04-26 14:57:35,177 : INFO : PROGRESS: at sentence #1560000, processed 37297977 words, keeping 150774 word types\n",
      "2017-04-26 14:57:35,227 : INFO : PROGRESS: at sentence #1570000, processed 37537484 words, keeping 151166 word types\n",
      "2017-04-26 14:57:35,288 : INFO : PROGRESS: at sentence #1580000, processed 37778423 words, keeping 151621 word types\n",
      "2017-04-26 14:57:35,349 : INFO : PROGRESS: at sentence #1590000, processed 38017723 words, keeping 152027 word types\n",
      "2017-04-26 14:57:35,410 : INFO : PROGRESS: at sentence #1600000, processed 38255699 words, keeping 152386 word types\n",
      "2017-04-26 14:57:35,472 : INFO : PROGRESS: at sentence #1610000, processed 38493736 words, keeping 152779 word types\n",
      "2017-04-26 14:57:35,522 : INFO : PROGRESS: at sentence #1620000, processed 38731839 words, keeping 153104 word types\n",
      "2017-04-26 14:57:35,573 : INFO : PROGRESS: at sentence #1630000, processed 38971509 words, keeping 153519 word types\n",
      "2017-04-26 14:57:35,624 : INFO : PROGRESS: at sentence #1640000, processed 39212178 words, keeping 153950 word types\n",
      "2017-04-26 14:57:35,676 : INFO : PROGRESS: at sentence #1650000, processed 39451840 words, keeping 154302 word types\n",
      "2017-04-26 14:57:35,728 : INFO : PROGRESS: at sentence #1660000, processed 39691099 words, keeping 154670 word types\n",
      "2017-04-26 14:57:35,783 : INFO : PROGRESS: at sentence #1670000, processed 39929413 words, keeping 155065 word types\n",
      "2017-04-26 14:57:35,834 : INFO : PROGRESS: at sentence #1680000, processed 40169115 words, keeping 155434 word types\n",
      "2017-04-26 14:57:35,883 : INFO : PROGRESS: at sentence #1690000, processed 40409999 words, keeping 155810 word types\n",
      "2017-04-26 14:57:35,935 : INFO : PROGRESS: at sentence #1700000, processed 40647395 words, keeping 156209 word types\n",
      "2017-04-26 14:57:35,986 : INFO : PROGRESS: at sentence #1710000, processed 40887062 words, keeping 156593 word types\n",
      "2017-04-26 14:57:36,037 : INFO : PROGRESS: at sentence #1720000, processed 41126602 words, keeping 156991 word types\n",
      "2017-04-26 14:57:36,092 : INFO : PROGRESS: at sentence #1730000, processed 41365999 words, keeping 157366 word types\n",
      "2017-04-26 14:57:36,143 : INFO : PROGRESS: at sentence #1740000, processed 41605519 words, keeping 157709 word types\n",
      "2017-04-26 14:57:36,194 : INFO : PROGRESS: at sentence #1750000, processed 41846291 words, keeping 158066 word types\n",
      "2017-04-26 14:57:36,247 : INFO : PROGRESS: at sentence #1760000, processed 42085104 words, keeping 158454 word types\n",
      "2017-04-26 14:57:36,298 : INFO : PROGRESS: at sentence #1770000, processed 42322747 words, keeping 158805 word types\n",
      "2017-04-26 14:57:36,349 : INFO : PROGRESS: at sentence #1780000, processed 42560740 words, keeping 159147 word types\n",
      "2017-04-26 14:57:36,400 : INFO : PROGRESS: at sentence #1790000, processed 42799404 words, keeping 159485 word types\n",
      "2017-04-26 14:57:36,452 : INFO : PROGRESS: at sentence #1800000, processed 43040128 words, keeping 159842 word types\n",
      "2017-04-26 14:57:36,503 : INFO : PROGRESS: at sentence #1810000, processed 43278316 words, keeping 160178 word types\n",
      "2017-04-26 14:57:36,554 : INFO : PROGRESS: at sentence #1820000, processed 43516381 words, keeping 160592 word types\n",
      "2017-04-26 14:57:36,605 : INFO : PROGRESS: at sentence #1830000, processed 43754431 words, keeping 160940 word types\n",
      "2017-04-26 14:57:36,658 : INFO : PROGRESS: at sentence #1840000, processed 43994031 words, keeping 161286 word types\n",
      "2017-04-26 14:57:36,713 : INFO : PROGRESS: at sentence #1850000, processed 44233441 words, keeping 161633 word types\n",
      "2017-04-26 14:57:36,768 : INFO : PROGRESS: at sentence #1860000, processed 44474504 words, keeping 161992 word types\n",
      "2017-04-26 14:57:36,823 : INFO : PROGRESS: at sentence #1870000, processed 44713992 words, keeping 162322 word types\n",
      "2017-04-26 14:57:36,878 : INFO : PROGRESS: at sentence #1880000, processed 44954109 words, keeping 162627 word types\n",
      "2017-04-26 14:57:36,932 : INFO : PROGRESS: at sentence #1890000, processed 45191888 words, keeping 162936 word types\n",
      "2017-04-26 14:57:36,987 : INFO : PROGRESS: at sentence #1900000, processed 45430711 words, keeping 163279 word types\n",
      "2017-04-26 14:57:37,042 : INFO : PROGRESS: at sentence #1910000, processed 45670050 words, keeping 163650 word types\n",
      "2017-04-26 14:57:37,097 : INFO : PROGRESS: at sentence #1920000, processed 45909079 words, keeping 163990 word types\n",
      "2017-04-26 14:57:37,152 : INFO : PROGRESS: at sentence #1930000, processed 46148737 words, keeping 164338 word types\n",
      "2017-04-26 14:57:37,207 : INFO : PROGRESS: at sentence #1940000, processed 46389002 words, keeping 164640 word types\n",
      "2017-04-26 14:57:37,263 : INFO : PROGRESS: at sentence #1950000, processed 46628955 words, keeping 164995 word types\n",
      "2017-04-26 14:57:37,318 : INFO : PROGRESS: at sentence #1960000, processed 46867551 words, keeping 165352 word types\n",
      "2017-04-26 14:57:37,373 : INFO : PROGRESS: at sentence #1970000, processed 47105772 words, keeping 165677 word types\n",
      "2017-04-26 14:57:37,425 : INFO : PROGRESS: at sentence #1980000, processed 47345107 words, keeping 166003 word types\n",
      "2017-04-26 14:57:37,480 : INFO : PROGRESS: at sentence #1990000, processed 47584069 words, keeping 166342 word types\n",
      "2017-04-26 14:57:37,536 : INFO : PROGRESS: at sentence #2000000, processed 47822895 words, keeping 166661 word types\n",
      "2017-04-26 14:57:37,592 : INFO : PROGRESS: at sentence #2010000, processed 48063437 words, keeping 166974 word types\n",
      "2017-04-26 14:57:37,647 : INFO : PROGRESS: at sentence #2020000, processed 48301572 words, keeping 167358 word types\n",
      "2017-04-26 14:57:37,703 : INFO : PROGRESS: at sentence #2030000, processed 48538913 words, keeping 167655 word types\n",
      "2017-04-26 14:57:37,758 : INFO : PROGRESS: at sentence #2040000, processed 48778849 words, keeping 167965 word types\n",
      "2017-04-26 14:57:37,814 : INFO : PROGRESS: at sentence #2050000, processed 49018009 words, keeping 168298 word types\n",
      "2017-04-26 14:57:37,869 : INFO : PROGRESS: at sentence #2060000, processed 49256760 words, keeping 168640 word types\n",
      "2017-04-26 14:57:37,925 : INFO : PROGRESS: at sentence #2070000, processed 49496339 words, keeping 168984 word types\n",
      "2017-04-26 14:57:37,980 : INFO : PROGRESS: at sentence #2080000, processed 49735347 words, keeping 169330 word types\n",
      "2017-04-26 14:57:38,036 : INFO : PROGRESS: at sentence #2090000, processed 49973488 words, keeping 169654 word types\n",
      "2017-04-26 14:57:38,092 : INFO : PROGRESS: at sentence #2100000, processed 50213582 words, keeping 169945 word types\n",
      "2017-04-26 14:57:38,147 : INFO : PROGRESS: at sentence #2110000, processed 50451771 words, keeping 170240 word types\n",
      "2017-04-26 14:57:38,203 : INFO : PROGRESS: at sentence #2120000, processed 50691538 words, keeping 170575 word types\n",
      "2017-04-26 14:57:38,262 : INFO : PROGRESS: at sentence #2130000, processed 50931756 words, keeping 170923 word types\n",
      "2017-04-26 14:57:38,318 : INFO : PROGRESS: at sentence #2140000, processed 51171305 words, keeping 171236 word types\n",
      "2017-04-26 14:57:38,376 : INFO : PROGRESS: at sentence #2150000, processed 51412236 words, keeping 171579 word types\n",
      "2017-04-26 14:57:38,441 : INFO : PROGRESS: at sentence #2160000, processed 51650509 words, keeping 171877 word types\n",
      "2017-04-26 14:57:38,493 : INFO : PROGRESS: at sentence #2170000, processed 51888253 words, keeping 172202 word types\n",
      "2017-04-26 14:57:38,548 : INFO : PROGRESS: at sentence #2180000, processed 52128010 words, keeping 172514 word types\n",
      "2017-04-26 14:57:38,604 : INFO : PROGRESS: at sentence #2190000, processed 52367983 words, keeping 172864 word types\n",
      "2017-04-26 14:57:38,663 : INFO : PROGRESS: at sentence #2200000, processed 52607069 words, keeping 173152 word types\n",
      "2017-04-26 14:57:38,715 : INFO : PROGRESS: at sentence #2210000, processed 52846458 words, keeping 173474 word types\n",
      "2017-04-26 14:57:38,787 : INFO : PROGRESS: at sentence #2220000, processed 53087167 words, keeping 173799 word types\n",
      "2017-04-26 14:57:38,849 : INFO : PROGRESS: at sentence #2230000, processed 53327269 words, keeping 174150 word types\n",
      "2017-04-26 14:57:38,901 : INFO : PROGRESS: at sentence #2240000, processed 53566836 words, keeping 174473 word types\n",
      "2017-04-26 14:57:38,970 : INFO : PROGRESS: at sentence #2250000, processed 53805360 words, keeping 174767 word types\n",
      "2017-04-26 14:57:39,024 : INFO : PROGRESS: at sentence #2260000, processed 54045846 words, keeping 175095 word types\n",
      "2017-04-26 14:57:39,080 : INFO : PROGRESS: at sentence #2270000, processed 54282408 words, keeping 175388 word types\n",
      "2017-04-26 14:57:39,136 : INFO : PROGRESS: at sentence #2280000, processed 54521421 words, keeping 175706 word types\n",
      "2017-04-26 14:57:39,195 : INFO : PROGRESS: at sentence #2290000, processed 54760499 words, keeping 176013 word types\n",
      "2017-04-26 14:57:39,266 : INFO : PROGRESS: at sentence #2300000, processed 54999529 words, keeping 176299 word types\n",
      "2017-04-26 14:57:39,336 : INFO : PROGRESS: at sentence #2310000, processed 55239611 words, keeping 176611 word types\n",
      "2017-04-26 14:57:39,397 : INFO : PROGRESS: at sentence #2320000, processed 55480014 words, keeping 176987 word types\n",
      "2017-04-26 14:57:39,453 : INFO : PROGRESS: at sentence #2330000, processed 55720202 words, keeping 177278 word types\n",
      "2017-04-26 14:57:39,510 : INFO : PROGRESS: at sentence #2340000, processed 55959722 words, keeping 177576 word types\n",
      "2017-04-26 14:57:39,567 : INFO : PROGRESS: at sentence #2350000, processed 56199416 words, keeping 177874 word types\n",
      "2017-04-26 14:57:39,623 : INFO : PROGRESS: at sentence #2360000, processed 56438419 words, keeping 178216 word types\n",
      "2017-04-26 14:57:39,681 : INFO : PROGRESS: at sentence #2370000, processed 56670487 words, keeping 179564 word types\n",
      "2017-04-26 14:57:39,739 : INFO : PROGRESS: at sentence #2380000, processed 56900309 words, keeping 180790 word types\n",
      "2017-04-26 14:57:39,797 : INFO : PROGRESS: at sentence #2390000, processed 57130981 words, keeping 181870 word types\n",
      "2017-04-26 14:57:39,853 : INFO : PROGRESS: at sentence #2400000, processed 57360384 words, keeping 182811 word types\n",
      "2017-04-26 14:57:39,910 : INFO : PROGRESS: at sentence #2410000, processed 57590308 words, keeping 183699 word types\n",
      "2017-04-26 14:57:39,966 : INFO : PROGRESS: at sentence #2420000, processed 57820083 words, keeping 184513 word types\n",
      "2017-04-26 14:57:40,023 : INFO : PROGRESS: at sentence #2430000, processed 58050197 words, keeping 185282 word types\n",
      "2017-04-26 14:57:40,079 : INFO : PROGRESS: at sentence #2440000, processed 58280821 words, keeping 186025 word types\n",
      "2017-04-26 14:57:40,135 : INFO : PROGRESS: at sentence #2450000, processed 58512320 words, keeping 186754 word types\n",
      "2017-04-26 14:57:40,193 : INFO : PROGRESS: at sentence #2460000, processed 58744111 words, keeping 187371 word types\n",
      "2017-04-26 14:57:40,251 : INFO : PROGRESS: at sentence #2470000, processed 58975381 words, keeping 188051 word types\n",
      "2017-04-26 14:57:40,303 : INFO : PROGRESS: at sentence #2480000, processed 59205886 words, keeping 188662 word types\n",
      "2017-04-26 14:57:40,359 : INFO : PROGRESS: at sentence #2490000, processed 59438762 words, keeping 189266 word types\n",
      "2017-04-26 14:57:40,415 : INFO : PROGRESS: at sentence #2500000, processed 59670278 words, keeping 189864 word types\n",
      "2017-04-26 14:57:40,471 : INFO : PROGRESS: at sentence #2510000, processed 59901835 words, keeping 190406 word types\n",
      "2017-04-26 14:57:40,527 : INFO : PROGRESS: at sentence #2520000, processed 60133104 words, keeping 190912 word types\n",
      "2017-04-26 14:57:40,583 : INFO : PROGRESS: at sentence #2530000, processed 60361771 words, keeping 191382 word types\n",
      "2017-04-26 14:57:40,639 : INFO : PROGRESS: at sentence #2540000, processed 60591521 words, keeping 191918 word types\n",
      "2017-04-26 14:57:40,693 : INFO : PROGRESS: at sentence #2550000, processed 60825142 words, keeping 192894 word types\n",
      "2017-04-26 14:57:40,745 : INFO : PROGRESS: at sentence #2560000, processed 61059649 words, keeping 193860 word types\n",
      "2017-04-26 14:57:40,797 : INFO : PROGRESS: at sentence #2570000, processed 61295185 words, keeping 194701 word types\n",
      "2017-04-26 14:57:40,850 : INFO : PROGRESS: at sentence #2580000, processed 61531176 words, keeping 195462 word types\n",
      "2017-04-26 14:57:40,902 : INFO : PROGRESS: at sentence #2590000, processed 61765454 words, keeping 196194 word types\n",
      "2017-04-26 14:57:40,954 : INFO : PROGRESS: at sentence #2600000, processed 62000902 words, keeping 196887 word types\n",
      "2017-04-26 14:57:41,005 : INFO : PROGRESS: at sentence #2610000, processed 62237357 words, keeping 197588 word types\n",
      "2017-04-26 14:57:41,057 : INFO : PROGRESS: at sentence #2620000, processed 62472004 words, keeping 198203 word types\n",
      "2017-04-26 14:57:41,110 : INFO : PROGRESS: at sentence #2630000, processed 62708382 words, keeping 198801 word types\n",
      "2017-04-26 14:57:41,162 : INFO : PROGRESS: at sentence #2640000, processed 62942256 words, keeping 199346 word types\n",
      "2017-04-26 14:57:41,214 : INFO : PROGRESS: at sentence #2650000, processed 63176398 words, keeping 199911 word types\n",
      "2017-04-26 14:57:41,266 : INFO : PROGRESS: at sentence #2660000, processed 63411307 words, keeping 200460 word types\n",
      "2017-04-26 14:57:41,334 : INFO : PROGRESS: at sentence #2670000, processed 63647373 words, keeping 200950 word types\n",
      "2017-04-26 14:57:41,404 : INFO : PROGRESS: at sentence #2680000, processed 63882007 words, keeping 201439 word types\n",
      "2017-04-26 14:57:41,453 : INFO : PROGRESS: at sentence #2690000, processed 64116430 words, keeping 201926 word types\n",
      "2017-04-26 14:57:41,506 : INFO : PROGRESS: at sentence #2700000, processed 64352417 words, keeping 202413 word types\n",
      "2017-04-26 14:57:41,562 : INFO : PROGRESS: at sentence #2710000, processed 64585979 words, keeping 202832 word types\n",
      "2017-04-26 14:57:41,612 : INFO : PROGRESS: at sentence #2720000, processed 64823523 words, keeping 203275 word types\n",
      "2017-04-26 14:57:41,664 : INFO : PROGRESS: at sentence #2730000, processed 65056023 words, keeping 203679 word types\n",
      "2017-04-26 14:57:41,698 : INFO : collected 203912 word types from a corpus of 65189817 raw words and 2735697 sentences\n",
      "2017-04-26 14:57:41,699 : INFO : Loading a fresh vocabulary\n",
      "2017-04-26 14:57:41,911 : INFO : min_count=5 retains 72100 unique words (35% of original 203912, drops 131812)\n",
      "2017-04-26 14:57:41,911 : INFO : min_count=5 leaves 64971608 word corpus (99% of original 65189817, drops 218209)\n",
      "2017-04-26 14:57:42,160 : INFO : deleting the raw counts dictionary of 203912 items\n",
      "2017-04-26 14:57:42,173 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2017-04-26 14:57:42,174 : INFO : downsampling leaves estimated 50263169 word corpus (77.4% of prior 64971608)\n",
      "2017-04-26 14:57:42,190 : INFO : estimated required memory for 72100 words and 300 dimensions: 209090000 bytes\n",
      "2017-04-26 14:57:42,500 : INFO : resetting layer weights\n",
      "2017-04-26 14:57:43,313 : INFO : training model with 4 workers on 72100 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-26 14:57:43,314 : INFO : expecting 2735697 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-26 14:57:44,358 : INFO : PROGRESS: at 0.26% examples, 642520 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:57:45,391 : INFO : PROGRESS: at 0.55% examples, 672531 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:57:46,399 : INFO : PROGRESS: at 0.83% examples, 685455 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:47,412 : INFO : PROGRESS: at 1.12% examples, 692988 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:48,431 : INFO : PROGRESS: at 1.40% examples, 696598 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:57:49,451 : INFO : PROGRESS: at 1.65% examples, 681428 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:57:50,480 : INFO : PROGRESS: at 1.87% examples, 659807 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:57:51,489 : INFO : PROGRESS: at 2.09% examples, 648091 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:57:52,490 : INFO : PROGRESS: at 2.30% examples, 636145 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:53,496 : INFO : PROGRESS: at 2.58% examples, 642192 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:57:54,536 : INFO : PROGRESS: at 2.87% examples, 648661 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:57:55,537 : INFO : PROGRESS: at 3.19% examples, 659849 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:56,543 : INFO : PROGRESS: at 3.49% examples, 668510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:57,545 : INFO : PROGRESS: at 3.81% examples, 676754 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:58,549 : INFO : PROGRESS: at 4.12% examples, 683744 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:57:59,556 : INFO : PROGRESS: at 4.40% examples, 685059 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:58:00,559 : INFO : PROGRESS: at 4.71% examples, 691242 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:01,576 : INFO : PROGRESS: at 4.95% examples, 685664 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:02,592 : INFO : PROGRESS: at 5.17% examples, 678333 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:03,595 : INFO : PROGRESS: at 5.43% examples, 676708 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:04,602 : INFO : PROGRESS: at 5.68% examples, 674764 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:05,616 : INFO : PROGRESS: at 5.93% examples, 671728 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:06,627 : INFO : PROGRESS: at 6.19% examples, 671064 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:07,634 : INFO : PROGRESS: at 6.46% examples, 670854 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:08,643 : INFO : PROGRESS: at 6.76% examples, 674283 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:09,662 : INFO : PROGRESS: at 7.04% examples, 674840 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:10,677 : INFO : PROGRESS: at 7.30% examples, 674616 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:58:11,701 : INFO : PROGRESS: at 7.58% examples, 674740 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:12,714 : INFO : PROGRESS: at 7.87% examples, 676690 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:13,726 : INFO : PROGRESS: at 8.16% examples, 677756 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:14,735 : INFO : PROGRESS: at 8.46% examples, 680532 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:15,737 : INFO : PROGRESS: at 8.77% examples, 683526 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:16,743 : INFO : PROGRESS: at 9.04% examples, 683255 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:58:17,779 : INFO : PROGRESS: at 9.31% examples, 682858 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:58:18,792 : INFO : PROGRESS: at 9.59% examples, 683134 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:19,797 : INFO : PROGRESS: at 9.90% examples, 685227 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:20,799 : INFO : PROGRESS: at 10.20% examples, 687469 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:21,826 : INFO : PROGRESS: at 10.49% examples, 688156 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:58:22,830 : INFO : PROGRESS: at 10.79% examples, 689782 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:23,835 : INFO : PROGRESS: at 11.10% examples, 691890 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:24,843 : INFO : PROGRESS: at 11.40% examples, 693658 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:25,849 : INFO : PROGRESS: at 11.71% examples, 695376 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:26,858 : INFO : PROGRESS: at 12.00% examples, 696272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:27,867 : INFO : PROGRESS: at 12.31% examples, 697981 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:28,870 : INFO : PROGRESS: at 12.62% examples, 700031 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:29,872 : INFO : PROGRESS: at 12.93% examples, 701677 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:30,881 : INFO : PROGRESS: at 13.24% examples, 703336 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:58:31,884 : INFO : PROGRESS: at 13.54% examples, 704193 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:32,886 : INFO : PROGRESS: at 13.77% examples, 701934 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:33,897 : INFO : PROGRESS: at 13.97% examples, 697798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:34,916 : INFO : PROGRESS: at 14.17% examples, 693577 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:35,919 : INFO : PROGRESS: at 14.36% examples, 689435 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:58:36,922 : INFO : PROGRESS: at 14.56% examples, 686180 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:37,932 : INFO : PROGRESS: at 14.77% examples, 683361 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:58:38,945 : INFO : PROGRESS: at 15.03% examples, 682699 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:58:39,957 : INFO : PROGRESS: at 15.30% examples, 682197 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:40,986 : INFO : PROGRESS: at 15.57% examples, 681785 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:58:41,990 : INFO : PROGRESS: at 15.85% examples, 682204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:42,991 : INFO : PROGRESS: at 16.13% examples, 682785 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:44,000 : INFO : PROGRESS: at 16.40% examples, 682875 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:45,028 : INFO : PROGRESS: at 16.60% examples, 679499 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:46,035 : INFO : PROGRESS: at 16.82% examples, 677437 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:58:47,041 : INFO : PROGRESS: at 17.04% examples, 675697 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:48,042 : INFO : PROGRESS: at 17.25% examples, 673226 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:58:49,050 : INFO : PROGRESS: at 17.45% examples, 670335 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:50,060 : INFO : PROGRESS: at 17.67% examples, 668093 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:51,072 : INFO : PROGRESS: at 17.88% examples, 665673 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:52,090 : INFO : PROGRESS: at 18.10% examples, 663471 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:58:53,111 : INFO : PROGRESS: at 18.39% examples, 663823 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:54,115 : INFO : PROGRESS: at 18.68% examples, 664225 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:55,117 : INFO : PROGRESS: at 18.96% examples, 664639 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:58:56,135 : INFO : PROGRESS: at 19.25% examples, 665326 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:57,143 : INFO : PROGRESS: at 19.56% examples, 666385 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:58:58,158 : INFO : PROGRESS: at 19.86% examples, 667361 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 14:58:59,167 : INFO : PROGRESS: at 20.16% examples, 668310 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:00,175 : INFO : PROGRESS: at 20.45% examples, 669176 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:01,178 : INFO : PROGRESS: at 20.76% examples, 670463 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:02,188 : INFO : PROGRESS: at 21.07% examples, 671767 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:03,192 : INFO : PROGRESS: at 21.35% examples, 672104 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:59:04,196 : INFO : PROGRESS: at 21.62% examples, 672341 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:59:05,198 : INFO : PROGRESS: at 21.92% examples, 673335 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:06,205 : INFO : PROGRESS: at 22.23% examples, 674455 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:07,213 : INFO : PROGRESS: at 22.55% examples, 675996 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:08,221 : INFO : PROGRESS: at 22.86% examples, 677327 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:09,230 : INFO : PROGRESS: at 23.17% examples, 678347 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:10,236 : INFO : PROGRESS: at 23.47% examples, 679447 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:11,240 : INFO : PROGRESS: at 23.78% examples, 680541 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:12,267 : INFO : PROGRESS: at 24.04% examples, 680050 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:59:13,284 : INFO : PROGRESS: at 24.26% examples, 678447 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:59:14,285 : INFO : PROGRESS: at 24.46% examples, 676497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:15,297 : INFO : PROGRESS: at 24.65% examples, 674324 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:16,308 : INFO : PROGRESS: at 24.86% examples, 672705 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:17,309 : INFO : PROGRESS: at 25.08% examples, 671366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:18,313 : INFO : PROGRESS: at 25.30% examples, 670116 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:19,321 : INFO : PROGRESS: at 25.51% examples, 668700 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:20,330 : INFO : PROGRESS: at 25.80% examples, 669137 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:21,334 : INFO : PROGRESS: at 26.09% examples, 669760 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:22,338 : INFO : PROGRESS: at 26.36% examples, 669900 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:23,369 : INFO : PROGRESS: at 26.64% examples, 670091 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:24,373 : INFO : PROGRESS: at 26.95% examples, 671064 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:25,379 : INFO : PROGRESS: at 27.23% examples, 671629 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:59:26,381 : INFO : PROGRESS: at 27.53% examples, 672429 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:27,387 : INFO : PROGRESS: at 27.84% examples, 673338 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:28,391 : INFO : PROGRESS: at 28.15% examples, 674392 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:29,391 : INFO : PROGRESS: at 28.46% examples, 675300 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:30,419 : INFO : PROGRESS: at 28.73% examples, 675366 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:31,446 : INFO : PROGRESS: at 29.01% examples, 675516 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:59:32,467 : INFO : PROGRESS: at 29.23% examples, 674141 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 14:59:33,471 : INFO : PROGRESS: at 29.45% examples, 672961 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:34,487 : INFO : PROGRESS: at 29.67% examples, 671951 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:35,498 : INFO : PROGRESS: at 29.88% examples, 670561 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:36,502 : INFO : PROGRESS: at 30.08% examples, 669105 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:59:37,502 : INFO : PROGRESS: at 30.31% examples, 668306 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:38,507 : INFO : PROGRESS: at 30.56% examples, 667968 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:39,517 : INFO : PROGRESS: at 30.82% examples, 667731 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:40,524 : INFO : PROGRESS: at 31.08% examples, 667654 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:41,527 : INFO : PROGRESS: at 31.34% examples, 667597 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:42,527 : INFO : PROGRESS: at 31.63% examples, 668133 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:43,533 : INFO : PROGRESS: at 31.94% examples, 669025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:44,537 : INFO : PROGRESS: at 32.26% examples, 670165 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:45,546 : INFO : PROGRESS: at 32.55% examples, 670678 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:46,550 : INFO : PROGRESS: at 32.85% examples, 671218 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:47,554 : INFO : PROGRESS: at 33.14% examples, 671751 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:48,559 : INFO : PROGRESS: at 33.42% examples, 671960 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:49,572 : INFO : PROGRESS: at 33.70% examples, 672188 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:50,602 : INFO : PROGRESS: at 33.98% examples, 672321 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:59:51,605 : INFO : PROGRESS: at 34.25% examples, 672413 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 14:59:52,611 : INFO : PROGRESS: at 34.46% examples, 671356 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:53,617 : INFO : PROGRESS: at 34.66% examples, 669959 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:54,643 : INFO : PROGRESS: at 34.85% examples, 668358 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:55,652 : INFO : PROGRESS: at 35.08% examples, 667691 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:56,658 : INFO : PROGRESS: at 35.31% examples, 667043 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 14:59:57,684 : INFO : PROGRESS: at 35.54% examples, 666135 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:58,700 : INFO : PROGRESS: at 35.76% examples, 665351 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 14:59:59,707 : INFO : PROGRESS: at 35.98% examples, 664452 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:00,707 : INFO : PROGRESS: at 36.24% examples, 664500 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:01,727 : INFO : PROGRESS: at 36.52% examples, 664727 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:00:02,729 : INFO : PROGRESS: at 36.80% examples, 664933 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:03,730 : INFO : PROGRESS: at 37.07% examples, 665133 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:04,741 : INFO : PROGRESS: at 37.29% examples, 664242 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:05,750 : INFO : PROGRESS: at 37.51% examples, 663294 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:06,765 : INFO : PROGRESS: at 37.74% examples, 662432 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:07,773 : INFO : PROGRESS: at 37.98% examples, 661775 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:08,780 : INFO : PROGRESS: at 38.29% examples, 662385 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:09,784 : INFO : PROGRESS: at 38.61% examples, 663114 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:10,789 : INFO : PROGRESS: at 38.90% examples, 663409 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:11,794 : INFO : PROGRESS: at 39.18% examples, 663607 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:12,807 : INFO : PROGRESS: at 39.49% examples, 664118 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:13,815 : INFO : PROGRESS: at 39.80% examples, 664802 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:14,827 : INFO : PROGRESS: at 40.12% examples, 665681 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:15,857 : INFO : PROGRESS: at 40.42% examples, 666137 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 15:00:16,865 : INFO : PROGRESS: at 40.70% examples, 666385 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:17,867 : INFO : PROGRESS: at 40.98% examples, 666510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:18,889 : INFO : PROGRESS: at 41.25% examples, 666538 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:19,898 : INFO : PROGRESS: at 41.53% examples, 666772 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:20,916 : INFO : PROGRESS: at 41.81% examples, 667017 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:21,917 : INFO : PROGRESS: at 42.11% examples, 667524 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:22,924 : INFO : PROGRESS: at 42.40% examples, 667897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:23,929 : INFO : PROGRESS: at 42.69% examples, 668326 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:24,940 : INFO : PROGRESS: at 42.96% examples, 668345 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:25,958 : INFO : PROGRESS: at 43.22% examples, 668288 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:26,963 : INFO : PROGRESS: at 43.47% examples, 667999 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:27,973 : INFO : PROGRESS: at 43.71% examples, 667644 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:28,992 : INFO : PROGRESS: at 43.91% examples, 666514 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:30,018 : INFO : PROGRESS: at 44.13% examples, 665695 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:31,019 : INFO : PROGRESS: at 44.31% examples, 664485 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:32,027 : INFO : PROGRESS: at 44.53% examples, 663757 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:33,037 : INFO : PROGRESS: at 44.72% examples, 662711 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:34,057 : INFO : PROGRESS: at 44.94% examples, 662002 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:35,065 : INFO : PROGRESS: at 45.14% examples, 661038 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:36,104 : INFO : PROGRESS: at 45.36% examples, 660187 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:37,109 : INFO : PROGRESS: at 45.58% examples, 659651 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:38,119 : INFO : PROGRESS: at 45.82% examples, 659279 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:39,120 : INFO : PROGRESS: at 46.03% examples, 658509 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:40,127 : INFO : PROGRESS: at 46.23% examples, 657632 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:41,141 : INFO : PROGRESS: at 46.49% examples, 657615 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:42,141 : INFO : PROGRESS: at 46.78% examples, 657989 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:43,152 : INFO : PROGRESS: at 47.07% examples, 658365 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:44,163 : INFO : PROGRESS: at 47.36% examples, 658736 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:45,181 : INFO : PROGRESS: at 47.63% examples, 658782 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:46,198 : INFO : PROGRESS: at 47.88% examples, 658580 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:47,218 : INFO : PROGRESS: at 48.09% examples, 657819 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:48,224 : INFO : PROGRESS: at 48.31% examples, 657240 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:49,225 : INFO : PROGRESS: at 48.54% examples, 656769 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:50,236 : INFO : PROGRESS: at 48.77% examples, 656314 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:51,249 : INFO : PROGRESS: at 49.05% examples, 656633 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:00:52,253 : INFO : PROGRESS: at 49.31% examples, 656570 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:53,258 : INFO : PROGRESS: at 49.58% examples, 656711 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:54,259 : INFO : PROGRESS: at 49.87% examples, 657104 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:55,259 : INFO : PROGRESS: at 50.14% examples, 657250 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:00:56,278 : INFO : PROGRESS: at 50.43% examples, 657537 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:00:57,302 : INFO : PROGRESS: at 50.72% examples, 657876 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:58,313 : INFO : PROGRESS: at 51.01% examples, 658182 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:00:59,334 : INFO : PROGRESS: at 51.30% examples, 658451 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:00,340 : INFO : PROGRESS: at 51.58% examples, 658768 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:01,347 : INFO : PROGRESS: at 51.89% examples, 659272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:02,347 : INFO : PROGRESS: at 52.18% examples, 659755 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:03,353 : INFO : PROGRESS: at 52.48% examples, 660211 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:04,358 : INFO : PROGRESS: at 52.77% examples, 660550 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:05,383 : INFO : PROGRESS: at 53.07% examples, 660902 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 15:01:06,391 : INFO : PROGRESS: at 53.36% examples, 661261 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:07,413 : INFO : PROGRESS: at 53.65% examples, 661537 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-26 15:01:08,435 : INFO : PROGRESS: at 53.94% examples, 661777 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:01:09,445 : INFO : PROGRESS: at 54.23% examples, 662084 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:10,451 : INFO : PROGRESS: at 54.53% examples, 662558 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:11,451 : INFO : PROGRESS: at 54.80% examples, 662632 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:12,462 : INFO : PROGRESS: at 55.01% examples, 661898 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:01:13,482 : INFO : PROGRESS: at 55.20% examples, 660996 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:14,491 : INFO : PROGRESS: at 55.39% examples, 660173 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:15,512 : INFO : PROGRESS: at 55.58% examples, 659177 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:16,533 : INFO : PROGRESS: at 55.79% examples, 658554 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:17,556 : INFO : PROGRESS: at 55.98% examples, 657607 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:18,570 : INFO : PROGRESS: at 56.14% examples, 656443 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:19,574 : INFO : PROGRESS: at 56.30% examples, 655247 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:20,584 : INFO : PROGRESS: at 56.49% examples, 654404 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:21,584 : INFO : PROGRESS: at 56.68% examples, 653630 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:01:22,591 : INFO : PROGRESS: at 56.92% examples, 653337 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:23,593 : INFO : PROGRESS: at 57.19% examples, 653478 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:24,609 : INFO : PROGRESS: at 57.49% examples, 653798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:25,617 : INFO : PROGRESS: at 57.81% examples, 654341 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:26,621 : INFO : PROGRESS: at 58.13% examples, 654815 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:27,624 : INFO : PROGRESS: at 58.45% examples, 655390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:28,625 : INFO : PROGRESS: at 58.78% examples, 656003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:29,627 : INFO : PROGRESS: at 59.07% examples, 656274 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:30,627 : INFO : PROGRESS: at 59.38% examples, 656714 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:31,630 : INFO : PROGRESS: at 59.66% examples, 656907 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:32,647 : INFO : PROGRESS: at 59.96% examples, 657130 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:33,658 : INFO : PROGRESS: at 60.25% examples, 657455 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:34,677 : INFO : PROGRESS: at 60.54% examples, 657692 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:35,687 : INFO : PROGRESS: at 60.84% examples, 658154 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:36,693 : INFO : PROGRESS: at 61.07% examples, 657762 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:37,695 : INFO : PROGRESS: at 61.27% examples, 657123 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:38,715 : INFO : PROGRESS: at 61.47% examples, 656436 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:39,725 : INFO : PROGRESS: at 61.68% examples, 655819 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:40,733 : INFO : PROGRESS: at 61.83% examples, 654688 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:41,759 : INFO : PROGRESS: at 61.98% examples, 653486 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:42,786 : INFO : PROGRESS: at 62.14% examples, 652293 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:43,786 : INFO : PROGRESS: at 62.32% examples, 651472 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:44,797 : INFO : PROGRESS: at 62.53% examples, 650945 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:45,806 : INFO : PROGRESS: at 62.75% examples, 650592 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:01:46,813 : INFO : PROGRESS: at 62.93% examples, 649735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:47,824 : INFO : PROGRESS: at 63.12% examples, 649035 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:01:48,834 : INFO : PROGRESS: at 63.35% examples, 648748 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:49,842 : INFO : PROGRESS: at 63.57% examples, 648315 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:50,846 : INFO : PROGRESS: at 63.82% examples, 648208 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:51,846 : INFO : PROGRESS: at 64.08% examples, 648297 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:01:52,855 : INFO : PROGRESS: at 64.31% examples, 647962 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:53,855 : INFO : PROGRESS: at 64.53% examples, 647652 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:54,863 : INFO : PROGRESS: at 64.79% examples, 647597 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:01:55,887 : INFO : PROGRESS: at 65.08% examples, 647844 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:56,899 : INFO : PROGRESS: at 65.37% examples, 648145 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:01:57,903 : INFO : PROGRESS: at 65.65% examples, 648345 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:01:58,904 : INFO : PROGRESS: at 65.83% examples, 647615 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 15:01:59,930 : INFO : PROGRESS: at 66.05% examples, 647221 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:00,957 : INFO : PROGRESS: at 66.24% examples, 646524 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:01,977 : INFO : PROGRESS: at 66.43% examples, 645795 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:02,983 : INFO : PROGRESS: at 66.60% examples, 644928 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:03,997 : INFO : PROGRESS: at 66.79% examples, 644252 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:05,006 : INFO : PROGRESS: at 66.99% examples, 643682 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:06,019 : INFO : PROGRESS: at 67.16% examples, 642903 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:07,037 : INFO : PROGRESS: at 67.35% examples, 642203 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:08,045 : INFO : PROGRESS: at 67.56% examples, 641825 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:09,051 : INFO : PROGRESS: at 67.79% examples, 641572 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:10,083 : INFO : PROGRESS: at 68.01% examples, 641114 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:11,089 : INFO : PROGRESS: at 68.18% examples, 640376 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:12,114 : INFO : PROGRESS: at 68.40% examples, 639914 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:13,114 : INFO : PROGRESS: at 68.64% examples, 639856 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:14,121 : INFO : PROGRESS: at 68.91% examples, 639956 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:15,127 : INFO : PROGRESS: at 69.10% examples, 639345 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:16,155 : INFO : PROGRESS: at 69.29% examples, 638688 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:17,170 : INFO : PROGRESS: at 69.48% examples, 638095 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:18,172 : INFO : PROGRESS: at 69.67% examples, 637509 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:19,179 : INFO : PROGRESS: at 69.92% examples, 637473 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:20,188 : INFO : PROGRESS: at 70.15% examples, 637236 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:21,193 : INFO : PROGRESS: at 70.38% examples, 637010 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:22,202 : INFO : PROGRESS: at 70.63% examples, 637028 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:23,230 : INFO : PROGRESS: at 70.90% examples, 637085 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:24,238 : INFO : PROGRESS: at 71.15% examples, 637018 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:25,280 : INFO : PROGRESS: at 71.37% examples, 636661 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:26,297 : INFO : PROGRESS: at 71.55% examples, 635979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:27,320 : INFO : PROGRESS: at 71.76% examples, 635532 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:28,332 : INFO : PROGRESS: at 71.95% examples, 634953 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:29,338 : INFO : PROGRESS: at 72.14% examples, 634417 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:30,378 : INFO : PROGRESS: at 72.36% examples, 634026 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:31,416 : INFO : PROGRESS: at 72.55% examples, 633426 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:32,422 : INFO : PROGRESS: at 72.73% examples, 632822 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:33,431 : INFO : PROGRESS: at 72.95% examples, 632532 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:34,442 : INFO : PROGRESS: at 73.19% examples, 632374 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:35,448 : INFO : PROGRESS: at 73.43% examples, 632334 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:36,455 : INFO : PROGRESS: at 73.68% examples, 632265 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:37,463 : INFO : PROGRESS: at 73.86% examples, 631673 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:38,469 : INFO : PROGRESS: at 74.04% examples, 631088 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:39,479 : INFO : PROGRESS: at 74.20% examples, 630288 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:40,486 : INFO : PROGRESS: at 74.38% examples, 629631 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:41,512 : INFO : PROGRESS: at 74.59% examples, 629273 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:42,540 : INFO : PROGRESS: at 74.76% examples, 628578 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:02:43,566 : INFO : PROGRESS: at 74.93% examples, 627842 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:44,570 : INFO : PROGRESS: at 75.11% examples, 627233 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:45,579 : INFO : PROGRESS: at 75.31% examples, 626799 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:46,590 : INFO : PROGRESS: at 75.56% examples, 626843 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-26 15:02:47,596 : INFO : PROGRESS: at 75.81% examples, 626822 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:48,606 : INFO : PROGRESS: at 76.08% examples, 626972 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:49,618 : INFO : PROGRESS: at 76.29% examples, 626663 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:50,631 : INFO : PROGRESS: at 76.52% examples, 626504 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:51,657 : INFO : PROGRESS: at 76.78% examples, 626519 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:52,670 : INFO : PROGRESS: at 77.04% examples, 626586 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 15:02:53,679 : INFO : PROGRESS: at 77.35% examples, 627027 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:54,682 : INFO : PROGRESS: at 77.60% examples, 626972 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:55,699 : INFO : PROGRESS: at 77.85% examples, 626861 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:56,735 : INFO : PROGRESS: at 78.06% examples, 626373 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:02:57,748 : INFO : PROGRESS: at 78.24% examples, 625785 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:02:58,752 : INFO : PROGRESS: at 78.44% examples, 625319 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:02:59,755 : INFO : PROGRESS: at 78.63% examples, 624759 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:00,763 : INFO : PROGRESS: at 78.82% examples, 624268 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:01,777 : INFO : PROGRESS: at 79.04% examples, 623982 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:03:02,813 : INFO : PROGRESS: at 79.23% examples, 623419 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:03,823 : INFO : PROGRESS: at 79.42% examples, 622885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:04,828 : INFO : PROGRESS: at 79.69% examples, 623031 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:05,832 : INFO : PROGRESS: at 79.97% examples, 623247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:06,842 : INFO : PROGRESS: at 80.24% examples, 623371 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:07,843 : INFO : PROGRESS: at 80.45% examples, 623088 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:08,845 : INFO : PROGRESS: at 80.70% examples, 623115 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:09,872 : INFO : PROGRESS: at 80.94% examples, 623020 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:10,887 : INFO : PROGRESS: at 81.14% examples, 622621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:11,921 : INFO : PROGRESS: at 81.38% examples, 622515 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:12,922 : INFO : PROGRESS: at 81.62% examples, 622448 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:13,938 : INFO : PROGRESS: at 81.87% examples, 622402 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:03:14,959 : INFO : PROGRESS: at 82.09% examples, 622206 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:03:15,974 : INFO : PROGRESS: at 82.31% examples, 621954 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:17,000 : INFO : PROGRESS: at 82.45% examples, 621125 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:18,018 : INFO : PROGRESS: at 82.62% examples, 620524 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:19,055 : INFO : PROGRESS: at 82.79% examples, 619918 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:20,075 : INFO : PROGRESS: at 82.96% examples, 619299 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:03:21,101 : INFO : PROGRESS: at 83.15% examples, 618832 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:22,113 : INFO : PROGRESS: at 83.35% examples, 618484 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:23,121 : INFO : PROGRESS: at 83.52% examples, 617922 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:24,135 : INFO : PROGRESS: at 83.72% examples, 617507 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:25,144 : INFO : PROGRESS: at 83.99% examples, 617714 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:03:26,176 : INFO : PROGRESS: at 84.27% examples, 617902 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:27,183 : INFO : PROGRESS: at 84.54% examples, 618066 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:03:28,191 : INFO : PROGRESS: at 84.83% examples, 618361 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:29,204 : INFO : PROGRESS: at 85.06% examples, 618266 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:30,205 : INFO : PROGRESS: at 85.36% examples, 618616 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:31,218 : INFO : PROGRESS: at 85.60% examples, 618611 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:03:32,222 : INFO : PROGRESS: at 85.85% examples, 618622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:33,222 : INFO : PROGRESS: at 86.08% examples, 618486 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:34,269 : INFO : PROGRESS: at 86.28% examples, 618092 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:35,272 : INFO : PROGRESS: at 86.50% examples, 617951 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:36,275 : INFO : PROGRESS: at 86.77% examples, 618098 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:03:37,297 : INFO : PROGRESS: at 86.93% examples, 617425 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:03:38,348 : INFO : PROGRESS: at 87.10% examples, 616858 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:39,367 : INFO : PROGRESS: at 87.23% examples, 616023 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:40,378 : INFO : PROGRESS: at 87.41% examples, 615533 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:41,431 : INFO : PROGRESS: at 87.62% examples, 615231 words/s, in_qsize 7, out_qsize 2\n",
      "2017-04-26 15:03:42,450 : INFO : PROGRESS: at 87.81% examples, 614774 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:43,496 : INFO : PROGRESS: at 87.99% examples, 614295 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:44,509 : INFO : PROGRESS: at 88.20% examples, 614044 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:45,513 : INFO : PROGRESS: at 88.44% examples, 613980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:46,517 : INFO : PROGRESS: at 88.75% examples, 614405 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:47,528 : INFO : PROGRESS: at 89.05% examples, 614818 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:48,542 : INFO : PROGRESS: at 89.27% examples, 614631 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:49,545 : INFO : PROGRESS: at 89.45% examples, 614212 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:50,559 : INFO : PROGRESS: at 89.64% examples, 613798 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:51,577 : INFO : PROGRESS: at 89.82% examples, 613295 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:52,602 : INFO : PROGRESS: at 90.04% examples, 613115 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:53,616 : INFO : PROGRESS: at 90.30% examples, 613204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:54,620 : INFO : PROGRESS: at 90.51% examples, 612980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:55,622 : INFO : PROGRESS: at 90.75% examples, 612965 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:56,638 : INFO : PROGRESS: at 90.94% examples, 612576 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:03:57,654 : INFO : PROGRESS: at 91.14% examples, 612250 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:03:58,697 : INFO : PROGRESS: at 91.38% examples, 612192 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:03:59,711 : INFO : PROGRESS: at 91.64% examples, 612283 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:04:00,719 : INFO : PROGRESS: at 91.86% examples, 612120 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:01,729 : INFO : PROGRESS: at 92.04% examples, 611669 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:04:02,751 : INFO : PROGRESS: at 92.25% examples, 611463 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:03,761 : INFO : PROGRESS: at 92.52% examples, 611581 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:04,780 : INFO : PROGRESS: at 92.73% examples, 611363 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:05,781 : INFO : PROGRESS: at 92.99% examples, 611455 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:06,789 : INFO : PROGRESS: at 93.20% examples, 611255 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:04:07,796 : INFO : PROGRESS: at 93.44% examples, 611237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:08,828 : INFO : PROGRESS: at 93.69% examples, 611240 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:09,835 : INFO : PROGRESS: at 93.92% examples, 611122 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:10,836 : INFO : PROGRESS: at 94.14% examples, 610995 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:04:11,857 : INFO : PROGRESS: at 94.43% examples, 611254 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:12,895 : INFO : PROGRESS: at 94.66% examples, 611169 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:13,943 : INFO : PROGRESS: at 94.83% examples, 610612 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:14,979 : INFO : PROGRESS: at 95.01% examples, 610138 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:15,996 : INFO : PROGRESS: at 95.18% examples, 609659 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-26 15:04:17,014 : INFO : PROGRESS: at 95.38% examples, 609355 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:04:18,030 : INFO : PROGRESS: at 95.54% examples, 608839 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:19,047 : INFO : PROGRESS: at 95.70% examples, 608268 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:20,051 : INFO : PROGRESS: at 95.85% examples, 607682 words/s, in_qsize 7, out_qsize 2\n",
      "2017-04-26 15:04:21,059 : INFO : PROGRESS: at 96.04% examples, 607366 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:22,061 : INFO : PROGRESS: at 96.28% examples, 607347 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-26 15:04:23,063 : INFO : PROGRESS: at 96.52% examples, 607368 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:24,066 : INFO : PROGRESS: at 96.75% examples, 607312 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:25,068 : INFO : PROGRESS: at 96.99% examples, 607255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:26,078 : INFO : PROGRESS: at 97.21% examples, 607131 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:27,081 : INFO : PROGRESS: at 97.43% examples, 606967 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:28,088 : INFO : PROGRESS: at 97.67% examples, 606872 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:29,117 : INFO : PROGRESS: at 97.94% examples, 606915 words/s, in_qsize 8, out_qsize 2\n",
      "2017-04-26 15:04:30,123 : INFO : PROGRESS: at 98.18% examples, 606840 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:31,124 : INFO : PROGRESS: at 98.40% examples, 606698 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-26 15:04:32,151 : INFO : PROGRESS: at 98.64% examples, 606593 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:33,158 : INFO : PROGRESS: at 98.81% examples, 606128 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:34,190 : INFO : PROGRESS: at 98.99% examples, 605684 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:35,198 : INFO : PROGRESS: at 99.18% examples, 605298 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:36,201 : INFO : PROGRESS: at 99.37% examples, 604994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:37,207 : INFO : PROGRESS: at 99.56% examples, 604668 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:38,217 : INFO : PROGRESS: at 99.77% examples, 604395 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-26 15:04:39,239 : INFO : PROGRESS: at 99.98% examples, 604140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-26 15:04:39,303 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-26 15:04:39,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-26 15:04:39,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-26 15:04:39,328 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-26 15:04:39,329 : INFO : training on 325949085 raw words (251323074 effective words) took 416.0s, 604157 effective words/s\n",
      "2017-04-26 15:04:39,330 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-26 15:04:39,967 : INFO : saving Word2Vec object under Results/mouse_dros_yeast_BE_comb_model, separately None\n",
      "2017-04-26 15:04:39,968 : INFO : storing np array 'syn0' to Results/mouse_dros_yeast_BE_comb_model.wv.syn0.npy\n",
      "2017-04-26 15:04:40,031 : INFO : not storing attribute syn0norm\n",
      "2017-04-26 15:04:40,032 : INFO : storing np array 'syn1neg' to Results/mouse_dros_yeast_BE_comb_model.syn1neg.npy\n",
      "2017-04-26 15:04:40,257 : INFO : not storing attribute cum_table\n",
      "2017-04-26 15:04:42,976 : INFO : saved Results/mouse_dros_yeast_BE_comb_model\n"
     ]
    }
   ],
   "source": [
    "#Strict model\n",
    "mouse_old_SR_sentence_pkl = 'Results/mouse/strict_real.pkl'\n",
    "dros_SR_sentences_pkl = 'Results/drosophila/strict_real.pkl'\n",
    "yeast_SR_sentences_pkl = 'Results/yeast/strict_real.pkl'\n",
    "data_list = [mouse_old_SR_sentence_pkl, dros_SR_sentences_pkl, yeast_SR_sentences_pkl]\n",
    "mouse_dros_yeast_SR_comb_model = make_w2v_model(data_list, 'mouse_dros_yeast_SR_comb_model')\n",
    "\n",
    "#Gen model\n",
    "mouse_old_GEN_sentence_pkl = 'Results/mouse/gen_real.pkl'\n",
    "dros_GEN_sentences_pkl = 'Results/drosophila/gen_real.pkl'\n",
    "yeast_GEN_sentences_pkl = 'Results/yeast/gen_real.pkl'\n",
    "data_list = [mouse_old_GEN_sentence_pkl, dros_GEN_sentences_pkl, yeast_GEN_sentences_pkl]\n",
    "mouse_dros_yeast_GEN_comb_model = make_w2v_model(data_list, 'mouse_dros_yeast_GEN_comb_model')\n",
    "\n",
    "#Both Ents model                                              \n",
    "mouse_old_BE_sentence_pkl = 'Results/mouse/be_real.pkl'\n",
    "dros_BE_sentences_pkl = 'Results/drosophila/be_real.pkl'\n",
    "yeast_BE_sentences_pkl = 'Results/yeast/be_real.pkl'\n",
    "data_list = [mouse_old_BE_sentence_pkl, dros_BE_sentences_pkl, yeast_BE_sentences_pkl]\n",
    "mouse_dros_yeast_BE_comb_model = make_w2v_model(data_list, 'mouse_dros_yeast_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "mouse_strict_real = pickle.load(open('Results/mouse/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_SR_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_GEN_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_BE_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/mouse_dros_yeast_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/mouse_dros_yeast_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/mouse_dros_yeast_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse_dros_yeast_comb/Seeded/Results/'\n",
    "errors_mouse_dros_yeast_comb = mult_open(drct, '_errors_')\n",
    "fpr_mouse_dros_yeast_comb = mult_open(drct, '_fpr_')\n",
    "tpr_mouse_dros_yeast_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse_dros_yeast_comb auc=0.641 error=0.339\n",
      "Strict error mouse_dros_yeast_comb auc=0.640 error=0.339\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.656 error=0.335\n",
      "Gen error mouse_dros_yeast_comb auc=0.653 error=0.336\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.658 error=0.340\n",
      "BE error mouse_dros_yeast_comb auc=0.652 error=0.338\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.670 error=0.260\n",
      "Strict error mouse_dros_yeast_comb auc=0.667 error=0.257\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.681 error=0.261\n",
      "Gen error mouse_dros_yeast_comb auc=0.681 error=0.261\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.677 error=0.261\n",
      "BE error mouse_dros_yeast_comb auc=0.672 error=0.260\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.664 error=0.322\n",
      "Strict error mouse_dros_yeast_comb auc=0.661 error=0.323\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.679 error=0.317\n",
      "Gen error mouse_dros_yeast_comb auc=0.675 error=0.316\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.677 error=0.321\n",
      "BE error mouse_dros_yeast_comb auc=0.666 error=0.323\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.685 error=0.235\n",
      "Strict error mouse_dros_yeast_comb auc=0.679 error=0.236\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.693 error=0.228\n",
      "Gen error mouse_dros_yeast_comb auc=0.697 error=0.229\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.685 error=0.231\n",
      "BE error mouse_dros_yeast_comb auc=0.683 error=0.231\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.609 error=0.289\n",
      "Strict error mouse_dros_yeast_comb auc=0.608 error=0.292\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.626 error=0.288\n",
      "Gen error mouse_dros_yeast_comb auc=0.624 error=0.290\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.625 error=0.294\n",
      "BE error mouse_dros_yeast_comb auc=0.622 error=0.291\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.638 error=0.330\n",
      "Strict error mouse_dros_yeast_comb auc=0.641 error=0.329\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.667 error=0.319\n",
      "Gen error mouse_dros_yeast_comb auc=0.665 error=0.320\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.657 error=0.329\n",
      "BE error mouse_dros_yeast_comb auc=0.658 error=0.328\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.652 error=0.142\n",
      "Strict error mouse_dros_yeast_comb auc=0.651 error=0.145\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.684 error=0.140\n",
      "Gen error mouse_dros_yeast_comb auc=0.682 error=0.143\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.684 error=0.142\n",
      "BE error mouse_dros_yeast_comb auc=0.680 error=0.144\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_comb auc=0.648 error=0.262\n",
      "Strict error mouse_dros_yeast_comb auc=0.647 error=0.264\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_comb auc=0.665 error=0.259\n",
      "Gen error mouse_dros_yeast_comb auc=0.665 error=0.262\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_comb auc=0.660 error=0.257\n",
      "BE error mouse_dros_yeast_comb auc=0.659 error=0.258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_dros_yeast_comb_strict = []\n",
    "mean_auc_mouse_dros_yeast_comb_strict = []\n",
    "mean_err_mouse_dros_yeast_comb_gen = []\n",
    "mean_auc_mouse_dros_yeast_comb_gen = []\n",
    "mean_err_mouse_dros_yeast_comb_be = []\n",
    "mean_auc_mouse_dros_yeast_comb_be = []\n",
    "for e, f, t in zip(errors_mouse_dros_yeast_comb, fpr_mouse_dros_yeast_comb, tpr_mouse_dros_yeast_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse_dros_yeast_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_dros_yeast_comb_strict.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_dros_yeast_comb_gen.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_dros_yeast_comb_be.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_dros_yeast_comb_org_strict = mean_err_mouse_dros_yeast_comb_strict[0::2]\n",
    "mean_err_mouse_dros_yeast_comb_fs_strict = mean_err_mouse_dros_yeast_comb_strict[1::2]\n",
    "mean_auc_mouse_dros_yeast_comb_org_strict = mean_auc_mouse_dros_yeast_comb_strict[0::2]\n",
    "mean_auc_mouse_dros_yeast_comb_fs_strict = mean_auc_mouse_dros_yeast_comb_strict[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_comb_org_gen = mean_err_mouse_dros_yeast_comb_gen[0::2]\n",
    "mean_err_mouse_dros_yeast_comb_fs_gen = mean_err_mouse_dros_yeast_comb_gen[1::2]\n",
    "mean_auc_mouse_dros_yeast_comb_org_gen = mean_auc_mouse_dros_yeast_comb_gen[0::2]\n",
    "mean_auc_mouse_dros_yeast_comb_fs_gen = mean_auc_mouse_dros_yeast_comb_gen[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_comb_org_be = mean_err_mouse_dros_yeast_comb_be[0::2]\n",
    "mean_err_mouse_dros_yeast_comb_fs_be = mean_err_mouse_dros_yeast_comb_be[1::2]\n",
    "mean_auc_mouse_dros_yeast_comb_org_be = mean_auc_mouse_dros_yeast_comb_be[0::2]\n",
    "mean_auc_mouse_dros_yeast_comb_fs_be = mean_auc_mouse_dros_yeast_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_dros_yeast_comb mean strict error original -  0.27257798267\n",
      "mouse_dros_yeast_comb mean strict error feature selection -  0.27292580159\n",
      "mouse_dros_yeast_comb mean strict AUC original -  0.650972477694\n",
      "mouse_dros_yeast_comb mean strict AUC feature selection -  0.649298581491\n",
      "\n",
      "\n",
      "mouse_dros_yeast_comb mean gen error original -  0.268226818739\n",
      "mouse_dros_yeast_comb mean gen error feature selection -  0.269550656527\n",
      "mouse_dros_yeast_comb mean gen AUC original -  0.668919572191\n",
      "mouse_dros_yeast_comb mean gen AUC feature selection -  0.667619088857\n",
      "\n",
      "\n",
      "mouse_dros_yeast_comb mean BE error original -  0.271991433226\n",
      "mouse_dros_yeast_comb mean BE error feature selection -  0.271723707837\n",
      "mouse_dros_yeast_comb mean BE AUC original -  0.665338058348\n",
      "mouse_dros_yeast_comb mean BE AUC feature selection -  0.661330713581\n"
     ]
    }
   ],
   "source": [
    "print('mouse_dros_yeast_comb mean strict error original - ', np.mean(mean_err_mouse_dros_yeast_comb_org_strict))\n",
    "print('mouse_dros_yeast_comb mean strict error feature selection - ', np.mean(mean_err_mouse_dros_yeast_comb_fs_strict))\n",
    "print('mouse_dros_yeast_comb mean strict AUC original - ', np.mean(mean_auc_mouse_dros_yeast_comb_org_strict))\n",
    "print('mouse_dros_yeast_comb mean strict AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast_comb mean gen error original - ', np.mean(mean_err_mouse_dros_yeast_comb_org_gen))\n",
    "print('mouse_dros_yeast_comb mean gen error feature selection - ', np.mean(mean_err_mouse_dros_yeast_comb_fs_gen))\n",
    "print('mouse_dros_yeast_comb mean gen AUC original - ', np.mean(mean_auc_mouse_dros_yeast_comb_org_gen))\n",
    "print('mouse_dros_yeast_comb mean gen AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast_comb mean BE error original - ', np.mean(mean_err_mouse_dros_yeast_comb_org_be))\n",
    "print('mouse_dros_yeast_comb mean BE error feature selection - ', np.mean(mean_err_mouse_dros_yeast_comb_fs_be))\n",
    "print('mouse_dros_yeast_comb mean BE AUC original - ', np.mean(mean_auc_mouse_dros_yeast_comb_org_be))\n",
    "print('mouse_dros_yeast_comb mean BE AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mouse_dros_yeast_rat_SR_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_SR_comb_model')\n",
    "mouse_dros_yeast_rat_GEN_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_GEN_comb_model')\n",
    "mouse_dros_yeast_rat_BE_comb_model = word2vec.Word2Vec.load('Results/dros_yeast_rat_mouse_comb/Seeded/Results/dros_yeast_rat_mouse_BE_comb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "random_seeds = [905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]\n",
    "mouse_strict_real = pickle.load(open('Results/mouse/strict_real.pkl', 'rb'))\n",
    "for seed in random_seeds:\n",
    "    strict_list_SR_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_rat_SR_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_rat_SR_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_GEN_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_rat_GEN_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_rat_GEN_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    \n",
    "    strict_list_BE_comb = pred.make_models(mouse_strict_real, \n",
    "                                             'mouse_dros_yeast_rat_BE_comb_'+str(seed),\n",
    "                                             prev_model=mouse_dros_yeast_rat_BE_comb_model, \n",
    "                                             ran_state=seed)\n",
    "    strict_final_list = [strict_list_SR_comb, \n",
    "                         strict_list_GEN_comb, \n",
    "                         strict_list_BE_comb]\n",
    "    \n",
    "    print ('\\nPredicting\\n')\n",
    "    errors = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for entry in strict_final_list:\n",
    "        error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                             entry[2], entry[3])\n",
    "        fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(entry[3], probs_w2v_norm)\n",
    "        error_w2v_fs, probs_w2v_fs = pred.XGB_classifier(entry[0], entry[1],\n",
    "                                                         entry[2], entry[3],\n",
    "                                                         feature_selection=True)\n",
    "        fpr_w2v_fs, tpr_w2v_fs, _ = roc_curve(entry[3], probs_w2v_fs)\n",
    "\n",
    "        errors.append([error_w2v_norm, error_w2v_fs])\n",
    "        fpr.append([fpr_w2v_norm, fpr_w2v_fs])\n",
    "        tpr.append([tpr_w2v_norm, tpr_w2v_fs])\n",
    "\n",
    "    pickle.dump(errors, open('Results/mouse_dros_yeast_rat_comb_errors_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(fpr, open('Results/mouse_dros_yeast_rat_comb_fpr_pickle_'+str(seed)+'.pkl', 'wb'))\n",
    "    pickle.dump(tpr, open('Results/mouse_dros_yeast_rat_comb_tpr_pickle_'+str(seed)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drct = 'Results/mouse_dros_yeast_rat_comb/Seeded/Results/'\n",
    "errors_mouse_dros_yeast_rat_comb = mult_open(drct, '_errors_')\n",
    "fpr_mouse_dros_yeast_rat_comb = mult_open(drct, '_fpr_')\n",
    "tpr_mouse_dros_yeast_rat_comb = mult_open(drct, '_tpr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict error mouse_dros_yeast_rat_comb auc=0.682 error=0.302\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.674 error=0.303\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.686 error=0.298\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.685 error=0.296\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.689 error=0.299\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.681 error=0.301\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.700 error=0.267\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.702 error=0.267\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.710 error=0.268\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.710 error=0.268\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.704 error=0.267\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.705 error=0.269\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.563 error=0.337\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.555 error=0.334\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.564 error=0.332\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.560 error=0.333\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.558 error=0.334\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.557 error=0.336\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.643 error=0.326\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.640 error=0.325\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.657 error=0.323\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.656 error=0.320\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.658 error=0.322\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.647 error=0.323\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.671 error=0.227\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.671 error=0.226\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.680 error=0.226\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.671 error=0.228\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.672 error=0.228\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.670 error=0.229\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.649 error=0.390\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.647 error=0.391\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.654 error=0.387\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.653 error=0.384\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.649 error=0.390\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.649 error=0.389\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.641 error=0.333\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.636 error=0.334\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.645 error=0.324\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.643 error=0.325\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.639 error=0.332\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.637 error=0.329\n",
      "\n",
      "\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.722 error=0.225\n",
      "Strict error mouse_dros_yeast_rat_comb auc=0.723 error=0.225\n",
      "\n",
      "\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.735 error=0.215\n",
      "Gen error mouse_dros_yeast_rat_comb auc=0.727 error=0.220\n",
      "\n",
      "\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.729 error=0.218\n",
      "BE error mouse_dros_yeast_rat_comb auc=0.728 error=0.221\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_err_mouse_dros_yeast_rat_comb_strict = []\n",
    "mean_auc_mouse_dros_yeast_rat_comb_strict = []\n",
    "mean_err_mouse_dros_yeast_rat_comb_gen = []\n",
    "mean_auc_mouse_dros_yeast_rat_comb_gen = []\n",
    "mean_err_mouse_dros_yeast_rat_comb_be = []\n",
    "mean_auc_mouse_dros_yeast_rat_comb_be = []\n",
    "for e, f, t in zip(errors_mouse_dros_yeast_rat_comb, fpr_mouse_dros_yeast_rat_comb, tpr_mouse_dros_yeast_rat_comb):\n",
    "    input_list = [[e, f, t]]\n",
    "    name_list = ['mouse_dros_yeast_rat_comb']\n",
    "    for idx in range(3):\n",
    "        for item, name in zip(input_list, name_list):\n",
    "            for fpr_item, tpr_item, error_item in zip(item[1][idx], item[2][idx], item[0][idx]):\n",
    "                roc_auc = auc(fpr_item, tpr_item)\n",
    "                auc_val = '%.3f' % roc_auc\n",
    "                error = '%.3f' % error_item\n",
    "                if idx == 0:\n",
    "                    mean_err_mouse_dros_yeast_rat_comb_strict.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_rat_comb_strict.append(roc_auc)\n",
    "                    legend_label = 'Strict error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 1:\n",
    "                    mean_err_mouse_dros_yeast_rat_comb_gen.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_rat_comb_gen.append(roc_auc)\n",
    "                    legend_label = 'Gen error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "                elif idx == 2:\n",
    "                    mean_err_mouse_dros_yeast_rat_comb_be.append(error_item)\n",
    "                    mean_auc_mouse_dros_yeast_rat_comb_be.append(roc_auc)\n",
    "                    legend_label = 'BE error ' + name + ' auc=' + str(auc_val) + ' error=' + str(error)\n",
    "                    print(legend_label)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_err_mouse_dros_yeast_rat_comb_org_strict = mean_err_mouse_dros_yeast_rat_comb_strict[0::2]\n",
    "mean_err_mouse_dros_yeast_rat_comb_fs_strict = mean_err_mouse_dros_yeast_rat_comb_strict[1::2]\n",
    "mean_auc_mouse_dros_yeast_rat_comb_org_strict = mean_auc_mouse_dros_yeast_rat_comb_strict[0::2]\n",
    "mean_auc_mouse_dros_yeast_rat_comb_fs_strict = mean_auc_mouse_dros_yeast_rat_comb_strict[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_rat_comb_org_gen = mean_err_mouse_dros_yeast_rat_comb_gen[0::2]\n",
    "mean_err_mouse_dros_yeast_rat_comb_fs_gen = mean_err_mouse_dros_yeast_rat_comb_gen[1::2]\n",
    "mean_auc_mouse_dros_yeast_rat_comb_org_gen = mean_auc_mouse_dros_yeast_rat_comb_gen[0::2]\n",
    "mean_auc_mouse_dros_yeast_rat_comb_fs_gen = mean_auc_mouse_dros_yeast_rat_comb_gen[1::2]\n",
    "\n",
    "mean_err_mouse_dros_yeast_rat_comb_org_be = mean_err_mouse_dros_yeast_rat_comb_be[0::2]\n",
    "mean_err_mouse_dros_yeast_rat_comb_fs_be = mean_err_mouse_dros_yeast_rat_comb_be[1::2]\n",
    "mean_auc_mouse_dros_yeast_rat_comb_org_be = mean_auc_mouse_dros_yeast_rat_comb_be[0::2]\n",
    "mean_auc_mouse_dros_yeast_rat_comb_fs_be = mean_auc_mouse_dros_yeast_rat_comb_be[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_dros_yeast_rat_comb mean strict error original -  0.300749135463\n",
      "mouse_dros_yeast_rat_comb mean strict error feature selection -  0.300643248896\n",
      "mouse_dros_yeast_rat_comb mean strict AUC original -  0.658823905948\n",
      "mouse_dros_yeast_rat_comb mean strict AUC feature selection -  0.656080391406\n",
      "\n",
      "\n",
      "mouse_dros_yeast_rat_comb mean gen error original -  0.296597219449\n",
      "mouse_dros_yeast_rat_comb mean gen error feature selection -  0.296813891798\n",
      "mouse_dros_yeast_rat_comb mean gen AUC original -  0.666519608133\n",
      "mouse_dros_yeast_rat_comb mean gen AUC feature selection -  0.663122285512\n",
      "\n",
      "\n",
      "mouse_dros_yeast_rat_comb mean BE error original -  0.298761635738\n",
      "mouse_dros_yeast_rat_comb mean BE error feature selection -  0.29957681202\n",
      "mouse_dros_yeast_rat_comb mean BE AUC original -  0.662138929158\n",
      "mouse_dros_yeast_rat_comb mean BE AUC feature selection -  0.659285849748\n"
     ]
    }
   ],
   "source": [
    "print('mouse_dros_yeast_rat_comb mean strict error original - ', np.mean(mean_err_mouse_dros_yeast_rat_comb_org_strict))\n",
    "print('mouse_dros_yeast_rat_comb mean strict error feature selection - ', np.mean(mean_err_mouse_dros_yeast_rat_comb_fs_strict))\n",
    "print('mouse_dros_yeast_rat_comb mean strict AUC original - ', np.mean(mean_auc_mouse_dros_yeast_rat_comb_org_strict))\n",
    "print('mouse_dros_yeast_rat_comb mean strict AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_rat_comb_fs_strict))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast_rat_comb mean gen error original - ', np.mean(mean_err_mouse_dros_yeast_rat_comb_org_gen))\n",
    "print('mouse_dros_yeast_rat_comb mean gen error feature selection - ', np.mean(mean_err_mouse_dros_yeast_rat_comb_fs_gen))\n",
    "print('mouse_dros_yeast_rat_comb mean gen AUC original - ', np.mean(mean_auc_mouse_dros_yeast_rat_comb_org_gen))\n",
    "print('mouse_dros_yeast_rat_comb mean gen AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_rat_comb_fs_gen))\n",
    "print('\\n')\n",
    "print('mouse_dros_yeast_rat_comb mean BE error original - ', np.mean(mean_err_mouse_dros_yeast_rat_comb_org_be))\n",
    "print('mouse_dros_yeast_rat_comb mean BE error feature selection - ', np.mean(mean_err_mouse_dros_yeast_rat_comb_fs_be))\n",
    "print('mouse_dros_yeast_rat_comb mean BE AUC original - ', np.mean(mean_auc_mouse_dros_yeast_rat_comb_org_be))\n",
    "print('mouse_dros_yeast_rat_comb mean BE AUC feature selection - ', np.mean(mean_auc_mouse_dros_yeast_rat_comb_fs_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
