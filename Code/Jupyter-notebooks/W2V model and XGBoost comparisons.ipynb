{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Core-scripts/')\n",
    "\n",
    "from parse_and_prepare import ProteinProteinInteractionClassifier as ppi\n",
    "import file_readers as fr\n",
    "import prediction as pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_w2v_model(dataset, name_for_model, model_features=None):\n",
    "    \"\"\"Produce a Word2Vec Model\n",
    "\n",
    "    Model_features (list): Features of the word to vec models\n",
    "        1. Word vector dimensionality\n",
    "        2. Minimum word count\n",
    "        3. Number of threads to run in parallel\n",
    "        4. Context window size\n",
    "        5. Downsample setting for frequent words\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print ('Parsing datasets sentences')\n",
    "\n",
    "    sentences = [fr.sentence_to_wordlist(sen) for sen in dataset]\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "    # Set values for various parameters\n",
    "    if model_features:\n",
    "        num_features = model_features[0] #300  # Word vector dimensionality\n",
    "        min_word_count = model_features[1] #5  # Minimum word count\n",
    "        num_workers = model_features[2] #4  # Number of threads to run in parallel\n",
    "        context = model_features[3] #6  # Context window size\n",
    "        downsampling = model_features[4] #0.001  # Downsample setting for frequent words\n",
    "    else:\n",
    "        num_features = 600  # Word vector dimensionality\n",
    "        min_word_count = 6  # Minimum word count\n",
    "        num_workers = 4  # Number of threads to run in parallel\n",
    "        context = 7  # Context window size\n",
    "        downsampling = 0.0001  # Downsample setting for frequent words\n",
    "\n",
    "    print('Training Word2Vec Model')\n",
    "\n",
    "    model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count=min_word_count, \\\n",
    "            window=context, sample=downsampling)\n",
    "\n",
    "    # If you don't plan to train the model any further, calling\n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=False)\n",
    "\n",
    "    model_name = 'Results/' + name_for_model + '_model'\n",
    "\n",
    "    model.save(model_name)\n",
    "\n",
    "    w2v_model = model\n",
    "\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Yeast using old model (w/o skipgramms and hierarchical softmax)\n",
    "\n",
    "yeast_strict = pickle.load(open('../../Results/Yeast/yeast_mentions_strict_real.pkl', 'rb'))\n",
    "yeast_gen = pickle.load(open('../../Results/Yeast/yeast_mentions_gen_real.pkl', 'rb'))\n",
    "yeast_be = pickle.load(open('../../Results/Yeast/yeast_mentions_be_real.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:09:36,218 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:09:36,219 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:09:36,252 : INFO : collected 11431 word types from a corpus of 188505 raw words and 7145 sentences\n",
      "2017-06-02 17:09:36,253 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:09:36,271 : INFO : min_count=5 retains 3346 unique words (29% of original 11431, drops 8085)\n",
      "2017-06-02 17:09:36,272 : INFO : min_count=5 leaves 175425 word corpus (93% of original 188505, drops 13080)\n",
      "2017-06-02 17:09:36,281 : INFO : deleting the raw counts dictionary of 11431 items\n",
      "2017-06-02 17:09:36,282 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2017-06-02 17:09:36,282 : INFO : downsampling leaves estimated 125739 word corpus (71.7% of prior 175425)\n",
      "2017-06-02 17:09:36,283 : INFO : estimated required memory for 3346 words and 100 dimensions: 4349800 bytes\n",
      "2017-06-02 17:09:36,295 : INFO : resetting layer weights\n",
      "2017-06-02 17:09:36,329 : INFO : training model with 3 workers on 3346 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:09:36,329 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:09:37,344 : INFO : PROGRESS: at 91.27% examples, 566814 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:37,414 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:09:37,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:09:37,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:09:37,434 : INFO : training on 942525 raw words (628544 effective words) took 1.1s, 570927 effective words/s\n",
      "2017-06-02 17:09:37,435 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:09:37,437 : INFO : saving Word2Vec object under Results/yeast_strict_kkas_model, separately None\n",
      "2017-06-02 17:09:37,437 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:09:37,438 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:09:37,463 : INFO : saved Results/yeast_strict_kkas_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:09:37,990 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:09:37,991 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:09:38,040 : INFO : PROGRESS: at sentence #10000, processed 241924 words, keeping 11195 word types\n",
      "2017-06-02 17:09:38,091 : INFO : PROGRESS: at sentence #20000, processed 485055 words, keeping 14860 word types\n",
      "2017-06-02 17:09:38,148 : INFO : PROGRESS: at sentence #30000, processed 727846 words, keeping 17547 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:09:38,205 : INFO : PROGRESS: at sentence #40000, processed 969967 words, keeping 19750 word types\n",
      "2017-06-02 17:09:38,245 : INFO : collected 21147 word types from a corpus of 1155938 raw words and 47662 sentences\n",
      "2017-06-02 17:09:38,246 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:09:38,271 : INFO : min_count=5 retains 8077 unique words (38% of original 21147, drops 13070)\n",
      "2017-06-02 17:09:38,272 : INFO : min_count=5 leaves 1134115 word corpus (98% of original 1155938, drops 21823)\n",
      "2017-06-02 17:09:38,292 : INFO : deleting the raw counts dictionary of 21147 items\n",
      "2017-06-02 17:09:38,294 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-06-02 17:09:38,294 : INFO : downsampling leaves estimated 829411 word corpus (73.1% of prior 1134115)\n",
      "2017-06-02 17:09:38,295 : INFO : estimated required memory for 8077 words and 100 dimensions: 10500100 bytes\n",
      "2017-06-02 17:09:38,324 : INFO : resetting layer weights\n",
      "2017-06-02 17:09:38,404 : INFO : training model with 3 workers on 8077 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:09:38,405 : INFO : expecting 47662 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-06-02 17:09:39,412 : INFO : PROGRESS: at 13.30% examples, 549938 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:09:40,428 : INFO : PROGRESS: at 27.30% examples, 560843 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:41,435 : INFO : PROGRESS: at 40.79% examples, 558724 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:42,446 : INFO : PROGRESS: at 53.74% examples, 552032 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:43,468 : INFO : PROGRESS: at 66.87% examples, 548203 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:44,469 : INFO : PROGRESS: at 80.17% examples, 548761 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:45,472 : INFO : PROGRESS: at 93.12% examples, 546921 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:45,970 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:09:45,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:09:45,976 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:09:45,977 : INFO : training on 5779690 raw words (4147842 effective words) took 7.6s, 548053 effective words/s\n",
      "2017-06-02 17:09:45,978 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:09:45,982 : INFO : saving Word2Vec object under Results/yeast_gen_kkas_model, separately None\n",
      "2017-06-02 17:09:45,982 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:09:45,983 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:09:46,067 : INFO : saved Results/yeast_gen_kkas_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:09:48,643 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:09:48,644 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:09:48,687 : INFO : PROGRESS: at sentence #10000, processed 228368 words, keeping 12408 word types\n",
      "2017-06-02 17:09:48,747 : INFO : PROGRESS: at sentence #20000, processed 455332 words, keeping 16984 word types\n",
      "2017-06-02 17:09:48,814 : INFO : PROGRESS: at sentence #30000, processed 686390 words, keeping 20127 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:09:48,870 : INFO : PROGRESS: at sentence #40000, processed 915781 words, keeping 22805 word types\n",
      "2017-06-02 17:09:48,921 : INFO : PROGRESS: at sentence #50000, processed 1145029 words, keeping 25157 word types\n",
      "2017-06-02 17:09:48,973 : INFO : PROGRESS: at sentence #60000, processed 1375391 words, keeping 27216 word types\n",
      "2017-06-02 17:09:49,022 : INFO : PROGRESS: at sentence #70000, processed 1605672 words, keeping 29012 word types\n",
      "2017-06-02 17:09:49,060 : INFO : PROGRESS: at sentence #80000, processed 1834240 words, keeping 30678 word types\n",
      "2017-06-02 17:09:49,101 : INFO : PROGRESS: at sentence #90000, processed 2061794 words, keeping 32258 word types\n",
      "2017-06-02 17:09:49,142 : INFO : PROGRESS: at sentence #100000, processed 2291681 words, keeping 33687 word types\n",
      "2017-06-02 17:09:49,181 : INFO : PROGRESS: at sentence #110000, processed 2521584 words, keeping 35002 word types\n",
      "2017-06-02 17:09:49,223 : INFO : PROGRESS: at sentence #120000, processed 2749912 words, keeping 36257 word types\n",
      "2017-06-02 17:09:49,269 : INFO : PROGRESS: at sentence #130000, processed 2978987 words, keeping 37489 word types\n",
      "2017-06-02 17:09:49,315 : INFO : PROGRESS: at sentence #140000, processed 3207319 words, keeping 38623 word types\n",
      "2017-06-02 17:09:49,361 : INFO : PROGRESS: at sentence #150000, processed 3435305 words, keeping 39690 word types\n",
      "2017-06-02 17:09:49,404 : INFO : PROGRESS: at sentence #160000, processed 3662047 words, keeping 40629 word types\n",
      "2017-06-02 17:09:49,450 : INFO : PROGRESS: at sentence #170000, processed 3891381 words, keeping 41660 word types\n",
      "2017-06-02 17:09:49,497 : INFO : PROGRESS: at sentence #180000, processed 4120204 words, keeping 42610 word types\n",
      "2017-06-02 17:09:49,537 : INFO : PROGRESS: at sentence #190000, processed 4349041 words, keeping 43520 word types\n",
      "2017-06-02 17:09:49,579 : INFO : PROGRESS: at sentence #200000, processed 4579505 words, keeping 44508 word types\n",
      "2017-06-02 17:09:49,617 : INFO : collected 45300 word types from a corpus of 4784186 raw words and 208973 sentences\n",
      "2017-06-02 17:09:49,618 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:09:49,665 : INFO : min_count=5 retains 16820 unique words (37% of original 45300, drops 28480)\n",
      "2017-06-02 17:09:49,665 : INFO : min_count=5 leaves 4736602 word corpus (99% of original 4784186, drops 47584)\n",
      "2017-06-02 17:09:49,705 : INFO : deleting the raw counts dictionary of 45300 items\n",
      "2017-06-02 17:09:49,707 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2017-06-02 17:09:49,708 : INFO : downsampling leaves estimated 3527961 word corpus (74.5% of prior 4736602)\n",
      "2017-06-02 17:09:49,709 : INFO : estimated required memory for 16820 words and 100 dimensions: 21866000 bytes\n",
      "2017-06-02 17:09:49,764 : INFO : resetting layer weights\n",
      "2017-06-02 17:09:49,932 : INFO : training model with 3 workers on 16820 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:09:49,933 : INFO : expecting 208973 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-06-02 17:09:50,949 : INFO : PROGRESS: at 2.63% examples, 458227 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:51,963 : INFO : PROGRESS: at 5.50% examples, 479633 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:52,971 : INFO : PROGRESS: at 8.55% examples, 497888 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:53,999 : INFO : PROGRESS: at 11.39% examples, 495151 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:09:55,000 : INFO : PROGRESS: at 14.40% examples, 501836 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:56,008 : INFO : PROGRESS: at 16.78% examples, 487692 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:57,016 : INFO : PROGRESS: at 18.45% examples, 459798 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:09:58,029 : INFO : PROGRESS: at 20.21% examples, 440445 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:09:59,041 : INFO : PROGRESS: at 21.93% examples, 424695 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:00,072 : INFO : PROGRESS: at 24.01% examples, 417862 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:01,084 : INFO : PROGRESS: at 26.79% examples, 424178 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:02,100 : INFO : PROGRESS: at 29.80% examples, 432372 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:03,111 : INFO : PROGRESS: at 32.76% examples, 438853 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:04,115 : INFO : PROGRESS: at 35.32% examples, 439449 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:05,118 : INFO : PROGRESS: at 37.87% examples, 440022 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:06,122 : INFO : PROGRESS: at 40.46% examples, 440929 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:07,123 : INFO : PROGRESS: at 43.46% examples, 446099 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:08,133 : INFO : PROGRESS: at 45.88% examples, 444811 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:09,149 : INFO : PROGRESS: at 47.54% examples, 436632 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:10,198 : INFO : PROGRESS: at 49.17% examples, 428197 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:11,218 : INFO : PROGRESS: at 50.93% examples, 422190 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:12,230 : INFO : PROGRESS: at 53.22% examples, 421177 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:13,237 : INFO : PROGRESS: at 55.82% examples, 422574 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:14,238 : INFO : PROGRESS: at 57.99% examples, 420918 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:15,248 : INFO : PROGRESS: at 60.79% examples, 423609 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:16,258 : INFO : PROGRESS: at 63.50% examples, 425549 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:17,272 : INFO : PROGRESS: at 66.12% examples, 426741 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:18,274 : INFO : PROGRESS: at 69.00% examples, 429587 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:19,281 : INFO : PROGRESS: at 71.96% examples, 432664 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:20,305 : INFO : PROGRESS: at 74.27% examples, 431391 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:21,308 : INFO : PROGRESS: at 75.90% examples, 426769 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:22,314 : INFO : PROGRESS: at 77.66% examples, 423071 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:23,330 : INFO : PROGRESS: at 79.24% examples, 418569 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:24,355 : INFO : PROGRESS: at 81.21% examples, 416159 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:25,357 : INFO : PROGRESS: at 83.50% examples, 415817 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:26,367 : INFO : PROGRESS: at 86.16% examples, 417227 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:27,374 : INFO : PROGRESS: at 89.08% examples, 419778 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:10:28,375 : INFO : PROGRESS: at 92.04% examples, 422448 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:29,389 : INFO : PROGRESS: at 94.47% examples, 422406 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:30,422 : INFO : PROGRESS: at 97.07% examples, 422906 words/s, in_qsize 4, out_qsize 1\n",
      "2017-06-02 17:10:31,423 : INFO : PROGRESS: at 99.57% examples, 423354 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:10:31,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:10:31,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:10:31,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:10:31,564 : INFO : training on 23920930 raw words (17638838 effective words) took 41.6s, 423729 effective words/s\n",
      "2017-06-02 17:10:31,565 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:10:31,573 : INFO : saving Word2Vec object under Results/yeast_be_kkas_model, separately None\n",
      "2017-06-02 17:10:31,574 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:10:31,575 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:10:31,718 : INFO : saved Results/yeast_be_kkas_model\n"
     ]
    }
   ],
   "source": [
    "yeast_strict_model = make_w2v_model(yeast_strict, 'yeast_strict_kkas')\n",
    "yeast_gen_model = make_w2v_model(yeast_gen, 'yeast_gen_kkas')\n",
    "yeast_be_model = make_w2v_model(yeast_be, 'yeast_be_kkas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:11:16,975 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:11:16,975 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:11:17,011 : INFO : collected 11431 word types from a corpus of 188505 raw words and 7145 sentences\n",
      "2017-06-02 17:11:17,011 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:11:17,028 : INFO : min_count=5 retains 3346 unique words (29% of original 11431, drops 8085)\n",
      "2017-06-02 17:11:17,028 : INFO : min_count=5 leaves 175425 word corpus (93% of original 188505, drops 13080)\n",
      "2017-06-02 17:11:17,037 : INFO : deleting the raw counts dictionary of 11431 items\n",
      "2017-06-02 17:11:17,039 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2017-06-02 17:11:17,042 : INFO : downsampling leaves estimated 125739 word corpus (71.7% of prior 175425)\n",
      "2017-06-02 17:11:17,043 : INFO : estimated required memory for 3346 words and 100 dimensions: 6357400 bytes\n",
      "2017-06-02 17:11:17,047 : INFO : constructing a huffman tree from 3346 words\n",
      "2017-06-02 17:11:17,119 : INFO : built huffman tree with maximum node depth 15\n",
      "2017-06-02 17:11:17,129 : INFO : resetting layer weights\n",
      "2017-06-02 17:11:17,161 : INFO : training model with 3 workers on 3346 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:11:17,162 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:11:17,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:11:17,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:11:17,900 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:11:17,901 : INFO : training on 942525 raw words (628224 effective words) took 0.7s, 854562 effective words/s\n",
      "2017-06-02 17:11:17,901 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:11:17,903 : INFO : saving Word2Vec object under Results/yeast_strict_kkas_model, separately None\n",
      "2017-06-02 17:11:17,904 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:11:17,904 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:11:17,967 : INFO : saved Results/yeast_strict_kkas_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:11:18,530 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:11:18,531 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:11:18,576 : INFO : PROGRESS: at sentence #10000, processed 241924 words, keeping 11195 word types\n",
      "2017-06-02 17:11:18,622 : INFO : PROGRESS: at sentence #20000, processed 485055 words, keeping 14860 word types\n",
      "2017-06-02 17:11:18,667 : INFO : PROGRESS: at sentence #30000, processed 727846 words, keeping 17547 word types\n",
      "2017-06-02 17:11:18,714 : INFO : PROGRESS: at sentence #40000, processed 969967 words, keeping 19750 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:11:18,748 : INFO : collected 21147 word types from a corpus of 1155938 raw words and 47662 sentences\n",
      "2017-06-02 17:11:18,749 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:11:18,771 : INFO : min_count=5 retains 8077 unique words (38% of original 21147, drops 13070)\n",
      "2017-06-02 17:11:18,772 : INFO : min_count=5 leaves 1134115 word corpus (98% of original 1155938, drops 21823)\n",
      "2017-06-02 17:11:18,793 : INFO : deleting the raw counts dictionary of 21147 items\n",
      "2017-06-02 17:11:18,794 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-06-02 17:11:18,795 : INFO : downsampling leaves estimated 829411 word corpus (73.1% of prior 1134115)\n",
      "2017-06-02 17:11:18,796 : INFO : estimated required memory for 8077 words and 100 dimensions: 15346300 bytes\n",
      "2017-06-02 17:11:18,808 : INFO : constructing a huffman tree from 8077 words\n",
      "2017-06-02 17:11:19,179 : INFO : built huffman tree with maximum node depth 18\n",
      "2017-06-02 17:11:19,202 : INFO : resetting layer weights\n",
      "2017-06-02 17:11:19,281 : INFO : training model with 3 workers on 8077 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:11:19,282 : INFO : expecting 47662 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-06-02 17:11:20,296 : INFO : PROGRESS: at 16.59% examples, 680874 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:21,305 : INFO : PROGRESS: at 31.96% examples, 656770 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:22,305 : INFO : PROGRESS: at 48.90% examples, 671743 words/s, in_qsize 5, out_qsize 1\n",
      "2017-06-02 17:11:23,306 : INFO : PROGRESS: at 67.05% examples, 691616 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:24,318 : INFO : PROGRESS: at 81.39% examples, 670733 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:25,325 : INFO : PROGRESS: at 92.95% examples, 638424 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:25,853 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:11:25,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:11:25,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:11:25,881 : INFO : training on 5779690 raw words (4147815 effective words) took 6.6s, 628890 effective words/s\n",
      "2017-06-02 17:11:25,882 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:11:25,886 : INFO : saving Word2Vec object under Results/yeast_gen_kkas_model, separately None\n",
      "2017-06-02 17:11:25,887 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:11:25,888 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:11:26,133 : INFO : saved Results/yeast_gen_kkas_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:11:29,139 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:11:29,139 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:11:29,179 : INFO : PROGRESS: at sentence #10000, processed 228368 words, keeping 12408 word types\n",
      "2017-06-02 17:11:29,219 : INFO : PROGRESS: at sentence #20000, processed 455332 words, keeping 16984 word types\n",
      "2017-06-02 17:11:29,260 : INFO : PROGRESS: at sentence #30000, processed 686390 words, keeping 20127 word types\n",
      "2017-06-02 17:11:29,303 : INFO : PROGRESS: at sentence #40000, processed 915781 words, keeping 22805 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:11:29,349 : INFO : PROGRESS: at sentence #50000, processed 1145029 words, keeping 25157 word types\n",
      "2017-06-02 17:11:29,398 : INFO : PROGRESS: at sentence #60000, processed 1375391 words, keeping 27216 word types\n",
      "2017-06-02 17:11:29,446 : INFO : PROGRESS: at sentence #70000, processed 1605672 words, keeping 29012 word types\n",
      "2017-06-02 17:11:29,490 : INFO : PROGRESS: at sentence #80000, processed 1834240 words, keeping 30678 word types\n",
      "2017-06-02 17:11:29,536 : INFO : PROGRESS: at sentence #90000, processed 2061794 words, keeping 32258 word types\n",
      "2017-06-02 17:11:29,585 : INFO : PROGRESS: at sentence #100000, processed 2291681 words, keeping 33687 word types\n",
      "2017-06-02 17:11:29,633 : INFO : PROGRESS: at sentence #110000, processed 2521584 words, keeping 35002 word types\n",
      "2017-06-02 17:11:29,673 : INFO : PROGRESS: at sentence #120000, processed 2749912 words, keeping 36257 word types\n",
      "2017-06-02 17:11:29,714 : INFO : PROGRESS: at sentence #130000, processed 2978987 words, keeping 37489 word types\n",
      "2017-06-02 17:11:29,757 : INFO : PROGRESS: at sentence #140000, processed 3207319 words, keeping 38623 word types\n",
      "2017-06-02 17:11:29,806 : INFO : PROGRESS: at sentence #150000, processed 3435305 words, keeping 39690 word types\n",
      "2017-06-02 17:11:29,853 : INFO : PROGRESS: at sentence #160000, processed 3662047 words, keeping 40629 word types\n",
      "2017-06-02 17:11:29,900 : INFO : PROGRESS: at sentence #170000, processed 3891381 words, keeping 41660 word types\n",
      "2017-06-02 17:11:29,946 : INFO : PROGRESS: at sentence #180000, processed 4120204 words, keeping 42610 word types\n",
      "2017-06-02 17:11:29,991 : INFO : PROGRESS: at sentence #190000, processed 4349041 words, keeping 43520 word types\n",
      "2017-06-02 17:11:30,039 : INFO : PROGRESS: at sentence #200000, processed 4579505 words, keeping 44508 word types\n",
      "2017-06-02 17:11:30,079 : INFO : collected 45300 word types from a corpus of 4784186 raw words and 208973 sentences\n",
      "2017-06-02 17:11:30,080 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:11:30,127 : INFO : min_count=5 retains 16820 unique words (37% of original 45300, drops 28480)\n",
      "2017-06-02 17:11:30,127 : INFO : min_count=5 leaves 4736602 word corpus (99% of original 4784186, drops 47584)\n",
      "2017-06-02 17:11:30,166 : INFO : deleting the raw counts dictionary of 45300 items\n",
      "2017-06-02 17:11:30,169 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2017-06-02 17:11:30,170 : INFO : downsampling leaves estimated 3527961 word corpus (74.5% of prior 4736602)\n",
      "2017-06-02 17:11:30,170 : INFO : estimated required memory for 16820 words and 100 dimensions: 31958000 bytes\n",
      "2017-06-02 17:11:30,195 : INFO : constructing a huffman tree from 16820 words\n",
      "2017-06-02 17:11:30,863 : INFO : built huffman tree with maximum node depth 20\n",
      "2017-06-02 17:11:30,904 : INFO : resetting layer weights\n",
      "2017-06-02 17:11:31,101 : INFO : training model with 3 workers on 16820 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:11:31,101 : INFO : expecting 208973 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-06-02 17:11:32,107 : INFO : PROGRESS: at 3.92% examples, 691564 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:33,110 : INFO : PROGRESS: at 7.63% examples, 672470 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:34,120 : INFO : PROGRESS: at 11.76% examples, 688865 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:35,135 : INFO : PROGRESS: at 15.87% examples, 694459 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:36,140 : INFO : PROGRESS: at 19.20% examples, 672782 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:37,160 : INFO : PROGRESS: at 21.97% examples, 639772 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:38,173 : INFO : PROGRESS: at 24.84% examples, 619991 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:39,204 : INFO : PROGRESS: at 27.71% examples, 603763 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:40,214 : INFO : PROGRESS: at 31.10% examples, 602332 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:41,220 : INFO : PROGRESS: at 34.69% examples, 605053 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:42,225 : INFO : PROGRESS: at 38.41% examples, 609295 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:43,243 : INFO : PROGRESS: at 42.13% examples, 612222 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:44,245 : INFO : PROGRESS: at 45.79% examples, 614893 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:45,261 : INFO : PROGRESS: at 49.55% examples, 617608 words/s, in_qsize 4, out_qsize 1\n",
      "2017-06-02 17:11:46,262 : INFO : PROGRESS: at 53.30% examples, 620505 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:47,267 : INFO : PROGRESS: at 57.11% examples, 623373 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:48,268 : INFO : PROGRESS: at 60.71% examples, 623893 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:49,285 : INFO : PROGRESS: at 63.50% examples, 616193 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:50,286 : INFO : PROGRESS: at 66.37% examples, 610545 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:51,290 : INFO : PROGRESS: at 69.21% examples, 604965 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:52,304 : INFO : PROGRESS: at 72.63% examples, 604539 words/s, in_qsize 4, out_qsize 1\n",
      "2017-06-02 17:11:53,310 : INFO : PROGRESS: at 76.99% examples, 611657 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:54,311 : INFO : PROGRESS: at 81.59% examples, 620166 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:11:55,313 : INFO : PROGRESS: at 85.87% examples, 625833 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:56,329 : INFO : PROGRESS: at 90.25% examples, 631283 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:57,331 : INFO : PROGRESS: at 94.22% examples, 633835 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:58,345 : INFO : PROGRESS: at 98.40% examples, 637267 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:11:58,674 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:11:58,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:11:58,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:11:58,681 : INFO : training on 23920930 raw words (17640317 effective words) took 27.6s, 639725 effective words/s\n",
      "2017-06-02 17:11:58,681 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:11:58,689 : INFO : saving Word2Vec object under Results/yeast_be_kkas_model, separately None\n",
      "2017-06-02 17:11:58,689 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:11:58,690 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:11:59,046 : INFO : saved Results/yeast_be_kkas_model\n"
     ]
    }
   ],
   "source": [
    "yeast_strict_model = make_w2v_model(yeast_strict, 'yeast_strict_kkas')\n",
    "yeast_gen_model = make_w2v_model(yeast_gen, 'yeast_gen_kkas')\n",
    "yeast_be_model = make_w2v_model(yeast_be, 'yeast_be_kkas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:12:37,960 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:12:37,961 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:12:37,997 : INFO : collected 11431 word types from a corpus of 188505 raw words and 7145 sentences\n",
      "2017-06-02 17:12:37,998 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:12:38,012 : INFO : min_count=5 retains 3346 unique words (29% of original 11431, drops 8085)\n",
      "2017-06-02 17:12:38,013 : INFO : min_count=5 leaves 175425 word corpus (93% of original 188505, drops 13080)\n",
      "2017-06-02 17:12:38,023 : INFO : deleting the raw counts dictionary of 11431 items\n",
      "2017-06-02 17:12:38,024 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2017-06-02 17:12:38,024 : INFO : downsampling leaves estimated 125739 word corpus (71.7% of prior 175425)\n",
      "2017-06-02 17:12:38,025 : INFO : estimated required memory for 3346 words and 100 dimensions: 6357400 bytes\n",
      "2017-06-02 17:12:38,030 : INFO : constructing a huffman tree from 3346 words\n",
      "2017-06-02 17:12:38,103 : INFO : built huffman tree with maximum node depth 15\n",
      "2017-06-02 17:12:38,114 : INFO : resetting layer weights\n",
      "2017-06-02 17:12:38,145 : INFO : training model with 3 workers on 3346 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:12:38,146 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:12:39,160 : INFO : PROGRESS: at 37.13% examples, 230653 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:40,199 : INFO : PROGRESS: at 77.35% examples, 237288 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:40,667 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:12:40,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:12:40,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:12:40,691 : INFO : training on 942525 raw words (628787 effective words) took 2.5s, 247452 effective words/s\n",
      "2017-06-02 17:12:40,692 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:12:40,695 : INFO : saving Word2Vec object under Results/yeast_strict_kkas_model, separately None\n",
      "2017-06-02 17:12:40,696 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:12:40,696 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:12:40,761 : INFO : saved Results/yeast_strict_kkas_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:12:41,268 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:12:41,269 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:12:41,311 : INFO : PROGRESS: at sentence #10000, processed 241924 words, keeping 11195 word types\n",
      "2017-06-02 17:12:41,356 : INFO : PROGRESS: at sentence #20000, processed 485055 words, keeping 14860 word types\n",
      "2017-06-02 17:12:41,401 : INFO : PROGRESS: at sentence #30000, processed 727846 words, keeping 17547 word types\n",
      "2017-06-02 17:12:41,446 : INFO : PROGRESS: at sentence #40000, processed 969967 words, keeping 19750 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:12:41,481 : INFO : collected 21147 word types from a corpus of 1155938 raw words and 47662 sentences\n",
      "2017-06-02 17:12:41,482 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:12:41,510 : INFO : min_count=5 retains 8077 unique words (38% of original 21147, drops 13070)\n",
      "2017-06-02 17:12:41,511 : INFO : min_count=5 leaves 1134115 word corpus (98% of original 1155938, drops 21823)\n",
      "2017-06-02 17:12:41,531 : INFO : deleting the raw counts dictionary of 21147 items\n",
      "2017-06-02 17:12:41,532 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-06-02 17:12:41,533 : INFO : downsampling leaves estimated 829411 word corpus (73.1% of prior 1134115)\n",
      "2017-06-02 17:12:41,533 : INFO : estimated required memory for 8077 words and 100 dimensions: 15346300 bytes\n",
      "2017-06-02 17:12:41,548 : INFO : constructing a huffman tree from 8077 words\n",
      "2017-06-02 17:12:41,732 : INFO : built huffman tree with maximum node depth 18\n",
      "2017-06-02 17:12:41,750 : INFO : resetting layer weights\n",
      "2017-06-02 17:12:41,824 : INFO : training model with 3 workers on 8077 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:12:41,825 : INFO : expecting 47662 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-06-02 17:12:42,836 : INFO : PROGRESS: at 6.06% examples, 249231 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:43,863 : INFO : PROGRESS: at 12.09% examples, 246754 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:44,888 : INFO : PROGRESS: at 18.65% examples, 252979 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:45,911 : INFO : PROGRESS: at 25.24% examples, 256239 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:46,944 : INFO : PROGRESS: at 31.45% examples, 255029 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:48,037 : INFO : PROGRESS: at 38.18% examples, 255118 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:12:49,115 : INFO : PROGRESS: at 42.33% examples, 240933 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:50,123 : INFO : PROGRESS: at 46.15% examples, 230708 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:12:51,128 : INFO : PROGRESS: at 50.11% examples, 223466 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:12:52,136 : INFO : PROGRESS: at 54.79% examples, 220394 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:53,167 : INFO : PROGRESS: at 61.00% examples, 223117 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:54,215 : INFO : PROGRESS: at 66.87% examples, 223938 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:12:55,225 : INFO : PROGRESS: at 72.91% examples, 225765 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:56,245 : INFO : PROGRESS: at 79.30% examples, 228185 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:12:57,269 : INFO : PROGRESS: at 85.72% examples, 230252 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:58,280 : INFO : PROGRESS: at 92.26% examples, 232656 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:59,319 : INFO : PROGRESS: at 98.65% examples, 233960 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:12:59,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:12:59,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:12:59,503 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:12:59,504 : INFO : training on 5779690 raw words (4147842 effective words) took 17.7s, 234667 effective words/s\n",
      "2017-06-02 17:12:59,505 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:12:59,511 : INFO : saving Word2Vec object under Results/yeast_gen_kkas_model, separately None\n",
      "2017-06-02 17:12:59,512 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:12:59,513 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:12:59,691 : INFO : saved Results/yeast_gen_kkas_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:13:02,175 : INFO : collecting all words and their counts\n",
      "2017-06-02 17:13:02,175 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-02 17:13:02,217 : INFO : PROGRESS: at sentence #10000, processed 228368 words, keeping 12408 word types\n",
      "2017-06-02 17:13:02,265 : INFO : PROGRESS: at sentence #20000, processed 455332 words, keeping 16984 word types\n",
      "2017-06-02 17:13:02,313 : INFO : PROGRESS: at sentence #30000, processed 686390 words, keeping 20127 word types\n",
      "2017-06-02 17:13:02,360 : INFO : PROGRESS: at sentence #40000, processed 915781 words, keeping 22805 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 17:13:02,405 : INFO : PROGRESS: at sentence #50000, processed 1145029 words, keeping 25157 word types\n",
      "2017-06-02 17:13:02,454 : INFO : PROGRESS: at sentence #60000, processed 1375391 words, keeping 27216 word types\n",
      "2017-06-02 17:13:02,500 : INFO : PROGRESS: at sentence #70000, processed 1605672 words, keeping 29012 word types\n",
      "2017-06-02 17:13:02,546 : INFO : PROGRESS: at sentence #80000, processed 1834240 words, keeping 30678 word types\n",
      "2017-06-02 17:13:02,587 : INFO : PROGRESS: at sentence #90000, processed 2061794 words, keeping 32258 word types\n",
      "2017-06-02 17:13:02,629 : INFO : PROGRESS: at sentence #100000, processed 2291681 words, keeping 33687 word types\n",
      "2017-06-02 17:13:02,672 : INFO : PROGRESS: at sentence #110000, processed 2521584 words, keeping 35002 word types\n",
      "2017-06-02 17:13:02,713 : INFO : PROGRESS: at sentence #120000, processed 2749912 words, keeping 36257 word types\n",
      "2017-06-02 17:13:02,754 : INFO : PROGRESS: at sentence #130000, processed 2978987 words, keeping 37489 word types\n",
      "2017-06-02 17:13:02,794 : INFO : PROGRESS: at sentence #140000, processed 3207319 words, keeping 38623 word types\n",
      "2017-06-02 17:13:02,841 : INFO : PROGRESS: at sentence #150000, processed 3435305 words, keeping 39690 word types\n",
      "2017-06-02 17:13:02,881 : INFO : PROGRESS: at sentence #160000, processed 3662047 words, keeping 40629 word types\n",
      "2017-06-02 17:13:02,927 : INFO : PROGRESS: at sentence #170000, processed 3891381 words, keeping 41660 word types\n",
      "2017-06-02 17:13:02,971 : INFO : PROGRESS: at sentence #180000, processed 4120204 words, keeping 42610 word types\n",
      "2017-06-02 17:13:03,017 : INFO : PROGRESS: at sentence #190000, processed 4349041 words, keeping 43520 word types\n",
      "2017-06-02 17:13:03,067 : INFO : PROGRESS: at sentence #200000, processed 4579505 words, keeping 44508 word types\n",
      "2017-06-02 17:13:03,108 : INFO : collected 45300 word types from a corpus of 4784186 raw words and 208973 sentences\n",
      "2017-06-02 17:13:03,109 : INFO : Loading a fresh vocabulary\n",
      "2017-06-02 17:13:03,160 : INFO : min_count=5 retains 16820 unique words (37% of original 45300, drops 28480)\n",
      "2017-06-02 17:13:03,161 : INFO : min_count=5 leaves 4736602 word corpus (99% of original 4784186, drops 47584)\n",
      "2017-06-02 17:13:03,202 : INFO : deleting the raw counts dictionary of 45300 items\n",
      "2017-06-02 17:13:03,205 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2017-06-02 17:13:03,206 : INFO : downsampling leaves estimated 3527961 word corpus (74.5% of prior 4736602)\n",
      "2017-06-02 17:13:03,206 : INFO : estimated required memory for 16820 words and 100 dimensions: 31958000 bytes\n",
      "2017-06-02 17:13:03,235 : INFO : constructing a huffman tree from 16820 words\n",
      "2017-06-02 17:13:03,644 : INFO : built huffman tree with maximum node depth 20\n",
      "2017-06-02 17:13:03,687 : INFO : resetting layer weights\n",
      "2017-06-02 17:13:03,838 : INFO : training model with 3 workers on 16820 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2017-06-02 17:13:03,838 : INFO : expecting 208973 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-06-02 17:13:04,848 : INFO : PROGRESS: at 1.26% examples, 220054 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:05,889 : INFO : PROGRESS: at 2.63% examples, 226879 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:06,901 : INFO : PROGRESS: at 3.92% examples, 226412 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:07,928 : INFO : PROGRESS: at 5.25% examples, 227185 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:08,935 : INFO : PROGRESS: at 6.54% examples, 227114 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:09,955 : INFO : PROGRESS: at 7.84% examples, 226543 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:11,022 : INFO : PROGRESS: at 9.26% examples, 227769 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:12,121 : INFO : PROGRESS: at 10.76% examples, 229491 words/s, in_qsize 6, out_qsize 1\n",
      "2017-06-02 17:13:13,137 : INFO : PROGRESS: at 11.63% examples, 221030 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:14,236 : INFO : PROGRESS: at 12.51% examples, 212553 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:15,309 : INFO : PROGRESS: at 13.39% examples, 206160 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:16,316 : INFO : PROGRESS: at 14.36% examples, 203097 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:17,332 : INFO : PROGRESS: at 15.58% examples, 203629 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:18,370 : INFO : PROGRESS: at 16.78% examples, 203794 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:19,441 : INFO : PROGRESS: at 18.04% examples, 203965 words/s, in_qsize 4, out_qsize 1\n",
      "2017-06-02 17:13:20,442 : INFO : PROGRESS: at 18.99% examples, 201874 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:21,472 : INFO : PROGRESS: at 19.87% examples, 198832 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:22,477 : INFO : PROGRESS: at 20.71% examples, 196004 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:23,515 : INFO : PROGRESS: at 21.51% examples, 192788 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:24,549 : INFO : PROGRESS: at 22.55% examples, 192066 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:25,557 : INFO : PROGRESS: at 23.76% examples, 192980 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:26,591 : INFO : PROGRESS: at 24.88% examples, 192938 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:27,599 : INFO : PROGRESS: at 26.00% examples, 193144 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:28,637 : INFO : PROGRESS: at 26.91% examples, 191595 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:29,641 : INFO : PROGRESS: at 27.67% examples, 189270 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:30,645 : INFO : PROGRESS: at 28.46% examples, 187406 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:31,671 : INFO : PROGRESS: at 29.30% examples, 185794 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:32,706 : INFO : PROGRESS: at 30.55% examples, 186774 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:33,750 : INFO : PROGRESS: at 31.88% examples, 188131 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:34,763 : INFO : PROGRESS: at 33.10% examples, 188878 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:35,778 : INFO : PROGRESS: at 34.31% examples, 189562 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:36,812 : INFO : PROGRESS: at 35.78% examples, 191434 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:37,834 : INFO : PROGRESS: at 37.16% examples, 192835 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:38,854 : INFO : PROGRESS: at 38.62% examples, 194578 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:39,877 : INFO : PROGRESS: at 40.04% examples, 196006 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:40,886 : INFO : PROGRESS: at 41.34% examples, 196834 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:41,915 : INFO : PROGRESS: at 42.59% examples, 197319 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:42,960 : INFO : PROGRESS: at 43.88% examples, 197888 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:43,969 : INFO : PROGRESS: at 45.09% examples, 198227 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:45,020 : INFO : PROGRESS: at 45.75% examples, 196028 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:46,135 : INFO : PROGRESS: at 46.50% examples, 193997 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:47,174 : INFO : PROGRESS: at 47.25% examples, 192410 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:48,198 : INFO : PROGRESS: at 48.25% examples, 191955 words/s, in_qsize 6, out_qsize 1\n",
      "2017-06-02 17:13:49,216 : INFO : PROGRESS: at 49.75% examples, 193491 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:50,235 : INFO : PROGRESS: at 51.26% examples, 194945 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:51,257 : INFO : PROGRESS: at 52.76% examples, 196333 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:52,272 : INFO : PROGRESS: at 54.27% examples, 197680 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:53,296 : INFO : PROGRESS: at 55.78% examples, 198951 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:54,328 : INFO : PROGRESS: at 57.28% examples, 200140 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:13:55,377 : INFO : PROGRESS: at 58.74% examples, 201064 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:56,401 : INFO : PROGRESS: at 59.87% examples, 200925 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:57,444 : INFO : PROGRESS: at 60.75% examples, 199904 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:58,473 : INFO : PROGRESS: at 61.63% examples, 198973 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:13:59,518 : INFO : PROGRESS: at 62.50% examples, 198020 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:00,540 : INFO : PROGRESS: at 63.67% examples, 198090 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:01,573 : INFO : PROGRESS: at 64.96% examples, 198495 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:02,602 : INFO : PROGRESS: at 66.08% examples, 198403 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:03,607 : INFO : PROGRESS: at 67.16% examples, 198269 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:04,608 : INFO : PROGRESS: at 68.00% examples, 197429 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:05,635 : INFO : PROGRESS: at 68.88% examples, 196649 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:06,712 : INFO : PROGRESS: at 69.71% examples, 195627 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:07,716 : INFO : PROGRESS: at 70.59% examples, 194971 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:08,750 : INFO : PROGRESS: at 71.79% examples, 195160 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:09,764 : INFO : PROGRESS: at 73.05% examples, 195507 words/s, in_qsize 4, out_qsize 1\n",
      "2017-06-02 17:14:10,774 : INFO : PROGRESS: at 74.31% examples, 195851 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:11,822 : INFO : PROGRESS: at 75.69% examples, 196405 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:12,852 : INFO : PROGRESS: at 76.57% examples, 195714 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:13,901 : INFO : PROGRESS: at 77.45% examples, 194996 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:14,921 : INFO : PROGRESS: at 78.32% examples, 194374 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:15,930 : INFO : PROGRESS: at 79.28% examples, 193998 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:16,931 : INFO : PROGRESS: at 80.45% examples, 194161 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:17,953 : INFO : PROGRESS: at 81.71% examples, 194467 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:18,962 : INFO : PROGRESS: at 82.96% examples, 194800 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:19,981 : INFO : PROGRESS: at 84.21% examples, 195088 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:21,025 : INFO : PROGRESS: at 85.08% examples, 194453 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:22,068 : INFO : PROGRESS: at 85.96% examples, 193840 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:23,081 : INFO : PROGRESS: at 86.78% examples, 193221 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:24,098 : INFO : PROGRESS: at 87.74% examples, 192883 words/s, in_qsize 4, out_qsize 1\n",
      "2017-06-02 17:14:25,105 : INFO : PROGRESS: at 88.84% examples, 192850 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:26,137 : INFO : PROGRESS: at 89.95% examples, 192848 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:27,144 : INFO : PROGRESS: at 91.29% examples, 193342 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:28,149 : INFO : PROGRESS: at 92.67% examples, 193921 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-02 17:14:29,167 : INFO : PROGRESS: at 94.10% examples, 194534 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:30,178 : INFO : PROGRESS: at 95.61% examples, 195329 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:31,211 : INFO : PROGRESS: at 97.11% examples, 196053 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:32,219 : INFO : PROGRESS: at 98.48% examples, 196566 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-02 17:14:33,289 : INFO : PROGRESS: at 99.86% examples, 196930 words/s, in_qsize 4, out_qsize 0\n",
      "2017-06-02 17:14:33,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-02 17:14:33,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-02 17:14:33,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-02 17:14:33,386 : INFO : training on 23920930 raw words (17638523 effective words) took 89.5s, 196986 effective words/s\n",
      "2017-06-02 17:14:33,387 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-02 17:14:33,395 : INFO : saving Word2Vec object under Results/yeast_be_kkas_model, separately None\n",
      "2017-06-02 17:14:33,396 : INFO : not storing attribute syn0norm\n",
      "2017-06-02 17:14:33,396 : INFO : not storing attribute cum_table\n",
      "2017-06-02 17:14:33,830 : INFO : saved Results/yeast_be_kkas_model\n"
     ]
    }
   ],
   "source": [
    "yeast_strict_model = make_w2v_model(yeast_strict, 'yeast_strict_kkas')\n",
    "yeast_gen_model = make_w2v_model(yeast_gen, 'yeast_gen_kkas')\n",
    "yeast_be_model = make_w2v_model(yeast_be, 'yeast_be_kkas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def XGB_classifier(train_vector, test_vector,\n",
    "                   labels_train, labels_test,\n",
    "                   feature_selection=False):\n",
    "    \"\"\"Perform XGB Classification\"\"\"\n",
    "    if feature_selection:\n",
    "        clf = ExtraTreesClassifier(n_estimators=100)\n",
    "        clf = clf.fit(train_vector, labels_train)\n",
    "        model = SelectFromModel(clf, prefit=True)\n",
    "        train_vector = model.transform(train_vector)\n",
    "        test_vector = model.transform(test_vector)\n",
    "\n",
    "    xgb_clf = XGBClassifier(seed=24)\n",
    "    print (\"\\n Fitting XGBoost Model!\")\n",
    "    xgb_clf = xgb_clf.fit(train_vector, labels_train)\n",
    "    print (\"\\n Making Predictions\")\n",
    "    result = xgb_clf.predict(test_vector)\n",
    "    probs = xgb_clf.predict_proba(test_vector)[:, 1]\n",
    "    predictions = [round(val) for val in result]\n",
    "    error = get_accuracy(predictions, labels_test)\n",
    "    return result, error, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(l_new, l_te):\n",
    "    \"\"\"Calculates the accuracy of predicted labels, based on the given labels\n",
    "\n",
    "    INPUT: New(Predicted) Labels, Test Labels\n",
    "\n",
    "    OUTPUT: Error  \"\"\"\n",
    "\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(len(l_te)):\n",
    "        if l_new[i] == l_te[i]:\n",
    "            acc += 1\n",
    "\n",
    "    acc = float(acc / len(l_te))\n",
    "\n",
    "    return 1-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train_vecs, train_labels, test_vecs, test_labels, w2v_model_type, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param=alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_vecs, \n",
    "                              label=train_labels)\n",
    "        cvresult = xgb.cv(xgb_param, \n",
    "                          xgtrain, \n",
    "                          num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds, \n",
    "                          metrics='auc', \n",
    "                          early_stopping_rounds=50)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        \n",
    "    #fit the algorithm on the data\n",
    "    alg.fit(train_vecs, train_labels, eval_metric='auc')\n",
    "    \n",
    "    #Predict training set:\n",
    "    test_predictions = alg.predict(test_vecs)\n",
    "    test_predprob = alg.predict_proba(test_vecs)[:,1]\n",
    "    \n",
    "    #Metrics\n",
    "    accuracy = metrics.accuracy_score(test_labels, test_predictions)\n",
    "    roc_auc = metrics.roc_auc_score(test_labels, test_predprob)\n",
    "    class_report = metrics.classification_report(test_labels, test_predictions)\n",
    "    \n",
    "    #Print Model report:\n",
    "    print(w2v_model_type, '\\nModel Report')\n",
    "    print(w2v_model_type, 'Accuracy: %.4g' % accuracy)\n",
    "    print(w2v_model_type, 'AUC Score (Train): %f' % roc_auc)\n",
    "    print(w2v_model_type, 'Report \\n', class_report)\n",
    "    \n",
    "    \n",
    "#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "\n",
    "    return accuracy, roc_auc, test_predictions, test_predprob, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 144 \n",
      "Model Report\n",
      "SR 144 Accuracy: 0.5256\n",
      "SR 144 AUC Score (Train): 0.544850\n",
      "SR 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.83      0.61        35\n",
      "          1       0.67      0.28      0.39        43\n",
      "\n",
      "avg / total       0.58      0.53      0.49        78\n",
      "\n",
      "GEN 144 \n",
      "Model Report\n",
      "GEN 144 Accuracy: 0.5897\n",
      "GEN 144 AUC Score (Train): 0.654485\n",
      "GEN 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.86      0.65        35\n",
      "          1       0.76      0.37      0.50        43\n",
      "\n",
      "avg / total       0.66      0.59      0.57        78\n",
      "\n",
      "BE 144 \n",
      "Model Report\n",
      "BE 144 Accuracy: 0.5769\n",
      "BE 144 AUC Score (Train): 0.714286\n",
      "BE 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.86      0.65        35\n",
      "          1       0.75      0.35      0.48        43\n",
      "\n",
      "avg / total       0.65      0.58      0.55        78\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 235 \n",
      "Model Report\n",
      "SR 235 Accuracy: 0.7021\n",
      "SR 235 AUC Score (Train): 0.611111\n",
      "SR 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.78      0.80        36\n",
      "          1       0.38      0.45      0.42        11\n",
      "\n",
      "avg / total       0.72      0.70      0.71        47\n",
      "\n",
      "GEN 235 \n",
      "Model Report\n",
      "GEN 235 Accuracy: 0.766\n",
      "GEN 235 AUC Score (Train): 0.752525\n",
      "GEN 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.83      0.85        36\n",
      "          1       0.50      0.55      0.52        11\n",
      "\n",
      "avg / total       0.77      0.77      0.77        47\n",
      "\n",
      "BE 235 \n",
      "Model Report\n",
      "BE 235 Accuracy: 0.766\n",
      "BE 235 AUC Score (Train): 0.775253\n",
      "BE 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.81      0.84        36\n",
      "          1       0.50      0.64      0.56        11\n",
      "\n",
      "avg / total       0.79      0.77      0.77        47\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 905 \n",
      "Model Report\n",
      "SR 905 Accuracy: 0.4433\n",
      "SR 905 AUC Score (Train): 0.535064\n",
      "SR 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.75      0.50        36\n",
      "          1       0.64      0.26      0.37        61\n",
      "\n",
      "avg / total       0.54      0.44      0.42        97\n",
      "\n",
      "GEN 905 \n",
      "Model Report\n",
      "GEN 905 Accuracy: 0.6495\n",
      "GEN 905 AUC Score (Train): 0.688980\n",
      "GEN 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.81      0.63        36\n",
      "          1       0.83      0.56      0.67        61\n",
      "\n",
      "avg / total       0.71      0.65      0.65        97\n",
      "\n",
      "BE 905 \n",
      "Model Report\n",
      "BE 905 Accuracy: 0.6701\n",
      "BE 905 AUC Score (Train): 0.733607\n",
      "BE 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.69      0.61        36\n",
      "          1       0.78      0.66      0.71        61\n",
      "\n",
      "avg / total       0.69      0.67      0.68        97\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 2895 \n",
      "Model Report\n",
      "SR 2895 Accuracy: 0.7143\n",
      "SR 2895 AUC Score (Train): 0.700000\n",
      "SR 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80        30\n",
      "          1       0.50      0.50      0.50        12\n",
      "\n",
      "avg / total       0.71      0.71      0.71        42\n",
      "\n",
      "GEN 2895 \n",
      "Model Report\n",
      "GEN 2895 Accuracy: 0.7381\n",
      "GEN 2895 AUC Score (Train): 0.744444\n",
      "GEN 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.83      0.82        30\n",
      "          1       0.55      0.50      0.52        12\n",
      "\n",
      "avg / total       0.73      0.74      0.73        42\n",
      "\n",
      "BE 2895 \n",
      "Model Report\n",
      "BE 2895 Accuracy: 0.7143\n",
      "BE 2895 AUC Score (Train): 0.727778\n",
      "BE 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.83      0.81        30\n",
      "          1       0.50      0.42      0.45        12\n",
      "\n",
      "avg / total       0.70      0.71      0.71        42\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 3462 \n",
      "Model Report\n",
      "SR 3462 Accuracy: 0.5395\n",
      "SR 3462 AUC Score (Train): 0.588521\n",
      "SR 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.81      0.65        79\n",
      "          1       0.55      0.25      0.34        73\n",
      "\n",
      "avg / total       0.54      0.54      0.50       152\n",
      "\n",
      "GEN 3462 \n",
      "Model Report\n",
      "GEN 3462 Accuracy: 0.6382\n",
      "GEN 3462 AUC Score (Train): 0.685799\n",
      "GEN 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66        79\n",
      "          1       0.63      0.59      0.61        73\n",
      "\n",
      "avg / total       0.64      0.64      0.64       152\n",
      "\n",
      "BE 3462 \n",
      "Model Report\n",
      "BE 3462 Accuracy: 0.5855\n",
      "BE 3462 AUC Score (Train): 0.652159\n",
      "BE 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.57      0.59        79\n",
      "          1       0.56      0.60      0.58        73\n",
      "\n",
      "avg / total       0.59      0.59      0.59       152\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 4225 \n",
      "Model Report\n",
      "SR 4225 Accuracy: 0.5068\n",
      "SR 4225 AUC Score (Train): 0.623824\n",
      "SR 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.86      0.58        29\n",
      "          1       0.75      0.27      0.40        44\n",
      "\n",
      "avg / total       0.63      0.51      0.47        73\n",
      "\n",
      "GEN 4225 \n",
      "Model Report\n",
      "GEN 4225 Accuracy: 0.6712\n",
      "GEN 4225 AUC Score (Train): 0.800157\n",
      "GEN 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.93      0.69        29\n",
      "          1       0.92      0.50      0.65        44\n",
      "\n",
      "avg / total       0.77      0.67      0.67        73\n",
      "\n",
      "BE 4225 \n",
      "Model Report\n",
      "BE 4225 Accuracy: 0.6027\n",
      "BE 4225 AUC Score (Train): 0.795455\n",
      "BE 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.86      0.63        29\n",
      "          1       0.83      0.43      0.57        44\n",
      "\n",
      "avg / total       0.70      0.60      0.59        73\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 5056 \n",
      "Model Report\n",
      "SR 5056 Accuracy: 0.6792\n",
      "SR 5056 AUC Score (Train): 0.635815\n",
      "SR 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.89      0.79        71\n",
      "          1       0.53      0.26      0.35        35\n",
      "\n",
      "avg / total       0.65      0.68      0.64       106\n",
      "\n",
      "GEN 5056 \n",
      "Model Report\n",
      "GEN 5056 Accuracy: 0.7736\n",
      "GEN 5056 AUC Score (Train): 0.783903\n",
      "GEN 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.90      0.84        71\n",
      "          1       0.72      0.51      0.60        35\n",
      "\n",
      "avg / total       0.77      0.77      0.76       106\n",
      "\n",
      "BE 5056 \n",
      "Model Report\n",
      "BE 5056 Accuracy: 0.7925\n",
      "BE 5056 AUC Score (Train): 0.814487\n",
      "BE 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.87      0.85        71\n",
      "          1       0.71      0.63      0.67        35\n",
      "\n",
      "avg / total       0.79      0.79      0.79       106\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 5192 \n",
      "Model Report\n",
      "SR 5192 Accuracy: 0.4783\n",
      "SR 5192 AUC Score (Train): 0.621331\n",
      "SR 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.93      0.57        42\n",
      "          1       0.84      0.22      0.35        73\n",
      "\n",
      "avg / total       0.68      0.48      0.43       115\n",
      "\n",
      "GEN 5192 \n",
      "Model Report\n",
      "GEN 5192 Accuracy: 0.5478\n",
      "GEN 5192 AUC Score (Train): 0.641226\n",
      "GEN 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.64      0.51        42\n",
      "          1       0.71      0.49      0.58        73\n",
      "\n",
      "avg / total       0.60      0.55      0.55       115\n",
      "\n",
      "BE 5192 \n",
      "Model Report\n",
      "BE 5192 Accuracy: 0.513\n",
      "BE 5192 AUC Score (Train): 0.611872\n",
      "BE 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.55      0.45        42\n",
      "          1       0.65      0.49      0.56        73\n",
      "\n",
      "avg / total       0.56      0.51      0.52       115\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 7751 \n",
      "Model Report\n",
      "SR 7751 Accuracy: 0.5909\n",
      "SR 7751 AUC Score (Train): 0.513684\n",
      "SR 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.80      0.69        25\n",
      "          1       0.55      0.32      0.40        19\n",
      "\n",
      "avg / total       0.58      0.59      0.56        44\n",
      "\n",
      "GEN 7751 \n",
      "Model Report\n",
      "GEN 7751 Accuracy: 0.4773\n",
      "GEN 7751 AUC Score (Train): 0.570526\n",
      "GEN 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.68      0.60        25\n",
      "          1       0.33      0.21      0.26        19\n",
      "\n",
      "avg / total       0.45      0.48      0.45        44\n",
      "\n",
      "BE 7751 \n",
      "Model Report\n",
      "BE 7751 Accuracy: 0.5909\n",
      "BE 7751 AUC Score (Train): 0.625263\n",
      "BE 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.68      0.65        25\n",
      "          1       0.53      0.47      0.50        19\n",
      "\n",
      "avg / total       0.59      0.59      0.59        44\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 7813 \n",
      "Model Report\n",
      "SR 7813 Accuracy: 0.5047\n",
      "SR 7813 AUC Score (Train): 0.576278\n",
      "SR 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.76      0.52        38\n",
      "          1       0.74      0.36      0.49        69\n",
      "\n",
      "avg / total       0.62      0.50      0.50       107\n",
      "\n",
      "GEN 7813 \n",
      "Model Report\n",
      "GEN 7813 Accuracy: 0.5701\n",
      "GEN 7813 AUC Score (Train): 0.670862\n",
      "GEN 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.84      0.58        38\n",
      "          1       0.83      0.42      0.56        69\n",
      "\n",
      "avg / total       0.69      0.57      0.57       107\n",
      "\n",
      "BE 7813 \n",
      "Model Report\n",
      "BE 7813 Accuracy: 0.6075\n",
      "BE 7813 AUC Score (Train): 0.674676\n",
      "BE 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.87      0.61        38\n",
      "          1       0.86      0.46      0.60        69\n",
      "\n",
      "avg / total       0.73      0.61      0.61       107\n",
      "\n",
      "Took  681.4933595657349  seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "name_of_result = 'yeast_OLD'\n",
    "strict_data = yeast_strict\n",
    "w2v_strict = yeast_strict_model\n",
    "w2v_gen = yeast_gen_model\n",
    "w2v_be = yeast_be_model\n",
    "xgb_clf = XGBClassifier(seed=24)\n",
    "start = time.time()\n",
    "for seed in random_seeds:\n",
    "        strict_list_SR = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_SR_'+str(seed),\n",
    "                                          prev_model=w2v_strict,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_list_GEN = pred.make_models(strict_data,\n",
    "                                           name_of_result+'_GEN_'+str(seed),\n",
    "                                           prev_model=w2v_gen,\n",
    "                                           ran_state=seed)\n",
    "        strict_list_BE = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_BE_'+str(seed),\n",
    "                                          prev_model=w2v_be,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_final_list = [strict_list_SR,\n",
    "                             strict_list_GEN,\n",
    "                             strict_list_BE]\n",
    "\n",
    "        print ('\\nPredicting\\n')\n",
    "        accuracy = []\n",
    "        probs = []\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        labels = []\n",
    "        auc_score = []\n",
    "        report = []\n",
    "\n",
    "        for entry, model_name in zip(strict_final_list, ['SR '+str(seed), 'GEN '+str(seed), 'BE '+str(seed)]):\n",
    "            accuracy_norm, auc_score_norm, pred_labels_norm, probs_norm, class_report_norm  = modelfit(xgb_clf, \n",
    "                                                                                                       entry[0], \n",
    "                                                                                                       entry[2], \n",
    "                                                                                                       entry[1], \n",
    "                                                                                                       entry[3], \n",
    "                                                                                                       model_name)\n",
    "            fpr_norm, tpr_norm, _ = roc_curve(entry[3], probs_norm)\n",
    "\n",
    "            accuracy.append([accuracy_norm])\n",
    "            probs.append([probs_norm])\n",
    "            fpr.append([fpr_norm])\n",
    "            tpr.append([tpr_norm])\n",
    "            labels.append([pred_labels_norm])\n",
    "            auc_score.append([auc_score_norm])\n",
    "            report.append([class_report_norm])\n",
    "\n",
    "        pickle.dump(accuracy, open('Results/'+name_of_result+'_accuracy_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(probs, open('Results/'+name_of_result+'_probs_pickle_'+str(seed)+'.pkl',\n",
    "                                'wb'))\n",
    "        pickle.dump(fpr, open('Results/'+name_of_result+'_fpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(tpr, open('Results/'+name_of_result+'_tpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(labels, open('Results/'+name_of_result+'_labels_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(auc_score, open('Results/'+name_of_result+'_auc_score_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(report, open('Results/'+name_of_result+'_report_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        \n",
    "print('Took ', time.time()-start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 13:33:46,449 : INFO : loading Word2Vec object from ../../Results/Yeast/models/yeast_strict_w2v_model\n",
      "2017-06-02 13:33:46,585 : INFO : loading wv recursively from ../../Results/Yeast/models/yeast_strict_w2v_model.wv.* with mmap=None\n",
      "2017-06-02 13:33:46,585 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-02 13:33:46,586 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-02 13:33:46,587 : INFO : loaded ../../Results/Yeast/models/yeast_strict_w2v_model\n",
      "2017-06-02 13:33:46,592 : INFO : loading Word2Vec object from ../../Results/Yeast/models/yeast_gen_w2v_model\n",
      "2017-06-02 13:33:46,937 : INFO : loading wv recursively from ../../Results/Yeast/models/yeast_gen_w2v_model.wv.* with mmap=None\n",
      "2017-06-02 13:33:46,938 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-02 13:33:46,939 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-02 13:33:46,939 : INFO : loaded ../../Results/Yeast/models/yeast_gen_w2v_model\n",
      "2017-06-02 13:33:46,952 : INFO : loading Word2Vec object from ../../Results/Yeast/models/yeast_be_w2v_model\n",
      "2017-06-02 13:33:47,712 : INFO : loading wv recursively from ../../Results/Yeast/models/yeast_be_w2v_model.wv.* with mmap=None\n",
      "2017-06-02 13:33:47,713 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-02 13:33:47,714 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-02 13:33:47,714 : INFO : loaded ../../Results/Yeast/models/yeast_be_w2v_model\n",
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 144 \n",
      "Model Report\n",
      "SR 144 Accuracy: 0.6094\n",
      "SR 144 AUC Score (Train): 0.637638\n",
      "SR 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.73      0.68        37\n",
      "          1       0.55      0.44      0.49        27\n",
      "\n",
      "avg / total       0.60      0.61      0.60        64\n",
      "\n",
      "GEN 144 \n",
      "Model Report\n",
      "GEN 144 Accuracy: 0.6719\n",
      "GEN 144 AUC Score (Train): 0.684685\n",
      "GEN 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.89      0.76        37\n",
      "          1       0.71      0.37      0.49        27\n",
      "\n",
      "avg / total       0.68      0.67      0.64        64\n",
      "\n",
      "BE 144 \n",
      "Model Report\n",
      "BE 144 Accuracy: 0.6562\n",
      "BE 144 AUC Score (Train): 0.727728\n",
      "BE 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.89      0.75        37\n",
      "          1       0.69      0.33      0.45        27\n",
      "\n",
      "avg / total       0.67      0.66      0.62        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 235 \n",
      "Model Report\n",
      "SR 235 Accuracy: 0.7101\n",
      "SR 235 AUC Score (Train): 0.735993\n",
      "SR 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.79      0.75        38\n",
      "          1       0.70      0.61      0.66        31\n",
      "\n",
      "avg / total       0.71      0.71      0.71        69\n",
      "\n",
      "GEN 235 \n",
      "Model Report\n",
      "GEN 235 Accuracy: 0.6957\n",
      "GEN 235 AUC Score (Train): 0.723260\n",
      "GEN 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.76      0.73        38\n",
      "          1       0.68      0.61      0.64        31\n",
      "\n",
      "avg / total       0.69      0.70      0.69        69\n",
      "\n",
      "BE 235 \n",
      "Model Report\n",
      "BE 235 Accuracy: 0.6812\n",
      "BE 235 AUC Score (Train): 0.721562\n",
      "BE 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.76      0.72        38\n",
      "          1       0.67      0.58      0.62        31\n",
      "\n",
      "avg / total       0.68      0.68      0.68        69\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 905 \n",
      "Model Report\n",
      "SR 905 Accuracy: 0.625\n",
      "SR 905 AUC Score (Train): 0.727273\n",
      "SR 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.60      0.73        53\n",
      "          1       0.28      0.73      0.40        11\n",
      "\n",
      "avg / total       0.80      0.62      0.67        64\n",
      "\n",
      "GEN 905 \n",
      "Model Report\n",
      "GEN 905 Accuracy: 0.5312\n",
      "GEN 905 AUC Score (Train): 0.694683\n",
      "GEN 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.49      0.63        53\n",
      "          1       0.23      0.73      0.35        11\n",
      "\n",
      "avg / total       0.78      0.53      0.58        64\n",
      "\n",
      "BE 905 \n",
      "Model Report\n",
      "BE 905 Accuracy: 0.5625\n",
      "BE 905 AUC Score (Train): 0.727273\n",
      "BE 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.53      0.67        53\n",
      "          1       0.24      0.73      0.36        11\n",
      "\n",
      "avg / total       0.79      0.56      0.61        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 2895 \n",
      "Model Report\n",
      "SR 2895 Accuracy: 0.6739\n",
      "SR 2895 AUC Score (Train): 0.760096\n",
      "SR 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.77      0.73        52\n",
      "          1       0.65      0.55      0.59        40\n",
      "\n",
      "avg / total       0.67      0.67      0.67        92\n",
      "\n",
      "GEN 2895 \n",
      "Model Report\n",
      "GEN 2895 Accuracy: 0.6957\n",
      "GEN 2895 AUC Score (Train): 0.724519\n",
      "GEN 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.83      0.75        52\n",
      "          1       0.70      0.53      0.60        40\n",
      "\n",
      "avg / total       0.70      0.70      0.69        92\n",
      "\n",
      "BE 2895 \n",
      "Model Report\n",
      "BE 2895 Accuracy: 0.6522\n",
      "BE 2895 AUC Score (Train): 0.716827\n",
      "BE 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.87      0.74        52\n",
      "          1       0.68      0.38      0.48        40\n",
      "\n",
      "avg / total       0.66      0.65      0.63        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 3462 \n",
      "Model Report\n",
      "SR 3462 Accuracy: 0.6753\n",
      "SR 3462 AUC Score (Train): 0.729420\n",
      "SR 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.67      0.68        39\n",
      "          1       0.67      0.68      0.68        38\n",
      "\n",
      "avg / total       0.68      0.68      0.68        77\n",
      "\n",
      "GEN 3462 \n",
      "Model Report\n",
      "GEN 3462 Accuracy: 0.7143\n",
      "GEN 3462 AUC Score (Train): 0.731444\n",
      "GEN 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72        39\n",
      "          1       0.71      0.71      0.71        38\n",
      "\n",
      "avg / total       0.71      0.71      0.71        77\n",
      "\n",
      "BE 3462 \n",
      "Model Report\n",
      "BE 3462 Accuracy: 0.7013\n",
      "BE 3462 AUC Score (Train): 0.767881\n",
      "BE 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.67      0.69        39\n",
      "          1       0.68      0.74      0.71        38\n",
      "\n",
      "avg / total       0.70      0.70      0.70        77\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 4225 \n",
      "Model Report\n",
      "SR 4225 Accuracy: 0.5814\n",
      "SR 4225 AUC Score (Train): 0.673643\n",
      "SR 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.67      0.66        52\n",
      "          1       0.47      0.44      0.45        34\n",
      "\n",
      "avg / total       0.58      0.58      0.58        86\n",
      "\n",
      "GEN 4225 \n",
      "Model Report\n",
      "GEN 4225 Accuracy: 0.593\n",
      "GEN 4225 AUC Score (Train): 0.665158\n",
      "GEN 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.73      0.68        52\n",
      "          1       0.48      0.38      0.43        34\n",
      "\n",
      "avg / total       0.58      0.59      0.58        86\n",
      "\n",
      "BE 4225 \n",
      "Model Report\n",
      "BE 4225 Accuracy: 0.6744\n",
      "BE 4225 AUC Score (Train): 0.696267\n",
      "BE 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.85      0.76        52\n",
      "          1       0.64      0.41      0.50        34\n",
      "\n",
      "avg / total       0.67      0.67      0.66        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 5056 \n",
      "Model Report\n",
      "SR 5056 Accuracy: 0.8235\n",
      "SR 5056 AUC Score (Train): 0.867424\n",
      "SR 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        22\n",
      "          1       0.71      0.83      0.77        12\n",
      "\n",
      "avg / total       0.83      0.82      0.83        34\n",
      "\n",
      "GEN 5056 \n",
      "Model Report\n",
      "GEN 5056 Accuracy: 0.7353\n",
      "GEN 5056 AUC Score (Train): 0.829545\n",
      "GEN 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.73      0.78        22\n",
      "          1       0.60      0.75      0.67        12\n",
      "\n",
      "avg / total       0.76      0.74      0.74        34\n",
      "\n",
      "BE 5056 \n",
      "Model Report\n",
      "BE 5056 Accuracy: 0.7941\n",
      "BE 5056 AUC Score (Train): 0.818182\n",
      "BE 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.77      0.83        22\n",
      "          1       0.67      0.83      0.74        12\n",
      "\n",
      "avg / total       0.81      0.79      0.80        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 5192 \n",
      "Model Report\n",
      "SR 5192 Accuracy: 0.6582\n",
      "SR 5192 AUC Score (Train): 0.759973\n",
      "SR 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.84      0.67        32\n",
      "          1       0.83      0.53      0.65        47\n",
      "\n",
      "avg / total       0.72      0.66      0.66        79\n",
      "\n",
      "GEN 5192 \n",
      "Model Report\n",
      "GEN 5192 Accuracy: 0.6456\n",
      "GEN 5192 AUC Score (Train): 0.767287\n",
      "GEN 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.78      0.64        32\n",
      "          1       0.79      0.55      0.65        47\n",
      "\n",
      "avg / total       0.69      0.65      0.65        79\n",
      "\n",
      "BE 5192 \n",
      "Model Report\n",
      "BE 5192 Accuracy: 0.6709\n",
      "BE 5192 AUC Score (Train): 0.754654\n",
      "BE 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.88      0.68        32\n",
      "          1       0.86      0.53      0.66        47\n",
      "\n",
      "avg / total       0.74      0.67      0.67        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 7751 \n",
      "Model Report\n",
      "SR 7751 Accuracy: 0.6\n",
      "SR 7751 AUC Score (Train): 0.605600\n",
      "SR 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.56      0.65        50\n",
      "          1       0.44      0.68      0.53        25\n",
      "\n",
      "avg / total       0.66      0.60      0.61        75\n",
      "\n",
      "GEN 7751 \n",
      "Model Report\n",
      "GEN 7751 Accuracy: 0.56\n",
      "GEN 7751 AUC Score (Train): 0.694400\n",
      "GEN 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.50      0.60        50\n",
      "          1       0.40      0.68      0.51        25\n",
      "\n",
      "avg / total       0.64      0.56      0.57        75\n",
      "\n",
      "BE 7751 \n",
      "Model Report\n",
      "BE 7751 Accuracy: 0.6267\n",
      "BE 7751 AUC Score (Train): 0.685600\n",
      "BE 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.58      0.67        50\n",
      "          1       0.46      0.72      0.56        25\n",
      "\n",
      "avg / total       0.69      0.63      0.64        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 7813 \n",
      "Model Report\n",
      "SR 7813 Accuracy: 0.6234\n",
      "SR 7813 AUC Score (Train): 0.688098\n",
      "SR 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.65      0.60        34\n",
      "          1       0.68      0.60      0.64        43\n",
      "\n",
      "avg / total       0.63      0.62      0.62        77\n",
      "\n",
      "GEN 7813 \n",
      "Model Report\n",
      "GEN 7813 Accuracy: 0.7273\n",
      "GEN 7813 AUC Score (Train): 0.756498\n",
      "GEN 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.76      0.71        34\n",
      "          1       0.79      0.70      0.74        43\n",
      "\n",
      "avg / total       0.74      0.73      0.73        77\n",
      "\n",
      "BE 7813 \n",
      "Model Report\n",
      "BE 7813 Accuracy: 0.6883\n",
      "BE 7813 AUC Score (Train): 0.720246\n",
      "BE 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.59      0.62        34\n",
      "          1       0.70      0.77      0.73        43\n",
      "\n",
      "avg / total       0.69      0.69      0.69        77\n",
      "\n",
      "Took  1404.1214997768402  seconds\n"
     ]
    }
   ],
   "source": [
    "name_of_result = 'yeast_NEW'\n",
    "strict_data = yeast_strict\n",
    "w2v_strict = word2vec.Word2Vec.load('../../Results/Yeast/models/yeast_strict_w2v_model')\n",
    "w2v_gen = word2vec.Word2Vec.load('../../Results/Yeast/models/yeast_gen_w2v_model')\n",
    "w2v_be = word2vec.Word2Vec.load('../../Results/Yeast/models/yeast_be_w2v_model')\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1,\n",
    "                        n_estimators=1000,\n",
    "                        max_depth=6,\n",
    "                        min_child_weight=1,\n",
    "                        gamma=0.2,\n",
    "                        subsample=0.6,\n",
    "                        colsample_bytree=0.8,\n",
    "                        reg_alpha=0.01,\n",
    "                        objective='binary:logistic',\n",
    "                        scale_pos_weight=1,\n",
    "                        seed=24)\n",
    "start = time.time()\n",
    "for seed in random_seeds:\n",
    "        strict_list_SR = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_SR_'+str(seed),\n",
    "                                          prev_model=w2v_strict,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_list_GEN = pred.make_models(strict_data,\n",
    "                                           name_of_result+'_GEN_'+str(seed),\n",
    "                                           prev_model=w2v_gen,\n",
    "                                           ran_state=seed)\n",
    "        strict_list_BE = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_BE_'+str(seed),\n",
    "                                          prev_model=w2v_be,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_final_list = [strict_list_SR,\n",
    "                             strict_list_GEN,\n",
    "                             strict_list_BE]\n",
    "\n",
    "        print ('\\nPredicting\\n')\n",
    "        accuracy = []\n",
    "        probs = []\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        labels = []\n",
    "        auc_score = []\n",
    "        report = []\n",
    "\n",
    "        for entry, model_name in zip(strict_final_list, ['SR '+str(seed), 'GEN '+str(seed), 'BE '+str(seed)]):\n",
    "            accuracy_norm, auc_score_norm, pred_labels_norm, probs_norm, class_report_norm  = modelfit(xgb_clf, \n",
    "                                                                                                       entry[0], \n",
    "                                                                                                       entry[2], \n",
    "                                                                                                       entry[1], \n",
    "                                                                                                       entry[3], \n",
    "                                                                                                       model_name)\n",
    "            fpr_norm, tpr_norm, _ = roc_curve(entry[3], probs_norm)\n",
    "\n",
    "            accuracy.append([accuracy_norm])\n",
    "            probs.append([probs_norm])\n",
    "            fpr.append([fpr_norm])\n",
    "            tpr.append([tpr_norm])\n",
    "            labels.append([pred_labels_norm])\n",
    "            auc_score.append([auc_score_norm])\n",
    "            report.append([class_report_norm])\n",
    "\n",
    "        pickle.dump(accuracy, open('Results/'+name_of_result+'_accuracy_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(probs, open('Results/'+name_of_result+'_probs_pickle_'+str(seed)+'.pkl',\n",
    "                                'wb'))\n",
    "        pickle.dump(fpr, open('Results/'+name_of_result+'_fpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(tpr, open('Results/'+name_of_result+'_tpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(labels, open('Results/'+name_of_result+'_labels_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(auc_score, open('Results/'+name_of_result+'_auc_score_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(report, open('Results/'+name_of_result+'_report_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "print('Took ', time.time()-start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-02 13:57:11,912 : INFO : loading Word2Vec object from ../../Results/Yeast/models/yeast_strict_w2v_model\n",
      "2017-06-02 13:57:12,086 : INFO : loading wv recursively from ../../Results/Yeast/models/yeast_strict_w2v_model.wv.* with mmap=None\n",
      "2017-06-02 13:57:12,087 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-02 13:57:12,088 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-02 13:57:12,089 : INFO : loaded ../../Results/Yeast/models/yeast_strict_w2v_model\n",
      "2017-06-02 13:57:12,106 : INFO : loading Word2Vec object from ../../Results/Yeast/models/yeast_gen_w2v_model\n",
      "2017-06-02 13:57:12,559 : INFO : loading wv recursively from ../../Results/Yeast/models/yeast_gen_w2v_model.wv.* with mmap=None\n",
      "2017-06-02 13:57:12,561 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-02 13:57:12,561 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-02 13:57:12,562 : INFO : loaded ../../Results/Yeast/models/yeast_gen_w2v_model\n",
      "2017-06-02 13:57:12,582 : INFO : loading Word2Vec object from ../../Results/Yeast/models/yeast_be_w2v_model\n",
      "2017-06-02 13:57:13,554 : INFO : loading wv recursively from ../../Results/Yeast/models/yeast_be_w2v_model.wv.* with mmap=None\n",
      "2017-06-02 13:57:13,555 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-02 13:57:13,556 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-02 13:57:13,557 : INFO : loaded ../../Results/Yeast/models/yeast_be_w2v_model\n",
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 144 \n",
      "Model Report\n",
      "SR 144 Accuracy: 0.625\n",
      "SR 144 AUC Score (Train): 0.691692\n",
      "SR 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.76      0.70        37\n",
      "          1       0.57      0.44      0.50        27\n",
      "\n",
      "avg / total       0.62      0.62      0.62        64\n",
      "\n",
      "GEN 144 \n",
      "Model Report\n",
      "GEN 144 Accuracy: 0.7188\n",
      "GEN 144 AUC Score (Train): 0.731732\n",
      "GEN 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.92      0.79        37\n",
      "          1       0.80      0.44      0.57        27\n",
      "\n",
      "avg / total       0.74      0.72      0.70        64\n",
      "\n",
      "BE 144 \n",
      "Model Report\n",
      "BE 144 Accuracy: 0.6406\n",
      "BE 144 AUC Score (Train): 0.724725\n",
      "BE 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.84      0.73        37\n",
      "          1       0.62      0.37      0.47        27\n",
      "\n",
      "avg / total       0.64      0.64      0.62        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 235 \n",
      "Model Report\n",
      "SR 235 Accuracy: 0.6812\n",
      "SR 235 AUC Score (Train): 0.717317\n",
      "SR 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.74      0.72        38\n",
      "          1       0.66      0.61      0.63        31\n",
      "\n",
      "avg / total       0.68      0.68      0.68        69\n",
      "\n",
      "GEN 235 \n",
      "Model Report\n",
      "GEN 235 Accuracy: 0.7246\n",
      "GEN 235 AUC Score (Train): 0.719015\n",
      "GEN 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.82      0.77        38\n",
      "          1       0.73      0.61      0.67        31\n",
      "\n",
      "avg / total       0.73      0.72      0.72        69\n",
      "\n",
      "BE 235 \n",
      "Model Report\n",
      "BE 235 Accuracy: 0.6522\n",
      "BE 235 AUC Score (Train): 0.729202\n",
      "BE 235 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.71      0.69        38\n",
      "          1       0.62      0.58      0.60        31\n",
      "\n",
      "avg / total       0.65      0.65      0.65        69\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 905 \n",
      "Model Report\n",
      "SR 905 Accuracy: 0.5625\n",
      "SR 905 AUC Score (Train): 0.722127\n",
      "SR 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.53      0.67        53\n",
      "          1       0.24      0.73      0.36        11\n",
      "\n",
      "avg / total       0.79      0.56      0.61        64\n",
      "\n",
      "GEN 905 \n",
      "Model Report\n",
      "GEN 905 Accuracy: 0.5938\n",
      "GEN 905 AUC Score (Train): 0.756432\n",
      "GEN 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.55      0.69        53\n",
      "          1       0.27      0.82      0.41        11\n",
      "\n",
      "avg / total       0.82      0.59      0.64        64\n",
      "\n",
      "BE 905 \n",
      "Model Report\n",
      "BE 905 Accuracy: 0.6406\n",
      "BE 905 AUC Score (Train): 0.765009\n",
      "BE 905 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.62      0.74        53\n",
      "          1       0.29      0.73      0.41        11\n",
      "\n",
      "avg / total       0.81      0.64      0.68        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 2895 \n",
      "Model Report\n",
      "SR 2895 Accuracy: 0.6087\n",
      "SR 2895 AUC Score (Train): 0.754327\n",
      "SR 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.77      0.69        52\n",
      "          1       0.57      0.40      0.47        40\n",
      "\n",
      "avg / total       0.60      0.61      0.59        92\n",
      "\n",
      "GEN 2895 \n",
      "Model Report\n",
      "GEN 2895 Accuracy: 0.6522\n",
      "GEN 2895 AUC Score (Train): 0.710577\n",
      "GEN 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.77      0.71        52\n",
      "          1       0.62      0.50      0.56        40\n",
      "\n",
      "avg / total       0.65      0.65      0.65        92\n",
      "\n",
      "BE 2895 \n",
      "Model Report\n",
      "BE 2895 Accuracy: 0.6848\n",
      "BE 2895 AUC Score (Train): 0.758173\n",
      "BE 2895 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.87      0.76        52\n",
      "          1       0.72      0.45      0.55        40\n",
      "\n",
      "avg / total       0.69      0.68      0.67        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 3462 \n",
      "Model Report\n",
      "SR 3462 Accuracy: 0.7013\n",
      "SR 3462 AUC Score (Train): 0.717949\n",
      "SR 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.69      0.70        39\n",
      "          1       0.69      0.71      0.70        38\n",
      "\n",
      "avg / total       0.70      0.70      0.70        77\n",
      "\n",
      "GEN 3462 \n",
      "Model Report\n",
      "GEN 3462 Accuracy: 0.7532\n",
      "GEN 3462 AUC Score (Train): 0.763158\n",
      "GEN 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.79      0.77        39\n",
      "          1       0.77      0.71      0.74        38\n",
      "\n",
      "avg / total       0.75      0.75      0.75        77\n",
      "\n",
      "BE 3462 \n",
      "Model Report\n",
      "BE 3462 Accuracy: 0.7013\n",
      "BE 3462 AUC Score (Train): 0.804993\n",
      "BE 3462 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.64      0.68        39\n",
      "          1       0.67      0.76      0.72        38\n",
      "\n",
      "avg / total       0.71      0.70      0.70        77\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n",
      "SR 4225 \n",
      "Model Report\n",
      "SR 4225 Accuracy: 0.6047\n",
      "SR 4225 AUC Score (Train): 0.700792\n",
      "SR 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.75      0.70        52\n",
      "          1       0.50      0.38      0.43        34\n",
      "\n",
      "avg / total       0.59      0.60      0.59        86\n",
      "\n",
      "GEN 4225 \n",
      "Model Report\n",
      "GEN 4225 Accuracy: 0.6163\n",
      "GEN 4225 AUC Score (Train): 0.700226\n",
      "GEN 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.73      0.70        52\n",
      "          1       0.52      0.44      0.48        34\n",
      "\n",
      "avg / total       0.61      0.62      0.61        86\n",
      "\n",
      "BE 4225 \n",
      "Model Report\n",
      "BE 4225 Accuracy: 0.6395\n",
      "BE 4225 AUC Score (Train): 0.691742\n",
      "BE 4225 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.75      0.72        52\n",
      "          1       0.55      0.47      0.51        34\n",
      "\n",
      "avg / total       0.63      0.64      0.63        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 5056 \n",
      "Model Report\n",
      "SR 5056 Accuracy: 0.8235\n",
      "SR 5056 AUC Score (Train): 0.863636\n",
      "SR 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.82      0.86        22\n",
      "          1       0.71      0.83      0.77        12\n",
      "\n",
      "avg / total       0.83      0.82      0.83        34\n",
      "\n",
      "GEN 5056 \n",
      "Model Report\n",
      "GEN 5056 Accuracy: 0.7647\n",
      "GEN 5056 AUC Score (Train): 0.814394\n",
      "GEN 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.77      0.81        22\n",
      "          1       0.64      0.75      0.69        12\n",
      "\n",
      "avg / total       0.78      0.76      0.77        34\n",
      "\n",
      "BE 5056 \n",
      "Model Report\n",
      "BE 5056 Accuracy: 0.7647\n",
      "BE 5056 AUC Score (Train): 0.863636\n",
      "BE 5056 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.77      0.81        22\n",
      "          1       0.64      0.75      0.69        12\n",
      "\n",
      "avg / total       0.78      0.76      0.77        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 5192 \n",
      "Model Report\n",
      "SR 5192 Accuracy: 0.6962\n",
      "SR 5192 AUC Score (Train): 0.789229\n",
      "SR 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.91      0.71        32\n",
      "          1       0.90      0.55      0.68        47\n",
      "\n",
      "avg / total       0.77      0.70      0.69        79\n",
      "\n",
      "GEN 5192 \n",
      "Model Report\n",
      "GEN 5192 Accuracy: 0.6835\n",
      "GEN 5192 AUC Score (Train): 0.767952\n",
      "GEN 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.91      0.70        32\n",
      "          1       0.89      0.53      0.67        47\n",
      "\n",
      "avg / total       0.76      0.68      0.68        79\n",
      "\n",
      "BE 5192 \n",
      "Model Report\n",
      "BE 5192 Accuracy: 0.7468\n",
      "BE 5192 AUC Score (Train): 0.815160\n",
      "BE 5192 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.88      0.74        32\n",
      "          1       0.89      0.66      0.76        47\n",
      "\n",
      "avg / total       0.78      0.75      0.75        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 7751 \n",
      "Model Report\n",
      "SR 7751 Accuracy: 0.64\n",
      "SR 7751 AUC Score (Train): 0.672800\n",
      "SR 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.62      0.70        50\n",
      "          1       0.47      0.68      0.56        25\n",
      "\n",
      "avg / total       0.69      0.64      0.65        75\n",
      "\n",
      "GEN 7751 \n",
      "Model Report\n",
      "GEN 7751 Accuracy: 0.6\n",
      "GEN 7751 AUC Score (Train): 0.663200\n",
      "GEN 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.58      0.66        50\n",
      "          1       0.43      0.64      0.52        25\n",
      "\n",
      "avg / total       0.65      0.60      0.61        75\n",
      "\n",
      "BE 7751 \n",
      "Model Report\n",
      "BE 7751 Accuracy: 0.6267\n",
      "BE 7751 AUC Score (Train): 0.670400\n",
      "BE 7751 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.62      0.69        50\n",
      "          1       0.46      0.64      0.53        25\n",
      "\n",
      "avg / total       0.67      0.63      0.64        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 7813 \n",
      "Model Report\n",
      "SR 7813 Accuracy: 0.6623\n",
      "SR 7813 AUC Score (Train): 0.704514\n",
      "SR 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.65      0.63        34\n",
      "          1       0.71      0.67      0.69        43\n",
      "\n",
      "avg / total       0.66      0.66      0.66        77\n",
      "\n",
      "GEN 7813 \n",
      "Model Report\n",
      "GEN 7813 Accuracy: 0.6623\n",
      "GEN 7813 AUC Score (Train): 0.760602\n",
      "GEN 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.65      0.63        34\n",
      "          1       0.71      0.67      0.69        43\n",
      "\n",
      "avg / total       0.66      0.66      0.66        77\n",
      "\n",
      "BE 7813 \n",
      "Model Report\n",
      "BE 7813 Accuracy: 0.6494\n",
      "BE 7813 AUC Score (Train): 0.751026\n",
      "BE 7813 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.62      0.61        34\n",
      "          1       0.69      0.67      0.68        43\n",
      "\n",
      "avg / total       0.65      0.65      0.65        77\n",
      "\n",
      "Took  1503.6061532497406  seconds\n"
     ]
    }
   ],
   "source": [
    "name_of_result = 'yeast_NEW_w2v_OLD_xgb'\n",
    "strict_data = yeast_strict\n",
    "w2v_strict = word2vec.Word2Vec.load('../../Results/Yeast/models/yeast_strict_w2v_model')\n",
    "w2v_gen = word2vec.Word2Vec.load('../../Results/Yeast/models/yeast_gen_w2v_model')\n",
    "w2v_be = word2vec.Word2Vec.load('../../Results/Yeast/models/yeast_be_w2v_model')\n",
    "xgb_clf = XGBClassifier(seed=24)\n",
    "start = time.time()\n",
    "for seed in random_seeds:\n",
    "        strict_list_SR = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_SR_'+str(seed),\n",
    "                                          prev_model=w2v_strict,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_list_GEN = pred.make_models(strict_data,\n",
    "                                           name_of_result+'_GEN_'+str(seed),\n",
    "                                           prev_model=w2v_gen,\n",
    "                                           ran_state=seed)\n",
    "        strict_list_BE = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_BE_'+str(seed),\n",
    "                                          prev_model=w2v_be,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_final_list = [strict_list_SR,\n",
    "                             strict_list_GEN,\n",
    "                             strict_list_BE]\n",
    "\n",
    "        print ('\\nPredicting\\n')\n",
    "        accuracy = []\n",
    "        probs = []\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        labels = []\n",
    "        auc_score = []\n",
    "        report = []\n",
    "\n",
    "        for entry, model_name in zip(strict_final_list, ['SR '+str(seed), 'GEN '+str(seed), 'BE '+str(seed)]):\n",
    "            accuracy_norm, auc_score_norm, pred_labels_norm, probs_norm, class_report_norm  = modelfit(xgb_clf, \n",
    "                                                                                                       entry[0], \n",
    "                                                                                                       entry[2], \n",
    "                                                                                                       entry[1], \n",
    "                                                                                                       entry[3], \n",
    "                                                                                                       model_name)\n",
    "            fpr_norm, tpr_norm, _ = roc_curve(entry[3], probs_norm)\n",
    "\n",
    "            accuracy.append([accuracy_norm])\n",
    "            probs.append([probs_norm])\n",
    "            fpr.append([fpr_norm])\n",
    "            tpr.append([tpr_norm])\n",
    "            labels.append([pred_labels_norm])\n",
    "            auc_score.append([auc_score_norm])\n",
    "            report.append([class_report_norm])\n",
    "\n",
    "        pickle.dump(accuracy, open('Results/'+name_of_result+'_accuracy_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(probs, open('Results/'+name_of_result+'_probs_pickle_'+str(seed)+'.pkl',\n",
    "                                'wb'))\n",
    "        pickle.dump(fpr, open('Results/'+name_of_result+'_fpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(tpr, open('Results/'+name_of_result+'_tpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(labels, open('Results/'+name_of_result+'_labels_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(auc_score, open('Results/'+name_of_result+'_auc_score_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(report, open('Results/'+name_of_result+'_report_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "print('Took ', time.time()-start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "\n",
      "SR 144 \n",
      "Model Report\n",
      "SR 144 Accuracy: 0.4744\n",
      "SR 144 AUC Score (Train): 0.537542\n",
      "SR 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.71      0.55        35\n",
      "          1       0.55      0.28      0.37        43\n",
      "\n",
      "avg / total       0.50      0.47      0.45        78\n",
      "\n",
      "GEN 144 \n",
      "Model Report\n",
      "GEN 144 Accuracy: 0.6154\n",
      "GEN 144 AUC Score (Train): 0.657143\n",
      "GEN 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.89      0.67        35\n",
      "          1       0.81      0.40      0.53        43\n",
      "\n",
      "avg / total       0.69      0.62      0.60        78\n",
      "\n",
      "BE 144 \n",
      "Model Report\n",
      "BE 144 Accuracy: 0.6667\n",
      "BE 144 AUC Score (Train): 0.714286\n",
      "BE 144 Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.86      0.70        35\n",
      "          1       0.81      0.51      0.63        43\n",
      "\n",
      "avg / total       0.71      0.67      0.66        78\n",
      "\n",
      "\n",
      "Predicting\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f4682abd6daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                                                                                                        \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                                                                                                        \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                                                                                                        model_name)\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mfpr_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f835bd3f2b6d>\u001b[0m in \u001b[0;36mmodelfit\u001b[0;34m(alg, train_vecs, train_labels, test_vecs, test_labels, w2v_model_type, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     10\u001b[0m                           \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                           \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                           early_stopping_rounds=50)\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    398\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name_of_result = 'yeast_OLD_w2v_NEW_XGB'\n",
    "strict_data = yeast_strict\n",
    "w2v_strict = yeast_strict_model\n",
    "w2v_gen = yeast_gen_model\n",
    "w2v_be = yeast_be_model\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1,\n",
    "                        n_estimators=1000,\n",
    "                        max_depth=6,\n",
    "                        min_child_weight=1,\n",
    "                        gamma=0.2,\n",
    "                        subsample=0.6,\n",
    "                        colsample_bytree=0.8,\n",
    "                        reg_alpha=0.01,\n",
    "                        objective='binary:logistic',\n",
    "                        scale_pos_weight=1,\n",
    "                        seed=24)\n",
    "start = time.time()\n",
    "for seed in random_seeds:\n",
    "        strict_list_SR = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_SR_'+str(seed),\n",
    "                                          prev_model=w2v_strict,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_list_GEN = pred.make_models(strict_data,\n",
    "                                           name_of_result+'_GEN_'+str(seed),\n",
    "                                           prev_model=w2v_gen,\n",
    "                                           ran_state=seed)\n",
    "        strict_list_BE = pred.make_models(strict_data,\n",
    "                                          name_of_result+'_BE_'+str(seed),\n",
    "                                          prev_model=w2v_be,\n",
    "                                          ran_state=seed)\n",
    "\n",
    "        strict_final_list = [strict_list_SR,\n",
    "                             strict_list_GEN,\n",
    "                             strict_list_BE]\n",
    "\n",
    "        print ('\\nPredicting\\n')\n",
    "        accuracy = []\n",
    "        probs = []\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        labels = []\n",
    "        auc_score = []\n",
    "        report = []\n",
    "\n",
    "        for entry, model_name in zip(strict_final_list, ['SR '+str(seed), 'GEN '+str(seed), 'BE '+str(seed)]):\n",
    "            accuracy_norm, auc_score_norm, pred_labels_norm, probs_norm, class_report_norm  = modelfit(xgb_clf, \n",
    "                                                                                                       entry[0], \n",
    "                                                                                                       entry[2], \n",
    "                                                                                                       entry[1], \n",
    "                                                                                                       entry[3], \n",
    "                                                                                                       model_name)\n",
    "            fpr_norm, tpr_norm, _ = roc_curve(entry[3], probs_norm)\n",
    "\n",
    "            accuracy.append([accuracy_norm])\n",
    "            probs.append([probs_norm])\n",
    "            fpr.append([fpr_norm])\n",
    "            tpr.append([tpr_norm])\n",
    "            labels.append([pred_labels_norm])\n",
    "            auc_score.append([auc_score_norm])\n",
    "            report.append([class_report_norm])\n",
    "\n",
    "        pickle.dump(accuracy, open('Results/'+name_of_result+'_accuracy_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(probs, open('Results/'+name_of_result+'_probs_pickle_'+str(seed)+'.pkl',\n",
    "                                'wb'))\n",
    "        pickle.dump(fpr, open('Results/'+name_of_result+'_fpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(tpr, open('Results/'+name_of_result+'_tpr_pickle_'+str(seed)+'.pkl',\n",
    "                              'wb'))\n",
    "        pickle.dump(labels, open('Results/'+name_of_result+'_labels_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(auc_score, open('Results/'+name_of_result+'_auc_score_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "        pickle.dump(report, open('Results/'+name_of_result+'_report_pickle_'+str(seed)+'.pkl',\n",
    "                                 'wb'))\n",
    "print('Took ', time.time()-start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
