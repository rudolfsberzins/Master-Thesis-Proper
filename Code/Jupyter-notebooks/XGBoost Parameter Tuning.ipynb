{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Core-scripts/')\n",
    "\n",
    "from parse_and_prepare import ProteinProteinInteractionClassifier as ppi\n",
    "import file_readers as fr\n",
    "import prediction as pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "yeast_strict_real = pickle.load(open('../../Results/Yeast/yeast_mentions_strict_real.pkl', 'rb'))\n",
    "yeast_gen_real = pickle.load(open('../../Results/Yeast/yeast_mentions_gen_real.pkl', 'rb'))\n",
    "yeast_be_real = pickle.load(open('../../Results/Yeast/yeast_mentions_be_real.pkl', 'rb'))\n",
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for seed in random_seeds:\n",
    "    real_tr_te_name = 'Yeast/train_test/yeast_tr_te_split_' + str(seed)\n",
    "    train_data, b, c, d = pred.manual_train_test_split(yeast_strict_real, real_tr_te_name, random_state=seed ,test_set_prop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:53:56,773 : INFO : collecting all words and their counts\n",
      "2017-05-30 08:53:56,774 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-30 08:53:56,817 : INFO : collected 11431 word types from a corpus of 188505 raw words and 7145 sentences\n",
      "2017-05-30 08:53:56,819 : INFO : Loading a fresh vocabulary\n",
      "2017-05-30 08:53:56,835 : INFO : min_count=8 retains 2372 unique words (20% of original 11431, drops 9059)\n",
      "2017-05-30 08:53:56,837 : INFO : min_count=8 leaves 169689 word corpus (90% of original 188505, drops 18816)\n",
      "2017-05-30 08:53:56,845 : INFO : deleting the raw counts dictionary of 11431 items\n",
      "2017-05-30 08:53:56,846 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2017-05-30 08:53:56,847 : INFO : downsampling leaves estimated 119416 word corpus (70.4% of prior 169689)\n",
      "2017-05-30 08:53:56,847 : INFO : estimated required memory for 2372 words and 800 dimensions: 24431600 bytes\n",
      "2017-05-30 08:53:56,856 : INFO : constructing a huffman tree from 2372 words\n",
      "2017-05-30 08:53:56,912 : INFO : built huffman tree with maximum node depth 14\n",
      "2017-05-30 08:53:56,922 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:53:56,972 : INFO : training model with 4 workers on 2372 vocabulary and 800 features, using sg=1 hs=1 sample=0.001 negative=5 window=8\n",
      "2017-05-30 08:53:56,974 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-30 08:53:58,034 : INFO : PROGRESS: at 7.44% examples, 42053 words/s, in_qsize 8, out_qsize 1\n",
      "2017-05-30 08:53:59,072 : INFO : PROGRESS: at 19.06% examples, 54436 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:00,115 : INFO : PROGRESS: at 29.64% examples, 56480 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:01,339 : INFO : PROGRESS: at 41.32% examples, 56583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:02,500 : INFO : PROGRESS: at 53.96% examples, 58434 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:03,695 : INFO : PROGRESS: at 66.79% examples, 59339 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:04,819 : INFO : PROGRESS: at 79.46% examples, 60495 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:05,842 : INFO : PROGRESS: at 89.00% examples, 59927 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:06,621 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-30 08:54:06,672 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-30 08:54:06,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-30 08:54:06,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-30 08:54:06,781 : INFO : training on 942525 raw words (596809 effective words) took 9.8s, 60891 effective words/s\n",
      "2017-05-30 08:54:06,782 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-05-30 08:54:06,802 : INFO : saving Word2Vec object under ../../Results/Yeast/models/yeast_strict_model, separately None\n",
      "2017-05-30 08:54:06,802 : INFO : not storing attribute syn0norm\n",
      "2017-05-30 08:54:06,803 : INFO : not storing attribute cum_table\n",
      "2017-05-30 08:54:07,001 : INFO : saved ../../Results/Yeast/models/yeast_strict_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:54:07,518 : INFO : collecting all words and their counts\n",
      "2017-05-30 08:54:07,519 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-30 08:54:07,562 : INFO : PROGRESS: at sentence #10000, processed 242489 words, keeping 11178 word types\n",
      "2017-05-30 08:54:07,604 : INFO : PROGRESS: at sentence #20000, processed 484360 words, keeping 14874 word types\n",
      "2017-05-30 08:54:07,647 : INFO : PROGRESS: at sentence #30000, processed 727638 words, keeping 17573 word types\n",
      "2017-05-30 08:54:07,691 : INFO : PROGRESS: at sentence #40000, processed 970418 words, keeping 19777 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:54:07,725 : INFO : collected 21147 word types from a corpus of 1155938 raw words and 47662 sentences\n",
      "2017-05-30 08:54:07,726 : INFO : Loading a fresh vocabulary\n",
      "2017-05-30 08:54:07,914 : INFO : min_count=8 retains 6303 unique words (29% of original 21147, drops 14844)\n",
      "2017-05-30 08:54:07,915 : INFO : min_count=8 leaves 1123722 word corpus (97% of original 1155938, drops 32216)\n",
      "2017-05-30 08:54:07,930 : INFO : deleting the raw counts dictionary of 21147 items\n",
      "2017-05-30 08:54:07,931 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2017-05-30 08:54:07,932 : INFO : downsampling leaves estimated 817860 word corpus (72.8% of prior 1123722)\n",
      "2017-05-30 08:54:07,933 : INFO : estimated required memory for 6303 words and 800 dimensions: 64920900 bytes\n",
      "2017-05-30 08:54:07,944 : INFO : constructing a huffman tree from 6303 words\n",
      "2017-05-30 08:54:08,076 : INFO : built huffman tree with maximum node depth 17\n",
      "2017-05-30 08:54:08,088 : INFO : resetting layer weights\n",
      "2017-05-30 08:54:08,203 : INFO : training model with 4 workers on 6303 vocabulary and 800 features, using sg=1 hs=1 sample=0.001 negative=5 window=8\n",
      "2017-05-30 08:54:08,204 : INFO : expecting 47662 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-30 08:54:09,299 : INFO : PROGRESS: at 0.86% examples, 32258 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:10,595 : INFO : PROGRESS: at 2.24% examples, 38458 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:11,639 : INFO : PROGRESS: at 3.81% examples, 45294 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:12,677 : INFO : PROGRESS: at 5.17% examples, 47390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:13,911 : INFO : PROGRESS: at 6.39% examples, 45832 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:15,244 : INFO : PROGRESS: at 7.78% examples, 45201 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:16,391 : INFO : PROGRESS: at 9.16% examples, 45756 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:17,881 : INFO : PROGRESS: at 10.54% examples, 44539 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:19,288 : INFO : PROGRESS: at 11.92% examples, 43980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:20,671 : INFO : PROGRESS: at 13.30% examples, 43637 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:21,729 : INFO : PROGRESS: at 14.68% examples, 44398 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:22,756 : INFO : PROGRESS: at 16.05% examples, 45136 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:23,951 : INFO : PROGRESS: at 17.45% examples, 45306 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:25,000 : INFO : PROGRESS: at 18.83% examples, 45844 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:26,005 : INFO : PROGRESS: at 19.87% examples, 45649 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:27,257 : INFO : PROGRESS: at 20.90% examples, 44869 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:28,328 : INFO : PROGRESS: at 22.11% examples, 44927 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:29,468 : INFO : PROGRESS: at 22.96% examples, 44186 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:30,779 : INFO : PROGRESS: at 24.36% examples, 44122 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:31,909 : INFO : PROGRESS: at 25.57% examples, 44096 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:33,086 : INFO : PROGRESS: at 26.61% examples, 43720 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:34,281 : INFO : PROGRESS: at 27.65% examples, 43348 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:35,437 : INFO : PROGRESS: at 28.69% examples, 43062 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:36,558 : INFO : PROGRESS: at 29.72% examples, 42850 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:37,890 : INFO : PROGRESS: at 30.75% examples, 42355 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:39,107 : INFO : PROGRESS: at 32.14% examples, 42519 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:40,296 : INFO : PROGRESS: at 33.51% examples, 42705 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:41,318 : INFO : PROGRESS: at 34.90% examples, 43088 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:42,368 : INFO : PROGRESS: at 36.28% examples, 43420 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:43,376 : INFO : PROGRESS: at 37.48% examples, 43584 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:44,504 : INFO : PROGRESS: at 38.35% examples, 43202 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:45,539 : INFO : PROGRESS: at 39.22% examples, 42955 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:46,588 : INFO : PROGRESS: at 40.43% examples, 43068 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:47,657 : INFO : PROGRESS: at 41.81% examples, 43330 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:48,816 : INFO : PROGRESS: at 43.19% examples, 43488 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:49,845 : INFO : PROGRESS: at 44.23% examples, 43430 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:50,869 : INFO : PROGRESS: at 45.61% examples, 43712 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:51,876 : INFO : PROGRESS: at 46.83% examples, 43839 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:52,904 : INFO : PROGRESS: at 48.22% examples, 44100 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:54:53,941 : INFO : PROGRESS: at 49.42% examples, 44180 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:55,039 : INFO : PROGRESS: at 50.45% examples, 44045 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:56,078 : INFO : PROGRESS: at 51.48% examples, 43974 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:57,204 : INFO : PROGRESS: at 52.53% examples, 43829 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:58,373 : INFO : PROGRESS: at 53.73% examples, 43796 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:54:59,462 : INFO : PROGRESS: at 54.77% examples, 43690 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:00,577 : INFO : PROGRESS: at 56.14% examples, 43837 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:01,787 : INFO : PROGRESS: at 57.53% examples, 43905 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:03,074 : INFO : PROGRESS: at 58.92% examples, 43904 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:04,200 : INFO : PROGRESS: at 60.30% examples, 44031 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:05,252 : INFO : PROGRESS: at 61.51% examples, 44086 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:06,357 : INFO : PROGRESS: at 62.37% examples, 43854 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:07,661 : INFO : PROGRESS: at 63.59% examples, 43727 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:08,867 : INFO : PROGRESS: at 64.97% examples, 43787 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:09,914 : INFO : PROGRESS: at 66.35% examples, 43960 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:11,107 : INFO : PROGRESS: at 67.73% examples, 44023 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:12,237 : INFO : PROGRESS: at 69.30% examples, 44237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:13,276 : INFO : PROGRESS: at 70.32% examples, 44181 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:14,335 : INFO : PROGRESS: at 71.35% examples, 44114 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:15,528 : INFO : PROGRESS: at 72.23% examples, 43857 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:16,781 : INFO : PROGRESS: at 73.60% examples, 43880 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:17,827 : INFO : PROGRESS: at 74.98% examples, 44030 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:19,061 : INFO : PROGRESS: at 76.37% examples, 44065 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:20,155 : INFO : PROGRESS: at 77.92% examples, 44278 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:21,193 : INFO : PROGRESS: at 78.79% examples, 44134 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:22,286 : INFO : PROGRESS: at 80.00% examples, 44154 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:23,332 : INFO : PROGRESS: at 81.03% examples, 44101 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:24,348 : INFO : PROGRESS: at 82.07% examples, 44068 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:25,410 : INFO : PROGRESS: at 83.45% examples, 44195 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:26,479 : INFO : PROGRESS: at 84.66% examples, 44222 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:27,616 : INFO : PROGRESS: at 85.70% examples, 44122 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:28,972 : INFO : PROGRESS: at 87.09% examples, 44083 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:30,170 : INFO : PROGRESS: at 88.47% examples, 44129 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:31,205 : INFO : PROGRESS: at 89.50% examples, 44090 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:32,267 : INFO : PROGRESS: at 90.37% examples, 43952 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:33,467 : INFO : PROGRESS: at 91.22% examples, 43747 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:34,634 : INFO : PROGRESS: at 92.44% examples, 43728 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:35,844 : INFO : PROGRESS: at 93.47% examples, 43608 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:37,018 : INFO : PROGRESS: at 94.85% examples, 43666 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:38,253 : INFO : PROGRESS: at 96.23% examples, 43694 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:39,362 : INFO : PROGRESS: at 97.45% examples, 43707 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:40,612 : INFO : PROGRESS: at 98.83% examples, 43728 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:41,270 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-30 08:55:41,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-30 08:55:41,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-30 08:55:41,559 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-30 08:55:41,560 : INFO : training on 5779690 raw words (4088467 effective words) took 93.4s, 43797 effective words/s\n",
      "2017-05-30 08:55:41,561 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-05-30 08:55:41,643 : INFO : saving Word2Vec object under ../../Results/Yeast/models/yeast_gen_model, separately None\n",
      "2017-05-30 08:55:41,644 : INFO : not storing attribute syn0norm\n",
      "2017-05-30 08:55:41,645 : INFO : not storing attribute cum_table\n",
      "2017-05-30 08:55:42,762 : INFO : saved ../../Results/Yeast/models/yeast_gen_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:55:46,119 : INFO : collecting all words and their counts\n",
      "2017-05-30 08:55:46,120 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-30 08:55:46,173 : INFO : PROGRESS: at sentence #10000, processed 229206 words, keeping 12313 word types\n",
      "2017-05-30 08:55:46,226 : INFO : PROGRESS: at sentence #20000, processed 457084 words, keeping 16840 word types\n",
      "2017-05-30 08:55:46,278 : INFO : PROGRESS: at sentence #30000, processed 686842 words, keeping 20179 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:55:46,332 : INFO : PROGRESS: at sentence #40000, processed 915527 words, keeping 22886 word types\n",
      "2017-05-30 08:55:46,395 : INFO : PROGRESS: at sentence #50000, processed 1144562 words, keeping 25201 word types\n",
      "2017-05-30 08:55:46,447 : INFO : PROGRESS: at sentence #60000, processed 1374108 words, keeping 27166 word types\n",
      "2017-05-30 08:55:46,502 : INFO : PROGRESS: at sentence #70000, processed 1602041 words, keeping 28983 word types\n",
      "2017-05-30 08:55:46,557 : INFO : PROGRESS: at sentence #80000, processed 1832714 words, keeping 30757 word types\n",
      "2017-05-30 08:55:46,612 : INFO : PROGRESS: at sentence #90000, processed 2060897 words, keeping 32306 word types\n",
      "2017-05-30 08:55:46,667 : INFO : PROGRESS: at sentence #100000, processed 2289067 words, keeping 33725 word types\n",
      "2017-05-30 08:55:46,721 : INFO : PROGRESS: at sentence #110000, processed 2516540 words, keeping 35030 word types\n",
      "2017-05-30 08:55:46,776 : INFO : PROGRESS: at sentence #120000, processed 2745541 words, keeping 36260 word types\n",
      "2017-05-30 08:55:46,830 : INFO : PROGRESS: at sentence #130000, processed 2972005 words, keeping 37476 word types\n",
      "2017-05-30 08:55:46,888 : INFO : PROGRESS: at sentence #140000, processed 3200934 words, keeping 38585 word types\n",
      "2017-05-30 08:55:46,940 : INFO : PROGRESS: at sentence #150000, processed 3430843 words, keeping 39735 word types\n",
      "2017-05-30 08:55:46,995 : INFO : PROGRESS: at sentence #160000, processed 3660294 words, keeping 40757 word types\n",
      "2017-05-30 08:55:47,049 : INFO : PROGRESS: at sentence #170000, processed 3888165 words, keeping 41710 word types\n",
      "2017-05-30 08:55:47,105 : INFO : PROGRESS: at sentence #180000, processed 4117871 words, keeping 42734 word types\n",
      "2017-05-30 08:55:47,160 : INFO : PROGRESS: at sentence #190000, processed 4348035 words, keeping 43673 word types\n",
      "2017-05-30 08:55:47,219 : INFO : PROGRESS: at sentence #200000, processed 4579991 words, keeping 44571 word types\n",
      "2017-05-30 08:55:47,270 : INFO : collected 45300 word types from a corpus of 4784186 raw words and 208973 sentences\n",
      "2017-05-30 08:55:47,271 : INFO : Loading a fresh vocabulary\n",
      "2017-05-30 08:55:47,615 : INFO : min_count=8 retains 13082 unique words (28% of original 45300, drops 32218)\n",
      "2017-05-30 08:55:47,616 : INFO : min_count=8 leaves 4714785 word corpus (98% of original 4784186, drops 69401)\n",
      "2017-05-30 08:55:47,655 : INFO : deleting the raw counts dictionary of 45300 items\n",
      "2017-05-30 08:55:47,658 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2017-05-30 08:55:47,659 : INFO : downsampling leaves estimated 3503890 word corpus (74.3% of prior 4714785)\n",
      "2017-05-30 08:55:47,659 : INFO : estimated required memory for 13082 words and 800 dimensions: 134744600 bytes\n",
      "2017-05-30 08:55:47,680 : INFO : constructing a huffman tree from 13082 words\n",
      "2017-05-30 08:55:48,054 : INFO : built huffman tree with maximum node depth 19\n",
      "2017-05-30 08:55:48,090 : INFO : resetting layer weights\n",
      "2017-05-30 08:55:48,394 : INFO : training model with 4 workers on 13082 vocabulary and 800 features, using sg=1 hs=1 sample=0.001 negative=5 window=8\n",
      "2017-05-30 08:55:48,395 : INFO : expecting 208973 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-30 08:55:50,039 : INFO : PROGRESS: at 0.21% examples, 22441 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:51,447 : INFO : PROGRESS: at 0.53% examples, 31305 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:52,624 : INFO : PROGRESS: at 0.88% examples, 36460 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:54,045 : INFO : PROGRESS: at 1.21% examples, 37649 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:55,113 : INFO : PROGRESS: at 1.50% examples, 39298 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:56,127 : INFO : PROGRESS: at 1.67% examples, 37922 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:55:57,533 : INFO : PROGRESS: at 1.88% examples, 36086 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:58,751 : INFO : PROGRESS: at 2.18% examples, 36777 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:55:59,876 : INFO : PROGRESS: at 2.47% examples, 37626 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:00,923 : INFO : PROGRESS: at 2.68% examples, 37402 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:02,281 : INFO : PROGRESS: at 2.88% examples, 36370 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:03,310 : INFO : PROGRESS: at 3.13% examples, 36803 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:04,492 : INFO : PROGRESS: at 3.34% examples, 36370 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:05,607 : INFO : PROGRESS: at 3.55% examples, 36140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:06,725 : INFO : PROGRESS: at 3.80% examples, 36344 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:07,842 : INFO : PROGRESS: at 4.09% examples, 36891 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:08,957 : INFO : PROGRESS: at 4.30% examples, 36671 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:10,243 : INFO : PROGRESS: at 4.63% examples, 37190 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:11,245 : INFO : PROGRESS: at 4.93% examples, 37797 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:12,340 : INFO : PROGRESS: at 5.14% examples, 37601 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:13,553 : INFO : PROGRESS: at 5.38% examples, 37536 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:14,901 : INFO : PROGRESS: at 5.64% examples, 37286 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:16,304 : INFO : PROGRESS: at 5.88% examples, 36978 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:17,681 : INFO : PROGRESS: at 6.22% examples, 37242 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:18,728 : INFO : PROGRESS: at 6.51% examples, 37652 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:19,847 : INFO : PROGRESS: at 6.72% examples, 37474 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:20,855 : INFO : PROGRESS: at 6.93% examples, 37431 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:22,266 : INFO : PROGRESS: at 7.18% examples, 37168 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:23,427 : INFO : PROGRESS: at 7.43% examples, 37190 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:24,558 : INFO : PROGRESS: at 7.68% examples, 37238 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:25,566 : INFO : PROGRESS: at 7.93% examples, 37406 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:26,846 : INFO : PROGRESS: at 8.22% examples, 37486 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:27,986 : INFO : PROGRESS: at 8.48% examples, 37512 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:29,393 : INFO : PROGRESS: at 8.68% examples, 37116 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:30,420 : INFO : PROGRESS: at 8.93% examples, 37252 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:32,022 : INFO : PROGRESS: at 9.19% examples, 36890 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:33,027 : INFO : PROGRESS: at 9.48% examples, 37205 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:34,063 : INFO : PROGRESS: at 9.69% examples, 37166 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:35,220 : INFO : PROGRESS: at 9.99% examples, 37341 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:36,281 : INFO : PROGRESS: at 10.23% examples, 37432 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:37,308 : INFO : PROGRESS: at 10.53% examples, 37699 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:38,349 : INFO : PROGRESS: at 10.74% examples, 37642 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:39,734 : INFO : PROGRESS: at 10.99% examples, 37477 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:41,104 : INFO : PROGRESS: at 11.23% examples, 37335 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:42,209 : INFO : PROGRESS: at 11.49% examples, 37382 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:43,284 : INFO : PROGRESS: at 11.74% examples, 37446 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:44,374 : INFO : PROGRESS: at 11.99% examples, 37504 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:45,376 : INFO : PROGRESS: at 12.25% examples, 37612 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:46,665 : INFO : PROGRESS: at 12.50% examples, 37532 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:47,790 : INFO : PROGRESS: at 12.71% examples, 37436 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:48,862 : INFO : PROGRESS: at 12.96% examples, 37498 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:50,293 : INFO : PROGRESS: at 13.17% examples, 37223 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:51,359 : INFO : PROGRESS: at 13.46% examples, 37407 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:52,495 : INFO : PROGRESS: at 13.67% examples, 37317 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:53,746 : INFO : PROGRESS: at 14.00% examples, 37498 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:54,856 : INFO : PROGRESS: at 14.29% examples, 37641 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:55,982 : INFO : PROGRESS: at 14.54% examples, 37662 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:57,107 : INFO : PROGRESS: at 14.70% examples, 37470 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:56:58,252 : INFO : PROGRESS: at 14.95% examples, 37486 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:56:59,260 : INFO : PROGRESS: at 15.16% examples, 37468 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:00,465 : INFO : PROGRESS: at 15.42% examples, 37447 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:01,754 : INFO : PROGRESS: at 15.71% examples, 37487 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:02,860 : INFO : PROGRESS: at 15.96% examples, 37522 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:04,327 : INFO : PROGRESS: at 16.21% examples, 37375 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:05,554 : INFO : PROGRESS: at 16.42% examples, 37254 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:06,932 : INFO : PROGRESS: at 16.71% examples, 37252 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:08,235 : INFO : PROGRESS: at 16.92% examples, 37103 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:09,327 : INFO : PROGRESS: at 17.21% examples, 37231 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:10,383 : INFO : PROGRESS: at 17.42% examples, 37199 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:11,446 : INFO : PROGRESS: at 17.67% examples, 37253 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:12,527 : INFO : PROGRESS: at 17.88% examples, 37208 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:14,052 : INFO : PROGRESS: at 18.08% examples, 36972 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:15,180 : INFO : PROGRESS: at 18.33% examples, 36997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:16,506 : INFO : PROGRESS: at 18.58% examples, 36939 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:17,514 : INFO : PROGRESS: at 18.87% examples, 37095 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:18,607 : INFO : PROGRESS: at 19.07% examples, 37052 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:19,856 : INFO : PROGRESS: at 19.41% examples, 37187 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:21,043 : INFO : PROGRESS: at 19.70% examples, 37264 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:22,126 : INFO : PROGRESS: at 19.96% examples, 37301 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:23,271 : INFO : PROGRESS: at 20.20% examples, 37313 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:24,340 : INFO : PROGRESS: at 20.41% examples, 37279 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:25,384 : INFO : PROGRESS: at 20.66% examples, 37329 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:26,581 : INFO : PROGRESS: at 20.87% examples, 37247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:27,718 : INFO : PROGRESS: at 21.08% examples, 37192 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:28,750 : INFO : PROGRESS: at 21.33% examples, 37247 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:30,113 : INFO : PROGRESS: at 21.63% examples, 37251 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:31,247 : INFO : PROGRESS: at 21.92% examples, 37338 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:32,712 : INFO : PROGRESS: at 22.13% examples, 37164 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:33,795 : INFO : PROGRESS: at 22.42% examples, 37266 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:35,351 : INFO : PROGRESS: at 22.63% examples, 37065 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:36,355 : INFO : PROGRESS: at 22.88% examples, 37127 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:37,546 : INFO : PROGRESS: at 23.13% examples, 37124 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:38,590 : INFO : PROGRESS: at 23.38% examples, 37170 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:39,733 : INFO : PROGRESS: at 23.63% examples, 37183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:40,821 : INFO : PROGRESS: at 23.84% examples, 37150 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:41,919 : INFO : PROGRESS: at 24.09% examples, 37177 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:43,189 : INFO : PROGRESS: at 24.30% examples, 37083 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:44,239 : INFO : PROGRESS: at 24.51% examples, 37062 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:45,634 : INFO : PROGRESS: at 24.80% examples, 37058 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:46,996 : INFO : PROGRESS: at 25.13% examples, 37126 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:48,159 : INFO : PROGRESS: at 25.42% examples, 37193 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:49,650 : INFO : PROGRESS: at 25.76% examples, 37218 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:50,707 : INFO : PROGRESS: at 26.00% examples, 37255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:52,411 : INFO : PROGRESS: at 26.26% examples, 37098 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:53,417 : INFO : PROGRESS: at 26.55% examples, 37210 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:54,438 : INFO : PROGRESS: at 26.72% examples, 37140 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:55,735 : INFO : PROGRESS: at 26.93% examples, 37048 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:57:57,138 : INFO : PROGRESS: at 27.26% examples, 37099 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:58,445 : INFO : PROGRESS: at 27.59% examples, 37176 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:57:59,502 : INFO : PROGRESS: at 27.88% examples, 37265 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:01,045 : INFO : PROGRESS: at 28.09% examples, 37108 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:02,302 : INFO : PROGRESS: at 28.34% examples, 37087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:03,411 : INFO : PROGRESS: at 28.56% examples, 37053 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:04,798 : INFO : PROGRESS: at 28.84% examples, 37051 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 08:58:06,101 : INFO : PROGRESS: at 29.18% examples, 37127 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:07,193 : INFO : PROGRESS: at 29.48% examples, 37203 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:08,574 : INFO : PROGRESS: at 29.69% examples, 37097 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:09,634 : INFO : PROGRESS: at 29.98% examples, 37181 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:11,112 : INFO : PROGRESS: at 30.19% examples, 37052 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:12,312 : INFO : PROGRESS: at 30.48% examples, 37101 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:13,681 : INFO : PROGRESS: at 30.78% examples, 37103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:14,747 : INFO : PROGRESS: at 31.06% examples, 37182 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:15,831 : INFO : PROGRESS: at 31.27% examples, 37156 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:17,001 : INFO : PROGRESS: at 31.49% examples, 37110 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:18,027 : INFO : PROGRESS: at 31.70% examples, 37099 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:19,322 : INFO : PROGRESS: at 31.95% examples, 37071 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:20,396 : INFO : PROGRESS: at 32.25% examples, 37145 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:21,406 : INFO : PROGRESS: at 32.46% examples, 37139 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:22,525 : INFO : PROGRESS: at 32.67% examples, 37105 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:23,786 : INFO : PROGRESS: at 33.00% examples, 37181 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:25,172 : INFO : PROGRESS: at 33.33% examples, 37225 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:26,593 : INFO : PROGRESS: at 33.62% examples, 37214 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:27,727 : INFO : PROGRESS: at 33.83% examples, 37179 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:28,851 : INFO : PROGRESS: at 34.12% examples, 37236 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:29,935 : INFO : PROGRESS: at 34.37% examples, 37258 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:31,194 : INFO : PROGRESS: at 34.66% examples, 37284 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:32,451 : INFO : PROGRESS: at 34.99% examples, 37355 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:33,739 : INFO : PROGRESS: at 35.33% examples, 37418 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:34,740 : INFO : PROGRESS: at 35.58% examples, 37456 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:35,897 : INFO : PROGRESS: at 35.79% examples, 37416 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:37,209 : INFO : PROGRESS: at 36.00% examples, 37342 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 08:58:38,241 : INFO : PROGRESS: at 36.25% examples, 37374 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:39,608 : INFO : PROGRESS: at 36.50% examples, 37332 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:40,900 : INFO : PROGRESS: at 36.83% examples, 37393 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:41,966 : INFO : PROGRESS: at 37.08% examples, 37415 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:43,148 : INFO : PROGRESS: at 37.33% examples, 37413 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:44,281 : INFO : PROGRESS: at 37.59% examples, 37423 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:45,353 : INFO : PROGRESS: at 37.75% examples, 37361 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:46,467 : INFO : PROGRESS: at 38.00% examples, 37373 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:47,664 : INFO : PROGRESS: at 38.21% examples, 37327 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:48,756 : INFO : PROGRESS: at 38.45% examples, 37345 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:49,868 : INFO : PROGRESS: at 38.66% examples, 37318 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:51,126 : INFO : PROGRESS: at 38.95% examples, 37341 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:52,262 : INFO : PROGRESS: at 39.20% examples, 37349 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:58:53,433 : INFO : PROGRESS: at 39.45% examples, 37350 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:54,451 : INFO : PROGRESS: at 39.66% examples, 37342 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:55,819 : INFO : PROGRESS: at 39.87% examples, 37265 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:57,047 : INFO : PROGRESS: at 40.12% examples, 37255 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:58:58,147 : INFO : PROGRESS: at 40.36% examples, 37271 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 08:58:59,331 : INFO : PROGRESS: at 40.66% examples, 37307 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:00,543 : INFO : PROGRESS: at 40.95% examples, 37339 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:01,590 : INFO : PROGRESS: at 41.16% examples, 37328 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:02,698 : INFO : PROGRESS: at 41.46% examples, 37379 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:03,742 : INFO : PROGRESS: at 41.71% examples, 37403 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:05,100 : INFO : PROGRESS: at 41.96% examples, 37368 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:06,215 : INFO : PROGRESS: at 42.21% examples, 37379 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:07,941 : INFO : PROGRESS: at 42.46% examples, 37275 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:09,026 : INFO : PROGRESS: at 42.67% examples, 37256 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:10,451 : INFO : PROGRESS: at 42.96% examples, 37247 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:11,645 : INFO : PROGRESS: at 43.25% examples, 37281 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:12,899 : INFO : PROGRESS: at 43.54% examples, 37302 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:14,113 : INFO : PROGRESS: at 43.79% examples, 37296 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 08:59:15,292 : INFO : PROGRESS: at 44.09% examples, 37330 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:16,439 : INFO : PROGRESS: at 44.30% examples, 37300 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:17,516 : INFO : PROGRESS: at 44.50% examples, 37283 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:18,688 : INFO : PROGRESS: at 44.71% examples, 37248 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:19,719 : INFO : PROGRESS: at 45.00% examples, 37309 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:20,957 : INFO : PROGRESS: at 45.25% examples, 37299 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:22,056 : INFO : PROGRESS: at 45.55% examples, 37347 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:23,246 : INFO : PROGRESS: at 45.75% examples, 37311 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:24,428 : INFO : PROGRESS: at 46.04% examples, 37343 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:25,704 : INFO : PROGRESS: at 46.25% examples, 37293 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:26,917 : INFO : PROGRESS: at 46.55% examples, 37321 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:28,232 : INFO : PROGRESS: at 46.76% examples, 37264 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:29,358 : INFO : PROGRESS: at 47.05% examples, 37306 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:30,611 : INFO : PROGRESS: at 47.34% examples, 37326 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:31,668 : INFO : PROGRESS: at 47.63% examples, 37378 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:32,766 : INFO : PROGRESS: at 47.84% examples, 37358 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:33,969 : INFO : PROGRESS: at 48.09% examples, 37353 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:35,231 : INFO : PROGRESS: at 48.34% examples, 37338 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:36,275 : INFO : PROGRESS: at 48.55% examples, 37327 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:37,427 : INFO : PROGRESS: at 48.76% examples, 37299 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:38,443 : INFO : PROGRESS: at 48.97% examples, 37293 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:39,473 : INFO : PROGRESS: at 49.18% examples, 37287 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:40,572 : INFO : PROGRESS: at 49.43% examples, 37299 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:41,729 : INFO : PROGRESS: at 49.68% examples, 37302 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:42,862 : INFO : PROGRESS: at 49.94% examples, 37309 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:44,205 : INFO : PROGRESS: at 50.19% examples, 37282 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:45,346 : INFO : PROGRESS: at 50.44% examples, 37288 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:46,474 : INFO : PROGRESS: at 50.65% examples, 37265 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:47,654 : INFO : PROGRESS: at 50.85% examples, 37234 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:48,679 : INFO : PROGRESS: at 51.06% examples, 37227 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:49,732 : INFO : PROGRESS: at 51.27% examples, 37216 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:50,742 : INFO : PROGRESS: at 51.48% examples, 37212 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:51,840 : INFO : PROGRESS: at 51.78% examples, 37254 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:52,952 : INFO : PROGRESS: at 51.99% examples, 37234 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:54,477 : INFO : PROGRESS: at 52.33% examples, 37242 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:55,525 : INFO : PROGRESS: at 52.54% examples, 37231 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 08:59:56,554 : INFO : PROGRESS: at 52.74% examples, 37224 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:57,695 : INFO : PROGRESS: at 52.96% examples, 37200 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:58,712 : INFO : PROGRESS: at 53.16% examples, 37196 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 08:59:59,779 : INFO : PROGRESS: at 53.37% examples, 37183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:00,884 : INFO : PROGRESS: at 53.66% examples, 37223 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:01,939 : INFO : PROGRESS: at 53.87% examples, 37213 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:03,254 : INFO : PROGRESS: at 54.16% examples, 37222 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:04,379 : INFO : PROGRESS: at 54.37% examples, 37201 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:05,526 : INFO : PROGRESS: at 54.57% examples, 37177 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:06,772 : INFO : PROGRESS: at 54.78% examples, 37139 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:08,006 : INFO : PROGRESS: at 55.07% examples, 37160 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:09,170 : INFO : PROGRESS: at 55.37% examples, 37190 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:10,171 : INFO : PROGRESS: at 55.62% examples, 37215 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:11,236 : INFO : PROGRESS: at 55.87% examples, 37231 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:12,342 : INFO : PROGRESS: at 56.08% examples, 37214 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:13,357 : INFO : PROGRESS: at 56.29% examples, 37210 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:14,366 : INFO : PROGRESS: at 56.50% examples, 37206 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:15,418 : INFO : PROGRESS: at 56.70% examples, 37197 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:16,501 : INFO : PROGRESS: at 56.91% examples, 37183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:17,678 : INFO : PROGRESS: at 57.16% examples, 37184 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:18,842 : INFO : PROGRESS: at 57.42% examples, 37186 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:20,019 : INFO : PROGRESS: at 57.71% examples, 37213 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:21,145 : INFO : PROGRESS: at 57.91% examples, 37194 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:22,151 : INFO : PROGRESS: at 58.08% examples, 37164 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:23,342 : INFO : PROGRESS: at 58.29% examples, 37136 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:24,394 : INFO : PROGRESS: at 58.49% examples, 37127 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:25,712 : INFO : PROGRESS: at 58.74% examples, 37109 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:26,743 : INFO : PROGRESS: at 58.98% examples, 37129 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:28,016 : INFO : PROGRESS: at 59.23% examples, 37117 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:29,218 : INFO : PROGRESS: at 59.53% examples, 37141 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:30,228 : INFO : PROGRESS: at 59.70% examples, 37112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:31,331 : INFO : PROGRESS: at 59.91% examples, 37097 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:33,061 : INFO : PROGRESS: at 60.20% examples, 37051 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:34,503 : INFO : PROGRESS: at 60.53% examples, 37069 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:35,990 : INFO : PROGRESS: at 60.87% examples, 37081 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:37,502 : INFO : PROGRESS: at 61.20% examples, 37090 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:38,569 : INFO : PROGRESS: at 61.45% examples, 37105 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:39,706 : INFO : PROGRESS: at 61.66% examples, 37086 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:41,173 : INFO : PROGRESS: at 61.87% examples, 37025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:42,282 : INFO : PROGRESS: at 62.08% examples, 37010 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 09:00:43,576 : INFO : PROGRESS: at 62.37% examples, 37020 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:44,979 : INFO : PROGRESS: at 62.71% examples, 37042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:46,268 : INFO : PROGRESS: at 63.04% examples, 37079 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:47,448 : INFO : PROGRESS: at 63.25% examples, 37055 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:48,950 : INFO : PROGRESS: at 63.54% examples, 37040 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:50,099 : INFO : PROGRESS: at 63.75% examples, 37020 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:51,151 : INFO : PROGRESS: at 63.96% examples, 37013 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:52,197 : INFO : PROGRESS: at 64.17% examples, 37006 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:53,236 : INFO : PROGRESS: at 64.42% examples, 37024 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:54,569 : INFO : PROGRESS: at 64.71% examples, 37030 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:55,811 : INFO : PROGRESS: at 64.96% examples, 37023 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:56,947 : INFO : PROGRESS: at 65.17% examples, 37005 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:00:58,195 : INFO : PROGRESS: at 65.38% examples, 36974 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:00:59,260 : INFO : PROGRESS: at 65.63% examples, 36989 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:00,368 : INFO : PROGRESS: at 65.83% examples, 36975 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:01,397 : INFO : PROGRESS: at 66.08% examples, 36994 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:02,579 : INFO : PROGRESS: at 66.29% examples, 36971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:03,700 : INFO : PROGRESS: at 66.50% examples, 36956 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:04,818 : INFO : PROGRESS: at 66.76% examples, 36964 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:06,305 : INFO : PROGRESS: at 66.97% examples, 36906 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:07,416 : INFO : PROGRESS: at 67.17% examples, 36892 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:08,605 : INFO : PROGRESS: at 67.46% examples, 36915 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:09,682 : INFO : PROGRESS: at 67.67% examples, 36905 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:10,883 : INFO : PROGRESS: at 67.96% examples, 36926 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:11,901 : INFO : PROGRESS: at 68.13% examples, 36900 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:13,181 : INFO : PROGRESS: at 68.34% examples, 36867 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:14,494 : INFO : PROGRESS: at 68.55% examples, 36831 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:15,875 : INFO : PROGRESS: at 68.84% examples, 36832 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:16,950 : INFO : PROGRESS: at 69.14% examples, 36868 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:18,334 : INFO : PROGRESS: at 69.43% examples, 36868 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:19,355 : INFO : PROGRESS: at 69.64% examples, 36866 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:20,378 : INFO : PROGRESS: at 69.81% examples, 36840 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:21,397 : INFO : PROGRESS: at 69.98% examples, 36815 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:22,452 : INFO : PROGRESS: at 70.14% examples, 36787 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:23,712 : INFO : PROGRESS: at 70.39% examples, 36780 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:24,721 : INFO : PROGRESS: at 70.60% examples, 36778 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:25,755 : INFO : PROGRESS: at 70.81% examples, 36773 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:26,888 : INFO : PROGRESS: at 71.06% examples, 36780 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:28,025 : INFO : PROGRESS: at 71.31% examples, 36785 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:29,070 : INFO : PROGRESS: at 71.52% examples, 36780 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:30,439 : INFO : PROGRESS: at 71.82% examples, 36782 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:31,608 : INFO : PROGRESS: at 72.03% examples, 36763 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:32,664 : INFO : PROGRESS: at 72.28% examples, 36777 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:33,986 : INFO : PROGRESS: at 72.49% examples, 36742 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:35,245 : INFO : PROGRESS: at 72.83% examples, 36777 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:36,694 : INFO : PROGRESS: at 73.16% examples, 36792 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:37,728 : INFO : PROGRESS: at 73.45% examples, 36830 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:39,068 : INFO : PROGRESS: at 73.74% examples, 36836 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:40,148 : INFO : PROGRESS: at 73.99% examples, 36847 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:41,514 : INFO : PROGRESS: at 74.24% examples, 36829 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:42,515 : INFO : PROGRESS: at 74.49% examples, 36849 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:43,754 : INFO : PROGRESS: at 74.82% examples, 36885 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:44,846 : INFO : PROGRESS: at 75.07% examples, 36895 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:45,973 : INFO : PROGRESS: at 75.33% examples, 36901 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:47,113 : INFO : PROGRESS: at 75.58% examples, 36905 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:48,309 : INFO : PROGRESS: at 75.83% examples, 36905 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:49,478 : INFO : PROGRESS: at 76.08% examples, 36908 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:50,565 : INFO : PROGRESS: at 76.33% examples, 36918 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:51,882 : INFO : PROGRESS: at 76.66% examples, 36945 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:53,019 : INFO : PROGRESS: at 76.87% examples, 36930 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:54,038 : INFO : PROGRESS: at 77.12% examples, 36947 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:01:55,063 : INFO : PROGRESS: at 77.33% examples, 36943 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:56,246 : INFO : PROGRESS: at 77.58% examples, 36944 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:57,384 : INFO : PROGRESS: at 77.83% examples, 36949 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:58,907 : INFO : PROGRESS: at 78.08% examples, 36915 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:01:59,911 : INFO : PROGRESS: at 78.33% examples, 36933 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:01,049 : INFO : PROGRESS: at 78.57% examples, 36939 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:02,062 : INFO : PROGRESS: at 78.86% examples, 36976 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:03,104 : INFO : PROGRESS: at 79.07% examples, 36971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:04,416 : INFO : PROGRESS: at 79.40% examples, 36998 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:05,794 : INFO : PROGRESS: at 79.74% examples, 37018 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:07,160 : INFO : PROGRESS: at 80.07% examples, 37039 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:08,197 : INFO : PROGRESS: at 80.36% examples, 37072 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:09,209 : INFO : PROGRESS: at 80.53% examples, 37051 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:10,311 : INFO : PROGRESS: at 80.69% examples, 37020 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:11,675 : INFO : PROGRESS: at 80.91% examples, 36984 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:12,734 : INFO : PROGRESS: at 81.20% examples, 37016 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:13,923 : INFO : PROGRESS: at 81.45% examples, 37015 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:15,136 : INFO : PROGRESS: at 81.75% examples, 37032 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:16,287 : INFO : PROGRESS: at 81.96% examples, 37016 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:17,435 : INFO : PROGRESS: at 82.21% examples, 37019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:18,683 : INFO : PROGRESS: at 82.42% examples, 36994 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:19,746 : INFO : PROGRESS: at 82.63% examples, 36987 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:20,967 : INFO : PROGRESS: at 82.87% examples, 36984 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:22,005 : INFO : PROGRESS: at 83.08% examples, 36979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:23,131 : INFO : PROGRESS: at 83.29% examples, 36966 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:24,180 : INFO : PROGRESS: at 83.58% examples, 36997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:25,184 : INFO : PROGRESS: at 83.79% examples, 36996 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:26,247 : INFO : PROGRESS: at 84.04% examples, 37008 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:27,540 : INFO : PROGRESS: at 84.30% examples, 36998 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:28,645 : INFO : PROGRESS: at 84.54% examples, 37005 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:29,789 : INFO : PROGRESS: at 84.75% examples, 36990 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:30,801 : INFO : PROGRESS: at 84.96% examples, 36988 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:32,049 : INFO : PROGRESS: at 85.21% examples, 36983 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:33,408 : INFO : PROGRESS: at 85.54% examples, 37003 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:34,821 : INFO : PROGRESS: at 85.88% examples, 37019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:36,296 : INFO : PROGRESS: at 86.21% examples, 37028 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:37,315 : INFO : PROGRESS: at 86.42% examples, 37026 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:38,354 : INFO : PROGRESS: at 86.63% examples, 37022 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:39,360 : INFO : PROGRESS: at 86.84% examples, 37020 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:40,662 : INFO : PROGRESS: at 87.05% examples, 36992 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:41,730 : INFO : PROGRESS: at 87.34% examples, 37020 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:43,034 : INFO : PROGRESS: at 87.63% examples, 37027 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:44,263 : INFO : PROGRESS: at 87.92% examples, 37041 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:45,380 : INFO : PROGRESS: at 88.13% examples, 37029 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:46,407 : INFO : PROGRESS: at 88.38% examples, 37043 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:47,459 : INFO : PROGRESS: at 88.59% examples, 37037 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:48,578 : INFO : PROGRESS: at 88.80% examples, 37026 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:49,616 : INFO : PROGRESS: at 89.09% examples, 37056 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:50,674 : INFO : PROGRESS: at 89.30% examples, 37050 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 09:02:51,788 : INFO : PROGRESS: at 89.55% examples, 37057 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:52,848 : INFO : PROGRESS: at 89.77% examples, 37051 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:54,177 : INFO : PROGRESS: at 90.06% examples, 37055 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:55,191 : INFO : PROGRESS: at 90.27% examples, 37053 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:56,458 : INFO : PROGRESS: at 90.56% examples, 37063 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:02:57,696 : INFO : PROGRESS: at 90.90% examples, 37092 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:02:59,080 : INFO : PROGRESS: at 91.23% examples, 37108 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:00,104 : INFO : PROGRESS: at 91.48% examples, 37121 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:01,196 : INFO : PROGRESS: at 91.69% examples, 37112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:02,350 : INFO : PROGRESS: at 91.90% examples, 37097 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:03:03,389 : INFO : PROGRESS: at 92.07% examples, 37076 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:04,660 : INFO : PROGRESS: at 92.37% examples, 37085 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:05,720 : INFO : PROGRESS: at 92.54% examples, 37062 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:06,947 : INFO : PROGRESS: at 92.83% examples, 37075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:08,242 : INFO : PROGRESS: at 93.16% examples, 37099 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:09,246 : INFO : PROGRESS: at 93.45% examples, 37131 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:10,606 : INFO : PROGRESS: at 93.66% examples, 37100 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:11,687 : INFO : PROGRESS: at 93.91% examples, 37108 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:13,029 : INFO : PROGRESS: at 94.16% examples, 37095 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:14,034 : INFO : PROGRESS: at 94.33% examples, 37076 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:03:15,085 : INFO : PROGRESS: at 94.53% examples, 37071 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:16,268 : INFO : PROGRESS: at 94.78% examples, 37071 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:17,428 : INFO : PROGRESS: at 95.03% examples, 37073 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:18,615 : INFO : PROGRESS: at 95.33% examples, 37089 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:03:19,667 : INFO : PROGRESS: at 95.58% examples, 37099 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:20,960 : INFO : PROGRESS: at 95.87% examples, 37107 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:22,086 : INFO : PROGRESS: at 96.12% examples, 37111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:23,087 : INFO : PROGRESS: at 96.33% examples, 37110 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:24,111 : INFO : PROGRESS: at 96.54% examples, 37107 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:25,213 : INFO : PROGRESS: at 96.74% examples, 37097 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:03:26,306 : INFO : PROGRESS: at 96.95% examples, 37088 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-30 09:03:27,745 : INFO : PROGRESS: at 97.21% examples, 37068 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:28,863 : INFO : PROGRESS: at 97.42% examples, 37057 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:29,902 : INFO : PROGRESS: at 97.66% examples, 37069 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:31,376 : INFO : PROGRESS: at 97.87% examples, 37030 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:32,458 : INFO : PROGRESS: at 98.08% examples, 37022 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:33,683 : INFO : PROGRESS: at 98.37% examples, 37035 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:34,758 : INFO : PROGRESS: at 98.66% examples, 37060 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:35,828 : INFO : PROGRESS: at 98.86% examples, 37053 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-30 09:03:36,854 : INFO : PROGRESS: at 99.07% examples, 37050 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:37,945 : INFO : PROGRESS: at 99.28% examples, 37042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:39,171 : INFO : PROGRESS: at 99.53% examples, 37039 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:40,467 : INFO : PROGRESS: at 99.74% examples, 37015 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-30 09:03:41,134 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-30 09:03:41,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-30 09:03:41,521 : INFO : PROGRESS: at 99.96% examples, 37013 words/s, in_qsize 1, out_qsize 1\n",
      "2017-05-30 09:03:41,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-30 09:03:41,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-30 09:03:41,548 : INFO : training on 23920930 raw words (17518569 effective words) took 473.1s, 37026 effective words/s\n",
      "2017-05-30 09:03:41,549 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-05-30 09:03:41,706 : INFO : saving Word2Vec object under ../../Results/Yeast/models/yeast_be_model, separately None\n",
      "2017-05-30 09:03:41,707 : INFO : not storing attribute syn0norm\n",
      "2017-05-30 09:03:41,708 : INFO : not storing attribute cum_table\n",
      "2017-05-30 09:03:43,761 : INFO : saved ../../Results/Yeast/models/yeast_be_model\n"
     ]
    }
   ],
   "source": [
    "yeast_w2v_model_strict = pred.make_w2v_model(yeast_strict_real, 'Yeast/models/yeast_strict')\n",
    "yeast_w2v_model_gen = pred.make_w2v_model(yeast_gen_real, 'Yeast/models/yeast_gen')\n",
    "yeast_w2v_model_be = pred.make_w2v_model(yeast_be_real, 'Yeast/models/yeast_be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Core-scripts/prediction.py:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    }
   ],
   "source": [
    "for seed in random_seeds:\n",
    "    data_name = '../../Results/Yeast/train_test/yeast_tr_te_split_' + str(seed)\n",
    "    train_data = pickle.load(open(data_name + '_train_data.pkl', 'rb'))\n",
    "    train_labels = pickle.load(open(data_name + '_train_labels.pkl', 'rb'))\n",
    "    test_data = pickle.load(open(data_name + '_test_data.pkl', 'rb'))\n",
    "    test_labels = pickle.load(open(data_name + '_test_labels.pkl', 'rb'))\n",
    "\n",
    "    w2v_train_vecs, w2v_test_vecs = pred.word_2_vec_feat_vecs(train_data, test_data, yeast_w2v_model_strict, feature_count=800)\n",
    "\n",
    "    strict_list_SR_dims_param = [w2v_train_vecs, w2v_test_vecs,\n",
    "                                 train_labels, test_labels]\n",
    "    w2v_train_vecs, w2v_test_vecs = pred.word_2_vec_feat_vecs(train_data, test_data, yeast_w2v_model_gen, feature_count=800)\n",
    "\n",
    "    strict_list_GEN_dims_param = [w2v_train_vecs, w2v_test_vecs,\n",
    "                                  train_labels, test_labels]\n",
    "\n",
    "    w2v_train_vecs, w2v_test_vecs = pred.word_2_vec_feat_vecs(train_data, test_data, yeast_w2v_model_be, feature_count=800)\n",
    "\n",
    "    strict_list_BE_dims_param = [w2v_train_vecs, w2v_test_vecs,\n",
    "                                 train_labels, test_labels]\n",
    "\n",
    "    pickle.dump(strict_list_SR_dims_param, open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'wb'))\n",
    "    pickle.dump(strict_list_GEN_dims_param, open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'wb'))\n",
    "    pickle.dump(strict_list_BE_dims_param, open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train_vecs, train_labels, w2v_model_type, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param=alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_vecs, \n",
    "                              label=train_labels)\n",
    "        cvresult = xgb.cv(xgb_param, \n",
    "                          xgtrain, \n",
    "                          num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds, \n",
    "                          metrics='auc', \n",
    "                          early_stopping_rounds=50)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        \n",
    "    #fit the algorithm on the data\n",
    "    alg.fit(train_vecs, train_labels, eval_metric='auc')\n",
    "    \n",
    "    #Predict training set:\n",
    "    train_predictions = alg.predict(train_vecs)\n",
    "    train_predprob = alg.predict_proba(train_vecs)[:,1]\n",
    "    \n",
    "    #Print Model report:\n",
    "    print(w2v_model_type, '\\nModel Report')\n",
    "    print(w2v_model_type, 'Accuracy: %.4g' % metrics.accuracy_score(train_labels, train_predictions))\n",
    "    print(w2v_model_type, 'AUC Score (Train): %f' % metrics.roc_auc_score(train_labels, train_predprob))\n",
    "    \n",
    "#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "\n",
    "    error = 1-metrics.accuracy_score(train_labels, train_predictions)\n",
    "    auc = metrics.roc_auc_score(train_labels, train_predprob)\n",
    "    \n",
    "    return error, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6086\n",
      "STRICT AUC Score (Train): 0.607743\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5843\n",
      "GEN AUC Score (Train): 0.581177\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5965\n",
      "BE AUC Score (Train): 0.598749\n",
      "235\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6004\n",
      "STRICT AUC Score (Train): 0.614761\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6044\n",
      "GEN AUC Score (Train): 0.599407\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6018\n",
      "BE AUC Score (Train): 0.592301\n",
      "905\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6131\n",
      "STRICT AUC Score (Train): 0.627748\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5965\n",
      "GEN AUC Score (Train): 0.603445\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5879\n",
      "BE AUC Score (Train): 0.571791\n",
      "2895\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5841\n",
      "STRICT AUC Score (Train): 0.587349\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5781\n",
      "GEN AUC Score (Train): 0.560142\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5917\n",
      "BE AUC Score (Train): 0.584521\n",
      "3462\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5953\n",
      "STRICT AUC Score (Train): 0.613894\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5783\n",
      "GEN AUC Score (Train): 0.536462\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5866\n",
      "BE AUC Score (Train): 0.578209\n",
      "4225\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5984\n",
      "STRICT AUC Score (Train): 0.611454\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5823\n",
      "GEN AUC Score (Train): 0.547984\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5849\n",
      "BE AUC Score (Train): 0.578985\n",
      "5056\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5963\n",
      "STRICT AUC Score (Train): 0.603952\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5866\n",
      "GEN AUC Score (Train): 0.568760\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6063\n",
      "BE AUC Score (Train): 0.601457\n",
      "5192\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5991\n",
      "STRICT AUC Score (Train): 0.607509\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5831\n",
      "GEN AUC Score (Train): 0.547776\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6036\n",
      "BE AUC Score (Train): 0.600838\n",
      "7751\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6085\n",
      "STRICT AUC Score (Train): 0.628763\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.593\n",
      "GEN AUC Score (Train): 0.587273\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6015\n",
      "BE AUC Score (Train): 0.592454\n",
      "7813\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.593\n",
      "STRICT AUC Score (Train): 0.606322\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5853\n",
      "GEN AUC Score (Train): 0.573034\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.586\n",
      "BE AUC Score (Train): 0.573165\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(learning_rate = 0.1, \n",
    "                     n_estimators=1000, \n",
    "                     max_depth=5, \n",
    "                     min_child_weight=1, \n",
    "                     gamma=0, \n",
    "                     subsample=0.8, \n",
    "                     colsample_bytree=0.8, \n",
    "                     objective='binary:logistic', \n",
    "                     nthread=4, \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=24)\n",
    "\n",
    "strict_error_list = []\n",
    "strict_auc_list = []\n",
    "gen_error_list = []\n",
    "gen_auc_list = []\n",
    "be_error_list = []\n",
    "be_auc_list = []\n",
    "\n",
    "\n",
    "for seed in random_seeds:  \n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    print(seed)\n",
    "    strict_error, strict_auc = modelfit(xgb1, strict_list[0], strict_list[2], 'STRICT')\n",
    "    gen_error, gen_auc = modelfit(xgb1, gen_list[0], gen_list[2], 'GEN')\n",
    "    be_error, be_auc = modelfit(xgb1, be_list[0], be_list[2], 'BE')\n",
    "    \n",
    "    strict_error_list.append(strict_error)\n",
    "    strict_auc_list.append(strict_auc)\n",
    "    gen_error_list.append(gen_error)\n",
    "    gen_auc_list.append(gen_auc)\n",
    "    be_error_list.append(be_error)\n",
    "    be_auc_list.append(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.637\n",
      "STRICT AUC Score (Train): 0.737125\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6552\n",
      "GEN AUC Score (Train): 0.748667\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6712\n",
      "BE AUC Score (Train): 0.785685\n",
      "235\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6624\n",
      "STRICT AUC Score (Train): 0.739747\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6504\n",
      "GEN AUC Score (Train): 0.738340\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6855\n",
      "BE AUC Score (Train): 0.784790\n",
      "905\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6512\n",
      "STRICT AUC Score (Train): 0.746496\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6653\n",
      "GEN AUC Score (Train): 0.765681\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6767\n",
      "BE AUC Score (Train): 0.790130\n",
      "2895\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6491\n",
      "STRICT AUC Score (Train): 0.744200\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6756\n",
      "GEN AUC Score (Train): 0.776996\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.687\n",
      "BE AUC Score (Train): 0.789860\n",
      "3462\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6515\n",
      "STRICT AUC Score (Train): 0.742703\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6644\n",
      "GEN AUC Score (Train): 0.781831\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6758\n",
      "BE AUC Score (Train): 0.787186\n",
      "4225\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6394\n",
      "STRICT AUC Score (Train): 0.736652\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6788\n",
      "GEN AUC Score (Train): 0.775084\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6611\n",
      "BE AUC Score (Train): 0.766342\n",
      "5056\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6279\n",
      "STRICT AUC Score (Train): 0.690399\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6741\n",
      "GEN AUC Score (Train): 0.780861\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6702\n",
      "BE AUC Score (Train): 0.775976\n",
      "5192\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.637\n",
      "STRICT AUC Score (Train): 0.728524\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6564\n",
      "GEN AUC Score (Train): 0.761131\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6617\n",
      "BE AUC Score (Train): 0.768612\n",
      "7751\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6441\n",
      "STRICT AUC Score (Train): 0.738843\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.65\n",
      "GEN AUC Score (Train): 0.757977\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6731\n",
      "BE AUC Score (Train): 0.786600\n",
      "7813\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6284\n",
      "STRICT AUC Score (Train): 0.716465\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6749\n",
      "GEN AUC Score (Train): 0.782777\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6802\n",
      "BE AUC Score (Train): 0.784594\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(learning_rate = 0.1, \n",
    "                     n_estimators=1000, \n",
    "                     max_depth=5, \n",
    "                     min_child_weight=1, \n",
    "                     gamma=0, \n",
    "                     subsample=0.8, \n",
    "                     colsample_bytree=0.8, \n",
    "                     objective='binary:logistic', \n",
    "                     nthread=4, \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=24)\n",
    "\n",
    "strict_error_list = []\n",
    "strict_auc_list = []\n",
    "gen_error_list = []\n",
    "gen_auc_list = []\n",
    "be_error_list = []\n",
    "be_auc_list = []\n",
    "\n",
    "\n",
    "for seed in random_seeds:  \n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    print(seed)\n",
    "    strict_error, strict_auc = modelfit(xgb1, strict_list[0], strict_list[2], 'STRICT')\n",
    "    gen_error, gen_auc = modelfit(xgb1, gen_list[0], gen_list[2], 'GEN')\n",
    "    be_error, be_auc = modelfit(xgb1, be_list[0], be_list[2], 'BE')\n",
    "    \n",
    "    strict_error_list.append(strict_error)\n",
    "    strict_auc_list.append(strict_auc)\n",
    "    gen_error_list.append(gen_error)\n",
    "    gen_auc_list.append(gen_auc)\n",
    "    be_error_list.append(be_error)\n",
    "    be_auc_list.append(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8676\n",
      "STRICT AUC Score (Train): 0.950801\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8706\n",
      "GEN AUC Score (Train): 0.958366\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8997\n",
      "BE AUC Score (Train): 0.973117\n",
      "235\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.845\n",
      "STRICT AUC Score (Train): 0.948836\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.851\n",
      "GEN AUC Score (Train): 0.956173\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8642\n",
      "BE AUC Score (Train): 0.963154\n",
      "905\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8262\n",
      "STRICT AUC Score (Train): 0.938901\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8519\n",
      "GEN AUC Score (Train): 0.961507\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8753\n",
      "BE AUC Score (Train): 0.970509\n",
      "2895\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8137\n",
      "STRICT AUC Score (Train): 0.930456\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8382\n",
      "GEN AUC Score (Train): 0.950308\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8613\n",
      "BE AUC Score (Train): 0.961133\n",
      "3462\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8333\n",
      "STRICT AUC Score (Train): 0.938910\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8718\n",
      "GEN AUC Score (Train): 0.960258\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8675\n",
      "BE AUC Score (Train): 0.957545\n",
      "4225\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8317\n",
      "STRICT AUC Score (Train): 0.939965\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8694\n",
      "GEN AUC Score (Train): 0.960917\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8771\n",
      "BE AUC Score (Train): 0.966802\n",
      "5056\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8071\n",
      "STRICT AUC Score (Train): 0.931239\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8435\n",
      "GEN AUC Score (Train): 0.955587\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8662\n",
      "BE AUC Score (Train): 0.969273\n",
      "5192\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8452\n",
      "STRICT AUC Score (Train): 0.948254\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8572\n",
      "GEN AUC Score (Train): 0.956580\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8779\n",
      "BE AUC Score (Train): 0.968184\n",
      "7751\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8424\n",
      "STRICT AUC Score (Train): 0.940002\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8592\n",
      "GEN AUC Score (Train): 0.950991\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8861\n",
      "BE AUC Score (Train): 0.969109\n",
      "7813\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.8375\n",
      "STRICT AUC Score (Train): 0.939679\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.8762\n",
      "GEN AUC Score (Train): 0.967245\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.8876\n",
      "BE AUC Score (Train): 0.972914\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(learning_rate = 0.1, \n",
    "                     n_estimators=1000, \n",
    "                     max_depth=6, \n",
    "                     min_child_weight=1, \n",
    "                     gamma=0.2, \n",
    "                     subsample=0.6, \n",
    "                     colsample_bytree=0.8,\n",
    "                     reg_alpha = 0.01,\n",
    "                     objective='binary:logistic', \n",
    "                     nthread=4, \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=24)\n",
    "\n",
    "strict_error_list = []\n",
    "strict_auc_list = []\n",
    "gen_error_list = []\n",
    "gen_auc_list = []\n",
    "be_error_list = []\n",
    "be_auc_list = []\n",
    "\n",
    "\n",
    "for seed in random_seeds:  \n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    print(seed)\n",
    "    strict_error, strict_auc = modelfit(xgb1, strict_list[0], strict_list[2], 'STRICT')\n",
    "    gen_error, gen_auc = modelfit(xgb1, gen_list[0], gen_list[2], 'GEN')\n",
    "    be_error, be_auc = modelfit(xgb1, be_list[0], be_list[2], 'BE')\n",
    "    \n",
    "    strict_error_list.append(strict_error)\n",
    "    strict_auc_list.append(strict_auc)\n",
    "    gen_error_list.append(gen_error)\n",
    "    gen_auc_list.append(gen_auc)\n",
    "    be_error_list.append(be_error)\n",
    "    be_auc_list.append(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict Results Error:  0.330430479588 , Auc:  0.768074209551\n",
      "Gen Results Error:  0.364579946523 , Auc:  0.707197019221\n",
      "Be Results Error:  0.344158176436 , Auc:  0.74322406605\n"
     ]
    }
   ],
   "source": [
    "print('Strict Results Error: ', np.mean(strict_error_list), ', Auc: ', np.mean(strict_auc_list))\n",
    "print('Gen Results Error: ', np.mean(gen_error_list), ', Auc: ', np.mean(gen_auc_list))\n",
    "print('Be Results Error: ', np.mean(be_error_list), ', Auc: ', np.mean(be_auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict Results Error:  0.165030797764 , Auc:  0.94070425964\n",
      "Gen Results Error:  0.14109773617 , Auc:  0.957793160646\n",
      "Be Results Error:  0.123702592979 , Auc:  0.967173857003\n"
     ]
    }
   ],
   "source": [
    "print('Strict Results Error: ', np.mean(strict_error_list), ', Auc: ', np.mean(strict_auc_list))\n",
    "print('Gen Results Error: ', np.mean(gen_error_list), ', Auc: ', np.mean(gen_auc_list))\n",
    "print('Be Results Error: ', np.mean(be_error_list), ', Auc: ', np.mean(be_auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':[3,4,5,6,7,8,9,10],\n",
    "    'min_child_weight':[1,2,3,4,5,6]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "                                                  n_estimators=140, \n",
    "                                                  max_depth=5, \n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, \n",
    "                                                  objective='binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1, \n",
    "                                                  seed=24), \n",
    "                        param_grid=param_test1, \n",
    "                        scoring='roc_auc',  \n",
    "                        iid=False, \n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "strict_param_test1 = []\n",
    "for seed in [144]:\n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gsearch1.fit(strict_list[0], strict_list[2])\n",
    "    strict_param_test1.append((seed, (gsearch1.best_params_, gsearch1.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen_param_test1 = []\n",
    "for seed in [144]:\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gsearch1.fit(gen_list[0], gen_list[2])\n",
    "    gen_param_test1.append((seed, (gsearch1.best_params_, gsearch1.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "be_param_test1 = []\n",
    "for seed in [144]:\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gsearch1.fit(be_list[0], be_list[2])\n",
    "    be_param_test1.append((seed, (gsearch1.best_params_, gsearch1.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(144, ({'max_depth': 3, 'min_child_weight': 1}, 0.5184627231701338))] [(144, ({'max_depth': 3, 'min_child_weight': 5}, 0.5033950980591407))] [(144, ({'max_depth': 6, 'min_child_weight': 6}, 0.4984421837963776))]\n"
     ]
    }
   ],
   "source": [
    "print(strict_param_test1, gen_param_test1, be_param_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.712\n",
      "STRICT AUC Score (Train): 0.869563\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6677\n",
      "GEN AUC Score (Train): 0.787012\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5891\n",
      "BE AUC Score (Train): 0.640011\n",
      "235\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.581\n",
      "STRICT AUC Score (Train): 0.660918\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.586\n",
      "GEN AUC Score (Train): 0.627057\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5887\n",
      "BE AUC Score (Train): 0.651093\n",
      "905\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5811\n",
      "STRICT AUC Score (Train): 0.656544\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5906\n",
      "GEN AUC Score (Train): 0.629023\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5933\n",
      "BE AUC Score (Train): 0.649648\n",
      "2895\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5872\n",
      "STRICT AUC Score (Train): 0.674281\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5776\n",
      "GEN AUC Score (Train): 0.640244\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5947\n",
      "BE AUC Score (Train): 0.655433\n",
      "3462\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5994\n",
      "STRICT AUC Score (Train): 0.673769\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5836\n",
      "GEN AUC Score (Train): 0.608703\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5922\n",
      "BE AUC Score (Train): 0.645321\n",
      "4225\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5956\n",
      "STRICT AUC Score (Train): 0.672983\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5818\n",
      "GEN AUC Score (Train): 0.634002\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6013\n",
      "BE AUC Score (Train): 0.660765\n",
      "5056\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5872\n",
      "STRICT AUC Score (Train): 0.668986\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5911\n",
      "GEN AUC Score (Train): 0.614930\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.596\n",
      "BE AUC Score (Train): 0.650820\n",
      "5192\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5955\n",
      "STRICT AUC Score (Train): 0.671295\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5789\n",
      "GEN AUC Score (Train): 0.622833\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5859\n",
      "BE AUC Score (Train): 0.641429\n",
      "7751\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6027\n",
      "STRICT AUC Score (Train): 0.686008\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5833\n",
      "GEN AUC Score (Train): 0.618640\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5955\n",
      "BE AUC Score (Train): 0.641817\n",
      "7813\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5836\n",
      "STRICT AUC Score (Train): 0.670016\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5932\n",
      "GEN AUC Score (Train): 0.613517\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5963\n",
      "BE AUC Score (Train): 0.662262\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(learning_rate = 0.1, \n",
    "                     n_estimators=1000, \n",
    "                     max_depth=3, \n",
    "                     min_child_weight=3, \n",
    "                     gamma=0, \n",
    "                     subsample=0.8, \n",
    "                     colsample_bytree=0.8, \n",
    "                     objective='binary:logistic', \n",
    "                     nthread=4, \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=24)\n",
    "\n",
    "strict_error_list = []\n",
    "strict_auc_list = []\n",
    "gen_error_list = []\n",
    "gen_auc_list = []\n",
    "be_error_list = []\n",
    "be_auc_list = []\n",
    "\n",
    "\n",
    "for seed in random_seeds:  \n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    print(seed)\n",
    "    strict_error, strict_auc = modelfit(xgb2, strict_list[0], strict_list[2], 'STRICT')\n",
    "    gen_error, gen_auc = modelfit(xgb2, gen_list[0], gen_list[2], 'GEN')\n",
    "    be_error, be_auc = modelfit(xgb2, be_list[0], be_list[2], 'BE')\n",
    "    \n",
    "    strict_error_list.append(strict_error)\n",
    "    strict_auc_list.append(strict_auc)\n",
    "    gen_error_list.append(gen_error)\n",
    "    gen_auc_list.append(gen_auc)\n",
    "    be_error_list.append(be_error)\n",
    "    be_auc_list.append(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
