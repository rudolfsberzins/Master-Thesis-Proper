{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Core-scripts/')\n",
    "\n",
    "from parse_and_prepare import ProteinProteinInteractionClassifier as ppi\n",
    "import file_readers as fr\n",
    "import prediction as pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "yeast_strict_real = pickle.load(open('../../Results/Yeast/yeast_mentions_strict_real.pkl', 'rb'))\n",
    "yeast_gen_real = pickle.load(open('../../Results/Yeast/yeast_mentions_gen_real.pkl', 'rb'))\n",
    "yeast_be_real = pickle.load(open('../../Results/Yeast/yeast_mentions_be_real.pkl', 'rb'))\n",
    "random_seeds = [144, 235, 905, 2895, 3462, 4225, 5056, 5192, 7751, 7813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for seed in random_seeds:\n",
    "    real_tr_te_name = 'Yeast/train_test/yeast_tr_te_split_' + str(seed)\n",
    "    train_data, b, c, d = pred.manual_train_test_split(yeast_strict_real, real_tr_te_name, random_state=seed ,test_set_prop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-16 14:30:14,727 : INFO : collecting all words and their counts\n",
      "2017-05-16 14:30:14,728 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-16 14:30:14,765 : INFO : collected 11431 word types from a corpus of 188505 raw words and 7145 sentences\n",
      "2017-05-16 14:30:14,765 : INFO : Loading a fresh vocabulary\n",
      "2017-05-16 14:30:14,780 : INFO : min_count=6 retains 2978 unique words (26% of original 11431, drops 8453)\n",
      "2017-05-16 14:30:14,781 : INFO : min_count=6 leaves 173585 word corpus (92% of original 188505, drops 14920)\n",
      "2017-05-16 14:30:14,791 : INFO : deleting the raw counts dictionary of 11431 items\n",
      "2017-05-16 14:30:14,793 : INFO : sample=0.0001 downsamples 549 most-common words\n",
      "2017-05-16 14:30:14,794 : INFO : downsampling leaves estimated 74593 word corpus (43.0% of prior 173585)\n",
      "2017-05-16 14:30:14,795 : INFO : estimated required memory for 2978 words and 600 dimensions: 15783400 bytes\n",
      "2017-05-16 14:30:14,802 : INFO : resetting layer weights\n",
      "2017-05-16 14:30:14,852 : INFO : training model with 4 workers on 2978 vocabulary and 600 features, using sg=0 hs=0 sample=0.0001 negative=5 window=7\n",
      "2017-05-16 14:30:14,853 : INFO : expecting 7145 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-16 14:30:15,589 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-16 14:30:15,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-16 14:30:15,602 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-16 14:30:15,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-16 14:30:15,606 : INFO : training on 942525 raw words (373011 effective words) took 0.7s, 498521 effective words/s\n",
      "2017-05-16 14:30:15,606 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-05-16 14:30:15,624 : INFO : saving Word2Vec object under ../../Results/Yeast/models/yeast_strict_model, separately None\n",
      "2017-05-16 14:30:15,625 : INFO : not storing attribute syn0norm\n",
      "2017-05-16 14:30:15,625 : INFO : not storing attribute cum_table\n",
      "2017-05-16 14:30:16,142 : INFO : saved ../../Results/Yeast/models/yeast_strict_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-16 14:30:16,668 : INFO : collecting all words and their counts\n",
      "2017-05-16 14:30:16,669 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-16 14:30:16,709 : INFO : PROGRESS: at sentence #10000, processed 240608 words, keeping 11144 word types\n",
      "2017-05-16 14:30:16,752 : INFO : PROGRESS: at sentence #20000, processed 483529 words, keeping 14874 word types\n",
      "2017-05-16 14:30:16,795 : INFO : PROGRESS: at sentence #30000, processed 727180 words, keeping 17441 word types\n",
      "2017-05-16 14:30:16,838 : INFO : PROGRESS: at sentence #40000, processed 969859 words, keeping 19663 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-16 14:30:16,871 : INFO : collected 21147 word types from a corpus of 1155938 raw words and 47662 sentences\n",
      "2017-05-16 14:30:16,872 : INFO : Loading a fresh vocabulary\n",
      "2017-05-16 14:30:16,893 : INFO : min_count=6 retains 7355 unique words (34% of original 21147, drops 13792)\n",
      "2017-05-16 14:30:16,894 : INFO : min_count=6 leaves 1130505 word corpus (97% of original 1155938, drops 25433)\n",
      "2017-05-16 14:30:16,913 : INFO : deleting the raw counts dictionary of 21147 items\n",
      "2017-05-16 14:30:16,914 : INFO : sample=0.0001 downsamples 521 most-common words\n",
      "2017-05-16 14:30:16,915 : INFO : downsampling leaves estimated 513926 word corpus (45.5% of prior 1130505)\n",
      "2017-05-16 14:30:16,916 : INFO : estimated required memory for 7355 words and 600 dimensions: 38981500 bytes\n",
      "2017-05-16 14:30:16,945 : INFO : resetting layer weights\n",
      "2017-05-16 14:30:17,058 : INFO : training model with 4 workers on 7355 vocabulary and 600 features, using sg=0 hs=0 sample=0.0001 negative=5 window=7\n",
      "2017-05-16 14:30:17,058 : INFO : expecting 47662 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-16 14:30:18,070 : INFO : PROGRESS: at 17.97% examples, 458897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:19,075 : INFO : PROGRESS: at 35.25% examples, 450062 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-16 14:30:20,081 : INFO : PROGRESS: at 52.70% examples, 448726 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:21,092 : INFO : PROGRESS: at 70.16% examples, 447475 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-16 14:30:22,110 : INFO : PROGRESS: at 87.64% examples, 446168 words/s, in_qsize 8, out_qsize 1\n",
      "2017-05-16 14:30:22,789 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-16 14:30:22,791 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-16 14:30:22,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-16 14:30:22,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-16 14:30:22,809 : INFO : training on 5779690 raw words (2570101 effective words) took 5.7s, 447306 effective words/s\n",
      "2017-05-16 14:30:22,810 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-05-16 14:30:22,853 : INFO : saving Word2Vec object under ../../Results/Yeast/models/yeast_gen_model, separately None\n",
      "2017-05-16 14:30:22,854 : INFO : not storing attribute syn0norm\n",
      "2017-05-16 14:30:22,854 : INFO : not storing attribute cum_table\n",
      "2017-05-16 14:30:23,218 : INFO : saved ../../Results/Yeast/models/yeast_gen_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing datasets sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-16 14:30:25,563 : INFO : collecting all words and their counts\n",
      "2017-05-16 14:30:25,563 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-16 14:30:25,604 : INFO : PROGRESS: at sentence #10000, processed 229990 words, keeping 12269 word types\n",
      "2017-05-16 14:30:25,642 : INFO : PROGRESS: at sentence #20000, processed 459245 words, keeping 16803 word types\n",
      "2017-05-16 14:30:25,685 : INFO : PROGRESS: at sentence #30000, processed 688639 words, keeping 20010 word types\n",
      "2017-05-16 14:30:25,728 : INFO : PROGRESS: at sentence #40000, processed 916935 words, keeping 22755 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-16 14:30:25,771 : INFO : PROGRESS: at sentence #50000, processed 1144943 words, keeping 25062 word types\n",
      "2017-05-16 14:30:25,818 : INFO : PROGRESS: at sentence #60000, processed 1373907 words, keeping 27120 word types\n",
      "2017-05-16 14:30:25,861 : INFO : PROGRESS: at sentence #70000, processed 1602580 words, keeping 29006 word types\n",
      "2017-05-16 14:30:25,906 : INFO : PROGRESS: at sentence #80000, processed 1832124 words, keeping 30626 word types\n",
      "2017-05-16 14:30:25,950 : INFO : PROGRESS: at sentence #90000, processed 2061054 words, keeping 32180 word types\n",
      "2017-05-16 14:30:25,993 : INFO : PROGRESS: at sentence #100000, processed 2288480 words, keeping 33620 word types\n",
      "2017-05-16 14:30:26,042 : INFO : PROGRESS: at sentence #110000, processed 2516418 words, keeping 34947 word types\n",
      "2017-05-16 14:30:26,090 : INFO : PROGRESS: at sentence #120000, processed 2746160 words, keeping 36208 word types\n",
      "2017-05-16 14:30:26,137 : INFO : PROGRESS: at sentence #130000, processed 2975457 words, keeping 37427 word types\n",
      "2017-05-16 14:30:26,180 : INFO : PROGRESS: at sentence #140000, processed 3203174 words, keeping 38606 word types\n",
      "2017-05-16 14:30:26,225 : INFO : PROGRESS: at sentence #150000, processed 3432243 words, keeping 39705 word types\n",
      "2017-05-16 14:30:26,268 : INFO : PROGRESS: at sentence #160000, processed 3662323 words, keeping 40806 word types\n",
      "2017-05-16 14:30:26,312 : INFO : PROGRESS: at sentence #170000, processed 3891699 words, keeping 41789 word types\n",
      "2017-05-16 14:30:26,358 : INFO : PROGRESS: at sentence #180000, processed 4120258 words, keeping 42745 word types\n",
      "2017-05-16 14:30:26,406 : INFO : PROGRESS: at sentence #190000, processed 4348504 words, keeping 43624 word types\n",
      "2017-05-16 14:30:26,450 : INFO : PROGRESS: at sentence #200000, processed 4577987 words, keeping 44490 word types\n",
      "2017-05-16 14:30:26,490 : INFO : collected 45300 word types from a corpus of 4784186 raw words and 208973 sentences\n",
      "2017-05-16 14:30:26,491 : INFO : Loading a fresh vocabulary\n",
      "2017-05-16 14:30:26,539 : INFO : min_count=6 retains 15261 unique words (33% of original 45300, drops 30039)\n",
      "2017-05-16 14:30:26,539 : INFO : min_count=6 leaves 4728807 word corpus (98% of original 4784186, drops 55379)\n",
      "2017-05-16 14:30:26,575 : INFO : deleting the raw counts dictionary of 45300 items\n",
      "2017-05-16 14:30:26,578 : INFO : sample=0.0001 downsamples 525 most-common words\n",
      "2017-05-16 14:30:26,579 : INFO : downsampling leaves estimated 2262232 word corpus (47.8% of prior 4728807)\n",
      "2017-05-16 14:30:26,580 : INFO : estimated required memory for 15261 words and 600 dimensions: 80883300 bytes\n",
      "2017-05-16 14:30:26,630 : INFO : resetting layer weights\n",
      "2017-05-16 14:30:26,857 : INFO : training model with 4 workers on 15261 vocabulary and 600 features, using sg=0 hs=0 sample=0.0001 negative=5 window=7\n",
      "2017-05-16 14:30:26,858 : INFO : expecting 208973 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-16 14:30:27,879 : INFO : PROGRESS: at 3.08% examples, 345873 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:28,897 : INFO : PROGRESS: at 6.85% examples, 382213 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:29,901 : INFO : PROGRESS: at 10.57% examples, 394084 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:30,905 : INFO : PROGRESS: at 14.29% examples, 400363 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:31,913 : INFO : PROGRESS: at 18.00% examples, 403529 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:32,923 : INFO : PROGRESS: at 21.75% examples, 406484 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:33,925 : INFO : PROGRESS: at 25.47% examples, 408493 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:34,955 : INFO : PROGRESS: at 29.10% examples, 407270 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-16 14:30:35,956 : INFO : PROGRESS: at 32.61% examples, 406081 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:36,965 : INFO : PROGRESS: at 36.36% examples, 407509 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:37,971 : INFO : PROGRESS: at 40.08% examples, 408459 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:38,975 : INFO : PROGRESS: at 43.79% examples, 409324 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:39,980 : INFO : PROGRESS: at 47.30% examples, 408189 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-16 14:30:41,003 : INFO : PROGRESS: at 50.53% examples, 404355 words/s, in_qsize 8, out_qsize 2\n",
      "2017-05-16 14:30:42,007 : INFO : PROGRESS: at 53.19% examples, 397519 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-16 14:30:43,026 : INFO : PROGRESS: at 55.78% examples, 390530 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-16 14:30:44,040 : INFO : PROGRESS: at 58.12% examples, 382906 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:45,049 : INFO : PROGRESS: at 60.66% examples, 377470 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:46,060 : INFO : PROGRESS: at 63.37% examples, 373588 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-16 14:30:47,073 : INFO : PROGRESS: at 66.88% examples, 374488 words/s, in_qsize 8, out_qsize 1\n",
      "2017-05-16 14:30:48,077 : INFO : PROGRESS: at 70.44% examples, 375660 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:49,083 : INFO : PROGRESS: at 73.99% examples, 376769 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:50,089 : INFO : PROGRESS: at 77.62% examples, 378131 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-16 14:30:51,106 : INFO : PROGRESS: at 81.20% examples, 378997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:52,113 : INFO : PROGRESS: at 84.96% examples, 380752 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:53,120 : INFO : PROGRESS: at 88.43% examples, 381074 words/s, in_qsize 6, out_qsize 1\n",
      "2017-05-16 14:30:54,122 : INFO : PROGRESS: at 91.19% examples, 378487 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:55,146 : INFO : PROGRESS: at 94.07% examples, 376312 words/s, in_qsize 8, out_qsize 1\n",
      "2017-05-16 14:30:56,150 : INFO : PROGRESS: at 97.37% examples, 376106 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-16 14:30:56,956 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-16 14:30:56,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-16 14:30:56,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-16 14:30:56,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-16 14:30:56,989 : INFO : training on 23920930 raw words (11311947 effective words) took 30.1s, 375538 effective words/s\n",
      "2017-05-16 14:30:56,990 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-05-16 14:30:57,131 : INFO : saving Word2Vec object under ../../Results/Yeast/models/yeast_be_model, separately None\n",
      "2017-05-16 14:30:57,132 : INFO : not storing attribute syn0norm\n",
      "2017-05-16 14:30:57,132 : INFO : not storing attribute cum_table\n",
      "2017-05-16 14:30:58,303 : INFO : saved ../../Results/Yeast/models/yeast_be_model\n"
     ]
    }
   ],
   "source": [
    "yeast_w2v_model_strict = pred.make_w2v_model(yeast_strict_real, 'Yeast/models/yeast_strict')\n",
    "yeast_w2v_model_gen = pred.make_w2v_model(yeast_gen_real, 'Yeast/models/yeast_gen')\n",
    "yeast_w2v_model_be = pred.make_w2v_model(yeast_be_real, 'Yeast/models/yeast_be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for seed in random_seeds:\n",
    "    data_name = '../../Results/Yeast/train_test/yeast_tr_te_split_' + str(seed)\n",
    "    train_data = pickle.load(open(data_name + '_train_data.pkl', 'rb'))\n",
    "    train_labels = pickle.load(open(data_name + '_train_labels.pkl', 'rb'))\n",
    "    test_data = pickle.load(open(data_name + '_test_data.pkl', 'rb'))\n",
    "    test_labels = pickle.load(open(data_name + '_test_labels.pkl', 'rb'))\n",
    "\n",
    "    w2v_train_vecs, w2v_test_vecs = pred.word_2_vec_feat_vecs(train_data, test_data, yeast_w2v_model_strict, feature_count=600)\n",
    "\n",
    "    strict_list_SR_dims_param = [w2v_train_vecs, w2v_test_vecs,\n",
    "                                 train_labels, test_labels]\n",
    "\n",
    "    w2v_train_vecs, w2v_test_vecs = pred.word_2_vec_feat_vecs(train_data, test_data, yeast_w2v_model_gen, feature_count=600)\n",
    "\n",
    "    strict_list_GEN_dims_param = [w2v_train_vecs, w2v_test_vecs,\n",
    "                                  train_labels, test_labels]\n",
    "\n",
    "    w2v_train_vecs, w2v_test_vecs = pred.word_2_vec_feat_vecs(train_data, test_data, yeast_w2v_model_be, feature_count=600)\n",
    "\n",
    "    strict_list_BE_dims_param = [w2v_train_vecs, w2v_test_vecs,\n",
    "                                 train_labels, test_labels]\n",
    "\n",
    "    pickle.dump(strict_list_SR_dims_param, open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'wb'))\n",
    "    pickle.dump(strict_list_GEN_dims_param, open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'wb'))\n",
    "    pickle.dump(strict_list_BE_dims_param, open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train_vecs, train_labels, w2v_model_type, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param=alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_vecs, \n",
    "                              label=train_labels)\n",
    "        cvresult = xgb.cv(xgb_param, \n",
    "                          xgtrain, \n",
    "                          num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds, \n",
    "                          metrics='auc', \n",
    "                          early_stopping_rounds=50)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        \n",
    "    #fit the algorithm on the data\n",
    "    alg.fit(train_vecs, train_labels, eval_metric='auc')\n",
    "    \n",
    "    #Predict training set:\n",
    "    train_predictions = alg.predict(train_vecs)\n",
    "    train_predprob = alg.predict_proba(train_vecs)[:,1]\n",
    "    \n",
    "    #Print Model report:\n",
    "    print(w2v_model_type, '\\nModel Report')\n",
    "    print(w2v_model_type, 'Accuracy: %.4g' % metrics.accuracy_score(train_labels, train_predictions))\n",
    "    print(w2v_model_type, 'AUC Score (Train): %f' % metrics.roc_auc_score(train_labels, train_predprob))\n",
    "    \n",
    "#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "\n",
    "    error = 1-metrics.accuracy_score(train_labels, train_predictions)\n",
    "    auc = metrics.roc_auc_score(train_labels, train_predprob)\n",
    "    \n",
    "    return error, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6566\n",
      "STRICT AUC Score (Train): 0.740780\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6362\n",
      "GEN AUC Score (Train): 0.714120\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6472\n",
      "BE AUC Score (Train): 0.736452\n",
      "235\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6621\n",
      "STRICT AUC Score (Train): 0.761532\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6273\n",
      "GEN AUC Score (Train): 0.695405\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.65\n",
      "BE AUC Score (Train): 0.749577\n",
      "905\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6447\n",
      "STRICT AUC Score (Train): 0.742371\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6378\n",
      "GEN AUC Score (Train): 0.709266\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6521\n",
      "BE AUC Score (Train): 0.738487\n",
      "2895\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6724\n",
      "STRICT AUC Score (Train): 0.771002\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6532\n",
      "GEN AUC Score (Train): 0.726471\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6596\n",
      "BE AUC Score (Train): 0.754778\n",
      "3462\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6795\n",
      "STRICT AUC Score (Train): 0.780634\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6374\n",
      "GEN AUC Score (Train): 0.715171\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6607\n",
      "BE AUC Score (Train): 0.748674\n",
      "4225\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6851\n",
      "STRICT AUC Score (Train): 0.782775\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6283\n",
      "GEN AUC Score (Train): 0.701834\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6743\n",
      "BE AUC Score (Train): 0.749910\n",
      "5056\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6755\n",
      "STRICT AUC Score (Train): 0.780938\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6284\n",
      "GEN AUC Score (Train): 0.681208\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6648\n",
      "BE AUC Score (Train): 0.744923\n",
      "5192\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6719\n",
      "STRICT AUC Score (Train): 0.773276\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6302\n",
      "GEN AUC Score (Train): 0.704405\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6427\n",
      "BE AUC Score (Train): 0.733164\n",
      "7751\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6786\n",
      "STRICT AUC Score (Train): 0.776879\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.628\n",
      "GEN AUC Score (Train): 0.720426\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6502\n",
      "BE AUC Score (Train): 0.733104\n",
      "7813\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6692\n",
      "STRICT AUC Score (Train): 0.770554\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6474\n",
      "GEN AUC Score (Train): 0.703663\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6569\n",
      "BE AUC Score (Train): 0.743171\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(learning_rate = 0.1, \n",
    "                     n_estimators=1000, \n",
    "                     max_depth=5, \n",
    "                     min_child_weight=1, \n",
    "                     gamma=0, \n",
    "                     subsample=0.8, \n",
    "                     colsample_bytree=0.8, \n",
    "                     objective='binary:logistic', \n",
    "                     nthread=4, \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=24)\n",
    "\n",
    "strict_error_list = []\n",
    "strict_auc_list = []\n",
    "gen_error_list = []\n",
    "gen_auc_list = []\n",
    "be_error_list = []\n",
    "be_auc_list = []\n",
    "\n",
    "\n",
    "for seed in random_seeds:  \n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    print(seed)\n",
    "    strict_error, strict_auc = modelfit(xgb1, strict_list[0], strict_list[2], 'STRICT')\n",
    "    gen_error, gen_auc = modelfit(xgb1, gen_list[0], gen_list[2], 'GEN')\n",
    "    be_error, be_auc = modelfit(xgb1, be_list[0], be_list[2], 'BE')\n",
    "    \n",
    "    strict_error_list.append(strict_error)\n",
    "    strict_auc_list.append(strict_auc)\n",
    "    gen_error_list.append(gen_error)\n",
    "    gen_auc_list.append(gen_auc)\n",
    "    be_error_list.append(be_error)\n",
    "    be_auc_list.append(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict Results Error:  0.330430479588 , Auc:  0.768074209551\n",
      "Gen Results Error:  0.364579946523 , Auc:  0.707197019221\n",
      "Be Results Error:  0.344158176436 , Auc:  0.74322406605\n"
     ]
    }
   ],
   "source": [
    "print('Strict Results Error: ', np.mean(strict_error_list), ', Auc: ', np.mean(strict_auc_list))\n",
    "print('Gen Results Error: ', np.mean(gen_error_list), ', Auc: ', np.mean(gen_auc_list))\n",
    "print('Be Results Error: ', np.mean(be_error_list), ', Auc: ', np.mean(be_auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':[3,4,5,6,7,8,9,10],\n",
    "    'min_child_weight':[1,2,3,4,5,6]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "                                                  n_estimators=140, \n",
    "                                                  max_depth=5, \n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, \n",
    "                                                  objective='binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1, \n",
    "                                                  seed=24), \n",
    "                        param_grid=param_test1, \n",
    "                        scoring='roc_auc',  \n",
    "                        iid=False, \n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "strict_param_test1 = []\n",
    "for seed in [144]:\n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gsearch1.fit(strict_list[0], strict_list[2])\n",
    "    strict_param_test1.append((seed, (gsearch1.best_params_, gsearch1.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen_param_test1 = []\n",
    "for seed in [144]:\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gsearch1.fit(gen_list[0], gen_list[2])\n",
    "    gen_param_test1.append((seed, (gsearch1.best_params_, gsearch1.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "be_param_test1 = []\n",
    "for seed in [144]:\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gsearch1.fit(be_list[0], be_list[2])\n",
    "    be_param_test1.append((seed, (gsearch1.best_params_, gsearch1.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(144, ({'max_depth': 3, 'min_child_weight': 1}, 0.5184627231701338))] [(144, ({'max_depth': 3, 'min_child_weight': 5}, 0.5033950980591407))] [(144, ({'max_depth': 6, 'min_child_weight': 6}, 0.4984421837963776))]\n"
     ]
    }
   ],
   "source": [
    "print(strict_param_test1, gen_param_test1, be_param_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.712\n",
      "STRICT AUC Score (Train): 0.869563\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.6677\n",
      "GEN AUC Score (Train): 0.787012\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5891\n",
      "BE AUC Score (Train): 0.640011\n",
      "235\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.581\n",
      "STRICT AUC Score (Train): 0.660918\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.586\n",
      "GEN AUC Score (Train): 0.627057\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5887\n",
      "BE AUC Score (Train): 0.651093\n",
      "905\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5811\n",
      "STRICT AUC Score (Train): 0.656544\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5906\n",
      "GEN AUC Score (Train): 0.629023\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5933\n",
      "BE AUC Score (Train): 0.649648\n",
      "2895\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5872\n",
      "STRICT AUC Score (Train): 0.674281\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5776\n",
      "GEN AUC Score (Train): 0.640244\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5947\n",
      "BE AUC Score (Train): 0.655433\n",
      "3462\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5994\n",
      "STRICT AUC Score (Train): 0.673769\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5836\n",
      "GEN AUC Score (Train): 0.608703\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5922\n",
      "BE AUC Score (Train): 0.645321\n",
      "4225\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5956\n",
      "STRICT AUC Score (Train): 0.672983\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5818\n",
      "GEN AUC Score (Train): 0.634002\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.6013\n",
      "BE AUC Score (Train): 0.660765\n",
      "5056\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5872\n",
      "STRICT AUC Score (Train): 0.668986\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5911\n",
      "GEN AUC Score (Train): 0.614930\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.596\n",
      "BE AUC Score (Train): 0.650820\n",
      "5192\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5955\n",
      "STRICT AUC Score (Train): 0.671295\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5789\n",
      "GEN AUC Score (Train): 0.622833\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5859\n",
      "BE AUC Score (Train): 0.641429\n",
      "7751\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.6027\n",
      "STRICT AUC Score (Train): 0.686008\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5833\n",
      "GEN AUC Score (Train): 0.618640\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5955\n",
      "BE AUC Score (Train): 0.641817\n",
      "7813\n",
      "STRICT \n",
      "Model Report\n",
      "STRICT Accuracy: 0.5836\n",
      "STRICT AUC Score (Train): 0.670016\n",
      "GEN \n",
      "Model Report\n",
      "GEN Accuracy: 0.5932\n",
      "GEN AUC Score (Train): 0.613517\n",
      "BE \n",
      "Model Report\n",
      "BE Accuracy: 0.5963\n",
      "BE AUC Score (Train): 0.662262\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(learning_rate = 0.1, \n",
    "                     n_estimators=1000, \n",
    "                     max_depth=3, \n",
    "                     min_child_weight=3, \n",
    "                     gamma=0, \n",
    "                     subsample=0.8, \n",
    "                     colsample_bytree=0.8, \n",
    "                     objective='binary:logistic', \n",
    "                     nthread=4, \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=24)\n",
    "\n",
    "strict_error_list = []\n",
    "strict_auc_list = []\n",
    "gen_error_list = []\n",
    "gen_auc_list = []\n",
    "be_error_list = []\n",
    "be_auc_list = []\n",
    "\n",
    "\n",
    "for seed in random_seeds:  \n",
    "    strict_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_SR_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    gen_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_GEN_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    be_list = pickle.load(open('../../Results/Yeast/result_list/yeast_strict_list_BE_'+str(seed)+'_results_list.pkl', 'rb'))\n",
    "    print(seed)\n",
    "    strict_error, strict_auc = modelfit(xgb2, strict_list[0], strict_list[2], 'STRICT')\n",
    "    gen_error, gen_auc = modelfit(xgb2, gen_list[0], gen_list[2], 'GEN')\n",
    "    be_error, be_auc = modelfit(xgb2, be_list[0], be_list[2], 'BE')\n",
    "    \n",
    "    strict_error_list.append(strict_error)\n",
    "    strict_auc_list.append(strict_auc)\n",
    "    gen_error_list.append(gen_error)\n",
    "    gen_auc_list.append(gen_auc)\n",
    "    be_error_list.append(be_error)\n",
    "    be_auc_list.append(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
