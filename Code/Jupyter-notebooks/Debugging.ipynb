{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from classifier import PPIclassifier as ppi_old\n",
    "from parse_and_prepare import ProteinProteinInteractionClassifier as ppi\n",
    "import prediction as pred\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "files_old = ['data/MEDLINE_FILES',\n",
    "             'data/output_mentions_yeast_1',\n",
    "             'data/output_pairs_yeast_1',\n",
    "             'data/yeast_entities.tsv',\n",
    "             'data/4932.protein.actions.v10.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "files = ['MEDLINE_FILES',\n",
    "         'output_mentions_yeast_1',\n",
    "         'output_pairs_yeast_1',\n",
    "         'yeast_entities.tsv',\n",
    "         '4932.protein.actions.v10.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing Pairs data frame\n",
      "BROKE\n",
      "Done with  \n",
      "BROKE\n",
      "Done with  \n",
      "BROKE\n",
      "Done with  \n",
      "BROKE\n",
      "Done with  \n",
      "BROKE\n",
      "Done with  \n",
      "BROKE\n",
      "Something went wrong with   \n",
      " There was a  \"['Text'] not in index\" ! Ignoring it!\n",
      "\n",
      " DONE with Pairs data frame production! \n",
      "\n",
      "Producing Pre BOW data frame\n",
      "Couldn't mask  Na(+)/H(+) antiporter  with RegEx\n",
      " Trying a different way\n",
      "Couldn't mask  3-oxoacyl-[acyl-carrier-protein]-reductase  with RegEx\n",
      " Trying a different way\n",
      "\n",
      " Done with Pre Bow data frame \n",
      "\n",
      "Producing BOW data frame\n",
      "\n",
      " Done with Bag of Words data frame \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 21:35:02,744 : INFO : collecting all words and their counts\n",
      "2017-04-02 21:35:02,745 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-02 21:35:02,748 : INFO : collected 3581 word types from a corpus of 12573 raw words and 441 sentences\n",
      "2017-04-02 21:35:02,749 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 21:35:02,752 : INFO : min_count=5 retains 397 unique words (11% of original 3581, drops 3184)\n",
      "2017-04-02 21:35:02,753 : INFO : min_count=5 leaves 7844 word corpus (62% of original 12573, drops 4729)\n",
      "2017-04-02 21:35:02,755 : INFO : deleting the raw counts dictionary of 3581 items\n",
      "2017-04-02 21:35:02,756 : INFO : sample=0.001 downsamples 60 most-common words\n",
      "2017-04-02 21:35:02,757 : INFO : downsampling leaves estimated 4683 word corpus (59.7% of prior 7844)\n",
      "2017-04-02 21:35:02,758 : INFO : estimated required memory for 397 words and 300 dimensions: 1151300 bytes\n",
      "2017-04-02 21:35:02,759 : INFO : resetting layer weights\n",
      "2017-04-02 21:35:02,766 : INFO : training model with 4 workers on 397 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-02 21:35:02,769 : INFO : expecting 441 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-02 21:35:02,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-02 21:35:02,794 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 21:35:02,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 21:35:02,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 21:35:02,799 : INFO : training on 62865 raw words (23451 effective words) took 0.0s, 879970 effective words/s\n",
      "2017-04-02 21:35:02,801 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-04-02 21:35:02,802 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-02 21:35:02,806 : INFO : saving Word2Vec object under 300features_5minwords_6context_random_state22, separately None\n",
      "2017-04-02 21:35:02,807 : INFO : not storing attribute syn0norm\n",
      "2017-04-02 21:35:02,807 : INFO : not storing attribute cum_table\n",
      "2017-04-02 21:35:02,815 : INFO : saved 300features_5minwords_6context_random_state22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "Training model...\n",
      "Creating average feature vecs for test reviews\n",
      "\n",
      " Fitting XGBoost Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/classifier.py:486: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "clf_old = ppi_old(files_old)\n",
    "clf_old.return_dfs()\n",
    "full_data_frame_old = clf_old.make_necessary_df()\n",
    "w2v_params = [300, 5, 4, 6, 1e-3]\n",
    "_, test_set = clf_old.make_tr_te_splits(22)\n",
    "full_model = clf_old.produce_w2v_model(w2v_params, 22, full_df=full_data_frame_old)\n",
    "error_w2v_f, prob_w2v_f = clf_old.predict_w2v(full_model, clf_model = \"xgb\")\n",
    "fpr_w2v_XGB, tpr_w2v_XGB, _ = roc_curve(test_set['Mode'].tolist(), prob_w2v_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_set['Mode'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Producing Pairs DFs \n",
      "\n",
      "length of common j 6890\n",
      "shared entities (23544, 8)\n",
      "ser_no_ents 23544\n",
      "temp_s1_values (146313, 8)\n",
      "temp_s2_list 146313\n",
      "both_entries (23347, 8)\n",
      "\n",
      "\n",
      "(23347, 8)\n",
      "(23348, 8)\n",
      "\n",
      "\n",
      "BROKE\n",
      "23347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:2440: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n",
      "2017-04-02 21:36:56,525 : INFO : collecting all words and their counts\n",
      "2017-04-02 21:36:56,526 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-02 21:36:56,530 : INFO : collected 3506 word types from a corpus of 12641 raw words and 436 sentences\n",
      "2017-04-02 21:36:56,530 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 21:36:56,533 : INFO : min_count=5 retains 419 unique words (11% of original 3506, drops 3087)\n",
      "2017-04-02 21:36:56,533 : INFO : min_count=5 leaves 8019 word corpus (63% of original 12641, drops 4622)\n",
      "2017-04-02 21:36:56,535 : INFO : deleting the raw counts dictionary of 3506 items\n",
      "2017-04-02 21:36:56,535 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2017-04-02 21:36:56,537 : INFO : downsampling leaves estimated 4818 word corpus (60.1% of prior 8019)\n",
      "2017-04-02 21:36:56,537 : INFO : estimated required memory for 419 words and 300 dimensions: 1215100 bytes\n",
      "2017-04-02 21:36:56,539 : INFO : resetting layer weights\n",
      "2017-04-02 21:36:56,546 : INFO : training model with 4 workers on 419 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2017-04-02 21:36:56,546 : INFO : expecting 436 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-02 21:36:56,567 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-02 21:36:56,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 21:36:56,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 21:36:56,576 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 21:36:56,576 : INFO : training on 63205 raw words (24085 effective words) took 0.0s, 898320 effective words/s\n",
      "2017-04-02 21:36:56,577 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-04-02 21:36:56,577 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-02 21:36:56,581 : INFO : saving Word2Vec object under Results/yeast_demo_strict_real_model, separately None\n",
      "2017-04-02 21:36:56,581 : INFO : not storing attribute syn0norm\n",
      "2017-04-02 21:36:56,582 : INFO : not storing attribute cum_table\n",
      "2017-04-02 21:36:56,590 : INFO : saved Results/yeast_demo_strict_real_model\n",
      "/home/bioinformatics/Desktop/KU/Master_Thesis/Code/Proper_Class/2.0/prediction.py:159: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vec = np.divide(feature_vec,nwords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done with Pairs DFs \n",
      "\n",
      "\n",
      " Adding Real_IDs in to the mix \n",
      "\n",
      " * Adding interactions to Strict Pairs \n",
      "\n",
      " Done with Real_IDs \n",
      "\n",
      "Parsing datasets sentences\n",
      "Training Word2Vec Model\n",
      "Cleaning and parsing the training set articles\n",
      "\n",
      "Cleaning and parsing the testing set articles\n",
      "\n",
      "\n",
      " Fitting XGBoost Model!\n",
      "\n",
      " Making Predictions\n"
     ]
    }
   ],
   "source": [
    "clf=ppi(files)\n",
    "clf.prepare()\n",
    "clf.produce_pairs()\n",
    "clf.add_real_ids_and_mask()\n",
    "strict_list_pure = pred.make_models(clf.strict_real, 'yeast_demo_strict_real')\n",
    "error_w2v_norm, probs_w2v_norm = pred.XGB_classifier(strict_list_pure[2], strict_list_pure[3], \n",
    "                                                     strict_list_pure[4], strict_list_pure[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fpr_w2v_norm, tpr_w2v_norm, _ = roc_curve(strict_list_pure[5], probs_w2v_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49444444444444446"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr_w2v_XGB, tpr_w2v_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44698660714285715"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr_w2v_norm, tpr_w2v_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data_set = pickle.load(open('Results/strict_real.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5798"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "mode_list = []\n",
    "for value in full_data_set.values():\n",
    "    val = value[0]\n",
    "    mode_list.append(val[-1])\n",
    "print(sum(mode_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "yeast_train_labs = pickle.load(open('Results/yeast/Results/yeast_strict_real_be_mod_train_labels.pkl', 'rb'))\n",
    "yeast_test_labs = pickle.load(open('Results/yeast/Results/yeast_strict_real_be_mod_test_labels.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6302"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yeast_train_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4216"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yeast_test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.3, 0.7],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=20, n_clusters_per_class=1,\n",
    "                           n_samples=80, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dros_gen = pickle.load(open('Results/drosophila/gen_real.pkl', 'rb'))\n",
    "dros_be = pickle.load(open('Results/drosophila/be_real.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37017"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dros_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dros_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
